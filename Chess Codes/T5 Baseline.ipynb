{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf4c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb631cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_data = pd.read_csv('../Data/Processed/cleaned_lichess08_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b082ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    e4 g6 d4 Bg7 c3 d6 Qf3 Nf6 h3 O-O Bg5 Nbd7 Bc4...\n",
       "1    d4 Nf6 c4 g6 a3 Bg7 Nf3 O-O Nc3 a5 Bf4 d6 e3 N...\n",
       "2    e4 c5 Qf3 e5 Bc4 Nf6 Nh3 h6 g4 g5 Ng1 a6 h4 Bg...\n",
       "3    e4 e5 Nf3 d6 Nc3 f5 exf5 Bxf5 d3 Nf6 h3 Be7 Be...\n",
       "4    f3 e5 g4 d5 Bg2 d4 c4 dxc3 Nxc3 Nc6 Qa4 Qh4+ K...\n",
       "Name: PGN, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chess_data.head()['PGN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1a2f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2608635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = chess_data['PGN'].apply(generate_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582279b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data.to_list(), columns=['inp', 'out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3eeccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following 2 hyperparameters are task-specific\n",
    "max_source_length = 40\n",
    "max_target_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e5a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have the following 2 training examples:\n",
    "#input_sequence_1 = \"Welcome to NYC\"\n",
    "#output_sequence_1 = \"Bienvenue Ã  NYC\"\n",
    "\n",
    "#input_sequence_2 = \"HuggingFace is a #company\"\n",
    "#output_sequence_2 = \"HuggingFace est une entreprise\"\n",
    "\n",
    "input_sequences = list(data['inp'].values)[:1000]\n",
    "output_sequences = list(data['out'].values)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4b99f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_sequences), len(output_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0cbc70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e4 g6 d4 Bg7 c3 d6 Qf3 Nf6 h3 O-O Bg5 Nbd7 Bc4 a6 h4 b5', 'Bd5 Nxd5 exd5')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[0], output_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6550553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the inputs\n",
    "# task_prefix = \"translate English to French: \"\n",
    "task_prefix = \"Chess: \"\n",
    "\n",
    "#input_sequences = [input_sequence_1, input_sequence_2]\n",
    "\n",
    "\n",
    "encoding = tokenizer([task_prefix + sequence for sequence in input_sequences],\n",
    "                     padding='longest',\n",
    "                     max_length=max_source_length,\n",
    "                     truncation=True,\n",
    "                     return_tensors=\"pt\")\n",
    "input_ids, attention_mask = encoding.input_ids, encoding.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dd2dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the targets\n",
    "#output_sequences = [output_sequence_1, output_sequence_2]\n",
    "\n",
    "target_encoding = tokenizer(output_sequences,\n",
    "                            padding='longest',\n",
    "                            max_length=max_target_length,\n",
    "                            truncation=True)\n",
    "labels = target_encoding.input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f22c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace padding token id's of the labels by -100\n",
    "labels = [\n",
    "           [(label if label != tokenizer.pad_token_id else -100) for label in labels_example] for labels_example in labels\n",
    "]\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# forward pass\n",
    "loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "752e8b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chess: e4 c5 Nf3 Nc6 Nc3', 'Chess: e4 c5 Nc3 Nc6 Nf3', 'Chess: e4 d5 exd5 Qxd5 Nc']\n"
     ]
    }
   ],
   "source": [
    "# when generating, we will use the logits of right-most token to predict the next token\n",
    "# so the padding should be on the left\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token # to avoid an error\n",
    "\n",
    "sentences = input_sequences[-3:] # use different length sentences to test batching\n",
    "inputs = tokenizer([task_prefix + sentence for sentence in sentences], return_tensors=\"pt\", padding=True)\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids=inputs['input_ids'],\n",
    "    attention_mask=inputs['attention_mask'],\n",
    "    do_sample=False, # disable sampling to test if batching affects output\n",
    ")\n",
    "\n",
    "print(tokenizer.batch_decode(output, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72e145cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Be6 Bg5 Rxg5', 'O-O Nec3 Re8', 'd5 b5 Bb3']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences[-3:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce1293f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e4 c5 Nf3 Nc6 Nc3 e6 d4 cxd4 Nxd4 e5 Nf5 d6 Qg4 Nf6 Nxg7+ Bxg7 Qxg7 Rg8 Qh6 Nd4 Bd3',\n",
       " 'e4 c5 Nc3 Nc6 Nf3 d6 Bb5 a6 Bxc6+ bxc6 d4 cxd4 Nxd4 Bb7 Qf3 Nf6 Bg5 c5 Nde2 g6 Bxf6 exf6 Nd5 Bg7 O-O',\n",
       " 'e4 d5 exd5 Qxd5 Nc3 Qd8 d4 g6 Nf3 Bg7 Bc4 Nf6 O-O O-O h3 a6']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eb0d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chess: e4 g6 d4 Bg7 c3', 'Chess: d4 Nf6 c4 g6 a3', 'Chess: e4 c5 Qf3 e5 Bc4']\n"
     ]
    }
   ],
   "source": [
    "# when generating, we will use the logits of right-most token to predict the next token\n",
    "# so the padding should be on the left\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token # to avoid an error\n",
    "\n",
    "sentences = input_sequences[:3] # use different length sentences to test batching\n",
    "inputs = tokenizer([task_prefix + sentence for sentence in sentences], return_tensors=\"pt\", padding=True)\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids=inputs['input_ids'],\n",
    "    attention_mask=inputs['attention_mask'],\n",
    "    do_sample=False, # disable sampling to test if batching affects output\n",
    ")\n",
    "\n",
    "print(tokenizer.batch_decode(output, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7b1430a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bd5 Nxd5 exd5', 'c6 Ne2 Rfe8', 'Bg7 hxg5 hxg5']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences[:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15844c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e4 g6 d4 Bg7 c3 d6 Qf3 Nf6 h3 O-O Bg5 Nbd7 Bc4 a6 h4 b5',\n",
       " 'd4 Nf6 c4 g6 a3 Bg7 Nf3 O-O Nc3 a5 Bf4 d6 e3 Nbd7 Be2 Nh5 Bg3 Nxg3 fxg3 Nf6 O-O Ng4 Qd2 e5 dxe5 Nxe5 Nxe5 Bxe5 Rf2 Be6 b3 Qg5 Raf1 f5 Bf3',\n",
       " 'e4 c5 Qf3 e5 Bc4 Nf6 Nh3 h6 g4 g5 Ng1 a6 h4']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933e1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
