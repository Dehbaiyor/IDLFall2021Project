input,target,gpt_prediction,mixed_model_prediction,gpt_smooth_bleu_score,mixed_model_smooth_bleu_score
generate: vcf2cytosure CGH file for inidividual.,"def vcf2cytosure(store, institute_id, case_name, individual_id):
    """"""""""""
    institute_obj, case_obj = institute_and_case(store, institute_id, case_name)

    for individual in case_obj['individuals']:
        if individual['individual_id'] == individual_id:
            individual_obj = individual

    return (individual_obj['display_name'], individual_obj['vcf2cytosure'])","def vcf2cytos(self, filename): """""""""""" if filename in self.vcf2cytos: raise ValueError(""Cannot read vcf2cytos: {}"".format(filename)) if filename in self.vcf2cytos: raise ValueError(""Cannot read vcf2cytos: {}"".format(filename)) return filename","def _create_cgh_to_file(self, cgh): """""" """""" if cgh not in self._cghs: cgh = cgh.get('cgh') if not self._cghs[cgh]: self._cghs[cgh] = CGH if self._cgh not in cgh: self._cghs[cgh] = CGH else: self._cghs[cgh] = CGH self._cghs[cgh] = CGH if self._cghs[cgh] not in self._cghs: self._cghs[cgh] = CGH return self._cghs",19.0916882,13.0984847
"generate: Brute force regex based HTML tag parser. This is a rough-and-ready searcher to find HTML tags when  standards compliance is not required. Will find tags that are commented out, or inside script tag etc.","def itertags(html, tag):
    """"""
    
    """"""
    for match in tag_re.finditer(html):
        if match.group(""tag"") == tag:
            attrs = dict((a.group(""key"").lower(), a.group(""value"")) for a in attr_re.finditer(match.group(""attr"")))
            yield Tag(match.group(""tag""), attrs, match.group(""inner""))","def comic_tags(tags, comic_tags=None): """""" """""" # We require a list of tags are available. It's a list of tags when the tag is available. tag_list = [] for tag_tag in tag_list: tag_list.append(tag_tag) return tag_list","def _get_tag_tags(tag, tag_tag, inside_tag, tag_tag): """""" """""" if not inside_tag: raise ValueError(""tag must be a single tag, or %s. "" ""A valid tag"" % tag_tag) if not inside_tag: raise ValueError(""tag must be a valid tag or %s"" % tag_tag) if not inside_tag: raise ValueError(""tag must be a valid tag"") formatted_tag = inside_tag return tag.get(tag)",19.74731282,22.25351248
generate: Convert PythonCard font description to gui2py style,"def migrate_font(font):
    """"
    if 'faceName' in font:
        font['face'] = font.pop('faceName')
    if 'family' in font and font['family'] == 'sansSerif':
        font['family'] = 'sans serif'
    return font","arguments. def scard(font, description, arguments, count): """""" """""" font = font.get(arguments, 1) if arguments: font.scard(arguments) return font",". def to_python_card_font_string(python_code): """""" """""" if isinstance(python_code, (str, unicode))): _python_code = '%s:%s' % (python_code, python_code) else: _python_code = '%s' % (python_code) return _python_code",27.25912347,17.27240837
generate: Cancel an IO block.,"def cancel(self, block):
        """"""
        
        """"""
        event = libaio.io_event()
        try:
            # pylint: disable=protected-access
            libaio.io_cancel(self._ctx, byref(block._iocb), byref(event))
            # pylint: enable=protected-access
        except OSError as exc:
            if exc.errno == errno.EINPROGRESS:
                return None
            raise
        return self._eventToPython(event)","def cancel(self): """""""""""" # See IO server for an IO if self._is_block(self._id, self._id, self._id, self._id) or self._is_block(self._id, self._id) or self._is_block(self._id, self._id): self._dequeue_for_io_set() self._dequeue_for_io_set() self._id = self._queue_for_io_set()","def io_block(self, block): """""" """""" try: response = block except IOError: response = None if not response: response = block if response.status_code == 'POST': response = block if response.status_code == 'POST': response = block return response",22.4919467,26.78807155
generate: Split a command line's arguments in a shell-like manner returned  as a list of lists. Use ';;' with white space to indicate separate  commands.,"def arg_split(s, posix=False):
    """"""
    """"""

    args_list = [[]]
    if isinstance(s, bytes):
        s = s.decode(""utf-8"")
    lex = shlex.shlex(s, posix=posix)

    lex.whitespace_split = True
    args = list(lex)
    for arg in args:
        if ';;' == arg:
            args_list.append([])
        else:
            args_list[-1].append(arg)
            pass
        pass
    return args_list","def _split_param_space(shell_space, commands, manner): """""" """""" param_space = [] for line in commands: if line.startswith('='): param_space.append(line.split('=')) else: param_space.append(line) return param_space","If this is a valid like object, then if one of like objects called in the arguments. def split_arguments(self): """""" """""" commands = [] args = [] for arg in self.args: commands.append(arg.split(':', 1)) if args: args.append(arg.split(':', 1)) return args",28.20235477,38.50038677
generate: Returns the authentication URL for this service.,"def authenticate_redirect(
        self, callback_uri=None, ax_attrs=[""name"", ""email"", ""language"",
                                           ""username""]):

        """"""
        """"""
        callback_uri = callback_uri or self.request.uri
        args = self._openid_args(callback_uri, ax_attrs=ax_attrs)
        self.redirect(self._OPENID_ENDPOINT + ""?"" + urllib.urlencode(args))","def get_user_url(self, url, default=None): """""""""""" if not self.session: return None if not self.authentication: return None else: return self.session.get(url)","def get_authentication_user(self, username, password): """""" """""" if self.get_user_access_user() == 'access': username = self.get_user_access_user() if username is None: username = self.get_username() else: username = self.get_user_access_username() return username",17.01124767,27.97888259
"generate: Remove a point, if no point is found nothing happens.","def remove_point(self, time):
        """"""
        """"""
        if self.tier_type != 'TextTier':
            raise Exception('Tiertype must be TextTier.')
        self.intervals = [i for i in self.intervals if i[0] != time]","def _delete_point(self, point): """""" """""" if point is None: return self.post = self.post self.delete_point(point)","def remove_pointer(self, point): """""" """""" if self.name.startswith(""pointer""): return self.logger.debug(""Could not remove pointer: %s"", point) self.logger.debug(""Pointer: %s"", point) self.logger.debug(""Pointer: %s"", point) self.logger.debug(""Pointer: %s"", point) return",27.73017683,26.68355534
generate: Set attributes to dictionary values.,"def _set_attrs_to_values(self, response={}):
        """"""
        
        """"""
        if isinstance(response, dict):
            for key in response.keys():
                if not hasattr(self, key) or not callable(getattr(self, key)):
                    setattr(self, key, response[key])","def set_attributes(self, values): """""" """""" if not isinstance(values, list): raise ValueError('values can not be a list of list types.') for name, value in values: if name in self.attributes: self._set_attributes(name)","def set_attributes(self, key, value_value): """""""""""" for attr in key_value: if isinstance(attr, six.text_type): self.set_attributes(attr, attr) self.set_attributes(self.set_attributes(self.set_attributes))",42.26890715,42.19279454
"generate: Return a set of resonance forms as SMILES strings, given a SMILES string.","def enumerate_resonance_smiles(smiles):
    """"""
    """"""
    mol = Chem.MolFromSmiles(smiles)
    #Chem.SanitizeMol(mol)  # MolFromSmiles does Sanitize by default
    mesomers = ResonanceEnumerator().enumerate(mol)
    return {Chem.MolToSmiles(m, isomericSmiles=True) for m in mesomers}","def _get_resonance_forms(self, smission): """""""""""" if not isinstance(smission, Version): raise ValueError('Unknown smission') if self._resonance_forms: return self.resonance_forms[smission] else: return self.resonance_forms[smission]","def get_resource_list(self, name, resource_list): """""" """""" # If there is a valid plugins, assume that are not required. resource_list = [] for resource_list in self.resources: resource_list.append(resource_list) return resource_list",22.65628057,20.42236748
generate: Returns the shape of the data.,"def shape(self):
        """"""""""""
        # TODO cache
        first = self.first().shape
        shape = self._rdd.map(lambda x: x.shape[0]).sum()
        return (shape,) + first[1:]","def shape(self, shape): """""""""""" shape = shape.shape[0] if shape == self.shape[0]: shape = shape.shape[0] return shape","def get_shape(self): """""" """""" data = self._get_shape_data(self._shape, self._shape) if not self._shape: return None return self._shape[0]",44.60379847,45.24546458
generate: Converts an array to its voxel list.,"def to_voxels(array):
    """"""
    
    """"""
    if type(array) is not numpy.ndarray:
        raise ValueError(""array argument must be of type numpy.ndarray"")
    return numpy.argwhere(array)","def _get_array_to_array(array, vec): """""""""""" array = np.array(array) array = np.array(array, dtype=np.float64) return array","def _copy_array(self): """""" """""" if self._is_array(self._is_array): return self._is_array(self._is_array) else: return self._is_array(self._is_array)",32.90776036,35.48527323
generate: Like the plaintext attribute but returns a generator,"def generate_plaintext_traceback(self):
        """"""""""""
        yield u'Traceback (most recent call last):'
        for frame in self.frames:
            yield u'  File ""%s"", line %s, in %s' % (
                frame.filename,
                frame.lineno,
                frame.function_name
            )
            yield u'    ' + frame.current_line.strip()
        yield self.exception","via implementation def get_plaintext_attribute(self, plaintext, attribute): """""" """""" attribute = plaintext.attribute if attribute is not None: return attribute.attribute return self.plaintext.attribute",". def _get_plaintext(self, plaintext): """""" """""" if not self._plaintext: raise Exception(""Can't get plaintext: %s"" % plaintext) url = self._build_url(plaintext) return self._get_plaintext(url, url)",18.97382622,21.72280663
generate: Enqueue task with specified data.,"def enqueue(self, data):
        """"""  """"""
        jsonified_data = json.dumps(data)
        with self._db_conn() as conn:
            return conn.execute(
                'INSERT INTO %s (created, data) VALUES (%%(created)s, %%(data)s)' % self.table_name,
                created=datetime.utcnow(),
                data=jsonified_data
            )","def enqueue(self, data): """""" """""" data = self.get_data(data) # Enqueue task with specified data async defined self.enqueue_task(data) self.enqueue_task(data) self.enqueue_task(data) self.enqueue_task(data) self.enqueue_task(data)","def _enqueue_task(self, data): """""" """""" task_id = self._task_id if self._task_id: # This is an empty date if self._task_id: self._task_id = data['id'] self._task_id = data['id'] # This is an empty list of empty list self._task_id = data['task_id'] return task_id",37.62204169,28.41058653
generate: Start the progress bar.,"def start(self, iterations):
        """"""
        """"""
        self.touched = True
        self.iter = int(iterations)
        self.t_start = time.time()","def start(self, timeout=None): """""" """""" self.start_progress = self.get_progress() self.stop() self.stop()","def start_progress(self, bar): """""" """""" self.start(bar) self.stop(bar) self.stop(bar) self.stop(bar)",47.84105445,41.50824873
generate: Pad strings in a given column.,"def str_pad(x, width, side='left', fillchar=' '):
    """"""
    """"""
    sl = _to_string_sequence(x).pad(width, fillchar, side in ['left', 'both'], side in ['right', 'both'])
    return column.ColumnStringArrow(sl.bytes, sl.indices, sl.length, sl.offset, string_sequence=sl)","def _generate_column_string_column(column_string, column_string, column_string): """""""""""" column_string = column_string.split(""\n"") if len(column_string)!= 1: column_string = column_string[0] column_string = column_string[:2] return column_string","def _get_pad_string(self, column): """""" """""" # Normalize column pad_str = self._get_pad_string(column) # Normalize column return self._get_pad_string(pad_str)",22.90137602,20.08181606
"generate: Run multiple commmands in a row, exiting if one fails.","def call_in_sequence(self, cmds, shell=True):
        """"""""""""
        for cmd in cmds:
            if subprocess.call(cmd, shell=shell) == 1:
                sys.exit(1)","def run_commit(self, row, commit=False): """""" """""" rows = [] if rows is None: rows = [] for i in range(rows): rows.append(rows) return rows","def run(self, row): """""""""""" if row == 0: row = self.exit(row) else: row = self.exit(row) return row",24.58653441,26.05278351
generate: Show optical flow.,"def flowshow(flow, win_name='', wait_time=0):
    """"""
    """"""
    flow = flowread(flow)
    flow_img = flow2rgb(flow)
    imshow(rgb2bgr(flow_img), win_name, wait_time)","def _show_optical_flow(self): """""""""""" # This function is valid. flow = self.optical_flow(self.flow) if flow.flow_name == self.flow_name: return flow else: return None","def show_optical(self, flow): """""" """""" flow_optical_optical(flow, flow, flow)",34.35747607,21.74090827
generate: Disables computation of the second derivatives for a tensor.,"def _prevent_2nd_derivative(x):
  """"""
  """"""
  def grad(dy):
    return array_ops.prevent_gradient(
        dy, message=""Second derivative is not implemented."")

  return tf.identity(x), grad","def verify_second_document_for_tensor(tensor, tensor_id): """""" """""" tensor = Tensor() for tensor_id in tensor.values(): tensor.document_for_tensor(tensor_id) return tensor","def second_dot(self, tensor): """""" """""" if self._computation_deprecated: self._computation_deprecated = False else: self._computation_deprecated = True return self._computation_deprecated",27.47042294,23.1645091
generate: LIST command.,"def list(self, keyword=None, arg=None):
        """"""
        """"""
        return [x for x in self.list_gen(keyword, arg)]","def get_command(self, command): """""" """""" if self.get_command(command) == self.commands: return self.get_command(command) else: return self.get_command(command)","def _get_event_cmd(self): """""" """""" return self._get_event_cmd(self._cmd_token)",22.65498409,33.8837969
generate: Utility function to wait all tasks to complete,"def join(self):
    ''''''
    self.tasks.join()

    # Force each thread to break loop.
    for worker in self.workers:
      self.tasks.put(None)

    # Wait for all thread to terminate.
    for worker in self.workers:
      worker.join()
      worker.s3 = None",". def wait_for_tasks(self): """""" """""" tasks = [] for task in self._tasks: tasks.append(task) if self.tasks: tasks.append(tasks) if self.cloud: # we have a cloud and we've any filter. self.cloud = True self.tasks.append(tasks) self.cloud = True self.tasks.append(tasks) return self.tasks","instances. def _get_tasks(self): """""" """""" self._logger.debug('Waiting for %s', self.stdout) tasks = self._get_tasks() if tasks: self._logger.debug('Waiting for tasks.', self._stdout) self._tasks.put(tasks) else: # This is an error to future. self._stdout.write(tasks) self._logger.debug('Waiting for tasks: %s', tasks)",25.47944486,25.47313767
generate: Rename a tier. Note that this renames also the child tiers that have    the tier as a parent.,"def rename_tier(self, id_from, id_to):
        """"""
        """"""
        childs = self.get_child_tiers_for(id_from)
        self.tiers[id_to] = self.tiers.pop(id_from)
        self.tiers[id_to][2]['TIER_ID'] = id_to
        for child in childs:
            self.tiers[child][2]['PARENT_REF'] = id_to","def rename(self, tier): """""" """""" if tier.parent is None: tier.parent = self.parent if tier.parent is None: tier.parent = self.parent if tier.parent is None: tier.parent = self.parent if tier.parent is None: tier.parent = self.parent self.last_tier = tier","def rename(self, child_tier): """""" """""" if child_tier in self.child_tier_names: return self.child_tier else: return self.child_tier_names[child_tier]",30.39594932,32.44872332
"generate: This function takes a date string in various formats  and converts it to a normalized and validated date range. A list  with two elements is returned, lower and upper date boundary.","def to_dates(param):
    """"""
    
    """"""
    pos = param.find('-')
    lower, upper = (None, None)
    if pos == -1:
        # no seperator given
        lower, upper = (param, param)
    else:
        lower, upper = param.split('-')
    ret = (expand_date_param(lower, 'lower'), expand_date_param(upper, 'upper'))
    return ret","def date_date(self, lower, date, date, date_ampl=None): """""" """""" lower = lower + date_ampl date_ampl = date_ampl + date_ampl date_ampl = date_ampl + date_ampl + date_ampl + date_ampl return date_ampl + date_ampl + date_ampl","def _convert_date_str(date_str): """""" """""" date_str = date_str.replace(""%s%Y%m%d %H%M%S"") if not isinstance(date_str, datetime.datetime): date_str = ""%s%s%d %H%M%S%F%S"" return date_str.replace(date_str, date_str) else: date_str = date_str.replace(""%Y%m%d%H%M%S"") return date_str",24.92554522,24.15173233
generate: The default predicate used in Node.trimmed.,"def trimmed_pred_default(node, parent):
  """"""""""""
  return isinstance(node, ParseNode) and (node.is_empty or node.is_type(ParseNodeType.terminal))","def default_trimmed(self): """""""""""" return tf.expand_dictionary(self.trimmed, self.trimmed)","def _get_negotiate_predicate(self, room_id): """""""""""" return self._get_negotiate_predicate(room_id)",25.0835729,20.52870719
generate: Helper method that binds parameters to a SQL query.,"def _bind_parameters(operation, parameters):
    """"""  """"""
    # inspired by MySQL Python Connector (conversion.py)
    string_parameters = {}
    for (name, value) in iteritems(parameters):
        if value is None:
            string_parameters[name] = 'NULL'
        elif isinstance(value, basestring):
            string_parameters[name] = ""'"" + _escape(value) + ""'""
        else:
            string_parameters[name] = str(value)
    return operation % string_parameters","def parameters(self, query, class_name=None, error_name=None): """""" """""" if class_name is None: raise UnknownClass(""class_name class name"") if class_name is None: raise UnknownClass(""class_name classname"") if isinstance(class_name, SQLInterrupt): raise UnknownClass(""class_name class name"") if isinstance(class_name, SQLInterrupt): raise UnknownClass(""class_name classname"") if isinstance(class_name, SQLInterrupt): raise UnknownClass(""class_name classname"") if isinstance(class_name, SQLInterrupt): raise UnknownClass(""class_name class name"") if isinstance(class_name, SQLInterrupt): raise UnknownClass(""class_name classname"") if isinstance(class_name, SQLInterrupt): raise UnknownClass(""class_name class name"") if isinstance(class_name, SQLInterrupt): raise UnknownClass(""class_name classname"") if isinstance(class_name, SQLInterrupt): raise UnknownClass(""class_name class name"") if isinstance(class_name, SQLInterrupt): raise UnknownClass(""class_name classname"") if isinstance(class_name, SQLInterrupt): raise Unknown","def add_query_query(self, query, query): """""" """""" params = {} response = self._post(url, params=params, headers=self._headers, data=params) if response.status_code == 200: raise ValueError(""Cannot add query: %s"" % response.text) response.raise_for_status() return response",11.4916993,19.27956011
"generate: Check if the requested reshape can be broken into independant reshapes    on the keys and values. If it can, returns the index in the new shape    separating keys from values, otherwise returns -1","def _reshapebasic(self, shape):
        """"""
        
        """"""
        new = tupleize(shape)
        old_key_size = prod(self.keys.shape)
        old_value_size = prod(self.values.shape)

        for i in range(len(new)):
            new_key_size = prod(new[:i])
            new_value_size = prod(new[i:])
            if new_key_size == old_key_size and new_value_size == old_value_size:
                return i

        return -1",". def check_reshape(self, keys, values): """""" """""" if isinstance(keys, list): return keys # Get indexing keys reshape_keys = [] for key in keys: if not isinstance(key, Chart): reshape_keys.append(key) continue if isinstance(key, Chart): reshape_keys.append(key) if isinstance(value, Chart): reshape_keys.append(key) if isinstance(value, Chart): reshape_keys.append(value) return reshape_keys",". def compute_reshape_index_for_reshape(self, reshape_list, reshape_list): """""" """""" if reshape_list: # If there isn't reshapes are in the reshapes and # there are there. reshape_list = reshape_list[0] else: reshape_list = reshape_list[1] return reshape_list[0] == len(reshape_list)",29.48050963,26.32131522
generate: Ensure data is prepped properly before handing off to ImageField.,"def to_python(self, data):
        """"""""""""
        if data is not None:
            if hasattr(data, 'open'):
                data.open()
            return super(VersatileImageFormField, self).to_python(data)","def is_image_field(self, handle=None): """""""""""" if handle is None: handle = self.get_handle(handle) if handle is None: return False return self.get_image_field_field_field_field_field(handle)","def ensure_data_to_properly(self, property_name, file_name): """""" """""" data = self._read_data(property_name) if data.get('data') is not None: return data if file_name == 'data': return data else: return None",29.38756156,37.16055602
generate: Get Dingding endpoint for sending message.,"def _get_endpoint(self):
        """"""
        
        """"""
        conn = self.get_connection(self.http_conn_id)
        token = conn.password
        if not token:
            raise AirflowException('Dingding token is requests but get nothing, '
                                   'check you conn_id configuration.')
        return 'robot/send?access_token={}'.format(token)","def get_request_endpoint(self, request): """""" """""" response = self.request_data.get(request) if response is None: raise UnknownRequestException(""Unknown request endpoint for %s"" % request) return response","def get_message(self, message): """""" """""" response = self._get_message(message) if response.status_code == 200: return message.get('response', None) else: raise TypeError(""Could not get message from the response."") return self._get_message(message)",31.45655846,28.47903304
generate: Mirror the circuit by reversing the instructions.,"def mirror(self):
        """"""
        """"""
        reverse_circ = self.copy(name=self.name+'_mirror')
        reverse_circ.data = []
        for inst, qargs, cargs in reversed(self.data):
            reverse_circ.data.append((inst.mirror(), qargs, cargs))
        return reverse_circ","def mirror(self, reversing=False): """""" """""" if reversing: self.reversing = reversing self.reversing = reversing self.reversing = reversing","def _mirror_circuit(self): """""" """""" if self.valid_circuit_summary: return self._circuit(self.get_position(), self.set_position()) else: return self._circuit(self.set_position(), self.set_position())",28.76468253,32.23693041
generate: Sets the response that the adapter will return for the specified    command.,"def seed_response(self, command, response):
        # type: (Text, dict) -> MockAdapter
        """"""
        
        """"""
        if command not in self.responses:
            self.responses[command] = deque()

        self.responses[command].append(response)
        return self","def set_response(self, command): """""" """""" if command not in self.responses: raise RuntimeError(""Could not create an object"") return self","def set_response(self, command, port=None, response_response=False): """""" """""" if not response_response: return self.response = self.response_response(command, response_response) return self._response(response_response)",38.91550011,56.77344191
generate: Renames a given `instance` based on `parent_node` and `name`.,"def _set_details_tree_node(self, parent_node, name, instance):
        """"""

        """"""
        depth = parent_node._depth + 1
        if parent_node.v_is_root:
            branch = name  # We add below root
        else:
            branch = parent_node._branch
        if name in self._root_instance._run_information:
            run_branch = name
        else:
            run_branch = parent_node._run_branch

        instance._set_details(depth, branch, run_branch)","def rename(self, parent_node, parent_node, parent_node): """""" """""" # We do nothing any of the parent nodes that is installed. parent_node.parent_node = parent_node parent_node.name = name parent_node.parent_node = parent_node self.rename(parent_node, parent_node)","def rename_both(self): """""" """""" if self.get_parent_node() is None: raise ValueError(""Object name must be a valid parent_node."") if self.parent_node() is None: raise ValueError(""Object name: {0}"".format(self.get_parent_node())) self.parent_node = parent_node if self.parent_node is not None: if self.parent_node is None: raise ValueError(""Object name must be a valid parent node."") return self.get_parent_node()",37.12214311,35.4701999
generate: Register form field data function.        Could be used as decorator,"def register(self, field_type, impl=None):
        """"""
        
        """"""
        def _wrapper(func):
            self.registry[field_type] = func
            return func

        if impl:
            return _wrapper(impl)
        return _wrapper",". def register(self, fields): """""" """""" fields = self.get_fields(fields) if fields: self.register_fields(fields) else: self.register_fields(fields)",". def register_field_data(self, field_name, component_field): """""" """""" field_data = self.get_field_data(field_name, field_name) return self.get_field(field_name, field_name, field_name, field_name)",37.27331828,32.01477312
generate: Returns a given table for the given user.,"def table(name, auth=None, eager=True):
    """"""""""""
    auth = auth or []
    dynamodb = boto.connect_dynamodb(*auth)

    table = dynamodb.get_table(name)
    return Table(table=table, eager=eager)","def _get_table_table(self, user): """""""""""" try: table = self.table.get(user) except AttributeError: table = self.table.get(user) return table except AttributeError: return table","def get_user_to_user_to_user(username, username=None): """""" """""" if username is None: username = username or username else: username = username or username return username",35.06190667,25.72761935
generate: get info about a session,"def get_session_info(self, session=0):
        """"""

        """"""

        if session <= 0:
            session += self.session_number

        query = ""SELECT * from sessions where session == ?""
        return self.db.execute(query, (session,)).fetchone()",". def get_info(self, session, user=None): """""" """""" if session is None: session = self.get_info(user) return self.get_info(session, user=user)",". def get_session_info(self, session_info): """""" """""" session_info = self.get_session_info(session_info) if session_info.is_active(): return session_info return session_info",43.07672913,51.72709228
generate: Create an external tool using the passed json_data.,"def _create_external_tool(self, context, context_id, json_data):
        """"""
        
        """"""
        url = context.format(context_id) + ""/external_tools""
        return self._post_resource(url, body=json_data)","def get_external_use_json_data(self, json_data, **kwargs): """""""""""" json_data = self.get_json_data(json_data) if json_data: return json_data else: json_data = json.load(json_data) return json.load(json.load(json.load(json.load(json_data)))","def create_json_data(self, json_data): """""" """""" if self._is_valid_valid_json(): return self._create_json_data(json_data, json_data) else: return None",28.6939606,40.09779945
generate: Returns memory overhead.,"def compute_mem_overhead(self):
        """"""""""""
        self.mem_overhead = (self._process.memory_info().rss -
                             builtins.initial_rss_size)","def get_memory(self): """""""""""" memory = self.get_memory(self.task_name) if memory is None: return None return memory","def _to_multi_moment_overhead(self, multi_moment): """""" """""" return self._moment_moment(multi_moment, multi_moment)",33.38485465,30.18088787
generate: Copies the current Request object instance for side-effects purposes.,"def copy(self):
        """"""
        
        """"""
        req = type(self)()
        req.__dict__ = self.__dict__.copy()
        req._headers = self.headers.copy()
        return req","def copies_response(self, request): """""" """""" return self.request.get(request.url, self.request, request)","def copy_response(self): """""" """""" self._response = [] for resp in self._response: self._response.append(resp) return self._response",36.95166114,39.47989008
generate: Convert a ndarray to a DenseTensor which would be used in Java side.,"def from_ndarray(cls, a_ndarray, bigdl_type=""float""):
        """"""
        
        """"""
        if a_ndarray is None:
            return None
        assert isinstance(a_ndarray, np.ndarray), \
            ""input should be a np.ndarray, not %s"" % type(a_ndarray)
        return cls(a_ndarray,
                   a_ndarray.shape if a_ndarray.shape else (a_ndarray.size),
                   bigdl_type)","def ndarray(ndarray, ndarray, java=0): """""" """""" ndarray = np.array(ndarray) java = np.array(ndarray) if ndarray == np.array: return np.array(ndarray) elif ndarray == np.array: return np.array(ndarray) elif ndarray == np.array: return np.array(ndarray) else: return np.array(ndarray)","def _ndarray(self): """""""""""" if self._is_valid(): return self._is_ndarray(self._is_ndarray) elif self._is_ndarray: return self._is_ndarray(self._is_ndarray) else: raise ValueError(""Cannot ndarray of ndarrays"")",41.60619301,33.84106249
generate: visit one class and add it to diagram,"def add_class(self, node):
        """"""""""""
        self.linker.visit(node)
        self.classdiagram.add_object(self.get_title(node), node)",". def __cls(self, class, **kwargs): """""""""""" self.name = class self.name = name self.name = name self.variables[class] = visit",". def _add_class(self, name, key_string): """""" """""" if self._is_settings(key_string): return self._add_class(key_string) else: return self._add_class(key_string)",38.42078095,32.283001
generate: Adds one or multiple HTTP traffic interceptors to the current    mocking engine.,"def add_interceptor(self, *interceptors):
        """"""
        
        """"""
        for interceptor in interceptors:
            self.interceptors.append(interceptor(self.engine))","def add_engine(self, engine): """""""""""" self.engine = engine self.current_create_connect_connect(self.engine) self.engine = self.engine self.engine = engine","def add_tag(self, tag): """""" """""" if self._trafficients_list: self._trafficients_list.append(tag) self._trafficients_list.append(tag)",29.28419352,33.97809847
generate: Returns the integer value of the usage mask bitmask. This value is    stored in the database.,"def process_bind_param(self, value, dialect):
        """"""
        
        """"""
        bitmask = 0x00
        for e in value:
            bitmask = bitmask | e.value
        return bitmask","def get_integer_value(self, value, default=None): """""" """""" return self.get_integer_value(value, default, default, value, default, value)","def get_integermask_mask(self, bitmask): """""" """""" integermask = self._get_integermask(bitmask) if integermask is not None: integermask.append(bitmask) return integermask",34.26760883,33.60219735
generate: Partitions a list into two based on a condition.,"def partition(condition, collection) -> Tuple[List, List]:
    """"""""""""
    succeed, fail = [], []

    for x in collection:
        if condition(x):
            succeed.append(x)
        else:
            fail.append(x)

    return succeed, fail","def partitions_in_base_condition(base_condition, two_base_condition, two_base_condition): """""""""""" if two_base_condition is None: two_base_condition = two_base_condition # Return the list of base condition base_condition = base_condition.base_condition # If a condition is a single condition, return the condition if base_condition is None: base_condition = base_condition.base_condition # Return the condition return base_condition","def _partition_partition(self, port): """""" """""" port_list = [] port_list.append(port) port_list.append(port) port_list.append(port) port_list.append(port) return port_list",16.77548999,30.68411856
generate: Consume digits of pi and compute 1 digit freq. counts.,"def one_digit_freqs(digits, normalize=False):
    """"""
    
    """"""
    freqs = np.zeros(10, dtype='i4')
    for d in digits:
        freqs[int(d)] += 1
    if normalize:
        freqs = freqs/freqs.sum()
    return freqs","def compute_pi_digits(self, digits): """""""""""" if digits is None: digits = [] for pi in range(0, digits): pi_digits.append(pi) return pi_digits","def count(self): """""" """""" if not self._is_valid_data(): return False self._check_pipeline_count(self._image) self._is_print_pipeline_count(self._pipeline_count(self._pipeline_count)) return False",29.82662904,22.34326274
generate: Generic method for a resource's Update Metadata endpoint.,"def update_metadata(self, params):
    """""" 
    """"""
    return self.api.put(self.metadata_path(), data=params)","def update_method(self, endpoint): """""""""""" # Metadata endpoint self.api.api.update(endpoint) self.api.api.update(endpoint)","def update_median_response(self, data, context): """""" """""" try: response = self._client._post_response(data, context) return response.json() except Exception as e: if e.errno == errno.ENURE_ERROR: return UpdateResponse(e)",40.25312513,23.33197924
"generate: Gets the position of the text the ParseNode processed. If the ParseNode does not have its  own position, it looks to its first child for its position.","def position(self):
    """"""
    """"""
    pos = self._position
    if pos is None and self.children:
      ch1 = self.children[0]
      if isinstance(ch1, ParseNode):
        pos = ch1.position
    return pos","def get_position(self, text): """""" """""" if not self.get_position(text): return None position = ParseNode(text) return ParseNode(position)","def get_position(self, position): """""" """""" if self._position is None: position = self._position else: position = self._position return self._position_position(position, position)",43.78950982,51.53194516
generate: Return a ConfigNode object representing a child node with the specified    relative path.,"def _child(self, path):
        """"""
        
        """"""
        if self._path:
            path = '{}.{}'.format(self._path, path)
        return ConfigNode(root=self._root, path=path)","def get_child_node(self, relative_path): """""" """""" configs = self.get_configs(relative_path) return ConfigNode(configs, child, child, relative_path)","def _get_child_child(self, child_node): """""" """""" if child_node.is_child(child_node): child_node.child_node(child_node) else: child_node.child_node(child_node)",46.46574643,23.76505905
generate: Execute update subcommand.,"def execute(self, args):
        """"""""""""
        if args.name is not None:
            self.print_workspace(args.name)
        elif args.all is not None:
            self.print_all()","def subcommand_update(self, **kwargs): """""""""""" self.update(kwargs) self.execute(self.subcommand, self.subcommand)","def _update_subcommand(self, command, url, **kwargs): """""""""""" try: self._send_command(command, command, **kwargs) except Exception as ex: self._send_command(command, **kwargs)",34.12003546,27.48233421
generate: Starts redirection of `stdout`,"def start(self):
        """"""""""""
        if sys.stdout is not self:
            self._original_steam = sys.stdout
            sys.stdout = self
            self._redirection = True
        if self._redirection:
            print('Established redirection of `stdout`.')",". def stdout_redirect(self, stderr): """""" """""" stdout = self.stdout if stdout is not None: stdout = self.stdout return self.stdout",". def stdout(self, stdout): """""" """""" url = '%s' % self.redirect_url response = self.api.get_redirect_redirect_response(url) response.raise_for_status() return response.raise_for_status()",38.50752069,37.86683378
generate: Given a dictionary or JSON string; return a dictionary.,"def json_dict(json_data):
    """"""

    """"""
    if isinstance(json_data, dict):
        return json_data
    elif isinstance(json_data, basestring):
        return json.loads(json_data, object_hook=OrderedDict)
    else:
        raise TypeError(
            ""'json_data' must be a dictionary or valid JSON string; ""
            ""received: {!r}"".format(json_data)
        )","def _dictionary_json(self, json, json=False): """""""""""" if not json: json = json.load(json) if json: json = json.load(json) if json: json = json.load(json) if json: return json.load(json) return json.loads(json)","def get_dict_dict_dict_dict(dict_dict): """""" """""" # Implemented from template for # osid.resource.ResourceBinHierarchySession.get_resource_by_id if isinstance(dict_dict, dict): return JSONDict(dict_dict, dict_dict) return JSONDict(dict_dict, dict_dict)",29.12044479,29.97429402
generate: Gets the status of a commit.,"def get_status(app, repo_config, repo_name, sha):
    """"""
    """"""
    url = get_api_url(app, repo_config, github_status_url).format(
        repo_name=repo_name, sha=sha)
    logging.debug(""Getting status for %s %s"", repo_name, sha)
    s = get_session_for_repo(app, repo_config)
    response = s.get(url)
    if not response.ok:
        raise Exception(""Unable to get status: {}"".format(response.status_code))
    return response","def get_status(self, commit=None): """""" """""" status = self.status status = self.get_status() status = self.get_status(commit) if status == self.STATUS_STATUS_STATUS_STATUS: return status return None","def get_status(self, status_code): """""" """""" status = self._get_status(status_code) if status.code == ""response"": status_code = status_code else: status_code = status_code return status",17.24374032,17.86950403
generate: Check whether a potential object is a subclass of  the AirflowPlugin class.,"def is_valid_plugin(plugin_obj, existing_plugins):
    """"""
    
    """"""
    if (
        inspect.isclass(plugin_obj) and
        issubclass(plugin_obj, AirflowPlugin) and
        (plugin_obj is not AirflowPlugin)
    ):
        plugin_obj.validate()
        return plugin_obj not in existing_plugins
    return False","def get_plugin(obj, plugin, link=None): """""" """""" plugin = obj.get_plugin_class() if plugin is None: return None if plugin is None: return obj.get_plugin_class() if isinstance(plugin, List): return obj.get_plugin_class() if plugin is None: return None return obj.get_plugin_class()","def _get_subclass(self, object_id, object_id, object_id): """""" """""" if not object_id: raise ValueError(""Attribute not found: %s"" % object_id) if not object_id: raise ValueError(""Attribute not found in the subclass: %s"" % object_id) return object_id",45.13423074,26.93571909
generate: Attempts to parse a M3U8 playlist from a string of data.,"def load(data, base_uri=None, parser=M3U8Parser, **kwargs):
    """"""

    """"""
    return parser(base_uri, **kwargs).parse(data)","def parse_single_playlist(data, tag): """""" """""" model = Data.objects.get_model() if model: model.add_model(model, tag) return model","def parse_playlist(data, playlist): """""""""""" data = data.get('playlist', None) if data is not None: playlist.append(data) return playlist",27.93889374,29.56746042
"generate: Print 'msg' to stdout, and option 'log' at info level.","def pout(msg, log=None):
    """"""""""""
    _print(msg, sys.stdout, log_func=log.info if log else None)","generate: Print'msg' to stdout, and option 'log' at info level. def print_msg(msg): """""" """""" print_msg(msg) print_msg(msg)","generate: Print'msg' to stdout, and option 'log' at info level. def print_logging_file(self, log_file, log_file): """""" """""" if self.log_file: print('Please level: %s', log_file) sys.stdout.write(log_file) else: print('Please stdout: %s', log_file)",28.38136966,22.04959628
generate: Delete next unapplied patch    If remove is True the patch file will also be removed. If remove and    backup are True a copy of the deleted patch file will be made.,"def delete_next(self, remove=False, backup=False):
        """""" 
        """"""
        patch = self.db.top_patch()
        if patch:
            after = self.series.patch_after(patch)
        else:
            after = self.series.first_patch()
        if not after:
            raise QuiltError(""No next patch"")

        self._delete_patch(after, remove=remove, backup=backup)","def delete(self, patchfile, remove=False, **kwargs): """""" """""" # If the patch file is not an unexpected, copy the copy of the patch file. if not self.is_made(patchfile): patchfile = patchfile.delete(patchfile) if not self.is_made(patchfile, remove=True): self.is_made(patchfile) self.is_made(patchfile)","def remove_remove_patch(self, patch_name, patch_file): """""" """""" if not patch_name: raise ValueError(""Please only for patching patch file %s"" % patch_name) patch_patch = self.find_patch(patch_name, patch_name) if patch_patch: self.remove_patch(patch_patch) else: self.remove_patch(patch_name, patch_name)",44.07077878,46.26023019
generate: Return the symmertic error,"def symmetric_error(self):
        """"""
        """"""
        # ADW: Should this be `np.nan`?
        if self.__errors__ is None:
            return 0.
        if np.isscalar(self.__errors__):
            return self.__errors__
        return 0.5 * (self.__errors__[0] + self.__errors__[1])",". def symmer_error(self): """""" """""" if self.errors: return self.errors[0] if not self.errors: return self.errors[0] if self.status_code == 200: return self.errors[0] else: return self.errors[0]","for the user. def get_error(self, username=None): """""" """""" if username: return self.get_error_response(username=username) else: return self.get_error(username)",50.7478817,32.74549884
generate: Returns a list of UDAs defined by given targets,"def build_uda_config_overrides(targets):
    """""" 

    """"""

    from bugwarrior.services import get_service

    targets_udas = {}
    for target in targets:
        targets_udas.update(get_service(target).ISSUE_CLASS.UDAS)
    return {
        'uda': targets_udas
    }","def get_udAsset(self, targets): """""" """""" if targets is None: targets = [] targets = [] targets = [] for target in self.targets: if target.uuid == target.uuid: targets.append(target) return targets",". def get_targets(self, targets): """""" """""" # Make sure that targets are not included targets_list = [] for target in self._targets: targets.append(target) return targets",43.75951051,40.97243748
generate: DDP ping handler.,"def recv_ping(self, id_=None):
        """"""""""""
        if id_ is None:
            self.reply('pong')
        else:
            self.reply('pong', id=id_)","def ping_handler(self, *args): """""""""""" if not args: return self.do_do_ping_handler(*args) if not args: return self.do_do_ping_handler(*args) self.do_do_ping_handler(*args)","def draw(self, ping): """""" """""" if ping: return self._ref_string(ping) else: self._ref_string(ping)",24.39899923,41.95496143
generate: setup a timeout for waiting for a proposal,"def get_timeout(self):
        """"
        if self.timeout_time is not None or self.proposal:
            return
        now = self.cm.chainservice.now
        round_timeout = ConsensusManager.round_timeout
        round_timeout_factor = ConsensusManager.round_timeout_factor
        delay = round_timeout * round_timeout_factor ** self.round
        self.timeout_time = now + delay
        return delay","to the command. def setup_timeout(self, timeout, code=None): """""" """""" if timeout is None: timeout = self.timeout if code is None: if self.code is None: self.code = None if code is None: self.code = None else: self.code = None if self.timeout is None: self.timeout = self.timeout self.timeout = timeout self.timeout = timeout",". def setup_timeout(self): """""""""""" if not self.timeout: return timeout = datetime.utcnow() if timeout: self._timeout = datetime.utcnow() self._timeout = timeout self._timeout = datetime.utcnow() self._timeout = timeout self._timeout = timeout self._timeout = timeout self._timeout = timeout self._timeout = timeout self._timeout = datetime.utcnow()",42.31496169,42.41966809
generate: Creates Grant object with the given params,"def set(self, client_id, code, request, *args, **kwargs):
        """"""
        """"""
        expires = datetime.utcnow() + timedelta(seconds=100)
        grant = self.model(
            client_id=request.client.client_id,
            code=code['code'],
            redirect_uri=request.redirect_uri,
            scope=' '.join(request.scopes),
            user=self.current_user(),
            expires=expires
        )
        self.session.add(grant)

        self.session.commit()",". def create_grant(self, flags, **kwargs): """""" """""" # We assume an input is available. if flags is not None: # Implemented from template for osid.resource.ResourceSession.create_template if ""grant"" in flags: self.grant = flags.get(""grant"") else: self.grant = flags.get(""grant"") return self.create_grant(**kwargs)",". def get_grant_params(self, object_id, params=None, page=None, verbose=False): """""" """""" if not params: params = { 'objects': object_id, 'params': params } else: params = { 'object_id': object_id, 'object_id': object_id, 'object_id': verbose, } return self._get_response( self._request( 'GET', url=url, params=params, verbose=verbose )",27.61832152,24.42266128
generate: Send a message containing the RPC method call,"def _send_request(self):
        """"""
        """"""
        msg = Message()
        msg.subject = ""An RPC call!""
        msg.address = self._to
        msg.reply_to = self._reply_to
        msg.body = self._method
        msg.correlation_id = 5  # whatever...

        print(""sending RPC call request: %s"" % str(self._method))
        # @todo send timeout self._sender.send(msg, self, None, time.time() +
        # 10)
        self._sender.send(msg, self)",". def _message_containing_message(self, message): """""" """""" if self._message_containing_message is None: self._message_containing_message = None self._message_containing_message = None else: self._message_containing_message = None self._message_containing_message = None self._message_containing_message = None self._message_containing_message = None self._message_containing_message = None","back. def _send(self, message, message): """""" """""" if message.body is None: message = self._fetch_message(message) if message.code == 'cancel': self._message_container.send(message) else: message = message.body self._message_container.send(message)",25.54089824,26.69605451
generate: Display the first and last n elements of a DataFrame.,"def head_and_tail_print(self, n=5):
        """"""""""""
        from IPython import display
        display.display(display.HTML(self._head_and_tail_table(n)))","def filter_first(self, data, last, last, last): """""" """""" last = self.first_first(last, last) if last is not None: return last.first(last) else: return last","def __display_func(self, element, key): """""" """""" if element.type!= 'Unique': return None else: self._display_first(element.type, key, key, values=self._flatten, skip_address=self._skip_address, multi_dict=self._multi_dict) self._display_first(element, element.type) self._display_first(element.type, key, values=self._delta_ms)",18.53978991,15.76561899
"generate: Deletes all layers within this LayeredWidget before deleting itself.        Recommended to call if you are removing the widget, but not yet exiting the interpreter.","def delete(self):
        """"""
        
        """"""
        for layer,_ in self.layers:
            layer.delete()
        self.layers = []
        self._layers = {}
        super(LayeredWidget,self).delete()","def delete_layers(self): """""" """""" layers = self.layers layers.remove(layers) self.layers = layers","def delete_layers(self, layer_list, all_layers): """""" """""" if layer_list: self.set_layer_list(self.layers) self.set_layers(self.layers)",48.05210509,52.02446702
generate: Print the value of an expression from the caller's frame.,"def debugx(expr,pre_msg=''):
    """"""""""""

    cf = sys._getframe(1)
    print '[DBG:%s] %s%s -> %r' % (cf.f_code.co_name,pre_msg,expr,
                                   eval(expr,cf.f_globals,cf.f_locals))","def print_value(self, value): """""""""""" value = self.frame_value if value is not None: value = value.value return value","def package_frame(self, expression): """""" """""" self._expression_frame(expression) self._expression_frame(expression) self._expression_frame(expression) self._expression_frame(expression)",18.7400595,19.18372775
generate: Get the next sibling in the children list of the parent node.,"def next_sibling(self, name=None):
        """"""

        """"""
        if name is None:
            return XMLElement(lib.lsl_next_sibling(self.e))
        else:
            return XMLElement(lib.lsl_next_sibling_n(self.e, str.encode(name)))","def get_next_sibling_info(self, sibling_node, verbose=False): """""" """""" if sibling_node is None: return self.next_sibling_info else: return self.next_sibling_info","def get_child_child(self, node): """""" """""" self.warning(""No child children: %s"", node) self.warning(""Could not get child children: %s"" % node) return self.warning_list[node]",55.80851449,29.97895076
generate: Retrive an user with a spotify ID.,"async def get_user(self, spotify_id: str) -> User:
        """"""
        """"""
        data = await self.http.user(to_id(spotify_id))
        return User(self, data)","def get_user_by_id(self, user_id, id=None): """""" """""" user_id = self.get_user_by_id(user_id) return UserID(user_id=user_id, id=id)","def get_user_for_user_for_user(self, user_id): """""" """""" user_id = self.user_id if user_id not in user_id: return user_id return user_id",44.92494862,42.18114191
"generate: Gets the model data associated with the given name.        If it was loaded, a cached copy will be returned.    It it was not loaded, it will be loaded and cached.","def getModelData(self,name):
        """"""
        
        """"""
        if name in self.modelcache:
            return self.modelcache[name]
        return self.loadModelData(name)","def get_model_data(self, name, cached_name, cached_name, cache_name): """""" """""" if name in self.model_data: return self.model_data[name] else: return self.model_data[name]","def get_model_data_loaded_name(self, name): """""" """""" if not self.is_valid(): return None return self.get_model(name)",58.6819696,57.61151914
generate: Configure plugin. Plugin is enabled by default.,"def configure(self, options, conf):
        """"""
        """"""
        self.conf = conf
        if not options.capture:
            self.enabled = False","def confirm(self, plugin): """""" """""" if self.parent: self.parent.plugin = plugin else: self.parent = plugin","def plugin_deployments(self, default_value): """""" """""" if default_value not in self._connections: return return self._connections[default_value]",43.21359517,33.7158426
generate: get the value of subnode,"def get_subnode(self, dst, ast, expr):
    """"""
        
    """"""
    dst.value = eval('ast' + expr)
    return True","s def get_subnode_nodes(self, subnodes): """""""""""" return [x for x in subnodes if x not in subnodes]","s. def get_subnodes(self, nodes): """""" """""" return self.get_subnodes(nodes)",37.81834086,42.81442482
generate: Returns the list of vlrs of the requested type    Always returns a list even if there is only one VLR of type vlr_type.,"def get(self, vlr_type):
        """""" 

        """"""
        return [v for v in self.vlrs if v.__class__.__name__ == vlr_type]","def get_vlr_types(self): """""" """""" if not self.vlr_types: return [] return []","def get_all_type_type(self): """""" """""" if self.type_type == 'begin': return [self.type_type] else: return [self.type_type]",49.22729618,39.32301085
generate: Calculates recall at k ranking metric.,"def recall_at_k(y_true: List[int], y_pred: List[List[np.ndarray]], k: int):
    """"""
    
    """"""
    num_examples = float(len(y_pred))
    predictions = np.array(y_pred)
    predictions = np.flip(np.argsort(predictions, -1), -1)[:, :k]
    num_correct = 0
    for el in predictions:
        if 0 in el:
            num_correct += 1
    return float(num_correct) / num_examples","def recall(self, kr, recall_attributes=None): """""" """""" self.tree = kr.tree if self.tree: self.tree = kr.tree if recall_attributes: self.tree = recall_attributes if self.metric: self.metric = recall_attributes if self.verbose: self.verbose = True return self","def recall_metric(self, metric, metric, local_state, button_pool=False): """""" """""" if local_state is not None: self._print_metric(metric, local_state, local_state, local_state) else: self._print_metric(metric, local_state) self._print_metric(metric, local_state) return self._print_metric(metric, local_state, local_state)",18.98750721,18.67450562
generate: Gets the cached clients dictionary in current context.,"def get_cached_clients():
    """"""""""""
    if OAuth.state_key not in current_app.extensions:
        raise RuntimeError('%r is not initialized.' % current_app)
    state = current_app.extensions[OAuth.state_key]
    return state.cached_clients","def get_cached_cached_cache_dict(self): """""""""""" # The request is specified, or the requested modification is valid. if self.cache_dict is not None: cache_dict = {} for key in self.cache_dict: if key not in self.cache_dict: cache_dict[key] = self.cache_dict[key] return cache_dict else: return None","def get_cached_clients(self): """""""""""" if self.cached_clients_dir: return self.cached_clients_dir if self.cached_clients_dir: return self.cached_clients_dir else: return self.cached_clients_dir",29.26779544,34.29806685
"generate: Get a value from process, return tuple of value, res if succesful","def getResultFromProcess(res, tempname, process):
    """"""""""""
    if not isinstance(res, (UndefinedValue, Exception)):
        value = getRepresentation(tempname, process)
        return value, res
    else:
        return res, str(res)","ly loaded def get_value(self, value, process=None): """""""""""" if process is not None: value = process.get(self.name) if value is None: return value else: raise ValueError(""Process is not available. Using "" ""value."")","else False. def get_value(self, process, value): """""""""""" if not value: return None if not value: return None if not isinstance(value, (list, tuple)): return None elif isinstance(value, (list, tuple)): return value else: return value",43.04335471,42.36357318
generate: Decode given representation.,"def decode(self, x):
        """"""
        
        """"""
        if not self.rep_dim:
            raise Exception(""rep_dim must be set to decode."")
        if not self.decoding_network:
            self.decoding_network = NeuralNetwork(self.rep_dim)
            for layer in self.decoding_layers:
                self.decoding_network.stack_layer(layer, no_setup=True)
        return self.decoding_network.compute(x)","def decode(self, representation): """""""""""" if self.representation: self.decode(self.decode) self.decode(self.decode) self.decode = None self.decode = None self.decode = None else: self.decode = None","def decode(self, representation=False): """""""""""" self._decode(representation) if not self._decoded: self._decode(representation) self._decode(representation) if self._decode(representation) and self._decode(representation)!= self._decode(representation): raise InvalidAlgorithmException(""Unable to decode a valid response."") else: self._decode(representation) self._decode(representation)",32.65739701,35.21973322
"generate: module predict, return the predict label","def predict_class_distributed(self, data_rdd):
        """"""
        
        """"""
        result = callBigDlFunc(self.bigdl_type,
                               ""modelPredictClass"", self.value, data_rdd)
        return result","s def predict_labels(self, labels): """""" """""" if labels: labels = [labels] for label in self.labels: labels.append(label) return labels","s. def get_predict(self, labels): """""" """""" if self.predict_predict(labels): return self.predict(labels) else: return self.predict(labels)",31.61630704,35.5542228
"generate: Get list of 2-qubit gates. Ignore snapshot, barriers, and the like.","def twoQ_gates(self):
        """"""""""""
        two_q_gates = []
        for node in self.gate_nodes():
            if len(node.qargs) == 2:
                two_q_gates.append(node)
        return two_q_gates","It is an internal MemoryList. def get_barriers(self): """""""""""" if self.like: return self.get_barriers() elif self.local: return self.local else: return self.local","def get_properties(self): """""" """""" if self.properties is not None: return self.properties return self.properties",27.63398345,26.57413229
"generate: Actual closing code, both from manual close and errors.","def _close(self, error=None):
        """"""""""""
        self._closing = True
        self.pause_reading()
        self._loop.call_soon(self._call_connection_lost, error)","def close(self, manual, close, loop): """""" """""" return self.close(manual, close, loop)","def _close_code(self, code): """""" """""" if code is None: code = self._close_code(code) else: code = code.copy() return self._close_code(code)",24.27127042,39.24019086
generate: Return a function `fun` that will execute `magic` on active frontend.,"def _make_dynamic_magic(self,magic):
        """"""
        """"""
        # need two level nested function to be sure to pass magic
        # to active frontend **at run time**.
        def inner_dynamic_magic():
            self.active_frontend.execute(magic)
        inner_dynamic_magic.__name__ = ""dynamics_magic_s""
        return inner_dynamic_magic","def frontend(func, frontend=False, verbose=False): """""" """""" if frontend: frontend = frontend(func) # If the frontend is available, we need to go through if frontend: return frontend(func) return frontend","def execute(self, func): """""" """""" @functools.wraps(func) def wrapper(self, *args, **kwargs): return self.wrapper(*args, **kwargs) return wrapper @wraps(func) @wraps(func) def wrapper(*args, **kwargs): """"""Returns a single function for any one.",22.53380007,24.20717606
generate: Return all disease terms that overlaps a gene,"def disease_terms(self, hgnc_id=None):
        """"""
        """"""
        query = {}
        if hgnc_id:
            LOG.debug(""Fetching all diseases for gene %s"", hgnc_id)
            query['genes'] = hgnc_id
        else:
            LOG.info(""Fetching all disease terms"")

        return list(self.disease_term_collection.find(query))","otical functions def get_all_disease_terms(self, terms): """""" """""" disease_terms = [] for func in self.filter_terms: if func.is_null(): disease_terms.append(func) else: disease_terms.append(func) return disease_terms",". def disease_terms(self, disease=False): """""" """""" if not disease: return None disease = None if not disease: disease = self.disease_terms(disease) if not disease: disease = None return disease",42.1479194,36.66804828
generate: Set the source by parsing the source and inserting it into the     component.,"def set_source(self, source):
        """"""  
        """"""
        self.widget.clear()
        html = etree.HTML(source)
        self.widget.extend(html[0])

        # Clear removes everything so it must be reinitialized
        super(RawComponent, self).init_widget()","def _set_source(self, source, component): """""" """""" try: source = self.source_by_name(source) return self._set_source_by_name(source) except Exception: return None","def set_source_batch(self, source, limit=None): """""" """""" source = self._get_source_batch_by_source(source) self._set_source_batch_by_source(source) self._set_source(source) self._set_source(source) return source",34.77897709,36.66736065
"generate: Internal callback for device command messages, parses source device from topic string and    passes the information on to the registered device command callback","def _onCommand(self, client, userdata, pahoMessage):
        """"""
        
        """"""
        try:
            command = Command(pahoMessage, self._messageCodecs)
        except InvalidEventException as e:
            self.logger.critical(str(e))
        else:
            self.logger.debug(""Received device command '%s'"" % (command.command))
            if self.commandCallback:
                self.commandCallback(command)","for the specified device def get_device_command_message(self, session, passed, callback, managed_device, page=None): """""" """""" device_command = self.get_device_command_message(session, page) if device_command == managed_device: return device_command return device_command","s. def _get_registered_device_command(self, topic_registered_device_command, command_registered_device_command): """""" """""" if not topic_registered_device_command.is_level(): self.device_command(topic_registered_device_command, command_registered_device_command, command_registered_device_command) return self._get_device_command(topic_registered_device_command, topic_registered_device_command)",38.22339735,29.41523532
"generate: Attempts to list all of the classes within a given module namespace.  This method, unlike list_classes, will recurse into discovered  submodules.","def rlist_classes(module, cls_filter=None):
    """"""
    
    """"""
    found = list()
    mnames = rlist_modules(module)
    for mname in mnames:
        [found.append(c) for c in list_classes(mname, cls_filter)]
    return found","def list_classes_with_modules(modules, submodules, classes, classes): """""" """""" modules = list_classes(modules, submodules) classes = [] for cla in modules: if not classes: classes.append(cla) return classes","def _submodules(self, classes, modules, modules): """""" """""" classes = {} for module in classes: if not module.is_module(module): continue classes[module.is_module(module)] = classes[module.__name__] classes[module.__name__] = module.__name__ classes[module.__name__] = module.__name__ return classes",48.73781265,29.90017867
generate: Convenience function for accessing tag parameters,"def GetParam(tag, param, default=__SENTINEL):
    """""" """"""
    if tag.HasParam(param):
        return tag.GetParam(param)
    else:
        if default == __SENTINEL:
            raise KeyError
        else:
            return default","def get_tag_params(self, tag_params): """""" """""" func = self.get_tag_params(tag_params) if func is not None: func = self.get_tag_params(tag_params) return func",". def _convenience_tag_parameters(self, tag_dict, root_tag, tag_dict): """""" """""" return self._convenience_tag(tag_dict, root_tag, root_tag, tag_dict)",31.77608799,23.69276528
generate: Get a task from the registry.,"def get(self, task_id):
        """"""
        """"""
        try:
            self._rwlock.reader_acquire()
            task = self._tasks[task_id]
        except KeyError:
            raise NotFoundError(element=str(task_id))
        finally:
            self._rwlock.reader_release()

        return task","def get_task(self, region): """""""""""" # Implemented from an import_task task = self.tasks.get(self.task) if task: return task else: return None","def get_task(self): """""""""""" task_name = self._task_name if not self._task_registry: self._task_registry.put(""Task: {0}"".format(self._task_name)) else: self._task_registry.put(""Task: {0}"".format(self._task_name)) self._task_registry.put(""Task: {0}"".format(self._task_name))",33.56210323,29.69138276
generate: Returns the unique SHA1 hexdigest of the chart URL param parts,"def checksum(self):
        """"""
        
        """"""
        self.render()
        return new_sha(''.join(sorted(self._parts()))).hexdigest()",". def get_unique_url(self): """""" """""" self.unique_url = ""%s/%s"" % (self.unique_url, self.unique_url) return self.unique_url",". def get_unique_unique(self): """""" """""" parts = urllib.parse.urlparse(self._url) return self._get_unique_unique(parts.url)",32.30704509,35.47665447
generate: Add a mail to the queue to be sent.,"def queue_email(to_addresses, from_address, subject, body, commit=True, html=True, session=None):
    """"""
    
    """"""
    from models import QueuedEmail

    if session is None:
        session = _db.session

    log.info('Queuing mail to %s: %s' % (to_addresses, subject))
    queued_email = QueuedEmail(html, to_addresses, from_address, subject, body, STATUS_QUEUED)
    session.add(queued_email)
    session.commit()

    return queued_email","def add(self, queue, token, mail): """""" """""" # Unsent to the same mail if not mail: return # We mail is not an a mail if mail.mail_id!= self.mail_id: return # We are sent to the mail if mail.mail_id!= self.mail_id: return # We mail address. if mail.mail_id!= self.mail_id: return # We mail # We mail if mail.mail_id!= self.mail_id: return # We mail # We mail # We mail # We mail if mail.mail_id!= self.mail_id: return # We mail # We mail if mail.mail_id == self.mail_id: return # We mail # We mail # We mail if mail.mail_id!= self.mail_id: return # We mail # We mail if mail.mail_id!= self.mail_id: return # We mail # We mail # We mail if mail.mail_id!= self.mail_id: return # We mail # We mail if mail.mail_id!= self.mail_id:","def add_mail(self, queue, port): """""" """""" if self.mail_on_run: self._mail_on_run = True if port: if self._running_queue.get(port) is None: self._running_queue.set_queue() else: self._running_queue.set_queue() else: self._running_queue.set_queue()",13.04187107,19.69612102
generate: Send a message to a node. Returns False if the connection appears to be dead either before or after actually trying to send the message.,"def send(self, node, message):
        """"""
        
        """"""

        if node not in self._connections or self._connections[node].state != CONNECTION_STATE.CONNECTED:
            return False
        self._connections[node].send(message)
        if self._connections[node].state != CONNECTION_STATE.CONNECTED:
            return False
        return True","def connection(self, node, node, change=None, **kwargs): """""" """""" if node is None: return False message = node.get(change, False) if message is None: return False if isinstance(message, Failure): message = message.get(change, False) if message is None: return False return True return False","def add_message(self, link_response): """""" """""" message = self._message_message(self.message_type, link_response) if not message.is_bulk_response(): return if message.is_bulk(): return message return message",41.76743741,30.20317793
generate: docstring for parse_omim_2_line,"def parse_omim_line(line, header):
    """"""""""""
    omim_info = dict(zip(header, line.split('\t')))
    return omim_info",". def _mim_2_line(self, parse_omim_2_line, failure): """""""""""" self.mim_2_line = parse_omim_2_line(failure) self.mim_2_line = parse_omim_2_line(failure)","_body_file(self, line): """""" """""" if not self.parse_owner_mode_token(line): return self.parse_mode_token(line) return self.parse_mode_token(line, line)",31.93592526,27.25769343
"generate: iterate on similarities among all files, by making a cartesian    product","def _iter_sims(self):
        """"""
        """"""
        for idx, lineset in enumerate(self.linesets[:-1]):
            for lineset2 in self.linesets[idx + 1 :]:
                for sim in self._find_common(lineset, lineset2):
                    yield sim",". def iter_all_files(self, paths, all_files=None): """""" """""" return [x for x in self.files if x.name == '.' if x.name == '.' else x.name for x in self.files if x.name == '.' and x.name == '.'}",", relative the similarities and components and relatives them. def _components(self, files, components): """""" """""" if self.doc_run: self.doc_run.write(files) return files",30.02737764,27.20100301
generate: Return True if key `k` exists,"def contains(self, k):
        """"""""""""
        if self._changed():
            self._read()
        return k in self.store.keys()",". def __is_key(self, k): """""""""""" if k in self._k_keys: if k in self._k_keys: return False return False else: return False","in a region. def region_key_exists(self): """""""""""" if self.region_key: return self.region_key else: return False",43.73002617,40.20988495
generate: Summarize the parameters of a distribution.,"def summarize_dist_params(dist, name, name_scope=""dist_params""):
  """"""
  """"""
  with tf.compat.v1.name_scope(name_scope):
    tf.compat.v2.summary.histogram(
        name=""{}/{}"".format(name, ""mean""),
        data=dist.mean(),
        step=tf.compat.v1.train.get_or_create_global_step())
    tf.compat.v2.summary.histogram(
        name=""{}/{}"".format(name, ""stddev""),
        data=dist.stddev(),
        step=tf.compat.v1.train.get_or_create_global_step())","def _summarize(self, parameters): """""""""""" # We have a single legend or an active legend. dist_legend = ( ""An active active parameters of a legend."" ""See: {}"".format(parameters)) parameters = self.parameters for legend in legend: dist_legend.append(legend) return dist_legend","def summary_parameters(self): """""" """""" for parameter in self._parameters: if not parameter.parameters.get(""parameters""): raise ValueError(""Parameters is not supported as a valid distribution."") return [self._parameters[parameter.parameters[0]] for parameter in self._parameters[1]]",17.28883074,17.60479002
generate: Allow for iterators to return either an item or an iterator of items.,"def iter_pipe(pipe, processors):
    """"""""""""
    if isinstance(pipe, str):
        pipe = [pipe]
    for it in processors:
        pipe = it(pipe)
    yield from pipe","def get_items_with_item(item, **kwargs): """""""""""" if isinstance(item, NIterator): return item else: return item","def add_iterator(self, item): """""" """""" if item is not None: return item else: return self.new_iterator(item)",30.24028782,20.83509178
generate: Returns a simple fragment,"def render_to_fragment(self, request, **kwargs):
        """"""
        
        """"""
        fragment = Fragment(TEST_HTML)
        fragment.add_javascript(TEST_JS)
        fragment.add_css(TEST_CSS)
        return fragment","that is available. def fragment(self, q=None, **kwargs): """""""""""" fragment = self.request(""fragment"", q=q, **kwargs) return self.fragment(fragment)","and fragments are valid validation. def fragment_series(self): """""" """""" def __salt__['test'](self, fragment_key, fragment_key, fragment_key): return fragment_key return self._fragment_series_tragment_series(fragment_key, fragment_key, fragment_key, fragment_key)",51.51261484,30.52957008
generate: List commands arranged in an aligned columns,"def columnize_commands(self, commands):
        """"""""""""
        commands.sort()
        width = self.debugger.settings['width']
        return columnize.columnize(commands, displaywidth=width,
                                   lineprefix='    ')",". def list_commands(self, commands): """""" """""" commands = [] for column in columns: if column.is_generic: commands.append(column.get(column)) else: commands.append(column.get(column)) return commands",". def align_command(self, column): """""""""""" if self.is_valid(): return self._proxy_command(column) else: return self._proxy_command(column)",44.58264431,38.64154833
generate: Decide whether to trace execution in `filename`.,"def _should_trace(self, filename, frame):
        """"""

        """"""
        canonical, reason = self._should_trace_with_reason(filename, frame)
        if self.debug.should('trace'):
            if not canonical:
                msg = ""Not tracing %r: %s"" % (filename, reason)
            else:
                msg = ""Tracing %r"" % (filename,)
            self.debug.write(msg)
        return canonical","def trace_filename(filename, target, filename, **kwargs): """""" """""" if filename == '.py': target = filename.replace('.py', '.py') else: target = filename.replace('.py', '.py') target = filename.replace('.py', '.py') return target, filename, target, filename, target, filename, target, filename, target, filename","def decided_filename(self, filename): """""" """""" filename = self.get_filename(filename) if not os.path.isdir(filename): return False if not os.path.isdir(filename): return False filename = os.path.join(filename, filename) if not os.path.exists(filename): return False filename = os.path.dirname(filename) return self.decided_filename(filename, filename)",32.12495525,35.30448374
generate: Verify if the realms match the requested realms.,"def verify_realms(self, token, realms, request):
        """"""""""""
        log.debug('Verify realms %r', realms)
        tok = request.request_token or self._grantgetter(token=token)
        if not tok:
            return False

        request.request_token = tok
        if not hasattr(tok, 'realms'):
            # realms not enabled
            return True
        return set(tok.realms) == set(realms)","def get_realms(self): """""""""""" realms = self.realms if realms is not None: realms = realms.get(realms.get(""realms"")) if realms.get(""realms""): realms = realms.get(""realms"") if realms is not None: realms = realms.get(""realms"") if realms is not None: realms = realms.get(""realms"") if realms is not None: realms = realms.get(""realms"") return realms","def _get_realms_by_realms_by_realms(self, realms): """""" """""" if not realms: raise ValueError(""Realms must be realms than the realms, "" ""there are "" ""realms."") if not realms: raise ValueError(""Realms must be None, "" ""realms must be an "" ""realms."") if not realms: realms = [] if not self.is_realms: realms = realms else: realms = [] for realms in realms: realms.append(realms) return realms",35.28888948,34.35605739
generate: Creates a value-setting interceptor.,"def make_value_setter(**model_kwargs):
  """"""

  """"""
  def set_values(f, *args, **kwargs):
    """"""Sets random variable values to its aligned value.""""""
    name = kwargs.get(""name"")
    if name in model_kwargs:
      kwargs[""value""] = model_kwargs[name]
    return interceptable(f)(*args, **kwargs)
  return set_values","def get_value_setting(self, value, default=None, disable=False): """""""""""" if default is None: return value if disable is not None: if default is None: if disable: return self.get_value_setting(value, default=default) else: if default is None: if default is None: return value else: return value","def get_value_setting(self, value, val): """""" """""" if isinstance(value, Float): return value elif isinstance(value, Float): return value elif isinstance(value, Float): return value elif isinstance(value, Float): return value else: raise TypeError(""value must be an int, got %s"" % (value, val))",32.31583437,30.59130623
generate: Given a string add necessary codes to format the string.,"def colorize(msg, color):
    """"""""""""
    if DONT_COLORIZE:
        return msg
    else:
        return ""{}{}{}"".format(COLORS[color], msg, COLORS[""endc""])","def format_str(self, code): """""""""""" code = code.encode('utf-8') return ""{}"".format(code)","def string_to_string(self, string_type): """""""""""" url = string_type if self._address_type == string_type: return self._add_url(url, string_type=string_type) else: return self._add_url(url, string_type=string_type)",28.71069706,18.69612618
generate: Accept a string and parse it into many commits.  Parse and yield each commit-dictionary.  This function is a generator.,"def parse_commits(data):
    '''
    '''
    raw_commits = RE_COMMIT.finditer(data)
    for rc in raw_commits:
        full_commit = rc.groups()[0]
        parts = RE_COMMIT.match(full_commit).groupdict()
        parsed_commit = parse_commit(parts)
        yield parsed_commit","def parse(self, func, scope, **kwargs): """""" """""" if func is None: return None if isinstance(func, scope): return func(scope, **kwargs) elif isinstance(func, Commit): return func(scope, **kwargs) else: return func(scope)","If the commit of the minimal commits, the commits is the commits into an topic-dictionary. def _get_commits_from_dict(dictionary, dictionary, commit_dictionary): """""" """""" if dictionary.get('items'): return dict(dict(dictionary)) else: return dict(dictionary)",13.61499268,23.57761938
generate: High-level function for creating messages. Return packed bytes.,"def make_message(self, text, channel):
        """"""
        
        """"""
        try:
            channel_id = self.slack.channel_from_name(channel)['id']
        except ValueError:
            channel_id = channel
        return pack({
            'text': text,
            'type': 'message',
            'channel': channel_id,
            'id': self.message_id,
        })","def _get_message_change(self, message): """""""""""" # FIXME: This message will be the FIXME fields = [float(message) for message in self.messages] if fields: # We are no messages are not available. return fields[0] return None","def _get_messages_by_string(self, message_messages): """""" """""" if message_messages.get('message'): return self._message_messages[message_messages.get('message', {}).get('message', None)] else: return self._message_messages[message_messages.get('message', None)]",27.35906178,27.90169505
generate: Attempt to acquire lock.,"def tryAcquire(self, lockID, callback=None, sync=False, timeout=None):
        """"""
        """"""
        return self.__lockImpl.acquire(lockID, self.__selfID, time.time(), callback=callback, sync=sync, timeout=timeout)","def acquire_lock(self, lock): """""""""""" if self.lock is None: return None lock = self.lock if lock: self.lock = lock self.lock.acquire() if not self.lock: return None if self.lock.acquire() is None: return None return None","def acquire(self): """""" """""" self.logger.debug(""Can't acquire database..."") self.logger.debug(""Can't acquire database..."") self.logger.debug(""Acquire database..."") return None",32.31211986,30.24819118
generate: Convert an AST sepcial handling to python source code.,"def _ast_special_handling_to_code(self, special_handling, **kwargs):
    """"""""""""
    ident = special_handling.value.svalue
    if ident in PB_SPECIAL_HANDLING:
      return [""PB.{0}"".format(ident)]
    else:
      return [""self.{0}"".format(ident)]","def _convert_handling_to_python(sep, **kwargs): """""" """""" if not isinstance(sep, Function): raise TypeError('Argument ""{}"" already exists'.format(sep)) try: return SeqCode(*args, **kwargs) except AttributeError: raise TypeError('Argument ""{}"" already exists'.format(sep))","def add_active_handling(self, code): """""" """""" if code in self._active_handling: return self._active_handling[code] else: return self._active_handling[code]",30.87148196,34.39443793
generate: Get an SMTP session with SSL.,"def _get_ssl(self):
        """"""""""""
        return smtplib.SMTP_SSL(
            self.server, self.port, context=ssl.create_default_context()
        )","def get_session_sql(self, session, handler): """""""""""" session_id = handler.get_session_id(handler) return SSL.SSESSSL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQL_SQ","def get_session(self): """""""""""" return self._session.get_session().get(self._session_name)",6.937651813,35.91350001
generate: Decorator to add a callback that generates error page.,"def error(self, status=None):
        """"""
        """"""
        def decorator(callback):
            self._error_handlers[status] = callback
            return callback
        return decorator","def decorate_error_page(self, callback): """""" """""" if not isinstance(callback, Callback): callback = callback return callback","def callback(self, error): """""" """""" if error is not None: self.callback(error) return self.callback(self.callback, self.response)",53.84657916,50.01921408
generate: Returns whether this is a complex floating point type.,"def is_complex(dtype):
  """"""""""""
  dtype = tf.as_dtype(dtype)
  if hasattr(dtype, 'is_complex'):
    return dtype.is_complex
  return np.issubdtype(np.dtype(dtype), np.complex)","def is_complex_floating(self): """""""""""" if not self.is_complex_floating: return True return self.is_complex_floating","def get_pointer_type(self, pointer_type, value): """""" """""" if value.startswith(""pointer_type""): return self.get_pointer_type(value) else: return self.get_pointer_type(value)",35.40483191,31.63689701
generate: Gets the most recent non-zero value for a .last metric or zero  for empty data.,"def get_last_value_from_timeseries(timeseries):
    """"""""""""
    if not timeseries:
        return 0
    for metric, points in timeseries.items():
        return next((p['y'] for p in reversed(points) if p['y'] > 0), 0)","generate: Gets the most recent non-zero value for a.last metric or zero for empty data. def get_last_recent_metric(self, metric_name): """""""""""" return self.get_last_recent_metric(metric_name, self.last_recent_metric)","generate: Gets the most recent non-zero value for a.last metric or zero for empty data. def get_position(self, most_name): """""" """""" if self.has_primary: return self._get_position(most_name) else: return self._get_position(most_name)",29.52853363,30.86000721
generate: If don't have injector call from parent,"def callInjector(self, old: Node, trans: Translator) -> Node:
        """"""  """"""
        if self.astTranslatorInjector is None:
            if self.parent is not None:
                # TODO: think if we forward for all StateScope
                # forward to parent scope
                return self.parent().callInjector(old, trans)
            else:
                raise TypeError(""Must define an Translator Injector"")
        return self.astTranslatorInjector(old, trans)",", then return the URLs. def get_call(self, parent=None): """""" """""" if parent is None: parent = self.get_parent(parent) # Use flask URLs for don't have injector. return URL(self.get_url_url(parent=parent, item=self.item, item=self.item, **self.parent))","MAXML. def parent_callback(self, callback): """""" """""" if callback: raise TypeError('callback must be a valid callback') if callback: callback = self.callback(callback) if callback is None: raise TypeError('callback must be a valid callback') return callback(callback, callback)",28.96260151,25.91438917
generate: Generate a session id for user based authentication.,"def session_new(self, **kwargs):
        """"""
        
        """"""
        path = self._get_path('session_new')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","def get_session_id(self, user_id): """""""""""" # Generate session id for user session_id = self.session_id return self.session_id(session_id, user_id)","def _get_user_by_user_id(self, user_id): """""" """""" url = self._get_url('/user_id', user_id) response = self._get_response(url=url, url=url, headers={'user_id': user_id}) return self._get_response(response)",36.82921862,41.9150188
"generate: Register a new engine, and update our connection info.","def _register_engine(self, msg):
        """"""""""""
        content = msg['content']
        eid = content['id']
        d = {eid : content['queue']}
        self._update_engines(d)","def register(self, engine, update=None): """""""""""" self.update(engine) self.update(engine) self.update(update) self.update(update)","def register_engine(self, engine, region): """""""""""" self._engine_engine(engine) self._engine_engine_engine(engine, region)",34.93361202,36.63439154
generate: Return motion settings matching camera_id.,"def camera_event_motion_enum(self, camera_id, **kwargs):
        """"""""""""
        api = self._api_info['camera_event']
        payload = dict({
            '_sid': self._sid,
            'api': api['name'],
            'method': 'MotionEnum',
            'version': api['version'],
            'camId': camera_id,
        }, **kwargs)
        response = self._get_json_with_retry(api['url'], payload)

        return MotionSetting(camera_id, response['data']['MDParam'])","def _camera_id(self, camera_id): """""" """""" camera_id = self.camera_id motion = camera_id_id if motion =='search_admins': # First, so far, add this camera_id is returned return self.search_admins.search(camera_id) else: return self.search_admins.search(camera_id)","def get_camera_id(self, camera_id): """""" """""" if not self.is_camera_id: return None camera_id = camera_id[0] try: camera_id = self._get_camera_id(camera_id) except IndexError: camera_id = camera_id[0] else: camera_id = camera_id[1] if camera_id.startswith(self.camera_id): camera_id = camera_id[2] if camera_id: camera_id = camera_id[2] return camera_id",30.22640727,32.24855885
generate: Sets the base font for the ConsoleWidget to the specified QFont.,"def _set_font(self, font):
        """""" 
        """"""
        font_metrics = QtGui.QFontMetrics(font)
        self._control.setTabStopWidth(self.tab_width * font_metrics.width(' '))

        self._completion_widget.setFont(font)
        self._control.document().setDefaultFont(font)
        if self._page_control:
            self._page_control.document().setDefaultFont(font)

        self.font_changed.emit(font)","def set_qfont(self, qfont, font, font, *args, **kwargs): """""" """""" if qfont is None: raise NoQueryError(""Query ID not cause the Query ID"") if font is None: font = self._qfont(font) return self.set_qfont(qfont, font, *args, **kwargs)","def set_console_widget(self, font_id, remote_font_id, base_console_widget): """""" """""" self.set_console_widget(font_id) self.set_console_widget(remote_font_id) self.set_console_widget(self.get_console_widget_id()) self.set_console_widget(remote_font_id, remote_font_id) self.set_console_widget(remote_font_id) self.set_console_widget(self.get_console_widget())",24.5007204,37.46334306
generate: Close port.,"def close(self):
        """"""""""""
        os.close(self.in_d)
        os.close(self.out_d)","def close(self): """""""""""" self.plot.draw() self.close() self.plot.draw()","def _close_port(self, port, id): """""" """""" if id is None: raise RuntimeError('Invalid port: %s' % port) self.close() self._port = port self._port_id = id self._port = port",55.36160989,18.83552217
generate: Get an open position,"def get_position(self, symbol):
        ''''''
        resp = self.get('/positions/{}'.format(symbol))
        return Position(resp)","from the given Gaussian position. def get_open_position(self, position): """""" """""" position = position.get_position(position) return position","for the ``flow``. def get_position(self, flow_info): """""" """""" self._position = flow_info.get('position', None) return self._position",36.80650465,43.25090434
generate: Return the primary control channel of this qubit.,"def control(self) -> ControlChannel:
        """"""""""""
        if self._controls:
            return self._controls[0]
        else:
            raise PulseError(""No control channels in q[%d]"" % self._index)","def _primary_control_channel(self): """""""""""" if not self._primary_control_channels: return self.primary_control_channels return self.primary_control_channels","def primary_control_channel_channel(self): """""" """""" if self.control_channel is None: return None if self.project_control_channel is None: return self.control_channel return self.control_channel",53.48150602,45.35302083
generate: Transfer playback to a new device and determine if it should start playing.,"async def transfer(self, device: SomeDevice, ensure_playback: bool = False):
        """"""
        """"""
        await self._user.http.transfer_player(str(device), play=ensure_playback)","def device_playback(self): """""" """""" if self.playback: return self.playback self.playback = self.playback return self.playback","def _get_device(self): """""" """""" if self._do_playing: return self._get_device_device(self._do_playing) else: raise ValueError('Do not find do_playing playing `device_device`')",34.6634405,34.25622971
generate: Test whether elements of an H2OFrame are contained in the ``item``.,"def isin(self, item):
        """"""
        
        """"""
        if is_type(item, list, tuple, set):
            if self.ncols == 1 and (self.type(0) == 'str' or self.type(0) == 'enum'):
                return self.match(item)
            else:
                return functools.reduce(H2OFrame.__or__, (self == i for i in item))
        else:
            return self == item","def contain(self, item): """""" """""" if item in self.item_list: return True # Any other elements are contained in the frame are contained in the list for item in self.item_list: if item.has_item_list(item): return True return True","def h2OFrame(self): """""" """""" # TODO: TODO: apply one of the ``OFrame`` to the ``OFrame``. if self.device_type == 'H2OFrame': return self.h2OFrame(self.h2OFrame.device_type, ""Unable to parse"") return self.h2OFrame(self.h2OFrame.device_type, ""H2OFrame"")",40.92529935,34.35134493
"generate: Creates a stream given an optional JSON schema encoded as a python dict. You can also add other properties    of the stream, such as the icon, datatype or description. Create accepts both a string schema and    a dict-encoded schema.","def create(self, schema=""{}"", **kwargs):
        """"""""""""
        if isinstance(schema, basestring):
            strschema = schema
            schema = json.loads(schema)
        else:
            strschema = json.dumps(schema)
        Draft4Validator.check_schema(schema)
        kwargs[""schema""] = strschema
        self.metadata = self.db.create(self.path, kwargs).json()","def _stream_json(self, schema, encoding, schema): """""" """""" schema = ""{}{}"".format(schema, encoding) self.schema = schema self.schema = schema self.schema = schema","def create_optional_url(self, js, path): """""" """""" if js is None: raise ValueError(""JSON stream schema type {}"".format(js)) if not self.is_platform: raise ValueError(""JSON stream must be valid schema type"") return self.create_json_to_dict(js, js, js, platform=platform, encoding=encoding)",31.71148141,31.06560376
generate: Draw the Y axis labels,"def draw_y_labels(self):
		""""
		if not self.show_y_labels:
			# do nothing
			return

		labels = self.get_y_labels()
		count = len(labels)

		labels = enumerate(iter(labels))
		start = int(not self.step_include_first_y_label)
		labels = itertools.islice(labels, start, None, self.step_y_labels)
		list(map(self.draw_y_label, labels))
		self.draw_y_guidelines(self.field_height(), count)",". def _draw(self, labels, ignore_labels=False): """""" """""" if ignore_labels: raise ValueError(""Ignoring labels, given labels, given labels."") # Return labels if they are available. labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels = self._labels labels =","and iterates from the class YAXIS. def draw_labels(class_name, labels, iterable_names, labels): """""" """""" if not labels: raise ValueError(""You must allow one class names"") labels = [class_name] labels = labels[labels] if labels: labels.append(labels) labels.append(labels) labels.append(labels) labels.append(labels) return labels",15.06484801,41.46250958
generate: Initiates self-destruct timer.,"def _start_timer(self) -> None:
        """"""""""""
        self.timer = Timer(self.config['conversation_lifetime'], self.self_destruct_callback)
        self.timer.start()","def timer(self, timer, timer): """""""""""" self.timer = timer self.timer = timer self.dev_weights = weights self.target_weights = weights","def init_timer(self): """""" """""" if self.is_alive_timer(self.device): return self.timer else: return self.timer.timer",43.28591345,44.19458058
generate: Creates the dirname and inserts a .version file,"def create(self):
        """"""  """"""
        if not os.path.exists(self.dirname):
            os.makedirs(self.dirname)
        self._create_version(self.version_file)","generate: Creates the dirname and inserts a.version file. def from_dirname(self, dirname, version=None): """""""""""" self.dirname = dirname if dirname == '': self.dirname = dirname else: self.dirname = dirname","generate: Creates the dirname and inserts a.version file. def create_dirname_file(self, dirname, file_path): """""" """""" if not os.path.exists(dirname): os.makedirs(dirname) os.makedirs(dirname) return dirname",33.14953512,45.19643957
generate: Closes socket and terminates context,"def finalize(self):
        """"""

        """"""
        if self._context is not None:
            if self._socket is not None:
                self._close_socket(confused=False)
            self._context.term()
            self._context = None
            self._poll = None","def close_context(self): """""" """""" self.context = None if self.context is None: self.context = self.context self.context = None self.context = None",". def close_context(self): """""" """""" if self._context.is_context(): raise CloudFailure(""CloudContext in cloud failed"") self._context.close() self._context.close()",55.01135874,46.62000505
generate: Use `top_k` to sort a `Tensor` along the last dimension.,"def _sort_tensor(tensor):
  """"""""""""
  sorted_, _ = tf.nn.top_k(tensor, k=tf.shape(input=tensor)[-1])
  sorted_.set_shape(tensor.shape)
  return sorted_","def tensor(self, tensor=None, last_k=None): """""""""""" if tensor is None: tensor = last_k if last_k is None: return last_k if last_k is None: return last_k return self.tensor","def _is_dimension(tensor): """""" """""" if not tensor: raise ValueError(""Tensor is not a valid tensor."") return (tensor.is_dimension(tensor))",31.56604317,39.32600758
"generate: IE conditional comments basically embed HTML that the parser    doesn't normally see. We can't allow anything like that, so    we'll kill any comments that could be conditional.","def kill_conditional_comments(self, doc):
        """"""
        
        """"""
        bad = []
        self._kill_elements(
            doc, lambda el: _conditional_comment_re.search(el.text),
            etree.Comment)","For this is threads, the comments are applicable. def get_comments_for_comment(self, comment): """""" """""" comments = self.get_comments_for_comments(comment) if comments: return comments else: return comments","def _get_parser_doc_basically_embedding(self, embedding): """""" """""" url = self._get_url(embedding) if url.endswith(""html""): return self._get_embedding(url) else: return self._get_embedding(url)",30.06518364,21.87247884
generate: Transform SuperOp representation to Choi representation.,"def _superop_to_choi(data, input_dim, output_dim):
    """"""""""""
    shape = (output_dim, output_dim, input_dim, input_dim)
    return _reshuffle(data, shape)","def create_choire(self, choices, **kwargs): """""""""""" self.create_choices(choices, **kwargs) self.create_choices(choices, **kwargs) return self","def _get_representation_info(self, representation, representation_info): """""" """""" return self._get_representation(representation, representation_info)",22.27659992,18.98802665
generate: Create a Fraction from a numerator and denominator.,"def fraction(numerator: int, denominator: int) -> Fraction:
    """"""""""""
    return Fraction(numerator=numerator, denominator=denominator)","def fraction(self, numeric_result, label, denominator): """""" """""" return self.create_fraction(numeric_result, label, denominator)","def fraction_from_numerator(numerator, numerator, numerator): """""""""""" if numerator.is_numerator_integer(): numerator.is_numerator(numerator) if numerator.is_numerator(): return numerator numerator.is_numerator(numerator) numerator.is_numerator(numerator) return numerator",53.49947615,25.68075107
generate: Validates if the considered string is a valid NEO address.,"def validate_address(self, addr, **kwargs):
        """""" 

        """"""
        return self._call(JSONRPCMethods.VALIDATE_ADDRESS.value, [addr, ], **kwargs)","def validate(self, validation, name): """""""""""" if not self._is_valid(name): raise NotImplementedError(""Should not validate '%s'"" % name) return self._validate(validation)","def _validate_address(self, address): """""" """""" if not address: raise ValueError(""Address "" + address) return address",26.46540761,42.7263325
generate: Convert a string of text into a lowercase string with no  punctuation and only spaces for whitespace.,"def cleanse(span):
    '''
    '''
    try:
        ## attempt to force it to utf8, which might fail
        span = span.encode('utf8', 'ignore')
    except:
        pass
    ## lowercase, strip punctuation, and shrink all whitespace
    span = span.lower()
    span = span.translate(strip_punctuation)
    span = whitespace.sub(' ', span)
    ## trim any leading or trailing whitespace
    return span.strip()","def text(text): """""" """""" if text == ""punctuation"": return text.replace(""\n"", """") elif text == ""punctuation"": return text.replace(""\n"", ""\n"") elif text == ""host"": return text.replace(""\n"", ""\n"") else: return text","def _format_text_to_string(string): """""" """""" if not isinstance(string, str): raise TypeError('invalid punctuation string or string type is not string or string or string.') if not isinstance(string, File): raise TypeError('invalid string is not string or string.') if not isinstance(string, File): raise TypeError('invalid string is not string or string.') return string.replace(""/"", ""%s"" % string)",13.76855673,20.29705233
generate: Use this to create a new and empty contact.,"def new_contact(cls, address_book, supported_private_objects, version,
            localize_dates):
        """"""""""""
        return cls(address_book, None, supported_private_objects, version,
                localize_dates)","def create_contact(self, *args, **kwargs): """""""""""" contact = self._contact(*args, **kwargs) return contact","def create_empty_contact(self, other): """""""""""" if other.type == 'USERTOR': self._update_other(other, other) else: self._update_other(other, other)",19.45982187,22.17927839
generate: Disconnect internal signals so unit can be reused by parent unit,"def _cleanAsSubunit(self):
        """"""""""""
        for pi in self._entity.ports:
            pi.connectInternSig()
        for i in chain(self._interfaces, self._private_interfaces):
            i._clean()","can be reused. def can_reuse(self): """""""""""" # Disconnect on signals so far, can be reused by parent unit can be reused. if self.reuse: self.reuse = None return self","s. def disconnect(self, signals, val, **kwargs): """""""""""" if signals.is_primary_unit(signals): return self._disconnect(signals, signals, **kwargs) else: return self._disconnect(signals, signals, **kwargs)",29.9071893,27.06408774
generate: Flatten one level of attribute access.,"def visit_Attribute(self, node):
        """"""""""""
        new_node = ast.Name(""%s.%s"" % (node.value.id, node.attr), node.ctx)
        return ast.copy_location(new_node, node)","def flatten(self, attribute): """""" """""" if self.attribute is not None: return attribute if self.attribute is not None: return attribute self.attribute = attribute","def flatten_attribute(self, attr): """""" """""" self.set_attribute(attr) return self.set_attribute(attr)",28.84378142,24.9592485
generate: Deletes an object from the bucket.,"def delete(self, bucket_name, object_name):
        """"""
        
        """"""
        client = self.get_conn()
        bucket = client.get_bucket(bucket_name=bucket_name)
        blob = bucket.blob(blob_name=object_name)
        blob.delete()

        self.log.info('Blob %s deleted.', object_name)","def delete(self, bucket, obj): """""" """""" if obj is None: obj = self._object bucket.delete(bucket) bucket.delete(bucket) bucket.delete(bucket) bucket.delete(bucket) else: bucket.delete(bucket)","def delete(self, bucket): """""" """""" if bucket is None: raise errors.ProcessingBucket(bucket) if bucket is None: raise errors.ProcessingBucket(bucket) return self._delete(bucket)",42.67288321,33.88222719
generate: Provides a client for interacting with the Cloud Spanner API.,"def _get_client(self, project_id):
        """"""
        
        """"""
        if not self._client:
            self._client = Client(project=project_id, credentials=self._get_credentials())
        return self._client","def provide_cloud_request(self, client): """""" """""" if self.request is not None: self.request = client if self.request is not None: self.request.require() else: self.request.require() self.request.require()","def _provider_for_client(self, client): """""" """""" if not self._is_valid(): raise errors.NotFound( 'No client must be client: {}'.format(client)) return client",33.31224737,49.18167074
generate: All assignments to names go through this function.,"def visit_Name(self, node):
        """"""""""""
        if node.ctx == 'store':
            self.identifiers.declared_locally.add(node.name)
        elif node.ctx == 'param':
            self.identifiers.declared_parameter.add(node.name)
        elif node.ctx == 'load' and not \
             self.identifiers.is_declared(node.name):
            self.identifiers.undeclared.add(node.name)","def names_assignments(self, assignments, names_assignments): """""""""""" assignments = self.get_assignments(assignments) assignments = [] for assignment in assignments: assignments.append(assignment) return assignments","def assignments(self, name): """""" """""" if not self._is_alive(): return None # This is assignment for the same name. if not self._is_alive(): raise TypeError(""Can't find any one or "" ""not supported names"") return self._is_alive()",14.48842013,23.69605676
generate: Extract the set of configuration parameters from the properties attached  to the schedule,"def get_config_params(properties):
    '''
    '''
    param = []
    wdef = ''
    for prop in properties.split('\n'):
        if prop.startswith('org.opencastproject.workflow.config'):
            key, val = prop.split('=', 1)
            key = key.split('.')[-1]
            param.append((key, val))
        elif prop.startswith('org.opencastproject.workflow.definition'):
            wdef = prop.split('=', 1)[-1]
    return wdef, param",". def get_configuration_params(self): """""" """""" if self.configuration_params is not None: raise RuntimeError(""Cannot extract the configuration parameters from the properties"") try: return self.configuration_params[self.configuration_params] except KeyError: raise RuntimeError(""Cannot extract the configuration parameters from the properties"")","def set_config(self, input_set): """""" """""" url = self._url + '/set/configurations/list/set' if not self.contains_platform_access(): raise RuntimeError(""Unable to set configurations: {0}"".format(self._url)) self._set_config_set(input_set) self._set_config(url, None) self._set_config(self._get_config(self._config_path), True)",26.87990589,15.69647893
generate: Display the DataFrame from row i1 till i2,"def cat(self, i1, i2, format='html'):
        """"""
        """"""
        from IPython import display
        if format == 'html':
            output = self._as_html_table(i1, i2)
            display.display(display.HTML(output))
        else:
            output = self._as_table(i1, i2, format=format)
            print(output)","till items. def dframe(self, rows): """""" """""" till = self.get_till(rows) return self.dframe(till)",". def display(self, data, error): """""" """""" # If we'll do not first, return the dataframe # the error # Update the size of the error if self.error_type == 'Exception': self.error_type = error else: self.error_type = error # Stop the documentation if error.error_type == 'Type': self.error_type = error self.error_type = error else: self.error_type = error return self",9.215222616,19.19219146
"generate: Santizes the data for the given block.    If block has a matching embed serializer, use the `to_internal_value` method.","def sanitize_block(self, block):
        """"""""""""

        embed_type = block.get('type', None)
        data = block.get('data', {})
        serializer = self.serializers.get(embed_type, None)

        if serializer is None:
            return block

        block['data'] = serializer.to_internal_value(data)

        return block","def _get_data(self, block, query_type, **kwargs): """""" """""" # Add the data to the block, then the data if block.is_authenticated(): return block.data # Return the value of the data # Add the data return self._get_data(block, query_type)","def any_block(self, innal_value, block_size=10): """""" """""" if not block_size: return None block = self.get_block(innal_value) if block_size: block_size = block_size else: block_size = block_size return block",38.04463416,41.34498427
generate: Returns a new DataFrame where the virtual column is turned into an in memory numpy array.,"def materialize(self, virtual_column, inplace=False):
        '''
        '''
        df = self.trim(inplace=inplace)
        virtual_column = _ensure_string_from_expression(virtual_column)
        if virtual_column not in df.virtual_columns:
            raise KeyError('Virtual column not found: %r' % virtual_column)
        ar = df.evaluate(virtual_column, filtered=False)
        del df[virtual_column]
        df.add_column(virtual_column, ar)
        return df","def _get_discard_memory_for_discard_memory(self, display_name, input_memory, **kwargs): """""""""""" virtual_colors = self.get_discard_memory_for_discard_memory_for_discard_memory(display_name) if virtual_colors is not None: virtual_colors = virtual_colors.split(""."") return virtual_colors","def get_dframe_wrapper(self, virtual_column): """""" """""" # For We'll contains any data type self.df = VirtualDataFrameWrapper(virtual_column) self.df = DataFrameWrapper(self, virtual_column) self.df = DataFrameWrapper(self.df, virtual_column) self.df.column = VirtualDataFrameWrapper(self.df, virtual_column) self.df = DataFrameWrapper(self.df, virtual_column) self.df.column = VirtualDataFrameWrapper(self.df, virtual_column) self.df.column = VirtualDataFrameWrapper(self.df, virtual_column) self.df.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.column.col",27.99463188,26.56445992
generate: List quizzes for a given course,"def get_quizzes(self, course_id):
        """"""
        
        """"""
        url = QUIZZES_API.format(course_id)
        data = self._get_resource(url)
        quizzes = []
        for datum in data:
            quizzes.append(Quiz(data=datum))
        return quizzes","or corresponding with an interpreter. def list_quizzes(self, quizzes): """""""""""" quizzes = [] for quizz in quizzes: quizzes.append(quizz) return quizes","-name. def quizes_quizes(self, quizes): """""" """""" for course_name in self._course_name: if course_name == course_name: return self._course_name return self._course_name",43.18330075,38.08615202
generate: Converts a list into a list of lists with equal batch_size.,"def batch_list(sequence, batch_size, mod = 0, randomize = False):
    '''
    
    
    '''

    if randomize:
        sequence = random.sample(sequence, len(sequence))

    return [sequence[x:x + batch_size] for x in xrange(0, len(sequence)-mod, batch_size)]","def convert_lists(self, batch_size): """""""""""" batch_size = [] if batch_size == []: batch_size = self.batch_size if batch_size == 0: batch_size = self.batch_size return batch_size","def _create_batch_size(self, batch_size, batch_size, batch_size, points): """""" """""" if batch_size > batch_size: raise ValueError(""Batch_size must be a batch_size."") if batch_size > self.size: raise ValueError(""Batch_size must be a batch_size:"" + batch_size) return batch_size",31.91000728,30.18231044
"generate: Helper property containing the percentage this slider is ""filled"".        This property is read-only.","def p(self):
        """"""
        
        """"""
        return (self.n-self.nmin)/max((self.nmax-self.nmin),1)","def only_filled(self, filled): """""""""""" slider = self._slider # Make the filled with the ""filled"". if filled is not None: filled = filled.get(filled) return filled","def _get_all_plot(self, plot_id, plot_id): """""" """""" plot_id = self._get_plot_id(plot_id, plot_id) return self._get_percentage_percentage(plot_id, plot_id, plot_id)",15.92102791,19.24127244
generate: Return a batch client with same settings of the client,"def batch_client(self, size=512):
        # type: (int) -> BatchClient
        """"""""""""

        batch_client = BatchClient(self.host, self.port, self.prefix, size)
        self._configure_client(batch_client)
        return batch_client","with the given IP address. def get_batch_client(self, client): """""" """""" batch_client = self._client_with_client(client) if batch_client is None: return batch_client return batch_client",". def get_batch_client_client(self): """""" """""" if self._build_client_list: batch_client = self._build_client_client(self._build_client_list) else: batch_client = self._build_client_client(self._build_client_list) return batch_client",55.63657113,49.43262264
"generate: Convert a function based decorator into a class based decorator usable	on class based Views.","def view_decorator(function_decorator):
	""""""
	""""""

	def simple_decorator(View):
		View.dispatch = method_decorator(function_decorator)(View.dispatch)
		return View

	return simple_decorator","def class_name(func): """""" """""" @wraps(func) def decorator(*args, **kwargs): """"""Class instead of decorators """""" def decorator(*args, **kwargs) return decorator(*args, **kwargs) return decorator","def _fn_default_decorator(self, decorator): """""" """""" # Format the decorator decorator.update(decorator) # Determine a function for element decorator.update(decorator) return decorator",44.41039938,49.36515851
generate: set a Boolean-valued debugger setting. 'obj' is a generally a  subcommand that has 'name' and 'debugger.settings' attributes,"def run_set_bool(obj, args):
    """"""""""""
    try:
        if 0 == len(args): args = ['on']
        obj.debugger.settings[obj.name] = get_onoff(obj.errmsg, args[0])
    except ValueError:
        pass
    return",". def set_boolean_valued(self, name, obj, obj, **kwargs): """""" """""" if obj is None: obj = self._get_boolean_value(name, obj) self.set_boolean_value(name, obj, obj, **kwargs) return self",". def set_subcommand(self, subcommand, subcommand): """""" """""" try: subcommand = subcommand.split(':', 1) except AttributeError as e: # if not only works: pass return subcommand",31.28928395,32.34193521
"generate: When dispatched on loops, has_context the target vars are the attribute _target_vars.","def has_context_loop(state, incorrect_msg, exact_names):
    """"""
    """"""
    return _test(
        state,
        incorrect_msg or MSG_INCORRECT_LOOP,
        exact_names,
        tv_name=""_target_vars"",
        highlight_name=""target"",
    )","def dispatch_target_vars(target_vars, description_name, context_name): """""" """""" if description_name in target_vars: return target_vars[description_name] if description_name in target_vars: return target_vars[description_name] return target_vars[description_name]","def target_vars(self, target_vars): """""" """""" if self._loop_context is not None: return self._loop_context.dispatch_loop else: return self._loop_context.dispatch_loop",27.58189977,30.86703002
generate: Enables persistent mode for the current mock.,"def persist(self, status=None):
        """"""
        
        """"""
        self._persist = status if type(status) is bool else True","def enable_mode(self): """""" """""" self.mode = self.mode self.call = self.call self.mode = self.mode","def enable_persistent_mode(self, mode): """""" """""" url = self._get_url(mode) if self._mode == 'POST': return self._persistent_mode(url) else: return self._persistent_mode(url)",30.67728972,30.72940727
generate: Set the session state.,"async def set_session_state(self, state):
        """"""

        """"""
        await self._can_run()
        state = state.encode(self.encoding) if isinstance(state, six.text_type) else state
        return await self._mgmt_request_response(
            REQUEST_RESPONSE_SET_SESSION_STATE_OPERATION,
            {'session-id': self.session_id, 'session-state': bytearray(state)},
            mgmt_handlers.default)","def set_state(self, state, name, url=None): """""" """""" if name is None: name = self.name self.session_state = self.session_state if self.session_state is None: self.session_state = self.session_state self.session_state = self.session_state self.session_state = self.session_state self.session_state = self.session_state","def set_state(self, session, state): """""" """""" session = self._get_session() if self._state is None: self._state_state = state.session if self._state is None: self._state_state = state.session self._state_state = state.session return session",39.26469301,38.93280817
generate: Resets the state required for this actor to the default state.        Currently resets the matrix to its previous translation.,"def unset_state(self):
        """"""
        
        """"""
        x,y,z = self.obj.pos
        glTranslatef(-x,-y,-z)","def set_state(self, state, state): """""" """""" state = self.state if state is None: state = self.state state.close() self.state = state","def reset_to_state(self, state, state): """""" """""" if state =='state': return self.reset_to_state(state) else: raise ValueError(""Specified `state` should be installed as a state."")",27.14268692,19.08603433
generate: Expand a nodes compressed sequence into the real sequence,"def expanded_sequence(self, node, include_additional_constant_sites=False):
        """"""
        
        """"""
        if include_additional_constant_sites:
            L = self.seq_len
        else:
            L = self.seq_len - self.additional_constant_sites

        return node.cseq[self.full_to_reduced_sequence_map[:L]]",". def error_real_sequence(nodes, nodes): """""" """""" if nodes == []: return nodes if nodes == []: return nodes elif isinstance(nodes, list): return nodes else: raise TypeError(""nodes compressed sequence must be a list of list of list of strings, or a list of strings"")","and relations in the nodes. def expand_sequence_sequence(self, sequence, tag): """""" """""" self.relations[sequence] = sequence self.relations[sequence] = sequence self.relations[sequence] = relations",31.27275491,36.83478588
"generate: For each string, find the count of all possible substrings with 2 characters or more that are contained in    the line-separated text file whose path is given.","def num_valid_substrings(self, path_to_words):
        """"""
        
        """"""
        assert_is_type(path_to_words, str)
        fr = H2OFrame._expr(expr=ExprNode(""num_valid_substrings"", self, path_to_words))
        fr._ex._cache.nrows = self.nrow
        fr._ex._cache.ncol = self.ncol
        return fr","def find_possible_substrings(self, path, text): """""" """""" possible_lines = self.populate_possible_lines(path) for possible_lines in possible_lines: text = text.replace(""{0}{1}"".format(possible_lines, possible_lines), ""{0}"".format(possible_lines, possible_lines)) return text","def find_possible_substrings(self, possible): """""" """""" if possible: possible_substring = self._get_possible_substrings(possible) else: possible_substring = self._get_possible_substrings(possible) return possible_substrings(possible_substring)",28.29014351,31.29196169
generate: Call the method repeatedly such that it will return a PKey object.,"def check_success(self):
        """"""
        
        """"""
        small = xrange(3)
        for i in xrange(self.iterations):
            key = PKey()
            key.generate_key(TYPE_DSA, 256)
            for i in small:
                cert = X509()
                cert.set_pubkey(key)
                for i in small:
                    cert.get_pubkey()","def _get_method_repeated(self): """""" """""" method = self.method_repeated if method.repeated: return method.repeated raise NotImplementedError(""An Method {0} is not implemented."".format(self.method))","def _get_method(self, project_name, method): """""" """""" url = self._get_method_url(project_name) if url.startswith(""/""): url = url_path + ""/method"" return self._get_request(url, method=method, data=data)",19.11729042,18.73611418
generate: Find all entry points in a group.,"def get_group_all(group, path=None):
    """"""
    """"""
    result = []
    for config, distro in iter_files_distros(path=path):
        if group in config:
            for name, epstr in config[group].items():
                with BadEntryPoint.err_to_warnings():
                    result.append(EntryPoint.from_string(epstr, name, distro))

    return result","def entry_points(self, entry_points, entry_points=None): """""" """""" points = [] for point in self.points: if point.entry_points is not None: if point.entry_points is not None: points.append(point.entry_points) else: points.append(point.entry_points) return points","If the group is valid, so we remove it. def find_entry_points(entry_points, points=None): """""" """""" if points is None: points = split_points(entry_points) if points is None: points = split_points(entry_points) else: points = split_points(entry_points, points) return split_points(entry_points, points)",28.78952912,24.12350582
generate: Creates the sentence alignment of two texts.,"def align_texts(source_blocks, target_blocks, params = LanguageIndependent):
    """"""
    """"""
    if len(source_blocks) != len(target_blocks):
        raise ValueError(""Source and target texts do not have the same number of blocks."")
    
    return [align_blocks(source_block, target_block, params) 
            for source_block, target_block in zip(source_blocks, target_blocks)]","def sentence_sentence(self, texts, sentence_types, two_sentence_length, texts, texts, two_sentence_length): """""" """""" texts = [] texts = [] for two_sentence_length in texts: texts.append(two_sentence_length) texts.append(two_sentence_length) texts.append(texts) return texts","def sentence_count(self, text): """""" """""" if not self.is_valid(): raise ValueError('Unknown entry: %s' % text) self.sentence_count = self.sentence_count if not self.sentence_count: raise ValueError('Unknown entry: %s' % text) if self.sentence_count == 1: return self.sentence_count else: raise ValueError('Unknown entry: %s' % self.sentence_count)",20.58340846,25.03871756
generate: Get key from connection or default to settings.,"def get_setting(connection, key):
    """"""""""""
    if key in connection.settings_dict:
        return connection.settings_dict[key]
    else:
        return getattr(settings, key)","def get_key(self, key): """""" """""" if self.key == '_settings': return self.settings.get(key) elif self.key =='settings': return self.settings.get(key) else: return self.settings.get(key)","def get_connection_media(self, key): """""" """""" key = self._connection_media.get(key) if key in self._connection_media.keys(): return self._connection_media.get(key) else: return self._connection_media.get(key)",44.45242394,43.12636338
generate: Sets the state required for this actor.        Currently translates the matrix to the position of the actor.,"def set_state(self):
        """"""
        
        """"""
        x,y,z = self.obj.pos
        glTranslatef(x,y,z)","def set_state_required(self, actor): """""""""""" self.state_required = True self.state_required = True","def setup_for_state(self, state_required): """""" """""" self._setup_for_state(state_required) self._setup_for_state(state_required) self._setup_for_state(state_required) self._setup_for_state(state_required)",31.85813909,16.32453303
generate: Attach a class to a parsing decorator and register it to the global    decorator list.    The class is registered with its name unless directname is provided,"def decorator(directname=None):
    """"""
        
    """"""
    global _decorators
    class_deco_list = _decorators

    def wrapper(f):
        nonlocal directname
        if directname is None:
            directname = f.__name__
        f.ns_name = directname
        set_one(class_deco_list, directname, f)

    return wrapper",". The function is a list of function name to the class instance. The class name is a list of class name is registered. def register_class(self, function): """""" """""" @wraps(function) def function(*args, **kwargs): return function(*args, **kwargs) return self",". def register(self, classname, *args, **kwargs): """""" """""" if not self._decorated: raise ValueError(""Unexpected classname or name "" ""decorated classname"") if classname: raise ValueError(""Unable to register decorator %s"" % classname) return self._decorator(self.classname, *args, **kwargs)",30.03522787,36.04507611
generate: Get proportion of GC from a string,"def _gc_prop(s, length):
        """"""
        """"""

        gc = sum(map(s.count, [""c"", ""g""]))

        return gc / length",". def get_proportion(self, text=None, key=None): """""" """""" try: return self._proportion_proportion(text=text) except IndexError: return None",". def get_proportion(self, string): """""" """""" if not self.strip_proportion: return None return string",20.18308449,27.89719016
generate: Returns True if node_type == value.,"def is_type(self, value):
    """"""
    """"""
    if isinstance(value, tuple):
      for opt in value:
        if self.node_type == opt:
          return True
      return False
    else:
      return self.node_type == value","def get_value(self, node_type, value): """""" """""" if node_type == value: return False if node_type == value: return True if node_type == value: return True return False","def input_type(self, val): """""" """""" if self._node_type == ""node_type"": return True if val.startswith(""node_type""): return False if val.startswith(""node_type""): return True return False",67.5188106,57.97759462
generate: This runs the protocol on port 8000,"def main():
    rollbar.init('ACCESS_TOKEN', environment='test', handler='twisted')

    """"""""""""
    factory = protocol.ServerFactory()
    factory.protocol = Echo
    reactor.listenTCP(8000, factory)
    reactor.run()",". def run_protocol(self): """""""""""" if self.protocol_confirm: self.protocol_confirm = self.protocol_confirm else: self.protocol_confirm = self.protocol_confirm return self.protocol_confirm","and records and their starting another server. def records_server(self): """""" """""" try: self.ports.remove(""ports"") except AttributeError: # This is an id to the protocol. # This is an exception to the port, then we should be in the server. self.ports.remove(""ports"") raise self.ports.remove(""ports"") return self.ports",20.97951955,13.12815228
generate: Add email header info.,"def _add_header(self):
        """"""""""""
        self.message[""From""] = self.from_
        self.message[""Subject""] = self.subject
        if self.to:
            self.message[""To""] = self.list_to_string(self.to)
        if self.cc:
            self.message[""Cc""] = self.list_to_string(self.cc)
        if self.bcc:
            self.message[""Bcc""] = self.list_to_string(self.bcc)","def add(self, request, message, **kwargs): """""" """""" if self.auth is None: self.auth = None self.auth = None self.auth = None self.auth = None self.auth = None self.add_headers(self.auth) self.auth = None self.auth = None self.body = None self.body = None self.body = None else: self.body = None self.body = None if self.body is None: self.body = None self.body = body","def add_header(self, request): """""" """""" headers = self.header.get('headers', None) headers.update(request) headers.update(request.header) headers.update(headers) headers.update(headers) headers.update(headers) self.headers['Content-Type'] = headers",33.25369298,16.81955217
"generate: Run all abort tasks, then all exit tasks, then exit with error    return status","def abort(self, signum):
        """""" """"""
        self.log.info('Signal handler received abort request')
        self._abort(signum)
        self._exit(signum)
        os._exit(1)",". def _exit_tasks(self): """""" """""" tasks = self.tasks tasks = [] for task in self.tasks: if task.status!= 'FAIL': tasks.append(task) tasks.append(task) return tasks","defined on the given files. def run(self, tasks): """""" """""" self.logger.debug(""Please run"") tasks.set_error(""Error operation status %s"", tasks) return tasks",22.90341427,27.55676708
generate: Yield names and strings used by `code` and its nested code objects,"def iter_symbols(code):
    """"""""""""
    for name in code.co_names:
        yield name
    for const in code.co_consts:
        if isinstance(const, basestring):
            yield const
        elif isinstance(const, CodeType):
            for name in iter_symbols(const):
                yield name",". def get_code(code): """""""""""" if not code: return for k, v in six.iteritems(code): if k not in (None, ""none""): return None if k in code: return k for k, v in six.iteritems(code): if k in code: return k return None",". def get_code_by_code(self, key_name, code): """""" """""" code = self.code_objects.get(key_name) if code.is_valid(): code.copy() code.copy() return code",34.42024388,21.64775836
generate: Helper to merge which handles merging one value.,"def _merge(self, old, new, use_equals=False):
    """"""""""""
    if old is None:
      return new
    if new is None:
      return old
    if (old == new) if use_equals else (old is new):
      return old
    raise ValueError(""Incompatible values: %s != %s"" % (old, new))","def merge_value(self, value): """""" """""" if isinstance(value, Variable): value = value.replace(""_"", ""_"") elif isinstance(value, Variable): value = value.replace(""_"", ""_"") elif isinstance(value, Variable): value = value.replace(""_"", ""_"") return value","def merge_wrapper(self, merge_response): """""" """""" if self._merge_response is not None: self._merge_response(merge_response) self._merge_response(merge_response) else: self._merge_response(merge_response)",24.95551201,22.12384573
generate: Returns whether or not this dependency is met for a given task instance. A    dependency is considered met if all of the dependency statuses it reports are    passing.,"def is_met(self, ti, session, dep_context=None):
        """"""
        
        """"""
        return all(status.passed for status in
                   self.get_dep_statuses(ti, session, dep_context))","def is_metadata(self): """""" """""" dependency = self.get_dependency_attributes(self.dependency) if not dependency: return False return True","def get_dependency(self, dependency_id): """""" """""" if not self._dependency_id: return None if dependency_id: return self._dependency_id else: return dependency_id",38.69530719,31.96173715
generate: Get a list of keys for the accounts,"def list(self, s3_folder='', full_key_data=False):
        """"""""""""
        if not s3_folder.startswith('/'):
            s3_folder = '/' + s3_folder

        s3_prefix = self.prefix + s3_folder

        bucket_data = self.client.list_objects(Bucket=self.bucket, Prefix=s3_prefix)

        if full_key_data:
            return bucket_data['Contents']
        else:
            return [k['Key'] for k in bucket_data['Contents']]","def get_access_keys(self, key_list): """""" """""" keys = [(key, self.access_key) for key, self in key_list] for key in keys: if isinstance(key, dict): return [self.get_access_key(key) for key in key] return [self.get_access_key(key) for key in keys]",". def get_accounts(self): """""" """""" keys = [self.accounts[key]] if self.accounts[key] not in self.accounts[keys]: keys = [self.accounts[key] for key in self.accounts[key]] else: keys = [self.accounts[key] for key in self.accounts[key]] return [key for key in keys if key not in self.accounts[key]]",24.54814902,24.59184882
generate: Gets or creates the last update object for this widget.,"def get_last_update(self):
        """"""""""""
        instance, created = \
            models.DashboardWidgetLastUpdate.objects.get_or_create(
                widget_name=self.get_name())
        return instance","def get_last_update(self, widget, update_id, widget): """""""""""" return self.create_update(widget, widget, widget, widget)","def get_update_object_for_update(self, name=None, modify=True, **kwargs): """""" """""" try: response = self.get_current_object(name, modify=modify) return response.get(name, None) except Exception as e: raise e",40.80237442,35.21770646
generate: Called by the PDFLite object to prompt creating,,,,,
      the font objects.,"def _output_fonts(self):
        """""" """"""
        self.session._save_object_number()
        self._output_encoding_diffs()
        self._output_font_files()

        for font in self.fonts:
            obj = self.session._add_object()
            font._set_number(obj.id)
            font._output()","def called_permission(self, uri, **kwargs): """""" """""" self._creat_data_objects.update(uri, **kwargs) self._creat_data_objects.update(uri, **kwargs) self._creat_data_objects.update(uri, **kwargs) self._creat_data_objects.update(uri, **kwargs)","def _prompt_pdflt(self, url, pdflt_object): """""" """""" if url.endswith('/'): return self.wrap_response(url, pdflt_object=pdflt_object) else: return None",29.51889867,20.07106538
generate: Verify signature certificate URL against Amazon Alexa requirements.,"def verify_sc_url(url: str) -> bool:
    """"""
    """"""
    parsed = urlsplit(url)

    scheme: str = parsed.scheme
    netloc: str = parsed.netloc
    path: str = parsed.path

    try:
        port = parsed.port
    except ValueError:
        port = None

    result = (scheme.lower() == 'https' and
              netloc.lower().split(':')[0] == 's3.amazonaws.com' and
              path.startswith('/echo.api/') and
              (port == 443 or port is None))

    return result","def Verify(self, certificate_url, url_url): """""" """""" if certificate_url == '/ALLOGE:': return self.v1.get_v1(url_url) elif certificate_url == '/ALLOGE:': return self.v1.get_v2(url_url) elif certificate_url == '/ALLOGE: return self.v1.get_v1(url_url) elif certificate_url == '/ALLOGE: return self.v1.get_v2(url_url) else: return self.v1.get_v1(url_url)","def apply_signature_certificate_certificate(self, signature, apply_signature): """""""""""" try: self.signature.add_signature(signature, signature) except AttributeError: raise AttributeError(""Signature certificate must be an "" ""certificated Application"") try: self.signature.add_signature(signature) except AttributeError as e: self.signature.add_signature(signature) self.signature.add_signature(signature) return self",18.42872585,17.78105627
"generate: Execute `callback` corresponding to `msg` reply, after ``_silent_exec_callback``","def _handle_exec_callback(self, msg):
        """"""

        """"""

        user_exp = msg['content'].get('user_expressions')
        if not user_exp:
            return
        for expression in user_exp:
            if expression in self._callback_dict:
                self._callback_dict.pop(expression)(user_exp[expression])","def execute_callback(self, msg, signatures): """""""""""" if signatures is None: signatures = self.callback signatures = self.execute_silent_exec_callback(msg) callback = callback(silent_exec_callback, callback) return callback",". def call_callback(self, other): """""" """""" if not self.is_begin_execute(other): return None if not self.is_executor(other): return None try: return self.callback(other) except Exception as e: return None",36.88998364,35.28131706
generate: Exports the DataFrame to a vaex hdf5 file,"def export_hdf5(self, path, column_names=None, byteorder=""="", shuffle=False, selection=False, progress=None, virtual=False, sort=None, ascending=True):
        """"""
        """"""
        import vaex.export
        vaex.export.export_hdf5(self, path, column_names, byteorder, shuffle, selection, progress=progress, virtual=virtual, sort=sort, ascending=ascending)",". def export_df(self, export_file, error_id, **kwargs): """""" """""" if export_file is None: # Make the document df = open(export_file, 'rb') df.seek(0) if export_file is None: df.seek(0) df.seek(0) df.seek(0) df.seek(0) return df",". def export_hdf5(self, hdf5, dest_file, dest_file): """""" """""" url = '%s/vax5' % (dest_file, dest_file) if dest_file.endswith(dest_file): url = hdf5.read(dest_file) if dest_file.endswith('/'): url = self._get_url(dest_file) response = self._get(url) if response.status_code == 'json': response.raise_for_status() else: response.raise_for_status()",19.53611634,22.21567167
"generate: Fit all the transforms one after the other and transform the    data, then fit the transformed data using the final estimator.","def fit(self, Z, **fit_params):
        """"""
        """"""
        Zt, fit_params = self._pre_transform(Z, **fit_params)
        self.steps[-1][-1].fit(Zt, **fit_params)
        Zt.unpersist()
        return self","def _fit_transform(self, fits): """""" """""" data = self.fit_transform(fits) if not data: self.fit_transform(fits) if self.final_data: self.fit_transform(fits)","def fit_transforms(self, transforms=1): """""" """""" transforms = [] for data in self.flatten: transforms.append(data) transforms.append(data) return transforms",40.95154644,36.43873416
generate: Increment the monitor with N units worked and an optional message,"def update(self, units: int=1, message: str=None):
        """"""""""""
        if self.total is None:
            raise Exception(""Cannot call progressmonitor.update before calling begin"")
        self.worked = min(self.total, self.worked+units)
        if message:
            self.message = message
        for listener in self.listeners:
            listener(self)","def _init_monitor(self, monitor): """""" """""" # Creating an optional message monitor = monitor.get_message() if monitor is not None: # Update the monitor is anopy monitor.update(monitor) monitor.update(monitor) return monitor","s. def _call_messages(self, message): """""""""""" message = message['message'] if not message['is_valid']: raise exceptions.APIError('Please calling message: %s' % message['id']) else: message['is_valid'] = message['is_valid'] message['is_valid'] = message['is_valid'] message['is_valid'] = message['is_valid'] return message['is_valid']",30.56470231,30.22985653
generate: Exclude any apparent package that apparently doesn't include its    parent.,"def require_parents(packages):
        """"""
        
        """"""
        found = []
        for pkg in packages:
            base, sep, child = pkg.rpartition('.')
            if base and base not in found:
                continue
            found.append(pkg)
            yield pkg","def _exclude_appparent_package(self, package): """""" """""" try: return self.appparent_package(package) except Exception as exc: raise MultiplePackage(exc)","def package_package(self, package): """""" """""" if package.is_manifest(): package = package.package package = self._get_package(package) if not package: return else: return None",28.18463992,29.91938879
generate: Get available marts and their names.,"def get_marts(self):
        """"""""""""

        mart_names = pd.Series(self.names, name=""Name"")
        mart_descriptions = pd.Series(self.displayNames, name=""Description"")

        return pd.concat([mart_names, mart_descriptions], axis=1)","def get_marts(self, marts, names, names=None): """""" """""" if names is None: names = self.get_marts(names) marts = self.get_marts(names) if marts is None: return None return marts","def get_marts_by_name(self, name_name): """""" """""" if name_name == '' and name_name in self.marts_by_name: return self.marts_by_name[name_name] else: raise ValueError('No marts_by_name_name is not found.')",44.75809604,35.38506772
generate: virtue discovers and runs tests found in the given objects.,"def main(context, **kwargs):
    """"""
    

    """"""

    result = run(**kwargs)
    context.exit(not result.wasSuccessful())","def fail(self, *args): """""" """""" if not self.is_done: raise IOError(""This object is a valid object, found."") done = self.done if done: return self.create_done(args) else: return self.create_done(args)","def _get_objects(self): """""" """""" obj = self._objects.get(self.object_name) if not obj: return obj if not obj.is_valid(): return obj return obj",18.08993382,17.27166988
generate: Encode argument to be sent in a valid GuacamoleInstruction.,"def encode_arg(arg):
        """"""
        
        """"""
        arg_utf8 = utf8(arg)

        return ELEM_SEP.join([str(len(str(arg_utf8))), str(arg_utf8)])","def encode(self, url): """""" """""" # NOTE: This is a function for failure? url = ""%s"" % url return self.encode(url)","def encode_guacamole_info(self): """""" """""" if self._guacamole_info: raise RuntimeError(""Unable to set"") return self._guacamole_info",29.04720405,26.79112722
generate: Send a GetAttributeList request to the server.,"def get_attribute_list(self, uid=None):
        """"""
        
        """"""
        batch_item = self._build_get_attribute_list_batch_item(uid)

        request = self._build_request_message(None, [batch_item])
        response = self._send_and_receive_message(request)
        results = self._process_batch_items(response)
        return results[0]","def __get_attribute_List(self, server_name, **kwargs): """""""""""" if server_name in self.__list_attribute_List: # Implemented from template for - # osid.resource.ResourceApplication if self.__list_attribute_List[server_name] == self.get_attribute_List[server_name]: return self.__list_attribute_List[server_name] return self.__list_attribute_List[server_name]","def set_ast_request(self, ast_response): """""" """""" ast_response = self._get_response_response(self.api_url) response = self._request_request(api_url=api_url, data=response.json()) self.logger.debug(""Sending GetAttributeList"") return response",31.4328908,43.28634877
generate: Clear out cache for api_path_map.,"def clear_api_path_map_cache(self):
        """"""""""""
        self._api_path_cache = None
        for api_provider in self.api_providers:
            if six.get_method_self(
                api_provider.clear_api_path_map_cache,
            ) is not None:
                api_provider.clear_api_path_map_cache()","def cache_cache(self, url, path, cache_path_map): """""""""""" path_map = [] for path in self._cache_path_map: path_map.append(path) path_map.append(path) if path_map: cache_path_map = [path_map] path_map.append(path) return path_map","def clear_cache_path(self): """""" """""" if not self.cache_path: self._cache_path = self._cache_path if not self.cache_path: self._cache_path = self._cache_path return self._cache_path",38.79998325,34.95344815
generate: Render the rel=prev and rel=next links to a Markup object for injection into a template,"def render_prev_next_links(self, scheme=None):
        """"""""""""
        output = ''

        if self.has_prev:
            output += '<link rel=""prev"" href=""{}"" />\n'.format(self.get_full_page_url(self.prev, scheme=scheme))
        
        if self.has_next:
            output += '<link rel=""next"" href=""{}"" />\n'.format(self.get_full_page_url(self.next, scheme=scheme))

        return Markup(output)",". def render(self, markup=None, links=None): """""" """""" links = [] if not markup: markup = markup if links: links.append(self.markup.get(links)) if not markup: markup = markup if markup: links.append(markup) return links",". def render_rel(self, rel): """""" """""" rel_path = self._get_rel_path(rel) rel_path = rel_path.get('rel_path') if rel_path.endswith('.'): rel_path = rel_path.split('.') rel_path = rel_path.split('.') rel_path = rel_path.split('.') else: rel_path = rel_path.split('.') rel_path = rel_path.split('.') rel_path = rel_path.split('.', 1) rel_path = rel_path[1:] return self._get_rel_rel(rel_path)",20.88984678,21.23761107
generate: Create regex and return. If error occurs returns None.,"def _create_regex(self, line, intent_name):
        """"""  """"""
        try:
            return re.compile(self._create_intent_pattern(line, intent_name),
                              re.IGNORECASE)
        except sre_constants.error as e:
            LOG.warning('Failed to parse the line ""{}"" '
                        'for {}'.format(line, intent_name))
            return None","def _regex_regex(self, regex): """""""""""" if regex is None: raise ValueError(""regex must be an error occurs return. It "" ""for error occurs return."") if regex.startswith(""/""): raise ValueError(""regex must be an error occurs."") if regex.endswith(""/""): return regex[-1] else: return regex","def create_regex(self, regex, state_name, regex, state_name, regex_name, regex_name, valid_state, valid_state_name, regex_name): """""" """""" try: regex = re.compile(regex_name, regex) if regex_name in regex_name: return regex else: return regex_name except KeyError: pass",26.904882,41.08519734
generate: Setup logging for the application and aiohttp.,"def _setup_logging(self, log_level: str):
        """"""""""""
        level = getattr(logging, log_level)
        names = (
            'aiohttp.access', 'aiohttp.internal', 'aiohttp.server',
            'aiohttp.web', self.name)
        for name in names:
            setup_logger(name=name, stream=sys.stderr, level=level)","def setup_logging_logging(self, api, host, port, timeout=None, timeout=None): """""" """""" host, host = self.get_log_host(host, timeout) if not host: host = host if timeout is None: timeout = self.get_log_host(host, timeout) self.setup_log_log_log_log_log_log_log_log_log_logger(host)","def setup_logging_logger_response(self, log_message, logging.DEBUG): """""" """""" logging.debug('Application logging logging logging logging logging logging logging logging.') self._setup_logger_response(logging.DEBUG)",29.99163674,29.99351434
generate: Return a connected Bitbucket session,"def connect(url, username, password):
    """"""
    
    """"""

    bb_session = stashy.connect(url, username, password)

    logger.info('Connected to: %s as %s', url, username)

    return bb_session",". def connectedBitbucket(self, session=None): """""""""""" bitbucket = self.bitbucket.get_bitbucket_session() return self.connectedBitbucket.get_bitbucket(session=bitbucket)",". def get_bitbucket_session(self, bitbucket): """""" """""" if not self._connected: raise error.BitbucketSyntaxError( 'SyntaxError: Unknown bitbucket: %s' % bitbucket) return bitbucket.session.get_bitbucket_session()",34.12955743,28.46194478
generate: Call this on an lxml.etree document to remove all namespaces,"def remove_namespaces(root):
    """"""""""""
    for elem in root.getiterator():
        if not hasattr(elem.tag, 'find'):
            continue

        i = elem.tag.find('}')
        if i >= 0:
            elem.tag = elem.tag[i + 1:]

    objectify.deannotate(root, cleanup_namespaces=True)",". def _call(self, namespace, document): """""""""""" document = document.split(""."")[0] for m in document: # Set all the documents in an lxml for m in m.group(1): document = m.group(1) document.append(m) return document",". def remove_all_namespaces(self, namespaces): """""" """""" namespaces = self.get_namespaces() if not namespaces: return None if not namespaces: raise ValueError(""No namespaces not found."") if not namespaces: raise ValueError(""No namespaces"") return None",22.2521626,29.13595741
generate: Tell postgres to encrypt this field using PGP.,"def get_placeholder(self, value=None, compiler=None, connection=None):
        """"""""""""
        return self.encrypt_sql.format(get_setting(connection, 'PUBLIC_PGP_KEY'))","def tell(self, field, postgres=None): """""""""""" if field == 'ENC': postgres = self.encrypt(field, postgres) return postgres return self","def encrypt(self, pgp, fields): """""" """""" pgp.update(fields) pgp.update(self.get_pgp()) return pgp",33.45091752,22.716691
generate: Parse a list of config files followed by extra Gin bindings.,"def parse_config_files_and_bindings(config_files,
                                    bindings,
                                    finalize_config=True,
                                    skip_unknown=False):
  """"""
  """"""
  if config_files is None:
    config_files = []
  if bindings is None:
    bindings = ''
  for config_file in config_files:
    parse_config_file(config_file, skip_unknown)
  parse_config(bindings, skip_unknown)
  if finalize_config:
    finalize()","def parse_config_files(config_files, filters=False): """""" """""" config_files = [config_file] if not filters: raise RuntimeError('Unsupported filters') config_files = [] for filter_file in filters: if filter_file.name: config_files.append(filter_file) config_files.append(config_files) return config_files","def parse_gin_bindings(self): """""" """""" if not os.path.exists(self.config_file): return for filename in os.path.exists(self.config_file): if not os.path.exists(filename): return if not os.path.isdir(filename): return return None",50.13668087,24.70383615
generate: Subscribe to the passed pair's raw order book channel.,"def subscribe_to_raw_order_book(self, pair, prec=None, **kwargs):
        """"""
        """"""
        identifier = ('raw_book', pair)
        prec = 'R0' if prec is None else prec
        self._subscribe('book', identifier, pair=pair, prec=prec, **kwargs)","def _subscribe_pair(self, pair_pair, passed_pair, pair_pair): """""" """""" if pair_pair in self.pairs: return self.pairs[pair_pair] else: return self.pairs[pair_pair]","def screen_pair(self, passed): """""" """""" if self._client.get('POST', None): passed = self._client.get('POST', None) else: passed = self._client.get('POST', None) return passed",31.65342998,27.53026922
generate: Save verifier to database.,"def save_verifier(self, token, verifier, request):
        """"""
        """"""
        log.debug('Save verifier %r for %r', verifier, token)
        self._verifiersetter(
            token=token, verifier=verifier, request=request
        )","def save_verifier(self, verifier, verifier, verifier_name, cache_type=None): """""" """""" return self.save_verifier(verifier, verifier, verifier, verifier, verifier_name, verifier, verifier)","def save_verifier(self, key_name, config_path): """""""""""" self.logger.info(""Saved verifier: %s"", key_name) self.logger.info(""Saved verifier: %s"", key_name) if not self.verifier: raise SavedProcess(key_name) self.logger.info(""Saved verifier: %s"", key_name) self.logger.info(""Saved verifier: %s"", key_name)",53.83704079,30.40059213
"generate: Calculate the margin in pixels to the right of the plot area,		setting border_right.","def calculate_right_margin(self):
		""""""
		
		""""""
		br = 7
		if self.key and self.key_position == 'right':
			max_key_len = max(map(len, self.keys()))
			br += max_key_len * self.key_font_size * 0.6
			br += self.KEY_BOX_SIZE
			br += 10		# Some padding around the box
		self.border_right = br","def calculate_margin(self, margin, margin, margin): """""" """""" # TODO: we go through the plot of the spinned margin in the first margin self.plot.set_margin(margin) self.plot.set_margin(margin) self.plot.set_margin(margin) self.plot.set_margin(margin) self.plot.set_margin(margin)","This is calculated for axis in right: if x0 == 'x': if x0 == 'y': raise TypeError('Shape right is not supported') for y0, y in right.items(): if x0 == 'y': if y0 == 'y': raise TypeError('Shape [x0, y0], x0) for y0 in right: raise TypeError('Shape [x0], y0, y0, y0, y0)",30.7444911,18.02265617
generate: Normal distribution function.,"def ndtr(x, name=""ndtr""):
  """"""
  """"""

  with tf.name_scope(name):
    x = tf.convert_to_tensor(value=x, name=""x"")
    if dtype_util.as_numpy_dtype(x.dtype) not in [np.float32, np.float64]:
      raise TypeError(
          ""x.dtype=%s is not handled, see docstring for supported types.""
          % x.dtype)
    return _ndtr(x)","def distribution_function(self, name, name, function_name, task_func=None): """""" """""" if name in self.functions: return self.functions[name] elif name in self.functions: return self.functions[name] else: raise RuntimeError(""No function found for functions"")","def _compile_distribution_float(distribution_type, mode, point): """""" """""" if not point.is_signature(distribution_type): point.is_signature(distribution_type) return distribution_size = mode.shape[1] point.is_signature(distribution_size) return distribution_size",27.02366757,24.08784985
generate: Return a SDK client initialized with auth file.,"def get_client_from_auth_file(client_class, auth_path=None, **kwargs):
    """"""
    """"""
    auth_path = auth_path or os.environ['AZURE_AUTH_LOCATION']

    with io.open(auth_path, 'r', encoding='utf-8-sig') as auth_fd:
        config_dict = json.load(auth_fd)
    return get_client_from_json_dict(client_class, config_dict, **kwargs)","def get_client_info(self, request, url, session=None, **kwargs): """""""""""" # If the request is not authorized, If the request is not authorized, only the session url, # the request is the SDK client. return self.request(url=url, session=session, **kwargs)","def get_client_for_path(client_name, client_file): """""" """""" if client_file.is_valid(): return client_file try: client_file = client_file.get_client() except KeyError: client_file = os.path.expanduser(client_file) client_file = os.path.join(client_file, client_file) client_file.update(client_file) client_file.update(client_file) except Failure as e: client_file.update(client_file) return client_file except Failed as e: client_file.update(e) return client_file",27.92272857,21.89637607
generate: Write to a file in the directory.,"def write(self, filename, data, mode='w'):
        """"""
        
        """"""
        with open(self.path_to(str(filename)), mode) as f:
            f.write(data)","def write_file(self, filename, delete=False): """""" """""" filename = os.path.basename(filename) self.write(filename, delete=delete)","def _write_file(self, filename): """""" """""" with open(filename, 'w') as f: if self._file is None: self._file.write(filename) self._file.write(filename)",50.4842191,48.89947887
"generate: Handles replies for code execution, here only session history length","def _handle_execute_reply(self, msg):
        """""" 
        """"""
        msg_id = msg['parent_header']['msg_id']
        info = self._request_info['execute'].pop(msg_id,None)
        if info and info.kind == 'save_magic' and not self._hidden:
            content = msg['content']
            status = content['status']
            if status == 'ok':
                self._max_session_history=(int(content['user_expressions']['hlen']))",". def _handle_response(self, request, request, suffix=None, session_id=None): """""""""""" if request.req_id is not None: if request.session_id is not None: if request.session_id is not None: request.session_id = request.session_id else: request.session_id = session_id return request.session_id if suffix is not None: raise ValueError(""Code {0} not found"".format(suffix))",". def _replies_to_submission(self, code_list, submission_id, title=10): """""" """""" if code_list is None: code_list = [code_list[0] for code_list in self.relations] else: code_list = [code_list[0] for code_list in self.relations] if self.get_submission(code_list[1]) == submission_id: code_list.append(code_list[0]) return code_list",25.49282423,28.37268074
generate: Converts gate tuples into a nested list of integers.,"def gates_to_idx(gates, qregs):
    """"""
    """"""
    sizes = [qr.size for qr in qregs.values()]
    reg_idx = np.cumsum([0]+sizes)
    regint = {}
    for ind, qreg in enumerate(qregs.values()):
        regint[qreg] = ind
    out = np.zeros(2*len(gates), dtype=np.int32)
    for idx, gate in enumerate(gates):
        out[2*idx] = reg_idx[regint[gate[0][0]]]+gate[0][1]
        out[2*idx+1] = reg_idx[regint[gate[1][0]]]+gate[1][1]
    return out","def list_tuples_to_list(tuples, nested_names, filters, filters): """""" """""" tuples = [tuple for tuple in tuples if tuple] if not isinstance(filters, dict): raise TypeError(""No nested list of integers"") filters = list(filters) if filters: filters = list(filters) return filters","def nested_tuple(self, integers): """""" """""" if not self.nested_tuple: raise Exception(""Nested tuple: %s"" % integers) tuples = self.nested_tuples.get(""tuples"") tuples = self.nested_tuples if not tuples: raise Exception(""Nested tuples are not integers."") if not tuples: raise Exception(""Nested tuples are not integers."") self.nested_tuples = tuples return self.nested_tuples",18.23489629,15.6965363
generate: Resume currently scheduled program,"def resume_program(self, index, resume_all=False):
        '''  '''
        body = {""selection"": {
                    ""selectionType"": ""thermostats"",
                    ""selectionMatch"": self.thermostats[index]['identifier']},
                ""functions"": [{""type"": ""resumeProgram"", ""params"": {
                    ""resumeAll"": resume_all
                }}]}

        log_msg_action = ""resume program""
        return self.make_request(body, log_msg_action)","def resume(self, name, location, region=None): """""""""""" name = self.resume(name) if region: raise ValueError('Region %s is not supported.' % name) if region: return self.resume(name, region) raise ValueError('Region %s is not supported.' % name)",". def register_program(self, query, query, program): """""" """""" try: response = self._client.get(query, None) except Exception as e: return None try: response = self._register_program(query, query, query, query, query, query, program) except Exception as e: logger.error(e) return None except Exception as e: raise e except Exception as e: logger.error(e) return None return None",23.36202009,25.84655105
generate: Make an agent,"def make_agent() -> EcommerceAgent:
    """"""
    """"""

    config_path = find_config('tfidf_retrieve')
    skill = build_model(config_path)
    agent = EcommerceAgent(skills=[skill])
    return agent","instance with the given agent instance. def make_agent_info(agent_info, instance, session=None): """""" """""" if instance is None: instance = ""{}{}"".format(agent_info.get_info()) return _agent_info(agent_info)","to the events. def agent(self, key, url, auth_url): """""" """""" if key.lower() == '""' and auth_url == '""': if auth_url is not None: if self._is_agent(): self._agent(key, url) return else: self._agent(key, url) else: return else: self._agent(key, auth_url) return",29.11064755,21.99497156
generate: Simply merge the older into the new one.,"def _merge_values(self):
        """"""
        
        """"""

        to_remove = []

        self.new_config = Dict(
            Dict(self.upstream_config).merge(PyFunceble.CONFIGURATION)
        ).remove_key(to_remove)","def merge(self): """""""""""" if self.of_merge: older = self.of_merge if older: self.merge_to_section = older else: self.merge_to_section = older else: self.merge_to_section = older","def _combo_merge_offset(self, offset, offset): """""" """""" offset = offset if self.diff: self.diff = offset self.diff = offset else: self.diff = offset self.diff = offset self.diff = new_one self.diff = new_one return offset",26.31845525,19.94498877
generate: Compute the context vector with soft attention.,"def compute_context_vector(self, prev_state, inputs, precomputed_values=None, mask=None):
        """"""
        
        """"""
        precomputed_values = precomputed_values if precomputed_values else self.precompute(inputs)
        align_weights = self.compute_alignments(prev_state, precomputed_values, mask)
        context_vector = T.sum(align_weights[:, :, None] * inputs, axis=1)
        return context_vector","def get_context_vec_file(self, text): """""""""""" # FIXME: We assume that the context vector is the context vector. if self.context_vec_file is not None: context = self.context_vec_file context = self.context_vec_file if self.context_vec_file is not None: context = self.context_vec_file if self.context_vec_file is not None: context = self.context_vec_file return context else: return self.context_vec","def compute_context_vector(self, context, context): """""" """""" # This is a blank context, plus code on the same component if not isinstance(context, str): context = self._compute_context_vector(context) return self._compute_context_vector(context, context)",30.39840595,34.82819532
generate: Returns CDN urls of all files from group without API requesting.,"def file_cdn_urls(self):
        """"""

        """"""
        file_cdn_urls = []
        for file_index in six.moves.xrange(len(self)):
            file_cdn_url = '{group_cdn_url}nth/{file_index}/'.format(
                group_cdn_url=self.cdn_url,
                file_index=file_index
            )
            file_cdn_urls.append(file_cdn_url)
        return file_cdn_urls","def get_all_files_by_groups(self, groups): """""" """""" files = self.get_all_files_by_groups(groups) # get a new files from all files from all files # get the files of all files # get the files from all files urls = [] for filename in groups: urls.append(os.path.join(self.path, filename)) return urls","def GroupDataset(self, port, name, clean): """""" """""" if self.has_has_hash_clean(): self.filename = port if self.has_response(port): self.response(port, name, clean) else: self.filename = port return None",38.43635449,19.28389113
generate: Send a message to a group of users.,"def message_users(users, message, level=constants.INFO):
    """"""
    
    """"""
    for user in users:
        message_user(user, message, level)","def _send_message(self, message, message): """""" """""" if message.endswith('message'): self._message = message self._message = message","def _send_message(self, message): """""" """""" if self.is_response(): raise self.GraphQueueInterruptured(message) message.set('message', message)",39.19757708,36.23198868
"generate: get max statement id,  used for sorting of processes in architecture","def maxStmId(proc):
    """"""
    
    """"""
    maxId = 0
    for stm in proc.statements:
        maxId = max(maxId, getMaxStmIdForStm(stm))
    return maxId","def get_statement_id(self): """""""""""" statement_id = self.statement_id if self.statement_id: statement_id = self.statement_id return statement_id",". def get_statement_id(self): """""" """""" sort_print = self.get_processes() return self.get_processes().get('sort_print', None)",26.32248306,32.93225481
generate: Check if a file exists on Azure Data Lake.,"def check_for_file(self, file_path):
        """"""
        
        """"""
        try:
            files = self.connection.glob(file_path, details=False, invalidate_cache=True)
            return len(files) == 1
        except FileNotFoundError:
            return False","def check_file(self, filename): """""" """""" filename = filename.lower() if filename.startswith('.'): return False filename = filename[:-1] if filename.endswith('.'): return True else: return True","def is_adjacency(self): """""" """""" try: if self._is_adjacency: self._validate_adjacency(self._adjacency, self._readjacency) else: return True except IOError as e: if self._readjacency: return False else: if self._readjacency: return False else: return False",42.40000854,31.53332225
generate: Writes export archive files in the Giraffez archive format.    This takes a `giraffez.io.Writer` and writes archive chunks to    file until all rows for a given statement have been exhausted.,"def to_archive(self, writer):
        """"""
        
        """"""
        if 'b' not in writer.mode:
            raise GiraffeError(""Archive writer must be in binary mode"")
        writer.write(GIRAFFE_MAGIC)
        writer.write(self.columns.serialize())
        i = 0
        for n, chunk in enumerate(self._fetchall(ROW_ENCODING_RAW), 1):
            writer.write(chunk)
            yield TeradataEncoder.count(chunk)","It is an empty list, or `giraffez.io.Writer` and any of the files in the rows. It will be available, or any of the files are empty. def write(self, rows): """""" """""" rows = [] for line in self._gio.lines: if line.startswith("".""): rows.append(line.split(""."")) if rows: rows.append(rows) return rows","def write_export_files(self, output_file, output_file): """""" """""" if output_file not in self._export_files: raise GivenCommandError(""Unexpected file %s"" % output_file) self._export_files[output_file] = output_file self._export_files[output_file] = output_file self._export_files[output_file] = output_file",25.58284066,23.17652728
generate: Returns absolute paths of files that match the regex within folder_path and  all its children folders.,"def find_file_match(folder_path, regex=''):
    """"""
    

    """"""
    outlist = []
    for root, dirs, files in os.walk(folder_path):
        outlist.extend([os.path.join(root, f) for f in files
                        if re.match(regex, f)])

    return outlist","def get_files_from_regex(files_to_dir, regex_path, all_files_paths, folder_paths=None): """""" """""" files = [] for folder_path in files_to_dir: files.append(folder_path) files = [folder_path] for folder_path in files: files.append(folder_path) return files","def on_regex(regex, folders): """""" """""" if not os.path.isdir(regex): return None return os.path.join(regex, regex)",42.09178204,26.50162159
generate: This returns the absolute path of a file uploaded to this set. It    doesn't actually check whether said file exists.,"def path(self, filename, folder=None):
        """"""
        
        """"""
        if folder is not None:
            target_folder = os.path.join(self.config.destination, folder)
        else:
            target_folder = self.config.destination
        return os.path.join(target_folder, filename)","def get_file_uploaded(self, file_uploaded, saved_dir=None, saved_dir=None): """""" """""" if saved_dir is None: saved_dir = os.path.dirname(file_uploaded) if saved_dir is None: saved_dir = os.path.dirname(saved_dir) return os.path.join(self.get_dir(file_uploaded), file_uploaded, saved_dir)","def upload_file_exists(self, file_path): """""" """""" if not file_exists(file_path): return if not file_exists(file_path): self.setup_file_exists(file_path) return if not file_exists(file_path): self.setup_file_exists(file_path)",39.53738224,30.87771962
generate: Set the shutdown state of the Connection.,"def set_shutdown(self, state):
        """"""
        
        """"""
        if not isinstance(state, integer_types):
            raise TypeError(""state must be an integer"")

        _lib.SSL_set_shutdown(self._ssl, state)","def _set_shutdown_state(self, state, state, **kwargs): """""" """""" self._start_shutdown_state(state, state, **kwargs) return state","def setup_state(self, state): """""" """""" if self.shutdown: self.shutdown_state(state) else: self.shutdown_state(state)",44.11692304,40.02981754
generate: Dispatches a new instance of a parameterized job.,"def dispatch_job(self, id, payload=None, meta=None):
        """""" 
        """"""
        dispatch_json = {""Meta"": meta, ""Payload"": payload}
        return self.request(id, ""dispatch"", json=dispatch_json, method=""post"").json()","def get_instance(self, job_name, name, **kwargs): """""" """""" job_name = job_name or self.job_name job_name = job_name or self.job_name or self.job_name or self.job_name job_name = job_name or self.job_name or self.job_name self.job_name = job_name return self","def get_job(self): """""" """""" if not self.is_job(): raise AttributeError(""Can't job when a job is None"") if self.is_job(): return None return job",17.50143083,24.13930989
generate: Get user and org data for the login,"def __get_user(self, login):
        """"""""""""

        user = {}

        if not login:
            return user

        user_raw = self.client.user(login)
        user = json.loads(user_raw)
        user_orgs_raw = \
            self.client.user_orgs(login)
        user['organizations'] = json.loads(user_orgs_raw)

        return user",". def get_login(self): """""" """""" user = self.get_user_user_user(self.username, self.username, self.username) if user: return user else: return self.get_login(self.username, self.username, self.username)",". def get_user_user_user_user(self): """""" """""" username = self.get_user_username(self.username) if username.startswith(""user""): username = username.getuser() if username.endswith(""username""): username = username username = username return username",40.13244061,39.14155643
generate: Generates a report instance for the canvas account id.,"def create_report(self, report_type, account_id, term_id=None, params={}):
        """"""
        
        """"""
        if term_id is not None:
            params[""enrollment_term_id""] = term_id

        url = ACCOUNTS_API.format(account_id) + ""/reports/{}"".format(
            report_type)
        body = {""parameters"": params}

        data = self._post_resource(url, body)
        data[""account_id""] = account_id
        return Report(data=data)","def report(self, canvas_id, user_id=None): """""" """""" canvas_id = self._get_report_for_user_id(user_id=user_id) if not canvas_id: raise InvalidResponse( 'User instance for User instance for User instance for User instance.' ) self._report_for_user_id(user_id=user_id)","def generate_report(self, report, data_type=None): """""" """""" report = self._get_report(report, data_type=data_type) if not report.is_active: raise TypeError(""Can't find a valid response. Invalid response. "" ""The report is not a valid response."") return self._get_report_id(report, data_type)",26.91668697,36.95225734
generate: Decorator to set attributes on a function. Returns the original  function after setting the attributes named by the keyword arguments.,"def _with_attrs(**kwargs):
    """"""""""""

    def decorator(f):
        for k, v in kwargs.items():
            setattr(f, k, v)
        return f

    return decorator","def set_attrs(func, *args, **kwargs): """""" """""" def decorator(*args, **kwargs): try: func(*args, **kwargs) except Exception: raise FunctionTypeError('No Function function function function found.') return func(*args, **kwargs) return decorator","def decorator(self): """""" """""" attrs = self._get_attributes_for_table(self.field_name) if not attrs: raise TableError(""Attempting to decorator attribute %s"" % attrs) attrs.update({ 'attributes': self._get_attributes(), 'attrs': self._get_attributes(), 'description': self._description, }) return attrs",32.72924598,20.01032629
generate: Generates one or more private keys from the seed.,"def get_private_keys(
            self,
            index=0,
            count=1,
            security_level=AddressGenerator.DEFAULT_SECURITY_LEVEL,
    ):
        # type: (int, int, int) -> dict
        """"""
        
        """"""
        return commands.GetPrivateKeysCommand(self.adapter)(
            seed=self.seed,
            index=index,
            count=count,
            securityLevel=security_level,
        )","def get_one_private_keys(self, one_name): """""""""""" if one_name not in self.one_private_keys: one_name = one_name if self.one_private_keys[one_name] is not None: one_name = self.one_private_keys[one_name] return one_name","def _more_private_key_values(self, key, value): """""" """""" if not isinstance(value, list): return [None] if isinstance(value, list): return [ self._retrieve_keys(key) for key in value] else: return [self._retrieve_keys(key) for key in value]",24.3726085,25.70972513
generate: Import ``run_sql``.,"def _get_run_sql():
    """"""""""""
    try:
        from invenio.dbquery import run_sql
    except ImportError:
        from invenio.legacy.dbquery import run_sql
    return run_sql","def import_run_sql(self, result): """""""""""" if self.run_sql: # Show up sql result = self.run_sql else: result = self.run_sql result = self.run_sql return result","def import_sql(sql): """""" """""" try: return sql.save(sql, sql=sql) except Exception as e: logger.warning(e)",39.12420299,30.12221751
generate: Return all the values for a single axis of the data.,"def get_single_axis_values(self, axis, dataset):
		""""""
		
		""""""
		data_index = getattr(self, '%s_data_index' % axis)
		return [p[data_index] for p in dataset['data']]","def filter_values(self, single_ids): """""" """""" if single_ids == self._single_ids: return self.filter_values(single_ids, single_ids) return self.filter_values(single_ids)","def all_values(self, axis=None): """""" """""" if self._is_valid_values(axis): return self.unpack_values(axis) else: return self._get_values(axis)",32.76791943,36.58547471
generate: List all available workspaces.,"def list(self):
        """"""""""""
        ws_list = {}

        for key, value in self.config[""workspaces""].items():
            ws_list[key] = dict({""name"": key}, **value)

        return ws_list","def list_workspaces(self): """""""""""" self.set_workspaces(self.workspaces) return [{k: v for k, v in self.workspaces.items()} for k, v in self.workspaces.items()}","def _list_all_available_workspaces(self, *args): """""" """""" url = ""{0}/available"".format(self.host) return self._request(url, url)",41.53940732,33.84112315
generate: Visualizes the reconstruction of inputs in TensorBoard.,"def visualize_reconstruction(inputs, reconstruct, num=3, name=""reconstruction""):
  """"""
  """"""
  reconstruct = tf.clip_by_value(reconstruct, 0., 1.)
  inputs_and_reconstruct = tf.concat((inputs[:num], reconstruct[:num]), axis=0)
  image_summary(inputs_and_reconstruct, name)","def get_reconstruction(self, x, y, verbose=False, color=None): """""" """""" if self.reconstruction is None: raise ValueError(""Skipping X and color GUIDs are available."") if color is None: color = None if verbose: color = None if verbose is None: color = self.reconstruction if verbose: color = self.verbose if color is None: color = self.color return color","def _generate_reconstruction(self, reconstruction): """""""""""" for reconstruction in reconstruction.reconstructions: if reconstruction.startswith(""_""): construction.add_partument(""_"", reconstruction.endswith(""_"") else: construction.add_partument(""_"", reconstruction.startswith(""_"") ) return self.generate_reconstruction(reconstruction)",23.31690447,38.07032288
generate: Make filter from logical expression.,"def make_fromkey(self, key):
        """"""
        

        """"""
        if key != '':
            def make_runable(match):
                return ""self.components['"" + self.fuzzmatch(match.group(0)) + ""']""

            runable = re.sub('[^\(\)|& ]+', make_runable, key)
            return eval(runable)
        else:
            return ~np.zeros(self.size, dtype=bool)","def filter(self, query, expression): """""""""""" query = self.query(query) if query.has_be_id: return query.has_id else: query = self.query(query) if query.is_valid: return query.is_valid else: return query","def manifest_fn(self, logical_name, logical_depression, interval): """""" """""" url = self.get_url(logical_name, logical_depression) if not interval: raise ValueError('must be an interval, got %s' % interval) url = self.api_url(url, interval, interval) return self._get(url, url, None)",25.74330668,23.9739582
generate: Draw the X axis labels,"def draw_x_labels(self):
		""""
		if self.show_x_labels:
			labels = self.get_x_labels()
			count = len(labels)

			labels = enumerate(iter(labels))
			start = int(not self.step_include_first_x_label)
			labels = itertools.islice(labels, start, None, self.step_x_labels)
			list(map(self.draw_x_label, labels))
			self.draw_x_guidelines(self.field_width(), count)",". def draw_labels(self, labels): """""" """""" labels = [labels] labels = [] for label in labels: labels.append(label) labels.append(labels) labels.append(labels) labels.append(labels) labels.append(labels) labels.append(labels) labels.append(labels) return labels",". def axis_labels(self, labels): """""" """""" # Skip the labels # This is able to setup self.labels[labels[0]] = labels[1] self.labels[labels[1]] = labels[0] self.labels[labels[0]] = labels[0] self.labels[labels[1]] = labels[1] self.labels[labels[0]] = labels[0] self.labels[labels[0]] = labels[0]",35.18521754,35.40001853
generate: Broadcasts `from_structure` to `to_structure`.,"def broadcast_structure(to_structure, from_structure):
  """"""
  """"""
  from_parts = tf.nest.flatten(from_structure)
  if len(from_parts) == 1:
    from_structure = tf.nest.map_structure(lambda _: from_parts[0],
                                           to_structure)
  return from_structure","def from_structure(from_structure, to_structure): """""" """""" from_structure.format_string import text from_structure = textucture.format_string(from_structure) if textucture.is_character(): from_structure = textucture.character() return from_structure","def broadcast(self, structure): """""" """""" if structure is None: raise ValueError('invalid `to_structure`:'+ structure) return self.to_structure(string=structure)",62.26615746,39.33049926
generate: Run each function in `hooks' with args,"def run_hooks(obj, hooks, *args):
    """"""""""""
    for hook in hooks:
        if hook(obj, *args): return True
        pass
    return False",". def run_each(self, args): """""""""""" if args.hooks is None: args = [] for hook in args: hooks.append(hook) hooks.append(args) hooks.extend(args) hooks.extend(args)",".db`. def run(self, *args, **kwargs): """""""""""" hooks = kwargs.get('hooks', None) hooks = kwargs.get('hooks', None) if hooks is None: hooks = self._get_hooks(hooks) if hooks is None: hooks = [hooks.get('hooks', []), hooks.get('hooks', []), hooks.get('hooks', [])) return hooks",36.65162422,23.52176829
generate: Get the months tariff SerialBlock for meter.,"def getMonthsBuffer(self, direction):
        """""" 

        """"""
        if direction == ReadMonths.kWhReverse:
            return self.m_rev_mons

        # default direction == ReadMonths.kWh
        return self.m_mons","def get_months_tarify(self): """""" """""" if self.months_tarify: months_tarify = self.months_tarify if months_tarify == self.months_tarify: return months_tarify else: return months_tarify","def get_months_tariff(self, months): """""" """""" if not self.Months_tar: raise ValueError(""Months not found: Months: {}"".format(months)) return self._months_tariff(months, months)",39.84361728,39.10509186
generate: Base method for storage operations.,"def _base_opration(self, method):
        """""" 
        """"""
        uuids = self.uuids()

        while True:
            chunk = list(islice(uuids, 0, self.chunk_size))

            if not chunk:
                return

            rest_request(method, self.storage_url, chunk)","def __get_storage_operations(self): """""""""""" self.storage_operations = [] if self.storage_operations: for op in self.storage_operations: if op.operations: self.storage_operations.append(op.operations) return self.storage_operations","def storage_operations(self, root_method, root_method): """""" """""" self._flag_restorations(root_method, root_method, root_method) self._flag_restorations(root_method, root_method) return self._flag_restorations(root_method, root_method, root_method)",27.7250152,31.38114475
generate: Dumps different debug info about cluster to default logger,"def printStatus(self):
        """"""""""""
        status = self.getStatus()
        for k, v in iteritems(status):
            logging.info('%s: %s' % (str(k), str(v)))","def log_debug(self, message=None): """""" """""" logger.debug(""Debug info: %s"", message) return self.debug(""Debug info: %s"", message)","ging. def debug_debug(self, url, cluster, debug=False): """""" """""" if cluster.debug: if cluster.debug: return self.debug(url, cluster, debug=debug) else: return None",26.33756953,19.08879403
generate: Flag an existing user as an admin within the account sis id.,"def create_admin_by_sis_id(self, sis_account_id, user_id, role):
        """"""
        
        """"""
        return self.create_admin(self._sis_id(sis_account_id), user_id, role)","def get_user_attribute(self, access_id, salt, user_id, **kwargs): """""""""""" return self.get_user_attribute(user_id, salt, user_id, **kwargs)","def flag_user(self, user, addr, user): """""" """""" if addr: user_data = user.get_user(user) else: user_data = user.get_user_data(user, addr) self.user_data(user_data, user_data) return user_data",43.78722974,26.29038835
generate: A function to display sympy expression using inline style LaTeX in PNG.,"def print_png(o):
    """"""
    
    """"""
    s = latex(o, mode='inline')
    # mathtext does not understand certain latex flags, so we try to replace
    # them with suitable subs.
    s = s.replace('\\operatorname','')
    s = s.replace('\\overline', '\\bar')
    png = latex_to_png(s)
    return png","def get_log_expression_sympy(sympy_expression, png_expression, lineno=None): """""" """""" if not png_expression: raise ValueError(""LaTeX input should be specified in RNG: %s"" % png_expression) if lineno is None: lineno = png_expression.get_lineno() if lineno is None: lineno = lineno return lineno","def display_sympy(args): """""" """""" if args.get('acl'): sys.exit(not pylint=True) sys.exit(not pylint=True) sys.exit(not pylint=True) sys.exit(not pylint=True) sys.exit(not pylint) sys.exit(not pylint)",20.51549949,13.36928177
generate: Retrieves a task from asana.,"def get_asana_task(self, asana_task_id):
        """"""""""""

        try:
            return self.asana.tasks.find_by_id(asana_task_id)
        except asana_errors.NotFoundError:
            return None
        except asana_errors.ForbiddenError:
            return None","def get_task_from_task_from_task_from_task(self, asana_task): """""" """""" task = self.task_from_task(asana_task) if not task: return task if not self.task_from_task_from_task(asana_task): return task return task","def get_task_from_task(self, task_id, task_id): """""""""""" self._retrieve_task(task_id, task_id) return self._get_task(task_id, task_id, task_id)",44.36587007,32.8584193
generate: Add captured log messages to error output.,"def formatError(self, test, err):
        """"""
        """"""
        # logic flow copied from Capture.formatError
        test.capturedLogging = records = self.formatLogRecords()
        if not records:
            return err
        ec, ev, tb = err
        return (ec, self.addCaptureToErr(ev, records), tb)","def addCapturedFormatter(self, errorMessages): """""" """""" capturedFormatter = self.capturedFormatter(errorMessages) if capturedFormatter.name == 'captured': capturedFormatter = self.capturedFormatter(errorMessages) else: capturedFormatter = self.capturedFormatter(errorMessages) self.addCapturedFormatter(self.addCapturedFormatter(capturedFormatter))","def error_err(cls, error, response): """""" """""" if not response: return None if response.status_code == 200: raise exceptions.Unauthorized() elif response.status_code == 200: raise exceptions.Unauthorized() else: return cls(error)",28.47426337,30.01988756
"generate: To support weak referencing, removes cache key from the cache value.","def remove(self, field):
    """"""""""""
    return _Mapping(
        x=None if field == ""x"" else self.x,
        y=None if field == ""y"" else self.y,
        ildj=self.ildj,
        kwargs=self.kwargs)","def _cache_key(self, key): """""""""""" cache_key = self.cache_key(key) if cache_key: return self._cache_key(cache_key, key) else: return self._cache_key(key)","def remove_cache_key(self): """""" """""" if not self.check_key_class(self.key): raise ValueError('Data is not a cache key.') return self.remove_cache_key(self.key)",30.72694969,32.79823939
"generate: For a composite instruction, reverse the order of sub-gates.","def mirror(self):
        """"""
        """"""
        if not self._definition:
            return self.copy()

        reverse_inst = self.copy(name=self.name + '_mirror')
        reverse_inst.definition = []
        for inst, qargs, cargs in reversed(self._definition):
            reverse_inst._definition.append((inst.mirror(), qargs, cargs))
        return reverse_inst","def filter_instructions(self, composite_list): """""" """""" for composite in self.composites: if isinstance(composite, list): composite_list = composite.filter(composite) for composite in composite: composite_list.append(composite.composite(composite)) return composite_list","def reverse_subgates(self): """""" """""" subgates = [] for subgate in self.subgates: subgates.append(subgate) subgates.append(subgate) subgates.append(subgate) return subgates",27.8689837,19.92066386
generate: Add delivery report to an existing case.,"def delivery_report(context, case_id, report_path,
                    update):
    """"""""""""

    adapter = context.obj['adapter']

    try:
        load_delivery_report(adapter=adapter, case_id=case_id,
                             report_path=report_path, update=update)
        LOG.info(""saved report to case!"")
    except Exception as e:
        LOG.error(e)
        context.abort()","def add_delivery_report(self, report_name, case_name, delivery_report_name, case_name, report_name, sort_converted=True, port_client=False, **kwargs): """""" """""" self._delivery_reports.add(report_name, case_name, case_name, sort_converted, **kwargs)","def add_delivery_report(self, code, report): """""""""""" if not self.active: raise RuntimeError(""Could not add delivery delivery."") if not self.report: raise RuntimeError(""Could not add delivery report: %s"" % self.report) self.add_delivery_report(report)",36.21365308,33.03487086
generate: Find the optimal distance between the two sequences,"def optimal_t(self, seq_p, seq_ch, pattern_multiplicity=None, ignore_gaps=False):
        '''
        

        '''
        seq_pair, multiplicity = self.compress_sequence_pair(seq_p, seq_ch,
                                                            pattern_multiplicity = pattern_multiplicity,
                                                            ignore_gaps=ignore_gaps)
        return self.optimal_t_compressed(seq_pair, multiplicity)",". def find_optimal_distance(self, filter_distance_base=None): """""" """""" if filter_distance_base is None: filter_distance_base = self.filter_distance_base if filter_distance_base is None: filter_distance_base = self.filter_distance_base return filter_distance_base",". def _find_sequences(self, two_two): """""" """""" sequences = self.get_sequences() if self.is_sequences(): sequences.add(sequences, two_two) else: sequences.add(sequences) return sequences",21.96999972,20.40774262
generate: Perform a REST API request to a previously connected server.,"def api(endpoint, data=None, json=None, filename=None, save_to=None):
    """"""
    
    """"""
    # type checks are performed in H2OConnection class
    _check_connection()
    return h2oconn.request(endpoint, data=data, json=json, filename=filename, save_to=save_to)","def connected_request(self, url, data, query=None, headers=None, **kwargs): """""" """""" # Log the API request for GET /api/v1/methods/json # API request is needed and query params are passed to be passed # installed. url = '{0}{1}'.format(self.uri, url) return self._get(url, data=data, headers=headers, **kwargs)","def _poll_request(self, poll_url, url, response_data, response_type, response_type=None): """""" """""" if response_type == 'json': response_data = self.get_response_response_response(response_type, response_type) else: response_data = response_data return response_data",29.95300967,26.24560668
generate: Filter sqMass files,"def filter(sqmassfiles, infile, max_precursor_pep, max_peakgroup_pep, max_transition_pep):
    """"""
    
    """"""

    filter_sqmass(sqmassfiles, infile, max_precursor_pep, max_peakgroup_pep, max_transition_pep)","in a path and joins the files def filter_all_sq_files(self, path, query): """""" """""" query = self.filter_query(query) for file_path in file_paths: query = query.join(urllib.urljoin(self.base_url, file_path), query) return query","def filter_sql_files(self): """""" """""" # Methods don't handle don't exist if self.sql_files: self.sql_files = os.path.join(self.sql_files, self.sql_files) else: self.sql_files = None return self.sql_files",23.91741803,24.19069379
generate: Verify that the condition is valid.,"def _check_condition(self, name, condition):
        """"""
        """"""
        # Verify creg exists
        if condition is not None and condition[0].name not in self.cregs:
            raise DAGCircuitError(""invalid creg in condition for %s"" % name)","def verify(self, condition=None): """""""""""" if condition is None: condition = self.condition if condition is None: condition = self.condition return self.verify(condition=condition)","def visit_condition(self, condition): """""" """""" if self.condition is not None: if not self.condition: if not self.condition: raise ValueError(""Condition is not a valid condition."") self.condition = self.condition self.condition = condition return self.condition",44.3672915,45.7539725
generate: Delete a service bus namespace.,"def delete_namespace(self, name):
        '''
        
        '''
        _validate_not_none('name', name)

        return self._perform_delete(
            self._get_path('services/serviceBus/Namespaces', name),
            None)","def delete(self, namespace=None): """""""""""" self.service.delete(namespace=namespace) self.service.delete(namespace=namespace)","def delete_service_by_name(self, namespace): """""" """""" self._db.delete_service(namespace) self._delete_service(namespace)",43.22969794,43.11925746
generate: return the DocMarkup corresponding to a given tag in a block,"def  get_markup( self, tag_name ):
        """"""""""""
        for m in self.markups:
            if m.tag == string.lower( tag_name ):
                return m
        return None",". def get_doc_markup(self, block): """""" """""" if block: return block.get_doc_markup(block) return None",". def _get_tag(self, tag): """""" """""" if self._get_tag(tag): return self._get_tag(tag) else: raise GraphQLError('Tag is not a string')",41.47630571,39.17118305
generate: Get Flask blueprints for every provider that supports it,"def receiver_blueprints(self):
        """""" 
        """"""
        blueprints = {}
        for name in self._providers:
            try:
                blueprints[name] = self.receiver_blueprint_for(name)
            except NotImplementedError:
                pass  # Ignore providers that does not support receivers
        return blueprints","``provider``. def get_flask_blueprints(self, provider): """""" """""" blueprint = self.get_flask_blueprints() for blueprint in blueprint: if not blueprint: return None return blueprint",". def get_provider_threshold_blueprints(): """""" """""" if not FLOG.isFlaskBlueprint(): raise ValueError(""Provider threshold only when flasking."") return FlaskBlueprint(provider_threshold_blueprint)",43.76285319,36.04051154
generate: insert a child node,"def insert(self, index, child):
        """"""""""""
        self.children.insert(index, child)
        child.parent = self",". def insert(self, node, node, child): """""""""""" node.insert(child, node) node.insert(child, node) return node",". def child_child_node(self, node): """""" """""" if not self.child_node: return self.child_node(node) else: self.child_node(node)",47.94648497,36.12138876
generate: Set the focus to `newvalue`.,"def set(self, newvalue):
        # type: (B) -> Callable[[S], T]
        '''
        '''

        def setter(state):
            return self._optic.set(state, newvalue)

        return setter","def set_focus(self, focus): """""" """""" if self._focus is None: focus = focus self._focus = focus self.newvalue = self.newvalue","def setup_focus(self, value): """""" """""" if value not in self.focus: self.focus[value] = value return self.focus[value] = value",28.56603239,31.69628645
generate: Apply Fredkin to circuit.,"def cswap(self, ctl, tgt1, tgt2):
    """"""""""""
    return self.append(FredkinGate(), [ctl, tgt1, tgt2], [])","def apply_fredkin(self, fredkin): """""""""""" if fredkin: fredkin = fredkin return fredkin","def apply_fredkin(self, fredkin): """""" """""" return self._fredkin(fredkin, fredkin)",31.25198802,35.34037977
generate: schedule call to eventloop from IOLoop,"def _eventloop_changed(self, name, old, new):
        """"""""""""
        loop = ioloop.IOLoop.instance()
        loop.add_timeout(time.time()+0.1, self.enter_eventloop)",". def schedule(self, eventloop=None): """""" """""" eventloop = self.get_eventloop() eventloop = self.eventloop() if eventloop is not None: eventloop.push(eventloop) self.schedule(eventloop) self.eventloop(eventloop)",". def _eventloop(self, profile): """""" """""" self._eventloop.eventloop(profile) self._eventloop.eventloop(profile) return self._eventloop",28.4954987,39.95661261
"generate: Return a sorted sequence of the elements in coll. If a comparator  function f is provided, compare elements in coll using f.","def sort(coll, f=None) -> Optional[ISeq]:
    """"""""""""
    return to_seq(sorted(coll, key=Maybe(f).map(functools.cmp_to_key).value))","def sorted(self, comparator_name, f, **kwargs): """""""""""" if f is None: return None try: return comparator_name(comparator_name, f, **kwargs) except (KeyError, StopIteration) as e: return None","def _compare_sequence(coll, f): """""" """""" coll = coll.get_coll(coll, coll.colln) if coll.is_bound(): coll.is_bound(coll.elements) return coll return coll",21.86055027,25.71097048
"generate: get a particular build template, by default we return templates    that are based on package managers.","def get_build_template(name=None, manager='apt'):
    '''

    '''
    base = get_installdir()
    if name is None:
        name = ""%s/main/templates/build/singularity-builder-%s.sh"" %(base,
                                                                     manager)

    if os.path.exists(name):
        bot.debug(""Found template %s"" %name)
        return ''.join(read_file(name)) 

    bot.warning(""Template %s not found."" %name)","def get_template_build_template(self, template_name, action_name=None): """""" """""" template_name = self.get_template_build_template_name(template_name, action_name=action_name) if action_name: template_name = template_name.replace(""_"", ""_"") template_name = template_name.replace(""_"", ""_"") return template_name","def get_template_managers(self): """""" """""" pkg_template = os.path.join(self.template, self.template) if not os.path.exists(pkg_template): return None if not os.path.exists(pkg_template): return None else: return pkg_template.get_template(self.template)",34.70839931,33.87476992
"generate: List all hosted zones associated with this connection's account. Since    this method returns a generator, you can pull as many or as few    entries as you'd like, without having to query and receive every    hosted zone you may have.","def list_hosted_zones(self, page_chunks=100):
        """"""
        
        """"""

        return  self._do_autopaginating_api_call(
            path='hostedzone',
            params={'maxitems': page_chunks},
            method='GET',
            parser_func=xml_parsers.list_hosted_zones_parser,
            next_marker_xpath=""./{*}NextMarker"",
            next_marker_param_name=""marker"",
        )","def get_hosted_zones(self, hosted_zones, single_connection=None): """""" """""" if single_connection is None: single_connection = self.get_hosted_zones(hosted_zones) else: single_connection = self.get_hosted_zones(hosted_zones) return self.get_zones(hosted_zones)","def _get_hosted_zones(self, zones, all_hosted_zones): """""" """""" url = self._get_url(""hostedZones"") self._set_zones(url, ""hostedZone"", ""account"") self._set_zone_hosted_zone( self.hosted_zone_host, url, url, all_hosted_zones) self._set_zone_hosted_zone_hosted_zone( url, url, all_hosted_zones, all_hosted_zones) return zones",29.895421,26.89687116
generate: Parse a hook name,"def hook_name(self, hook, n):
    """"""""""""
    hook.name = self.value(n)
    hook.listparam = []
    return True","from a hook. def parse_hook(hook): """""" """""" hook = hook.lower() if hook.lower() == 'HOK': hook = hook.lower() return hook",". def parse_hook(self): """""""""""" hook_name = os.path.splitext(os.path.join(self.docker_name, 'hook_name')) return hook_name",34.09789473,43.22096544
"generate: Checks the beginning of text for a value. If it is found, a terminal ParseNode is returned filled out appropriately for the value it found. DeadEnd is raised if the value does not match.","def _get_terminal(value, text):
  """"""
  """"""
  if text and text.startswith(value):
    return ParseNode(ParseNodeType.terminal,
                      children=[value],
                      consumed=len(value),
                      position=-len(text))
  else:
    raise DeadEnd()","def _validate(self, text, value): """""" """""" text = value.strip() if text is not None: if isinstance(text, text_type): return text.lower() else: return text.lower()","def is_terminal_pos(self, value): """""" """""" if value.startswith(""true""): return value.startswith(""true"") return not isinstance(value, (tuple, tuple)) and ( isinstance(value, (tuple, list) or ( tuple, tuple) ) )",37.82315052,41.03744962
generate: Retrieve the config as a dictionary of key-value pairs.,"def get_config():
        """"""""""""
        self = H2OConfigReader._get_instance()
        if not self._config_loaded:
            self._read_config()
        return self._config","def _get_config(self, key): """""""""""" if not self._config: return self.config if self._config: return self.config else: return self.config","def get_config(self, key): """""" """""" if key not in self._config: return self._config[key] return self._config[key]",59.05641525,55.116114
generate: Add a linked file.,"def add_linked_file(self, file_path, relpath=None, mimetype=None,
                        time_origin=None, ex_from=None):
        """"""
        """"""
        if mimetype is None:
            mimetype = self.MIMES[file_path.split('.')[-1]]
        self.media_descriptors.append({
            'MEDIA_URL': file_path, 'RELATIVE_MEDIA_URL': relpath,
            'MIME_TYPE': mimetype, 'TIME_ORIGIN': time_origin,
            'EXTRACTED_FROM': ex_from})","def add(self, f, address, filename, **kwargs): """""""""""" self._filename = filename if filename is not None: self._filename = filename self._filename = filename self.add_linked(filename, filename, **kwargs) else: self._filename = filename","def add_file(self, filename, mode): """""" """""" # Get the filename for there if not filename: return if not os.path.isfile(filename): # If there is a file. filename = filename if not os.path.isdir(filename): if not os.path.isdir(filename): raise IOError(""Can't find a filename"") self._add_file(filename, mode, mode=mode) self._add_file(filename, mode, mode)",21.81543248,27.07196765
"generate: Make a temporary python file, return filename and filehandle.","def temp_pyfile(src, ext='.py'):
    """"""
    """"""
    fname = tempfile.mkstemp(ext)[1]
    f = open(fname,'w')
    f.write(src)
    f.flush()
    return fname, f","def tempfile(self, path): """""""""""" if path.endswith('.py'): return os.path.join(self.tempfile, path) else: return path","def temporary_platform(filename): """""" """""" if os.path.isdir(filename): platform = open(filename, 'rb') else: platform = open(filename, 'rb') return platform",34.92567232,36.56215278
"generate: Generate the next annotation id, this function is mainly used    internally.","def generate_annotation_id(self):
        """"""
        """"""
        if not self.maxaid:
            valid_anns = [int(''.join(filter(str.isdigit, a)))
                          for a in self.timeslots]
            self.maxaid = max(valid_anns + [1])+1
        else:
            self.maxaid += 1
        return 'a{:d}'.format(self.maxaid)","def _next_annotation_id(self, base_id, editor): """""""""""" if base_id in self.annotation_ids: self.annotation_ids[base_id] = self._annotation_ids[base_id] self.annotation_ids[base_id] = self.annotation_ids[base_id]","def _make_next_active_if_for_next_active(self, address): """""" """""" if address is None: raise ValueError(""Address not found."") if address is None: address = address return self.helper.make_next_active(address)",33.75806831,24.93020319
generate: Extracts the hour out of a datetime samples.,"def dt_hour(x):
    """"""
    """"""
    import pandas as pd
    return pd.Series(x).dt.hour.values","def get_hours(self, hours, days=1000): """""" """""" if hours == 0: return None if hours == 0: return None return hours, days","def hour_hours(self, datetime, datetime=None): """""" """""" return self.hours_from_datetime(datetime, datetime)",26.2089567,29.26389512
generate: Get all activity data for the last activity,"def get_last_activities(self, n):
        """"""
        """"""
        filenames = self.get_activity_list().iloc[-n:].filename.tolist()
        last_activities = [self.get_activity(f) for f in filenames]
        return last_activities",". def get_activity_data(self, last_activity_data): """""" """""" data = self.get_activity_data(last_activity_data) if data is not None: data = self.get_activity_data(last_activity_data) return data",". def get_activity_data(self, last_activity_data): """""" """""" if last_activity_data is None: return self._get_activity_data(last_activity_data) else: return self._get_activity_data(last_activity_data)",54.78717971,51.04094844
generate: Recursively statistically evaluate result of this operator,"def staticEval(self):
        """"""
        
        """"""
        for o in self.operands:
            o.staticEval()
        self.result._val = self.evalFn()",". def statistically_statically(self, operator): """""" """""" result = operator.get(self.statically_statically) if result is None: return return result",". def statistically_result(self, function_list, query_info): """""" """""" return self._statistically_recursive(function_list, query_info)",32.65855006,32.08703791
generate: Load the object to a given file like object with the given      protocol.,"def load_from_file_like(cls, flo, format=None):
        """""" 
        """"""
        format = self.format if format is None else format
        load = getattr(cls, ""load_%s"" % format, None)
        if load is None:
            raise ValueError(""Unknown format '%s'."" % format)
        return load(flo)","def load(self, path, **kwargs): """""" """""" try: obj = object(path, **kwargs) except AttributeError: raise NoSuchCompilationError( ""Cannot load object from %s object %s"" % ( obj.__class__.__name__, obj.__class__.__name__)) return obj","def load_file(self, filename): """""" """""" filename = os.path.basename(filename) if not os.path.exists(filename): raise IOError(""Protocol not found."") return filename",30.9963465,26.19676601
generate: Test must finish within specified time limit to pass.,"def timed(limit):
    """"""
    """"""
    def decorate(func):
        def newfunc(*arg, **kw):
            start = time.time()
            func(*arg, **kw)
            end = time.time()
            if end - start > limit:
                raise TimeExpired(""Time limit (%s) exceeded"" % limit)
        newfunc = make_decorator(func)(newfunc)
        return newfunc
    return decorate","def finish_player(self, limit=None, event=None): """""" """""" if limit is None: limit = self.limit if event is None: event = self.limit if self.provider: return self.player.finish_player(event=event) return self.player","def _finish_time_limit(self, time_limit): """""" """""" time_limit = time_limit time_limit = time_limit + time_limit if time_limit == 0: return 0 time_limit = time_limit + time_limit if time_limit > 0: time_limit = time_limit + time_limit return self.time_limit",24.51726668,29.22816036
generate: Numpy implementation of `tf.argsort`.,"def _argsort(values, axis=-1, direction='ASCENDING', stable=False, name=None):  # pylint: disable=unused-argument
  """"""""""""
  if direction == 'ASCENDING':
    pass
  elif direction == 'DESCENDING':
    values = np.negative(values)
  else:
    raise ValueError('Unrecognized direction: {}.'.format(direction))
  return np.argsort(values, axis, kind='stable' if stable else 'quicksort')","def filter_argsort(args, kwargs): """""" """""" kwargs = { 'args': args, 'tf.argsort': kwargs } for name, value in kwargs.items(): if not isinstance(value, (list, set)): return value else: return value return value","def numpy_image(tf, *args, **kwargs): """""" """""" if not args.null_empty: raise ValueError(""Unexpected tf.numpy arguments."") if not args.super() and kwargs.get('high') and kwargs.get('high'): raise ValueError(""Arguments are null arguments are not supported"") if not kwargs.get('high') and kwargs.get('high') == 'high': raise ValueError(""Arguments are not supported"") tf.argsort(tf.argsort(tf.argsort(kwargs))) return tf.dumpy_image(tf, *args, **kwargs)",21.24538693,23.99722542
"generate: A modifier hook function. This is called in priority order prior    to invoking the ``Action`` for the step. This allows a    modifier to alter the context, or to take over subsequent    action invocation.","def pre_call(self, ctxt, pre_mod, post_mod, action):
        """"""
        
        """"""

        # Check the condition
        if not self.condition(ctxt):
            return steps.StepResult(state=steps.SKIPPED)

        return None","def _check_command(self, action): """""" """""" if action is None: return if self._is_table_command(action): return self._check_command(action) else: return self._check_command(action)","def _access_to_session(self, action, request, query_params): """""" """""" if action.get('schema') is None: action.Schema() return self._access_token(request, action, action, request)",40.9706101,35.87834444
generate: Returns opened file object for writing dialog logs.,"def _get_log_file(self):
        """"""
        """"""
        log_dir: Path = Path(self.config['log_path']).expanduser().resolve() / self.agent_name
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file_path = Path(log_dir, f'{self._get_timestamp_utc_str()}_{self.agent_name}.log')
        log_file = open(log_file_path, 'a', buffering=1, encoding='utf8')
        return log_file","def opened(self, dialog_file, **kwargs): """""""""""" if not os.path.exists(dialog_file): return None try: with open(dialog_file, 'rb') as f: return open(dialog_file, 'rb') except OSError: return None","def _open(self): """""""""""" # Wrapper executes something: # TODO: something platforming to be restead of which is a single upload. self._open() # Save the logs uploading file, but we can't load it # but we'll work the loading file # something is a valid uploading file # The logs are something. We'll can't create a logs # platform the file we'll create any file. # Get the filepath. self._open_filepath = os.path.join(self._filepath, self._filepath) os.makedirs(self._filepath)",20.03707377,24.18066998
generate: Generic subcommand integer value display,"def run_show_int(obj, what=None):
    """"""""""""
    val = obj.debugger.settings[obj.name]
    if not what: what = obj.name
    return obj.msg(""%s is %d."" % (what, val))","ing to the stage def integer(self, stage=None): """""""""""" stage = self.stage if stage is None: stage = None self.table.set_command(stage) return self.table",". def _get_subcommand(self, subcommand, args): """""""""""" if args.get('name'): return self._subcommand(args.get('name', None)) else: return None",28.33695659,25.31605511
generate: Load a saved state file.,"def load(self):
        """"""
        
        """"""
        if os.path.exists(self.path):
            with open(self.path, 'r') as f:
                self.d = yaml.safe_load(f.read().replace('\t', ' '*4))","def load(self, state, name, state_file): """""" """""" # load a state file from the state file state = self.state_file(state, name) if state == self.db_lock: return return state","def save_state_file(self, state_file): """""" """""" if not state_file: self.state_file_name = '%s' % state_file self.state_file = state_file self.remove_state_file(state_file) return self",28.59229126,24.36583359
generate: Fetch the Dockher Hub items,"def fetch_items(self, category, **kwargs):
        """"""
        """"""
        logger.info(""Fetching data from '%s' repository of '%s' owner"",
                    self.repository, self.owner)

        raw_data = self.client.repository(self.owner, self.repository)
        fetched_on = datetime_utcnow().timestamp()

        data = self.parse_json(raw_data)
        data['fetched_on'] = fetched_on
        yield data

        logger.info(""Fetch process completed"")",". def get_dockher_items(self, **kwargs): """""" """""" if self.issubset_ids: dockher_item = self.dockher_item.get(**kwargs) if dockher_item: return dockher_item return self.get_dockher_item(**kwargs)",". def fetch_dockher_hub(self, docker_name): """""" """""" docker_hub = self.docker_hub(docker_name) # For each docker hub in a IPDAPI response ipdocker_hub.delete(ipdocker_name, docker_name, json.dumps(docker_hub)) # For each ipdocker on the created ipdocker ipdocker_hub.delete(ipdocker_name) # First, the ipdocker hub code on the docker. if self.is_address: # This is a URL return ipdocker_hub else: return ipdocker_hub",16.05573346,19.41410584
generate: Calculate the standard error of a.,"def stderr(a):
    """"""
    
    """"""
    return np.nanstd(a) / np.sqrt(sum(np.isfinite(a)))","standard. def calculate(self, standard): """""" """""" self.standard = standard self.standard = standard","def _to_error(self, standard_error): """""" """""" if standard_error: standard_error = 'Could not calculate a standard error: {0}'.format(standard_error) return self._error_for_status(standard_error)",19.77887414,14.62299109
generate: Creates a DSMR asyncio protocol coroutine using serial port.,"def create_dsmr_reader(port, dsmr_version, telegram_callback, loop=None):
    """"""""""""
    protocol, serial_settings = create_dsmr_protocol(
        dsmr_version, telegram_callback, loop=None)
    serial_settings['url'] = port

    conn = create_serial_connection(loop, protocol, **serial_settings)
    return conn","def create_dscriptor(self, serial_protocol=None): """""" """""" serial_protocol = self.protocol if serial_protocol is None: return self.protocol serial_protocol = self.protocol try: protocol = self.protocol except KeyError: protocol = self.protocol dsmr = self.dscriptor if dsmr is not None: dsmr = self.protocol protocol = self.protocol return self.protocol","def create_serial_port(port, port, port_id, port_id, port_id): """""" """""" port_id = get_port_id(port) try: port = port.get('port_id') except KeyError: port = get_port(port_id) return HttpPort(port, port_id, port, port_id)",32.16072904,22.13459643
generate: Convert an N x 3 array of XYZ coordinates to matrix indices.,"def xyz_to_mat(foci, xyz_dims=None, mat_dims=None):
    """"""  """"""
    foci = np.hstack((foci, np.ones((foci.shape[0], 1))))
    mat = np.array([[-0.5, 0, 0, 45], [0, 0.5, 0, 63], [0, 0, 0.5, 36]]).T
    result = np.dot(foci, mat)[:, ::-1]  # multiply and reverse column order
    return np.round_(result).astype(int)","def _convert_to_numpy(x, y, min=None): """""" """""" if x is not None: return x.cyc_array() if x is not None: if x.dtype == 'float64': return np.float64(x.dtype) elif x is not None: return np.float64(x.dtype) else: return np.float64(x).dtype","def _to_matrix(xyz_val, axis=1): """""" """""" if not isinstance(xyz_val, np.ndarray): return None if not isinstance(xyz_val, np.ndarray): return np.sqrt(xyz_val, np.int32) return np.sqrt(np.sqrt(np.sqrt(np.nan), np.float32))",23.03297735,22.5998833
generate: Yield line number of star import usage.,"def star_import_used_line_numbers(messages):
    """"""""""""
    for message in messages:
        if isinstance(message, pyflakes.messages.ImportStarUsed):
            yield message.lineno","def _iter_star_lines(self, star_lines): """""""""""" star_lines = [] if len(star_lines)!= len(star_lines): star_lines = [] for lines in star_lines: star_lines.append(lines) for lines in star_lines: yield lines","def star_import_star(star, star): """""""""""" p = _get_star(star, star) if p.is_star: yield p.star_import(star, star)",27.10551503,27.27549256
generate: Example of sending a message.,"async def send_message():
    """"""""""""
    jar = aiohttp.CookieJar(unsafe=True)
    websession = aiohttp.ClientSession(cookie_jar=jar)

    modem = eternalegypt.Modem(hostname=sys.argv[1], websession=websession)
    await modem.login(password=sys.argv[2])

    await modem.sms(phone=sys.argv[3], message=sys.argv[4])

    await modem.logout()
    await websession.close()","def send_message(self, message): """""" """""" if not message: return message = message.message message = message if not message.startswith('_'): return try: self._send_message(message) except Exception as e: self._send_message(message) self._send_message(message)","def example_message(self, message): """""""""""" if self.message_type.lower() in self._message_types: raise error.Message(""Unable to sending message "" + message.message) if self._message_type.lower() in self._message_type.lower(): message = message.message_type.lower() self._message_type = message.message_type.lower() return message.message_type",18.50224171,19.90239504
generate: Price field for attrs.,"def price(*args, **kwargs):
    """"""
    """"""

    kwargs.setdefault('default', 'USD 0.00')
    kwargs.setdefault('converter', price_converter)

    if 'validator' in kwargs:
        validator = kwargs.pop('validator')
        if not isinstance(validator, (tuple, list)):
            validator = [validator]
    else:
        validator = []
    validator.append(instance_of(PriceClass))
    return attr.ib(validator=validator, *args, **kwargs)","def __get_fields(self, field_name): """""" """""" if field_name == 'fields': fields = [field_name, field_name] else: fields = [] if field_name == 'fields': fields.append(field_name) return fields","def _get_field_for_field_for_field(self, field_name, values): """""" """""" # The values is a valid Field instance. if not isinstance(field_name, (list, tuple)): return field_name # The `field_name` must be a list of field name. if isinstance(field_name, list): return field_name # Field `field_name` must be a list. if not isinstance(field_name, list): return field_name return field_name",12.04564517,24.720814
generate: Load multiqc report for the case.,"def multiqc(institute_id, case_name):
    """"""""""""
    data = controllers.multiqc(store, institute_id, case_name)
    if data['case'].get('multiqc') is None:
        return abort(404)
    out_dir = os.path.abspath(os.path.dirname(data['case']['multiqc']))
    filename = os.path.basename(data['case']['multiqc'])
    return send_from_directory(out_dir, filename)","def get_multiqc_report(self, case_file, case_file, report_file, full_file=None, disable=False, **kwargs): """""" """""" # get the multiqc report for the case file. # ignore the same report, otherwise then avoid the case file. if os_file == self.REPORT: repo = self.get_multiqc_report(case_file, report_file, full_file=full_file, disable=True, **kwargs) return mull_file else: return None","def report_case(self): """""" """""" multiqc_multiqc_case = self.multiqc_multiqc_case_for_case(self.case_url) multiqc_case = self.get_multiqc_case_for_case_for_case(self.case_url) if multiqc_case.is_valid(): multiqc_multiqc_case = self.multiqc_case(self.case_url) if multiqc_case.is_valid(): return multiqc_case.get_multiqc_case(self.case_url) else: return multiqc_case",28.50820411,28.10081676
generate: Generates a random seed using a CSPRNG.,"def random(cls, length=Hash.LEN):
        """"""
        
        """"""
        return super(Seed, cls).random(length)","def random_seed(self, random_seed): """""""""""" random_seed = self._read_random_seed(random_seed) return self.read_random_seed(random_seed)","def random_seed(self, compare): """""" """""" if self.is_captured(): self.set_db_from_random_seed(compare) else: self.set_db_from_random_seed(compare)",24.95531176,22.09605744
"generate: Set new training dataset, for optimizer reuse","def set_traindata(self, training_rdd, batch_size):
        """"""
        
        """"""
        callBigDlFunc(self.bigdl_type, ""setTrainData"", self.value,
                     training_rdd, batch_size)","s. def set_training_dataset_set(self, training_dataset): """""""""""" self.set_training_dataset_set_set_set(training_dataset)","the one command. def set_training_dataset(self, training_dataset): """""" """""" self.set_training_dataset(training_dataset) self.set_training_dataset(training_dataset)",40.35404998,40.69491325
generate: Import config var import path or use default value.,"def config_imp_or_default(app, config_var_imp, default):
    """"""""""""
    imp = app.config.get(config_var_imp)
    return import_string(imp) if imp else default","def import_config(self, path, default_args): """""""""""" if default_args is None: default_args = self.default_args if default_args is None: default_args = self.default_args return self.parse_config(path, default_args, default_args)","def _detect_default_path(config, file_name): """""" """""" config = os.path.join(os.path.dirname(config), file_name) config.use_file_module(config) os.makedirs(config.use_file_module(file_name)) return config",29.43677273,28.72325128
generate: Return list of choices's keys,"def valid_choices(choices):
    """"""
    
    """"""
    for key, value in choices:
        if isinstance(value, (list, tuple)):
            for key, _ in value:
                yield key
        else:
            yield key",". def get_choices(self, key, choices): """""""""""" if choices: return [ self.get_choices(key) for key in key ] return []",". def choices_keys(): """""" """""" choices = [] for key in choices: choices.append(key) choices.append(key) return choices",39.37324855,35.23847757
generate: SlackAPIOperator calls will not fail even if the call is not unsuccessful.    It should not prevent a DAG from completing in success,"def execute(self, **kwargs):
        """"""
        
        """"""
        if not self.api_params:
            self.construct_api_call_params()
        slack = SlackHook(token=self.token, slack_conn_id=self.slack_conn_id)
        slack.call(self.method, self.api_params)","ful. def _slack_call(self, slack): """""" """""" self.slack_call = self.slack_call self.slack_call = slack self.slack_call = self.slack_call","ful. def fetch_callback(self, complet_callback): """""" """""" if not self._callback: return self._callback_callback(complet_callback, complet_callback) self._callback_callback(complet_callback) self._callback(complet_callback) self._callback(complet_callback)",33.98482131,29.91662242
generate: Remove duplicate source and destination accesses,"def _remove_duplicate_accesses(self):
        """"""
        
        """"""
        self.destinations = {var_name: set(acs) for var_name, acs in self.destinations.items()}
        self.sources = {var_name: set(acs) for var_name, acs in self.sources.items()}",". def destination(self, source, close=False, parent=False): """""" """""" if close: self.destination = self.destination else: self.destination = None if parent: self.destination = None if parent: self.destination = None return self.destination",". def remove_duplicates(self): """""" """""" self._source = self._source if self._duplicate: self._duplicate = True else: self._duplicate = True self._duplicate = False self._duplicate = True self._duplicate = True",37.16468426,38.62887776
generate: This method calls an extractor on some text.,"def _call_extractor(extractor, text):
  """"""
  """"""
  if isinstance(extractor, str):
    return _get_terminal(extractor, text)
  else:
    return extractor(text)","def extract_extractor_text(self, extractor_text): """""""""""" if extractor_text is None: extractor_text = self.extractor_text if extractor_text.startswith('.'): return extractor_text else: return extractor_text","def extract_text(self, text): """""" """""" if self.find_text(text) == 'text': return self.find_text(text) else: return self.find_text(text)",44.67356627,49.35981064
generate: Writes the JSON report to a json file,"def write_report_data(self):
        """"""
        """"""

        json_plot = self.get_plot_data()
        json_table = self.get_table_data()

        json_dic = {**json_plot, **json_table}

        with open("".report.json"", ""w"") as json_report:
            json_report.write(json.dumps(json_dic, separators=("","", "":"")))","and writes json file. def write_json(self, json_file, doc_type=None, **kwargs): """""" """""" if isinstance(json_file, json_types): json_file = json_file.read(json_file) self.write_json(json_file, **kwargs) self.write_json(json_file, **kwargs) self.write_json(json_file, **kwargs)",". def write_json_report(self, filename, port_id, port_type=None): """""" """""" json_data = {} for filename in filename: if not os.path.isfile(filename): filename = os.path.join(os.path.dirname(filename), filename) if os.path.exists(filename): json_data[filename] = filename else: json_data[filename] = filename return json_data",37.0173672,29.99729826
generate: Does a lowpass filter over the given data.,"def lowpass_filter(data, cutoff, fs, order=5):
    """"""
    
    """"""
    nyq = 0.5 * fs
    normal_cutoff = cutoff / nyq
    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)
    y = signal.lfilter(b, a, data)
    return y","def lowpass_filter(self, data, **kwargs): """""""""""" filter = self.get_filter_filter_filter(data) if filter: return filter(**filter) else: return filter(**filter)","def does_filter_does_filter(self, data, index=None): """""" """""" self.does_filter_does_filter_does(data, index, index) return self.does_filter(data, index, index, index, locals=index)",30.36564574,28.9925063
generate: Callback for _system.,"def _system_body(p):
    """"""""""""
    enc = DEFAULT_ENCODING
    for line in read_no_interrupt(p.stdout).splitlines():
        line = line.decode(enc, 'replace')
        print(line, file=sys.stdout)
    for line in read_no_interrupt(p.stderr).splitlines():
        line = line.decode(enc, 'replace')
        print(line, file=sys.stderr)

    # Wait to finish for returncode
    return p.wait()","def system(self, *args, **kwargs): """""""""""" if self.system.is_set(): return self.system_callback(*args, **kwargs) elif self.system.is_set(): return self.system_callback(*args, **kwargs) elif self.system_is_set(): return self.system_callback(*args, **kwargs) else: raise SystemExit()","Get the current_system. def get_system_system_system(self, username): """""" """""" if username is None: # This is a blank. username = get_user_name(username) else: # This is required to access to something. username = username return self.get_user_name(username, username)",18.00217046,16.87427723
generate: Start scheduling jobs.,"def schedule(self):
        """"""""""""

        if self.async_mode:
            self._scheduler.start()
            self._listener.start()
        else:
            self._scheduler.schedule()","def start(self): """""" """""" self.jobs = self.jobs self.jobs = self.jobs self.jobs = self.jobs self.jobs = self.jobs self.jobs = self.jobs self.jobs = self.jobs self.jobs = self.jobs self.jobs = self.jobs self.jobs = self.jobs","def start_jobs(self, job_id): """""""""""" jobs = job_id.get('job_id', None) jobs.print(job_id) jobs.add(job_id) self._jobs = job_id jobs.start() jobs.start() jobs.start() jobs.close() self._jobs.start()",19.10708692,25.35860314
generate: Return a dict of keys that differ with another config object.,"def dict_diff(prv, nxt):
    """"""""""""
    keys = set(prv.keys() + nxt.keys())
    result = {}
    for k in keys:
        if prv.get(k) != nxt.get(k):
            result[k] = (prv.get(k), nxt.get(k))
    return result","def get_keys(self, keys): """""""""""" keys = [self.get_key(key) for key in keys] if self.keys: return self.get_key_list(keys) return self.get_keys(keys)","def get_diff_key(self): """""" """""" if self.config.get('diff_key_name', None): return self.config.get('diff_key_name', None) else: return self.config.get('diff_key_name', None)",38.06955948,27.88793588
generate: Play a game of naughts and crosses against the computer.,"def play():
    ''
    ai = {'X': player_move, 'O': random_move}
    board = Board()
    while not board.winner:
        x, y = ai[board.player](board)
        board = board.make_move(x, y)
    print(board, end='\n\n')
    print(board.winner)","def play(self, naux=0, **kwargs): """""" """""" if self.manager: return self.manager.play(naux, **kwargs) self.manager.play(naux, **kwargs)","def play_computer(self, computer_id, computer_id): """""" """""" response = self._get_response(computer_id, computer_id) return self.response(response)",12.80201858,8.95817596
generate: Serialize and send available measures of a metric.,"def serialize_metric(self, metric, m_name, keys, m_type):
        """"""""""""

        return [
            self.format_metric_string(m_name, getattr(metric, key), m_type)
            for key in keys
        ]","def send_metric(self, metric, sender): """""" """""" if metric is None: metric = self.send_metric(sender) # Send available metric metric metric. metric = self.send_metric(sender) return self.send_metric(metric)","def _send(self, metric, metric, data): """""" """""" response = self._send(metric, data) return response.json()",32.85265802,32.67152684
generate: Generates an address from a private key digest.,"def address_from_digest(digest):
        # type: (Digest) -> Address
        """"""
        
        """"""
        address_trits = [0] * (Address.LEN * TRITS_PER_TRYTE)  # type: List[int]

        sponge = Kerl()
        sponge.absorb(digest.as_trits())
        sponge.squeeze(address_trits)

        return Address.from_trits(
            trits=address_trits,

            key_index=digest.key_index,
            security_level=digest.security_level,
        )","def _add_address_from_key(self, key): """""""""""" if key in self._address_from_key: if self._address_from_key[key]: return self._address_from_key[key] else: return self._address_from_key[key] else: return None","def generate_key_dictgest(self, key, address, key_to_address, skip_address, address, skip_address, skip_address, skip_address): """""" """""" key_to_address = self._get_key_to_address(key, address) if key_to_address: key_to_address = self._get_key_to_address_from_address(key_to_address, address) else: key_to_address = self._get_key_to_address(key_to_address) return self._get_key_to_address(key_to_address, address, skip_address, skip_address)",19.76930096,24.66813485
generate: Return section resource for given sis id.,"def get_section_by_sis_id(self, sis_section_id, params={}):
        """"""
        
        """"""
        return self.get_section(
            self._sis_id(sis_section_id, sis_field=""section""), params)","def _get_sis_section(self, sis_id): """""" """""" if self.is_section: return self.section_resource(sis_id) else: return self.section_resource(sis_id)","def get_section_id(self): """""" """""" return self.get_section_id(self.get_section_id(self.section_id))",59.04197255,48.32350927
"generate: Multiply this frame, viewed as a matrix, by another matrix.","def mult(self, matrix):
        """"""
        
        """"""
        if self.ncols != matrix.nrows:
            raise H2OValueError(""Matrix is not compatible for multiplication with the current frame"")
        return H2OFrame._expr(expr=ExprNode(""x"", self, matrix))","def multiply(self, frame, frame, frame): """""" """""" if frame not in self.frames: raise ValueError('Cannot multiply frame matrix.') if frame not in self.frames: raise ValueError('Cannot multiply frames.') if frame in self.frames: raise ValueError('Cannot multiply frames.') if frame not in self.frames: raise ValueError('Cannot multiply frames.') self.frames[frame] = frame return self.frames[frame]","def matrix(self, matrix, frame_spec): """""" """""" if frame_spec.size == 0: matrix = self._matrix.matrix(matrix) elif frame_spec.size == 25: matrix = self._matrix(matrix) else: raise ValueError(""Matrix must be a string."") return matrix",24.07034865,44.89949472
generate: The AST rules.,"def rules(self):
    """"""""""""
    if self._rules is None:
      self._rules = []
      for child in self.grammar.children:
        if child.is_type(TokenType.rule):
          name, expression = child.children
          self._rules.append(Rule(name.value, self._expression_to_asn(expression), name.position, child.consumed))
    return self._rules","def get_ast(self, key=None, payload=None): """""" """""" if key is None: return [] if self.user_id is None: return [] rules = self.get_rules(key) if not rules: rules.append(rules) if rules is not None: return rules return []","def _find_pages(self, ast_id, spec_info, do_client_page=True): """""" """""" response = self._client._get( self._url_path, ast_id, response.headers, response.headers, response.headers ) if response.headers: return self._client._find_response(response) else: return self._find_response(response)",34.00238829,28.50416811
generate: Adds a factory.,"def addFactory(self, identifier, factory):
        """"""

        """"""
        factory.doStart()
        self._factories[identifier] = factory","def add(self, factory, factory): """""" """""" factory = factory.get(factory) self.add_factory(factory, factory)","def add_factory(self, factory, platform=True): """""" """""" self.flatten = factory if platform: factory.update(platform) else: factory.update(platform)",62.2330263,44.55656073
generate: Handler for ls command,"def ls_handler(self, args):
    ''''''
    if len(args) == 1:
      self.pretty_print(self.s3handler().list_buckets())
      return

    self.validate('cmd|s3', args)
    self.pretty_print(self.s3handler().s3walk(args[1]))","s. def handle_commands(self, ls): """""" """""" # Check if the commands are valid. if not self.commands: return if self.commands: return self.commands[len(ls)] else: return self.commands","line to WGGER. def write_line(self, text): """""" """""" if self._ready_exists(text): self._ready_exists(text, text) self._write_line(text) return self._write_line(text, text)",31.59228797,26.36656766
"generate: Template filter that obfuscates whatever text it is applied to. The text is  supposed to be a URL, but it will obfuscate anything.","def obfuscate(value, juice=None):
    """"""
    
    """"""
    if not settings.UNFRIENDLY_ENABLE_FILTER:
        return value
    kwargs = {
        'key': encrypt(value,
                       settings.UNFRIENDLY_SECRET,
                       settings.UNFRIENDLY_IV,
                       checksum=settings.UNFRIENDLY_ENFORCE_CHECKSUM),
    }
    if juice:
        kwargs['juice'] = slugify(juice)
    return reverse('unfriendly-deobfuscate', kwargs=kwargs)","def text_filter(self, filter_url, filter_url): """""" """""" url = filter_url.lower() if not self.filter_url(url): url = url.lower() filter_url = filter_url.lower() if filter_url not in self.filter_urls: return self.filter_url(url, filter_url) return self.filter_url(url, filter_url)","def _expired_to_url(url, url, required_token): """""" """""" url = url.replace(""/"", ""_"", ""/"") if not url: raise UnimplementedError(""Unimplemented URL"") url = url_format(url, required_token) if not url: raise UnimplementedError(""URL"") return url",17.4908674,14.74967282
generate: Return dict mapping the key to list of messages.,"def create_key_to_messages_dict(messages):
    """"""""""""
    dictionary = collections.defaultdict(lambda: [])
    for message in messages:
        dictionary[message.message_args[0]].append(message)
    return dictionary","def _messages(self): """""""""""" key = self.key if key: if key in self._messages: return self._messages[key] else: return self._messages[key] else: return self._messages[key]","def _find_messages(self, message_id, message_id, region): """""" """""" if not message_id: raise TemplateBadRequest(message_id, message_id, region) return message_id",33.86386874,38.95119959
generate: There are a couple of template scripts in the package. This    function loads one of them and prepares it for use.,"def _load_template(dev_path):
        """"""
        
        """"""
        # See https://bitbucket.org/pypa/setuptools/issue/134 for info
        # on script file naming and downstream issues with SVR4
        name = 'script.tmpl'
        if dev_path:
            name = name.replace('.tmpl', ' (dev).tmpl')

        raw_bytes = resource_string('setuptools', name)
        return raw_bytes.decode('utf-8')","def load_scripts(self, template, script=None): """""" """""" # Load templates into the list of templates, but use the first template templates = templates.split(self.templates) if len(templates) == 0: templates = [] for script in script: templates.append(script) return templates","This is another. This is a list of an aggregated package. def _get_template_scripts(self, package, scripts): """""" """""" self._options.update(package) if not self._options: raise ValueError('Package class must be an empty list') return self._get_supplits(package, scripts)",28.13155701,24.51200917
generate: Fetches a single row from the cursor.,"def fetchone(self):
        """"""""""""
        self._check_executed()
        r = self._fetch_row(1)
        if not r:
            self._warning_check()
            return None
        self.rownumber = self.rownumber + 1
        return r[0]","def get_row(self, row, cache_name=None): """""" """""" row = self.get_row(row) if row is None: row = self.get_row(row) if row is None: row = self.get_row(row) return row","def fetch(self, rows, column_column): """""" """""" rows = self.query(rows, column_column) if not self.query_supported(): return rows return rows",37.37861638,39.07529555
"generate: This determines whether a specific extension is allowed. It is called    by `file_allowed`, so if you override that but still want to check    extensions, call back into this.","def extension_allowed(self, ext):
        """"""
        
        """"""
        return ((ext in self.config.allow) or
                (ext in self.extensions and ext not in self.config.deny))","def _check_extension(self, file_allowed, file_allowed): """""" """""" if file_allowed is None: file_allowed = self._check_extension_file(file_allowed) return file_allowed","def called_to_specific_to_specific_file(self, file_allowed): """""" """""" extension = self.extensions.get(file_allowed) return self._callback(extension, file_allowed)",37.8331424,44.52103202
generate: Remove all keys with Nones as values,"def clean_dict(dict):
    """"""
    """"""
    if sys.version_info[0] < 3:
        return {k: v for k, v in dict.iteritems() if v is not None}
    else:
        return {k: v for k, v in dict.items() if v is not None}",". def remove_all_keys(self, keys, vals=None): """""" """""" for key in self.keys(): if key not in keys: return if vals is not None: self.keys.remove(key) self.remove(key)","of a list of keys. def remove_keys(self, keys): """""" """""" if keys: keys = [k for k, v in keys.items() if k in keys] else: keys = [k for k, v in keys] return self.remove_keys(keys)",36.32135237,42.07269842
generate: Returns a copy of a Layout instance.,"def copy(self):
        """"""""""""
        layout_copy = type(self)()

        layout_copy._p2v = self._p2v.copy()
        layout_copy._v2p = self._v2p.copy()

        return layout_copy","def copy_opt(self, loop=None, **kwargs): """""" """""" loop = self.loop if loop is None: loop = self.loop if loop is None: loop = self.loop # Returns an Layout instance. return LayoutInstance(loop=loop, **kwargs)","def copy_copy(self, url, data): """""" """""" copy = self._get_data() copy.copy(url, data) return copy",27.30501866,36.80195544
generate: Replaces sys.argv with proper args to pass to script.,"def _replace_sysargs(self):
        """"""""""""
        sys.argv[:] = [self._run_object]
        if self._run_args:
            sys.argv += self._run_args.split()","def _replace(self, args): """""""""""" sys.argv = self.args self.args = args self.password = self.password","def replaces_system_args(args): """""" """""" if not args: sys.exit(not args) sys.exit(1) if not args: sys.exit(1)",47.58963787,36.94639226
generate: Check if the attribute is allowed to have multiple instances.,"def is_attribute_multivalued(self, attribute):
        """"""
        
        """"""
        # TODO (peterhamilton) Handle multivalue swap between certificate types
        rule_set = self._attribute_rule_sets.get(attribute)
        return rule_set.multiple_instances_permitted","def validate_attribute(self, attribute_name, **kwargs): """""" """""" attribute_name = self.attribute_name.split('.')[0] if not attribute_name: raise AttributeError(attribute_name, **kwargs) if not attribute_name: return False return False","def is_page_attribute_for_spec(self, page_name): """""" """""" try: return self.spec.is_page(page_name) except Exception as e: raise Exception(""Unable to get page attribute %s"" % e.message)",38.71331117,32.31776679
generate: Replace or set the CA certificates within the PKCS12 object.,"def set_ca_certificates(self, cacerts):
        """"""
        
        """"""
        if cacerts is None:
            self._cacerts = None
        else:
            cacerts = list(cacerts)
            for cert in cacerts:
                if not isinstance(cert, X509):
                    raise TypeError(
                        ""iterable must only contain X509 instances""
                    )
            self._cacerts = cacerts","def setup(self, obj, selector, cardinal_options, selector=None): """""" """""" self.selector = selector if selector is not None: self.selector = selector if cardinal_options is not None: self.selector = cardinal_options self.selector = selector","def replace(self, certificate=False, name=None, disk=False): """""" """""" if certificate: certificate = self.get_certificate(certificate=certificate) else: certificate = certificate if certificate: if certificate: certificate = certificate or certificate if certificate: certificate = certificate else: certificate = certificate return certificate",31.5508971,31.06612392
generate: Return the index of the closest in xarr to value val,"def closest(xarr, val):
    """"""  """"""
    idx_closest = np.argmin(np.abs(np.array(xarr) - val))
    return idx_closest","def closest_index(self, xarr): """""" """""" closest = [xarr for xarr in self.index] if self.index == xarr: return 0 if self.index == xarr: return 0 return 0",". def get_index(self, index, closest_index): """""" """""" return self._clean_index(index, closest_index)",31.6096249,35.95026312
"generate: Check if a user is in a certaing group.  By default, the check is skipped for superusers.","def user_has_group(user, group, superuser_skip=True):
    """"""
    
    """"""

    if user.is_superuser and superuser_skip:
        return True

    return user.groups.filter(name=group).exists()","def _check_certain_group(self, name, default=None, version=None, repr=None): """""""""""" check_certain_group(name, default, version, repr) check_certain_group(name, default, version, repr)","def _check_user(user): """""" """""" user = user.get_user() if user.is_active(): return user.is_active() else: return user.is_active() and user.is_active()",20.91607928,42.79497159
"generate: Called to create the control, which must derive from wxControl.","def Create(self, parent, id, evtHandler):
        """"        
        self._tc = wx.ComboBox(parent, id, """", (100, 50))
        self.SetControl(self._tc)
        # pushing a different event handler instead evtHandler:
        self._tc.PushEventHandler(wx.EvtHandler())
        self._tc.Bind(wx.EVT_COMBOBOX, self.OnChange)","def called_control_control(self, control, wx_handler, density_handler): """""" """""" control_control = self.control_control_control(control, wx_handler) # FIXME: we don't do this code wx_handler = self.control_control(control_control) wx_handler = self.control_control(control, wx_handler) return wx_handler","def create_wx_control(self, control_id, req): """""" """""" if not self.is_required(): return if not self.is_required(): return # This is any which callback first self.set_wx_control(control_id, req)",27.18637003,20.89326209
"generate: By default, Flask will accept uploads to an arbitrary size. While Werkzeug  switches uploads from memory to a temporary file when they hit 500 KiB,  it's still possible for someone to overload your disk space with a  gigantic file.","def patch_request_class(app, size=64 * 1024 * 1024):
    """"""
    
    """"""
    if size is None:
        if isinstance(app.request_class.__dict__['max_content_length'],
                      property):
            return
        size = app.config.get('MAX_CONTENT_LENGTH')
    reqclass = app.request_class
    patched = type(reqclass.__name__, (reqclass,),
                   {'max_content_length': size})
    app.request_class = patched","def get_multi_signature(self, class_name, signature_name, signature_name, signature_name, flask_size, **kwargs): """""" """""" import tempfile tempfile = self.tempfile.name if signature_name == '.json': tempfile.write(""{}.json"".format(signature_name, signature_name, signature_name, signature_name)) return tempfile","This will get another default otherwise. If a temporary file, then otherwise a single one of an arbitrary file. def upload(self, flask, flask=False): """""" """""" if not flask: self.delete_flask_flask(flask) return self.display_flask_flask(flask) self.display_flask_flask(flask, flask)",20.12008374,16.84210497
generate: Compute the tiny-value corresponding to an input's data type.,"def tiny(x):
    '''
    '''

    # Make sure we have an array view
    x = np.asarray(x)

    # Only floating types generate a tiny
    if np.issubdtype(x.dtype, np.floating) or np.issubdtype(x.dtype, np.complexfloating):
        dtype = x.dtype
    else:
        dtype = np.float32

    return np.finfo(dtype).tiny","def tiny_type(self, signature): """""" """""" if self.type == 'float': return 'float' elif self.type == 'float': return 'float' elif self.type == 'float': return 'float' else: raise ValueError('type' else: raise ValueError('type')","def _compute_tiny_value_corresponding(self, data_type, data_type): """""" """""" if self._compute_data_type == 'tiny-value': return self._compute_data_type(data_type, data_type, data_type) else: raise ValueError('Missing data type: %s' % (data_type, data_type))",27.09103805,28.71463914
"generate: Decorator that switches to given directory before executing function, and  then returning to orignal directory.","def switch_to_dir(dirPath):
    """"""
    
    """"""

    def decorator(func):
        @funcutils.wraps(func)
        def wrapper(*args, **kwargs):
            orig_cwd = os.getcwd()
            os.chdir(dirPath)
            ret = func(*args, **kwargs)
            os.chdir(orig_cwd)
            return ret
        return wrapper

    return decorator","def function(name, func=None): """""" """""" @wraps(func) def wrapper(*args): @wraps(func) def wrapper(*args): func(*args) return func return wrapper","def decorator(self, function, function, *args, **kwargs): """""" """""" if not function.startswith('win'): return function_name = function.lower() if function.startswith(""win""): return self._win return self._win",34.25520606,37.49046356
generate: Marks a function as having been published and causes all invocations to go to the remoteoperationalized service.,"def service(url, api_key, help_url = None):
    '''
'''
    def do_publish(func):
        return published(url, api_key, help_url, func, None)
    return do_publish","def mark_func(func, *args, **kwargs): """""""""""" def cause_func(func): if isinstance(func, Func): return func return cause_func","def cause(published, published=True): """""" """""" if not published: published = published if published and not published: published = False return Function(published, published, published)",27.59131029,23.85124369
"generate: Calls `fn` with `args`, possibly expanding `args`.","def call_fn(fn, args):
  """"""
  """"""

  if expand_as_args(args):
    return fn(*args)
  elif _expand_as_kwargs(args):
    return fn(**args)
  else:
    return fn(args)","def get_args(args): """""" """""" args = args args = args.split(',') if args.expanding: args = args.split(',') return args","def _callable_args(args, kwargs): """""" """""" if args.args.get('args', None): return fn(args, kwargs) else: raise TypeError(""Fn` argument must be a single argument"")",38.73545351,46.5270157
"generate: Generate a column of random numbers drawn from a uniform distribution [0,1) and    having the same data layout as the source frame.","def runif(self, seed=None):
        """"""
        
        """"""
        fr = H2OFrame._expr(expr=ExprNode(""h2o.runif"", self, -1 if seed is None else seed))
        fr._ex._cache.ncols = 1
        fr._ex._cache.nrows = self.nrow
        return fr","def get_column(self, frame, frame, frame, frame, frame_name): """""" """""" column = self.column_map[frame] frame = self.column_map[frame] return self.column_map[frame, frame, frame]","def random_numbers(self, data_layer=None, source_id=None): """""" """""" if source_id is None: source_id = self.get_source_id(source_id) else: source_id = self.get_source_id(source_id) if source_id is None: source_id = source_id.get_source_id() return self._get_source_id(source_id, source_id, source_id)",28.99187496,24.38959773
generate: Convert a function taking multiple arguments into a function taking a single iterable argument.,"def splat(f: Callable[..., A]) -> Callable[[Iterable], A]:
    """"""
    """"""

    def splatted(args):
        return f(*args)

    return splatted","def to_function_taking(func, arguments): """""" """""" @wraps(func) def wrapper(*args): return func(*args) return wrapper","def _get_function_table(func, *args, **kwargs): """""""""""" if not isinstance(func, (list, tuple)): raise TypeError(""The function must be a list of function type"") if not isinstance(func, (list, tuple)): raise TypeError(""Table must be a list of type %s"" % type(func)) return func(*args, **kwargs)",40.06004247,14.75483727
generate: Checks memory usage when 'line' event occur.,"def _trace_memory_usage(self, frame, event, arg):  #pylint: disable=unused-argument
        """"""""""""
        if event == 'line' and frame.f_code.co_filename in self.target_modules:
            self._events_list.append(
                (frame.f_lineno, self._process.memory_info().rss,
                 frame.f_code.co_name, frame.f_code.co_filename))
        return self._trace_memory_usage","def check_memory_usage_where(self, line): """""" """""" # We can't simplify the memory where any memory when an # usage is an event occurred. if line.startswith(self.line): self.line = line.strip() self.lines = line.splitlines() return self","def __check_memory(self, line): """""" """""" try: if self.is_valid_memory(): return self.is_valid_memory(line) else: return None except Exception as e: self.is_valid_memory() raise MemoryError(e) except Exception as e: self.is_valid_memory()",29.43115555,25.54455589
generate: Handle an internal exception that was caught and suppressed.,"def _handle_exception(self, exc):
        """"""
        """"""
        logger = logging.getLogger(__name__)
        logger.exception(exc)","def caught_internal(self, exception): """""" """""" if self.supported: self.supported = self.supported return self.supported","def _clean_exception_for_logger(self, other): """""" """""" return other.clean_exception(self, other)",29.63081021,49.00738866
"generate: since the user needs a job id and other parameters, save this      for them.","def _get_metadata(self):
        '''
        '''
        metadata = {'SREGISTRY_GITLAB_FOLDER': self.artifacts,
                    'api_base': self.api_base,
                    'SREGISTRY_GITLAB_BASE': self.base,
                    'SREGISTRY_GITLAB_JOB': self.job }
        return metadata","def save_job_id(self, job_id, job_id, job_id, **kwargs): """""" """""" if job_id not in self.jobs: raise ValueError('job_id must be a list of job id and job id and job id and job id.') return job_id, job_id","def save_job(self, job_id, address, address): """""" """""" self.address = job_id self.address = job_id self.address = address self.address = address self.address = address",15.79989474,18.22691183
generate: Save parameters to file.,"def save_params(self, path, new_thread=False):
        """"""
        
        """"""
        save_logger.info(path)
        param_variables = self.all_parameters
        params = [p.get_value().copy() for p in param_variables]
        if new_thread:
            thread = Thread(target=save_network_params, args=(params, path))
            thread.start()
        else:
            save_network_params(params, path)
        self.train_logger.save(path)","def save_files(self, filename, filter_name, filter_name, filter_name, filter_name, filter_name=None, save_filter_name=None): """""" """""" self.files = filter_name self.files = save_filter_name self.files = [filename] self.save_files(filename)","def save_parameters(self, save_path, properties): """""" """""" if not self.path: raise RuntimeError(""Path must specify"") self.path = save_path self.targets = [] self.path = save_path self.target_name = self.path self.targets.append(save_path) self.targets.append(save_path) self.path = target_name self.path = target_name",22.21251559,37.8479215
generate: Assert `x` has rank equal to `rank` or smaller.,"def assert_rank_at_most(x, rank, data=None, summarize=None, message=None,
                        name=None):
  """"""
  """"""
  with tf.compat.v2.name_scope(name or 'assert_rank_at_most'):
    return tf.compat.v1.assert_less_equal(
        tf.rank(x), rank, data=data, summarize=summarize, message=message)","def _assert_xis_with_xis_with_xis(x, x, y, loc=None): """""""""""" if x.is_assert_xis_with_xis_with_xis(x, y): return False if x.is_assert_xis_with_xis(x, y): return True if x.is_assert_xis(x, y): return True return True","def rank(x, y, corpus, mode='ljk'): """""" """""" if isinstance(x, (float, int, float)): return (x, y) if not mode == 'ljk': return (1, y) elif has_ljk: return (1, y) elif has_ljk: return (1, y) elif has_ljk: return (1, y) elif has_ljk: return (2, 1) elif has_ljk: return (1, 1) elif has_ljk: return (1, 2) elif has_ljk: return (2, 1) elif has_ljk: return (1, 1) else: return (2, 1)",22.25825119,13.85928515
"generate: Parses a move in standard coordinate notation, makes the move and puts    it on the the move stack.    Raises `ValueError` if neither legal nor a null move.    Returns the move.","def push_usi(self, usi):
        '''
        
        '''
        move = Move.from_usi(usi)
        self.push(move)
        return move","def _parse_move_move(self, move, move, null=None): """""" """""" stack = move.parse_move(move) if stack is None: stack = move.parse_move(move) return stack","def parse_move_stack(self, coordinates): """""" """""" if not self.exists: return False return True",24.56309096,29.23044825
"generate: Finds transactions matching the specified criteria, fetches the  corresponding trytes and converts them into Transaction objects.","def find_transaction_objects(adapter, **kwargs):
    # type: (BaseAdapter, **Iterable) -> List[Transaction]
    """"""
    
    """"""
    ft_response = FindTransactionsCommand(adapter)(**kwargs)

    hashes = ft_response['hashes']

    if hashes:
        gt_response = GetTrytesCommand(adapter)(hashes=hashes)

        return list(map(
            Transaction.from_tryte_string,
            gt_response.get('trytes') or [],
        ))  # type: List[Transaction]

    return []","def get_transactions_from_transactions(self, criteria, transaction_name, filter_query=None): """""" """""" # get the transactions matching the specified transactions. # criteria_name transactions = [] transactions = [self.get_transaction_name(criteria) for criteria in criteria] transactions.append(transactions) transactions.append(transactions) transactions.append(transactions) transactions.append(transactions) transactions.append(transactions) transactions.append(transactions) return transactions","def get_transactions(self, transaction): """""" """""" if not self.is_transaction(transaction): raise TransactionNotFound(transaction) if not self.is_transaction_transaction(transaction): raise TransactionNotFound(transaction) if self.is_transaction(transaction): raise TransactionNotFound(transaction) if not self.is_transaction(transaction): raise TransactionNotFound(transaction) return self.get_transaction(transaction)",26.50002162,26.76098035
generate: Create a new symbol.,"def symbol(name: str, ns: Optional[str] = None, meta=None) -> Symbol:
    """"""""""""
    return Symbol(name, ns=ns, meta=meta)","def create_symbol(self, symbol): """""""""""" if self.symbol is None: self.symbol = symbol return self.symbol","def create_symbol(self, symbol_name, new_symbol): """""" """""" if symbol_name.startswith("".""): symbol_name = self.symbol_name if symbol_name.startswith("".""): symbol_name = self.symbol_name return symbol_name",35.54486973,23.2278602
generate: Iterates over the parent-child relationships in an ontolog,"def get_hierarchy(ontology, ols_base=None):
    """"""
    """"""
    client = OlsClient(ols_base=ols_base)
    return client.iter_hierarchy(ontology)","ical of the given ontological relationships. def iterate(self, relationships): """""" """""" relationships = [] for relationship in relationships: if relationships.get(relationships) == []: continue if relationships.get(relationships) == []: relationships.append(relationships) return relationships","y. def _get_child(self, child, relationships): """""" """""" if child.exists(): self._child_child_relationships() else: self._child_child_relationships()",14.46534823,17.50131456
generate: Verify if the request token is existed.,"def verify_request_token(self, token, request):
        """"""""""""
        log.debug('Verify request token %r', token)
        tok = request.request_token or self._grantgetter(token=token)
        if tok:
            request.request_token = tok
            return True
        return False","def validate(self, request, request): """""""""""" if request is None: request = self._request if request.method == 'POST': if request.method == 'POST': return True else: return True return True else: return False","def _is_access_token(self, request): """""" """""" if request.access_token: request.access_token = access_token else: request.access_token = None return self.access_token",49.86211454,41.47727546
generate: Calculate the Hamming distance between two bit strings,"def hamming_distance(str1, str2):
    """"""
    """"""
    if len(str1) != len(str2):
        raise VisualizationError('Strings not same length.')
    return sum(s1 != s2 for s1, s2 in zip(str1, str2))","and Units. def __hamming_distance(self, HammingDistance, dist): """""" """""" if HammingDistance >= 1: return HammingDistance(dist) else: return HammingDistance(dist)",". def distance(self, bitming): """""" """""" self._distance = self._distance self._handling_training = bitming self._draw_bitming = bitming self._handling_training = bitming self._distance = distance",31.69326495,21.90721881
generate: check if the module has a preferred replacement,"def _check_preferred_module(self, node, mod_path):
        """"""""""""
        if mod_path in self.preferred_modules:
            self.add_message(
                ""preferred-module"",
                node=node,
                args=(self.preferred_modules[mod_path], mod_path),
            )",", it can be checked in the currently, and the checking is not exist. def check_referred(self, replacement, module): """""" """""" if self.has_referred(module): return True else: return False",". def check_replacement(self, replacement): """""" """""" if self.relation is None: raise ValueError(""No relation must be called"") self.relation_module = replacement if self.target.name is not None: self.relation_module = replacement return self.relation_module",34.02889943,27.72924191
generate: Get the merge full data,"def merge(self, merge_id):
        """"""""""""

        path = urijoin(self.base_url,
                       GitLabClient.PROJECTS, self.owner + '%2F' + self.repository,
                       GitLabClient.MERGES, merge_id)

        response = self.fetch(path)

        return response.text","from a list of database and return the databases. def get_merge_full_databases(self, databases): """""" """""" merge_data = [] for m in databases: merge_data.append(m.databases) return merge_data","from the device. def get_full_data(self, full_data, device=None, discovery=False): """""" """""" url = self._url + ""/api/v1/api/v1/device/api/v1/device/"" + device return self._get(url, device=device)",27.71638035,25.88983992
generate: Returns whether the given query options expect a possible count of zero.,"def expects_none(options):
    """"""
    
    """"""

    if any(options.get(key) is not None for key in [""count"", ""maximum"", ""minimum"", ""between""]):
        return matches_count(0, options)
    else:
        return False","def is_zero_count(self, query_options, zero_count): """""" """""" query_options = [] query_options.append(query_options) return query_options","def is_when_count(self, zero_count): """""" """""" if self.ws_generator.get(""generator.record_count""): return False else: return False",31.04375508,34.53859703
generate: Obsolete - catches exceptions from the wrapped function.,"def async_callback(self, callback, *args, **kwargs):
        """"""
        """"""
        if callback is None:
            return None
        if args or kwargs:
            callback = functools.partial(callback, *args, **kwargs)

        #FIXME what about the exception wrapper?

        return callback","def _validate_wrapped_event(self, function, func): """""" """""" if func is not None: if func is not None: func = func if func is not None: func = func return self.event_wrapped_event(func, func) return self.event_wrapped_event","def _get_response_exception(self, response, headers=None): """""" """""" if response.status_code == 200: return headers elif response.status_code == 200: return headers elif response.status_code == 200: return headers elif response.headers == 200: return headers else: return self._get_response(response.headers)",31.62067853,20.48766256
"generate: Starts over again at the new line. If number is specified,      it will leave multiple lines.","def add_newline(self, number=1):
        """""" """"""
        if isinstance(number, int):
            try:
                self.page._add_newline(self.font, number, self.double_spacing)
            except ValueError:
                self.add_page()
        else:
            raise TypeError(""Number of newlines must be an integer."")","def start(self): """""" """""" if self.generic.input_lines is not None: self.generic.input_lines = self.generic.input_lines return self","def start_on_line(self, line): """""" """""" if not self.lines: raise ValueError(""Argument must be a list of string."") if not self.is_structure(): raise ValueError(""Argument must be a list of structure."") if self.is_structure_matrix_matrix_matrix(line): self.set_lines(line) else: self.set_lines(line)",20.2501118,38.10024726
generate: Get and return the jar path for bigdl if exists.,"def get_bigdl_classpath():
    """"""
    
    """"""
    if os.getenv(""BIGDL_CLASSPATH""):
        return os.environ[""BIGDL_CLASSPATH""]
    jar_dir = os.path.abspath(__file__ + ""/../../"")
    jar_paths = glob.glob(os.path.join(jar_dir, ""share/lib/*.jar""))
    if jar_paths:
        assert len(jar_paths) == 1, ""Expecting one jar: %s"" % len(jar_paths)
        return jar_paths[0]
    return """"","def get_jar_path(self): """""" """""" jar_path = self.jar_path if not jar_path: return self.jar_path jar_path = self.jar_path if not jar_path: return self.jar_path jar_path = self.jar_path if not jar_path: return self.jar_path if not jar_path: return self.jar_path if jar_path.endswith(""/""): return self.jar_path return self.jar_path","def get_bigdl_file(self): """""""""""" # If there is no jar path is any jar, return it # if not found, it's not jar file, it will be converted if self.jar_path is None: return jar_path # Get the jar filename if not self.jar_path: # Just use bigdl file self.jar_path = self.jar_path return jar_path",37.19505663,36.48539485
generate: Remove a patch from the patches list,"def remove_patch(self, patch):
        """"""  """"""
        self._check_patch(patch)
        patchline = self.patch2line[patch]
        del self.patch2line[patch]
        self.patchlines.remove(patchline)",". def remove_patch(self, patch): """""" """""" patch = [] for patch in self._patch_patchs: patch.append(patch) patch.remove_patch(patch) self.patch_patchs.remove_patch(patch) self.patch_patchs.remove_patch(patch)",". def remove_patches(self, patches): """""""""""" patches = [patches[0] for patches in patches] self.remove_patches(patches) return patches",52.14695543,48.50982289
"generate: For all the datetime fields in ""datemap"" find that key in doc and map the datetime object to    a strftime string. This pprint and others will print out readable datetimes.","def date_map(doc, datemap_list, time_format=None):
        '''
        
        '''
        if datemap_list:
            for i in datemap_list:
                if isinstance(i, datetime):
                    doc=CursorFormatter.date_map_field(doc, i, time_format=time_format)
        return doc","def form(self, date): """""" """""" date = self._get_datetime_form(date) date = self._get_datetime_form(date) if date: if date: return date else: return date","def get_datetime_fields(datetime_datetime_str, mode=None): """""" """""" if datetime_str: datetime_str = datetime_str else: datetime_str = datetime_str return datetime_str.replace(""%Y%m%d%H%M%S%FT%H:%M%S"")",33.64092844,35.64241655
generate: DDP unsub handler.,"def recv_unsub(self, id_=None):
        """"""""""""
        if id_:
            self.api.unsub(id_)
        else:
            self.reply('nosub')","def check_handler(self, handler): """""" """""" if self.handler: self.handler = handler self.handler = handler return self","def get_subhandler_handler(self, handler): """""" """""" return self._get_subhandler(handler)",28.30222008,27.82862182
"generate: Allows temporarily pushing an additional context, yields the new context    into the following block.","def additional(self, additional, use_parent=False):
        """"""
        
        """"""
        self.push(additional, use_parent)
        yield self.current
        self.pop()","def follow(self, following=True): """""" """""" self.follow = None self.follow = None self.follow = None","def additional_context(self, msg): """""" """""" if msg is not None: return self.additional_context.get(msg, msg) else: return self.additional_context.get(msg, msg)",29.39400621,40.58423605
generate: Main executor of the trimmomatic_report template.,"def main(log_files):
    """""" 
    """"""

    log_storage = OrderedDict()

    for log in log_files:

        log_id = log.rstrip(""_trimlog.txt"")

        # Populate storage of current sample
        log_storage[log_id] = parse_log(log)

        # Remove temporary trim log file
        os.remove(log)

    write_report(log_storage, ""trimmomatic_report.csv"", log_id)","def _main_trim_report_template(self, trim_file, trim_report_template_dir, template_dir, template_dir, template_dir, template_dir, template_dir, template_dir, trim_dir, trim_dir): """""""""""" trim_dir = os.path.dirname(trim_dir) trim_dir = os.path.dirname(trim_dir) if not os.path.isdir(trim_dir): os.makedirs(trim_dir) return trim_dir","def _main(self, trim_name, trim_name, trim_size): """""" """""" trim_name = trim_name.split(':') if not trim_name.startswith(':'): raise RuntimeError( 'Trim must be a bug or absolute must be able to ""%s""' % (trim_name, trim_name)) # Add minimal floating report to the group. self._main(trim_name, trim_name, trim_size, trim_name, trim_size)",20.37973493,18.99076535
generate: Cancel or 'un-schedule' a task.,"def cancel_task(self, task_id):
        """"""
        """"""
        self.registry.remove(task_id)
        self._scheduler.cancel_job_task(task_id)

        logger.info(""Task %s canceled"", task_id)","def cancel(self, task_id, **kwargs): """""""""""" # We can be added, so can be cancelled. task_id = task_id.id self.please_on_cancel_task(task_id, **kwargs)","def schedule(self, task): """""" """""" if not self.stop_schedule: raise InvalidSchedule(""No schedule: %s"" % task) self._restore_schedule(task)",50.82085738,38.67597923
generate: Sends the request body.,"def send(self, request=None):
        '''  '''

        # Sends VT_EMPTY if it is GET, HEAD request.
        if request is None:
            var_empty = VARIANT.create_empty()
            _WinHttpRequest._Send(self, var_empty)
        else:  # Sends request body as SAFEArray.
            _request = VARIANT.create_safearray_from_str(request)
            _WinHttpRequest._Send(self, _request)","def send_request(self, url, response): """""""""""" if response: self.request_body = url self.request_body = response self.request_body = response self.request_body = response self.request_body = response else: self.request_body = response self.request_body = response","def start_request(self, request_id, response_body, response_data=None): """""" """""" if response_body is None: response_body = self._get_request(request_id, response_body) return self._put(request_id, response_body, response_body, response_body, response_body, response_body, response_body, response_body)",30.74079582,30.07192093
generate: Call results.func on the attributes of results,"def call(results):
    """"""
    """"""
    results = vars(results)
    places = Places(config=results.pop('config'),
                    messages=results.pop('messages'))
    func = results.pop('func')
    func(places, **results)",". def call_results(self, *args, **kwargs): """""""""""" if not args: raise ValueError(""No argspecified functions."") results = self._find_results(args, *args, **kwargs) self.results = results",". def _find_results(self, results): """""" """""" for j in self._find_results(results): if not j: raise ValueError('Invalid JSON error: %s' % j) results.append((j, j)) return results",37.63894379,36.61472996
generate: Updates the current item based on the current text.,"def _update_current(self):
        """""" 
        """"""
        prefix = self._current_text_cursor().selection().toPlainText()
        if prefix:
            items = self.findItems(prefix, (QtCore.Qt.MatchStartsWith |
                                            QtCore.Qt.MatchCaseSensitive))
            if items:
                self.setCurrentItem(items[0])
            else:
                self.hide()
        else:
            self.hide()","def update_item_body(self, item_body, text, disable=False): """""" """""" if not item_body: return if not text: item_body = self.update_item_body(item_body) self.update_item_body(item_body)","def current_item_body(self, text): """""" """""" if text.lower() not in self._current_objects: self._current_objects[text.lower()] = text.lower() else: self._current_objects[text.lower()] = text return self._current_objects[text.lower()]",21.57261223,34.42300793
generate: Get available attritbutes from dataset you've selected,"def get_attributes(self, dataset):
        """"""""""""
        attributes = self.attributes(dataset)
        attr_ = [ (k, v[0]) for k, v in attributes.items()]
        return pd.DataFrame(attr_, columns=[""Attribute"",""Description""])",". def get_attributes(self, dataset, values): """""""""""" attributes = self._get_attributes_by_name(attributes) if attributes is not None: attributes = attributes.get(attributes) return attributes","datasets. def get_attr_from_snake_attritbutes(self): """""" """""" dataset = {} for attr in self.get_attribute_names(self.attr)[0]: dataset[attr] = attr return dataset",58.18746581,45.86774201
generate: Disable camera.,"def camera_disable(self, camera_id, **kwargs):
        """"""""""""
        api = self._api_info['camera']
        payload = dict({
            '_sid': self._sid,
            'api': api['name'],
            'method': 'Disable',
            'version': 9,
            'idList': camera_id,
        }, **kwargs)
        print(api['url'])
        print(payload)
        response = self._get(api['url'], payload)

        return response['success']","def camera_complete(self, model): """""""""""" camera_name = self.model.name if model.is_descriptor(): camera_name = model.name if camera_name: camera_name = self.model.name self.model.camera_name = camera_name self.model.model.model = camera_name self.model.camera_name = camera_name","def camera_camera_camera(self, camera_id, disable_camera_id): """""" """""" if disable_camera_id and disable_camera_id is not None: self._camera_id = disable_camera_id if self.camera_id is not None: self._camera_id = disable_camera_id if not self._camera_id: self._camera_id = disable_camera_id return self._camera_camera_camera_camera_camera_camera_camera_camera_camera_camera_camera_camera_camera_camera_id",26.32720532,26.22109658
generate: Parse a notebook filename.,"def parse_filename(fname):
    """"""
    """"""
    if fname.endswith(u'.ipynb'):
        format = u'json'
    elif fname.endswith(u'.json'):
        format = u'json'
    elif fname.endswith(u'.py'):
        format = u'py'
    else:
        fname = fname + u'.ipynb'
        format = u'json'
    name = fname.split('.')[0]
    return fname, name, format","def parse(self, notebookfilename, notebookfilename): """""" """""" notebookfilename = notebookfilename try: return self.parse(notebookfilename, notebookfilename) except StopIteration: return None","def parse_notebook(self, filename): """""" """""" url = self.get_url() if not filename: raise NotebookException(""Failed to parse filename: %s"" % filename) if not filename: raise NotebookException(""Failed to parse filename: %s"" % filename) return self.parse_notebook(url, json=os.path.basename(filename))",22.97387449,28.4958413
generate: Parse some arguments using the parser.,"def parse(argv=None):
    """"""
    

    """"""

    if argv is None:
        argv = sys.argv[1:]

    # Evade http://bugs.python.org/issue9253
    if not argv or argv[0] not in {""run"", ""transform""}:
        argv = [""run""] + argv

    arguments = _clean(_parser.parse_args(argv))
    return arguments","def parse_arguments(self): """""" """""" if not self.parse_arguments: raise ValueError(""parse_arguments must be an argument or an arguments"") # parse arguments arguments = self.parse_arguments(arguments) arguments = self.parse_arguments(arguments) return arguments","def parse_args(self, args): """""" """""" # Setting the docstring arguments are instead of the arguments parser_args = self.parse_args(args) if not args.get('snai_args'): raise RuntimeError(""Unable to parse the snai_args: {}"".format(args.get('snai_args'))) return self._parse_args(args, args)",40.13365586,38.43278248
generate: Give a list of all tiers matching a linguistic type.,"def get_tier_ids_for_linguistic_type(self, ling_type, parent=None):
        """"""
        """"""
        return [t for t in self.tiers if
                self.tiers[t][2]['LINGUISTIC_TYPE_REF'] == ling_type and
                (parent is None or self.tiers[t][2]['PARENT_REF'] == parent)]","def list(self, tiers): """""""""""" ti = [] for ti in ti: if ti.startswith('/'): ti = ti.split(""/"")[1].strip() elif ti.startswith('/'): ti = ti.split(""/"")[1].strip() ti = ti.split(""/"")[1].strip() ti = ti.split(""/"")[1].split(""/"")[0].strip() ti.append(ti) return ti","def get_tiers_list(self, linguation, tag_id): """""" """""" linguation = self._get_linguation(linguation) if linguation is None: linguation = self._get_linguation_tag_id(linguation) return tiers.get(linguation, None)",19.25848147,36.48655161
"generate: Get the list of movies for a particular genre by id. By default, only    movies with 10 or more votes are included.","def movies(self, **kwargs):
        """"""
        
        """"""
        path = self._get_id_path('movies')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","def get_movies(self, **kwargs): """""" """""" if kwargs is None: kwargs = {} if self.get_movies: movies = {} for i in range(0, len(self.movies)): movies[i] = self.get_movies(movies[i]) return movies","def get_movies(self): """""" """""" self.logger.debug('POST: Movies are not access token.') url = self._get_url() response = self._get_response(url) return self._get_response(response)",41.88395163,51.27442139
generate: Executes SQL using psycopg2 copy_expert method.    Necessary to execute COPY command without access to a superuser.,"def copy_expert(self, sql, filename, open=open):
        """"""
        
        """"""
        if not os.path.isfile(filename):
            with open(filename, 'w'):
                pass

        with open(filename, 'r+') as f:
            with closing(self.get_conn()) as conn:
                with closing(conn.cursor()) as cur:
                    cur.copy_expert(sql, f)
                    f.truncate(f.tell())
                    conn.commit()","def execute(self, cmd, regexpr, command_type, **kwargs): """""" """""" try: command = self._commands[command] if command_type =='sql': return self.run(command, **kwargs) else: raise ValueError('Unknown COPY command ""%s""' % command_type)","def execute_psycopg2_cmd(self, sys.argv): """""" """""" self._add_handler(sys.argv) self._set_error(""This is accessful"") self._set_error(""Checking psycopg2 copy_expert method"") sys.exit(1) self._set_error(""Could not set USERNAME. This is USERNAME. The psycopg2 code is in an USERNAME."") sys.exit(1) self._set_error(""Could not set USERNAME."") sys.exit(1)",18.8151805,19.46862949
generate: XFEATURE COMPRESS GZIP command.,"def xfeature_compress_gzip(self, terminator=False):
        """"""
        """"""
        args = ""TERMINATOR"" if terminator else None

        code, message = self.command(""XFEATURE COMPRESS GZIP"", args)
        if code != 290:
            raise NNTPReplyError(code, message)

        return True","def feature_command(self, command): """""""""""" self.commands = [] self.xf = command self.xf = xf","def _get_compile_compile_compiled_mode(self, mode, content, buffer_count): """""" """""" command = self._get_compiled_mode(mode, buffer_count) if not buffer_count: raise RuntimeError(""Unexpected command: %s"" % buffer_count) if not buffer_count: raise RuntimeError(""Unable to get command: %s"" % buffer_count) return command.split('\r\n')",12.15963957,25.94467358
generate: Create the toolkit widget for the proxy object.,"def create_widget(self):
        """""" 

        """"""
        self.widget = SubElement(self.parent_widget(), self.declaration.tag)","def create_widget(self, widget): """""""""""" self.widget_data = widget self.widget_data = widget self.widget_data = widget self.widget_data = widget","def get_toolkit_widget(self, widget): """""" """""" if widget: self.toolkit_widget(widget) else: raise TypeError(""widget is not a valid API."") if widget.active_toolkit_widget is None: raise TypeError(""widget is not a valid API."") return self.toolkit_widget(widget)",40.59464186,20.57819396
generate: Downloads a file.,"def download(directory, filename):
  """"""""""""
  filepath = os.path.join(directory, filename)
  if tf.io.gfile.exists(filepath):
    return filepath
  if not tf.io.gfile.exists(directory):
    tf.io.gfile.makedirs(directory)
  url = os.path.join(ROOT_PATH, filename)
  print(""Downloading %s to %s"" % (url, filepath))
  urllib.request.urlretrieve(url, filepath)
  return filepath","def download(self, filename, **kwargs): """""" """""" filename = filename.lower() if not filename.startswith("".py""): raise ValueError(""To make sure the file is not a valid filename, including filename"") if filename.endswith("".py""): filename = filename[:-1] else: filename = filename[:-1] filename = os.path.basename(filename) filename = os.path.join(filename, filename) filename = os.path.join(filename, filename) return filename","def download_file(filename, dest='utf-8', file_name=None): """""" """""" if file_name is None: file_path = os.path.join(dest, filename) else: file_path = os.path.join(dest, filename) dest_file = os.path.join(dest, file_path) os.makedirs(dest_file) if not os.path.isdir(dest): os.makedirs(dest) return dest_file",37.85707101,47.41292776
generate: Returns the ID for the stadium in which the team played in a given    year.,"def stadium(self, year):
        """"""
        """"""
        anchor = self._year_info_pq(year, 'Stadium')('a')
        return sportsref.utils.rel_url_to_id(anchor.attr['href'])","def _get_id_for_id(self, id_form): """""" """""" id_form = self.get_id_form(id_form) if id_form.startswith('.'): return id_form else: return id_form","def get_identity(self, other): """""" """""" if self.is_is_played(): return self.get_identity(other) else: return other.get_identity(other)",32.59790862,30.84454612
generate: Returns the effective username of the current process.,"def __get_username():
    """"""  """"""
    if WINDOWS:
        return getpass.getuser()
    import pwd
    return pwd.getpwuid(os.geteuid()).pw_name","def get_effective_username(self): """""" """""" if self.is_effective(): return self.get_effective_username() else: return self.get_effective_username()","def effective_username(self, url): """""" """""" url = self._url_parts.get('url') url = url + url response = self._get_response('GET', url) return url",39.60724305,29.35140263
generate: Starts the specified virtual machines.,"def start_roles(self, service_name, deployment_name, role_names):
        '''
        
        '''
        _validate_not_none('service_name', service_name)
        _validate_not_none('deployment_name', deployment_name)
        _validate_not_none('role_names', role_names)
        return self._perform_post(
            self._get_roles_operations_path(service_name, deployment_name),
            _XmlSerializer.start_roles_operation_to_xml(role_names),
            as_async=True)","def start_virtual_machines(self, virtual_machines): """""""""""" self.virtual_machines = virtual_machines self.set_virtual_machines(virtual_machines) self.set_virtual_machines(virtual_machines) self.set_virtual_machines(virtual_machines) self.set_virtual_machines(virtual_machines) self.set_virtual_machines(virtual_machines) self.set_virtual_machines(virtual_machines)","def start_virtualmachines(self, page_name, specification_name, address, address, delta_print=False, delta_address=False, page_address=False): """""" """""" if not address: raise ValueError(""Address must be one of address: %s"" % address) if not address: address = address if address: if not address: address = page_address return address",15.59579851,20.02546308
generate: Returns the RSS argument parser.,"def setup_cmd_parser(cls):
        """"""""""""

        parser = BackendCommandArgumentParser(cls.BACKEND.CATEGORIES,
                                              archive=True)

        # Required arguments
        parser.parser.add_argument('url',
                                   help=""URL of the RSS feed"")

        return parser","def rss_argument_parser(parser): """""""""""" argument = parser.add_argument(parser) argument_parser = argument.add_argument(parser) return argument_parser","def _get_rss_from_args(self): """""" """""" parser = parser.parse_args() try: parser.parse_args(self._args) except ValueError: raise RuntimeError(""Cannot parse rss file: %s"" % self._args) except InvalidParserError as e: raise RuntimeError(""Cannot parse parser with rss file: %s"" % e.args) return None",39.18117629,25.70033169
generate: Returns a judgement on the overall frequency of the variant.,"def frequency(variant_obj):
    """"""
    """"""
    most_common_frequency = max(variant_obj.get('thousand_genomes_frequency') or 0,
                                variant_obj.get('exac_frequency') or 0)
    if most_common_frequency > .05:
        return 'common'
    elif most_common_frequency > .01:
        return 'uncommon'
    else:
        return 'rare'","def variant_frequency_variant(self, variant, frequency_variant): """""" """""" # remove the overall frequency variant variant = self.variant_frequency_variant(variant) if variant.frequency_variant: return variant if variant.frequency_variant: return self.variant_frequency_variant(variant) # remove the overall frequency variant if variant.frequency_variant: return self.variant_frequency_variant(variant) # remove the overall frequency_variant if variant.frequency_variant: return self.variant_frequency_variant(variant) # remove the overall frequency variant if variant.frequency_variant: return self.variant_frequency_variant(variant) # remove the overall frequency variant if variant.frequency_variant: return self.variant_frequency_var","def _get_target_distribution(self, variant_id, overall_freqs): """""" """""" if overall_freqs: if not overall_freqs: return None if not overall_freqs: return None return None if overall_freqs: return None if overall_freqs: return overall_freqs return self.client.get(overall_freqs, None)",18.70166497,31.95478609
generate: Extract harmonic elements from an audio time-series.,"def harmonic(y, **kwargs):
    '''

    '''

    # Compute the STFT matrix
    stft = core.stft(y)

    # Remove percussives
    stft_harm = decompose.hpss(stft, **kwargs)[0]

    # Invert the STFTs
    y_harm = util.fix_length(core.istft(stft_harm, dtype=y.dtype), len(y))

    return y_harm","def _extract_harmonic_elements(self, elements): """""" """""" if not self.harmonic_elements: return self.harmonic_elements = [elements] self.harmonic_elements = [element for element in self.harmonic_elements] self.harmonic_elements = [element for element in self.harmonic_elements if element.harmonic_elements]","def elements(self, key, element): """""" """""" # First, check for an elements into a list element_dict = element.elements for element in element_dict: if element.endswith('_'): self._set_element(element.strip()) self._set_element(element) elif element.endswith('_'): self._set_element(element) elif element.endswith('_'): self._set_element(element) self._set_element(element) return self._set_element(element)",16.28256012,9.131046775
generate: notify all listeners about aggregate data and stats,"def __notify_listeners(self, data, stats):
        """"""  """"""
        for listener in self.listeners:
            listener.on_aggregated_data(data, stats)",". def _listeners(self, local, data): """""""""""" local = self.local if local.type == 'listeners': return local.get(self.aggregate_state, self.stats) else: return local","there area. def notify_response(self, data): """""" """""" response = self._post(data) if response.status_code!= 401: raise InvalidResponse(""Could not specifying data."") return response",40.8020844,28.12357778
generate: Convert the result back into the input type.,"def _transform_result(typ, result):
    """"""
    """"""
    if issubclass(typ, bytes):
        return tostring(result, encoding='utf-8')
    elif issubclass(typ, unicode):
        return tostring(result, encoding='unicode')
    else:
        return result","def convert(self, result): """""" """""" if not result: return self.convert(result) result = result.split("" "")[0] if not self.is_running(): return self.convert(result) else: return self.convert(result)","def to_array(self, type_name): """""" """""" if type_name.startswith('.'): result = [self.to_array(x) for x in type_name.split('.')] result.append(self.to_array(x)) else: result.append(self.to_array(x)) return result",44.45097757,35.88274971
generate: Check if the initital identifier on the line is an alias.,"def check(self, line_info):
        """"
        # Note: aliases can not contain '.'
        head = line_info.ifun.split('.',1)[0]
        if line_info.ifun not in self.shell.alias_manager \
               or head not in self.shell.alias_manager \
               or is_shadowed(head, self.shell):
            return None

        return self.prefilter_manager.get_handler_by_name('alias')","def _check_line(self, line): """""" """""" if self.allowed_line is not None: if not self.allowed_line: return False if line.startswith("".""): return True if line.startswith("".""): return True return False if self.allowed_line: if not self.allowed_line: return False return False","def check_line(self, alias): """""" """""" if alias.is_alias(): self.alias = alias elif alias.is_alias: self.alias = alias elif alias.is_alias: self.alias = alias elif alias.is_alias: self.alias = alias elif alias.is_alias: self.alias = alias else: self.alias = alias self.cookies = self.cookies self.response_type = response_type return self",34.62215143,26.82289874
generate: Check isinstance calls which can be merged together.,"def _check_consider_merging_isinstance(self, node):
        """"""""""""
        if node.op != ""or"":
            return

        first_args = self._duplicated_isinstance_types(node)
        for duplicated_name, class_names in first_args.items():
            names = sorted(name for name in class_names)
            self.add_message(
                ""consider-merging-isinstance"",
                node=node,
                args=(duplicated_name, "", "".join(names)),
            )","def check_calls(self, calls): """""" """""" calls = self.check_calls(calls) if self.is_merged: return True calls = self.check_calls(calls) if self.is_calls: return True return True","def calls_validation_validation_check(self, process_type): """""" """""" if not process_type: raise ValueError(""Process type is not a valid valid process type."") if not self.is_validation_check(process_type): raise ValueError(""Process type is not a validation type."") if self.is_validation_check(process_type): raise ValueError(""Process type must be either a validation."") return self.is_validation_check(process_type, process_type)",14.31112578,19.7357366
generate: return `dateobj` + `nb_years`,"def add_years(dateobj, nb_years):
    """"""
    """"""
    year = dateobj.year + nb_years
    lastday = monthrange(year, dateobj.month)[1]
    return dateobj.replace(year=year, day=min(lastday, dateobj.day))",". def date_obj(self, query_date, year, minutes=None): """""" """""" if minutes is None: minutes = self.get_minutes(query_date, year, minutes) return dateobj",". def update_db_years(self): """""" """""" if self.nb_day: self.db_day = db_day return self.datetime_structure.structure.update_timestamp(self.db_day, self.nb_day)",30.94323953,29.89513976
generate: Unreplicate a VM image from all regions This operation    is only for publishers. You have to be registered as image publisher    with Microsoft Azure to be able to call this,"def unreplicate_vm_image(self, vm_image_name):
        '''
        

        '''
        _validate_not_none('vm_image_name', vm_image_name)

        return self._perform_put(
            self._get_unreplication_path_using_vm_image_name(vm_image_name),
            None,
            as_async=True,
            x_ms_version='2015-04-01'
        )","VM. def _replicate_microsoft_and_regions(self, vim, regions): """""""""""" if not vim: return self.regions[vim] self.regions[vim] = vim self.regions[vim] = regions","version of any distributed database. def _get_regions_of_regions(self, regions): """""" """""" regions_of_body = self._get_regions(regions) regions_of_body = self._get_regions(regions_of_body) return self._get_regions_of_body(regions)",18.7287248,22.91944615
generate: A utility function that computes a bit mask from a collection of  enumeration values.,"def get_bit_mask_from_enumerations(enumerations):
    """"""
    
    """"""
    return functools.reduce(
        lambda x, y: x | y, [z.value for z in enumerations]
    )","def _get_bitmask_mask(self, left, enumeration, ang, nested_idx, nested_idx, save_idx): """""" """""" enumeration = [tuple(x for x in enumeration if x[0] == nested_idx] for x in left] if enumeration == nested_idx: return enumeration return ((tuple(x) for x in enumeration))","def collection(self, value): """""" """""" if value is None: return None if value is not None: return self._delete_bit_map(value) else: return value",28.67020705,29.9068198
generate: Decorate passed in function and log message to module logger.,"def logger(function):
    """"""""""""
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
        """"""Wrap function.""""""
        sep = kwargs.get('sep', ' ')
        end = kwargs.get('end', '')  # do not add newline by default
        out = sep.join([repr(x) for x in args])
        out = out + end
        _LOGGER.debug(out)
        return function(*args, **kwargs)
    return wrapper","def log(self, *args, **kwargs): """""""""""" passed = self.find_module_log(args, *args, **kwargs) if passed is not None: logger.debug(""Logging for passed in %s."", passed) passed = passed","def delete_response(self, response): """""" """""" self.logger.debug(""Delete %s"", response) if response.status_code == 200: logger.error(""Delete %s. %s"", response.text_code, response.text_code) return else: self.logger.error(""Delete %s: %s"", response.text_code, response.text_code) return self.logger.error(""Delete %s: %s"", response.text_code, response.text_code)",22.51706725,18.42192608
generate: Flatten a list of kernels which may contain _SumKernel instances.,"def _flatten_summand_list(kernels):
  """"""
  """"""
  flattened = []
  for k in kernels:
    if isinstance(k, _SumKernel):
      flattened += k.kernels
    else:
      flattened.append(k)
  return flattened","def _flatten_kernels(self, kernels, labels): """""" """""" kernels = [] for k in kernels: kernels.append(k) return kernels","def _flatten_kernels(self, impl): """""" """""" if not impl.is_many(): return None if not self.is_many_unknown_kernels(): return self.lstep_kernels(self.many_unknown_kernels) else: return self.lstep_kernels(self.many_unknown_kernels)",45.27930692,32.64611644
generate: Undo the scale transformation.,"def inverse_transform(self, X, y=None, **params):
        """"""
        
        """"""
        for i in range(X.ncol):
            X[i] = self.means[i] + self.stds[i] * X[i]
        return X","def scale_transformation(self): """""""""""" transformation = self.transformation return transformation.transformation","def _get_transformation(self): """""""""""" return self._get_transformation(self._to_transformation)",32.61824877,30.02798745
generate: Like tf.where but works on namedtuples.,"def val_where(cond, tval, fval):
  """"""""""""
  if isinstance(tval, tf.Tensor):
    return tf.where(cond, tval, fval)
  elif isinstance(tval, tuple):
    cls = type(tval)
    return cls(*(val_where(cond, t, f) for t, f in zip(tval, fval)))
  else:
    raise Exception(TypeError)","def on_works(self, namedtuples): """""" """""" # If it isn't available, then there is no filters if self.where: return self.on_works(namedtuples) return self.on_works(namedtuples)","def absolute(self, name, flag=True, **kwargs): """""" """""" if flag: if flag: return flag else: raise ValueError(""flag must be able to the flag."") if flag: raise ValueError(""flag must be able to absolute flag."") flag = self._begins[name].get('flag', None) if flag: if flag: return flag else: return flag return None",22.14152863,22.93048298
generate: Calculates all of the metrics associated with the registered gadgets.,"def calculate_statistics(stat, frequencies):
    """"""
    
    """"""
    stats = ensure_list(stat)
    frequencies = ensure_list(frequencies)

    for stat in stats:
        for f in frequencies:
            print ""Calculating %s (%s)..."" % (stat.__name__, settings.STATISTIC_FREQUENCY_DICT[f])
            stat.calculate(f)","def calculate(self, rows, next_gadgets=False, size=None): """""""""""" if next_gadgets is None: next_gadgets = self.next_gadgets rows = [] for gad in self.gadgets: rows.append(gad) if size is None: rows.append(rows) rows.append(rows) if next_gadgets: rows.append(rows) return rows","def _calc_metrics(self, video, metrics): """""" """""" url = '/v1/metrics.json' metrics = self._client._request('GET', metrics) return self._client._request('GET', metrics, metrics)",20.91639293,16.94893423
generate: Retrieve content ids in a range of ids.,"def scan_ids(self, *key_ranges):
        '''
        '''
        # (id, id) -> ((id,), (id,))
        key_ranges = [(tuplify(s), tuplify(e)) for s, e in key_ranges]
        scanner = self.kvl.scan_keys(self.TABLE, *key_ranges)
        return imap(itemgetter(0), scanner)","def get_content_ids(self, ids): """""""""""" content = ids.split('/') # TODO: This can be used for callbacks and we're caught content = content.split('/')[1:-1] return self.get_content_ids(content)","def get_content_ids(self): """""" """""" response = self._get_content_ids() response.set_content_ids(self.content_id) return self._get_content_ids(self._created_content_ids)",22.98479651,20.14244112
generate: Build a Theano expression for computing the accuracy of graph output.,"def accuracy(self, outputs):
        '''
        '''
        output = outputs[self.output_name]
        predict = TT.argmax(output, axis=-1)
        correct = TT.eq(predict, self._target)
        acc = correct.mean()
        if self._weights is not None:
            acc = (self._weights * correct).sum() / self._weights.sum()
        return acc","def build_table(self, graph, name, table, title): """""" """""" self.graph.build_table(table, name, title) self.graph.build_table(table, name, title) self.graph.build_table(table, name, title) self.graph.build_table(table, name, title) self.graph.build_table(table, name, title) self.graph.build_table(table, name, title)","def build_tracking_graph(self, output_file): """""" """""" if output_file.get('expression'): self.add_error_exc() raise TypeError('expression has pression is not an expression.') if output_file.get('expressions'): self.add_error_exc() self.add_error_exc() self.add_error_exc() self.add_error_exc()",15.03885974,29.15035267
generate: Reimplemented to cancel the hide timer.,"def enterEvent(self, event):
        """""" 
        """"""
        super(CallTipWidget, self).enterEvent(event)
        self._hide_timer.stop()","def cancel(self, timer): """""" """""" if self.timer is not None: self.timer = timer self.timer = timer","def timer_timer(self, timer): """""""""""" self.timer_timer(timer) timer.timer(timer) return self.timer_timer(timer)",32.5085071,32.15673594
generate: Return function's declared arguments as a string.,"def _get_args_str(func, highlight=None):
    """"""
    
    """"""
    if not func: return """"
    s = str(inspect.signature(func))[1:-1]
    if highlight:
        s = re.sub(r""\b%s\b"" % highlight, Style.BRIGHT + Fore.WHITE + highlight + Fore.LIGHTBLACK_EX + Style.NORMAL, s)
    return s","def _args_declared(self): """""""""""" if self._args_declared is None: return if self._args_declared is None: if self._args_declared is None: return self._args_declared return self._args_declared else: return self._args_declared","def declared_function(self, text, parts): """""" """""" if not parts: return None if not parts: return None if not isinstance(parts, str): return None return self._get_default_declared_function(parts, text, parts)",21.20568494,27.10700531
"generate: Returns the scaling values of x, y, z as a numpy array","def scales(self):
        """""" 
        """"""
        return np.array([self.x_scale, self.y_scale, self.z_scale])","s of the values. def scaling_scaling_scaling_values(self, x, y, z=None): """""""""""" return scaling_scaling_values(x, y, z)",". def _get_scaling_values(self, y, z): """""" """""" self.set_x_x(z) self.set_x_y(y, y) return self.set_x_y(y)",34.77472676,42.43499877
generate: Parse a zonefile into a dict,"def parse_zone_file(text, ignore_invalid=False):
    """"""
    
    """"""
    text = remove_comments(text)
    text = flatten(text)
    text = remove_class(text)
    text = add_default_name(text)
    json_zone_file = parse_lines(text, ignore_invalid=ignore_invalid)
    return json_zone_file",", but the file is returned. def parse(self, filename, *args): """""" """""" zonefile = zonefile.read() if not os.path.exists(zonefile): raise ValueError('Unsupported zonefile into a directory.') with open(filename, 'r') as f: return zonefile",", with the platforming. def parse_zonefile(zonefile): """""" """""" if not os.path.exists(zonefile): raise errors.Unimplemented() for info in zonefile.zonefile: if info.is_zonefile(zonefile): zonefile.write(info) else: zonefile.write(info) return zonefile",27.46279193,28.47146986
generate: Move the current seek pointer to the given block.,"def seek(self,index):
        """"""""""""
        if index<0:
            index = self.nblocks + index
        self._validate_index(index)
        self.block_index = index
        self.finished = False","def move(self, block): """""" """""" if block.clock_id not in self.seek_pointers: raise ValueError('Block pointer is %d' % block.clock_id) self.seek_pointers[block.clock_id] = block","def add_seek(self, block): """""" """""" if self.strip_block: self.add_seek(block) self.add_seek(block)",28.37582968,30.18821791
generate: Checks if the given move would move would leave the king in check or    put it into check.,"def is_suicide_or_check_by_dropping_pawn(self, move):
        '''
        
        '''

        self.push(move)
        is_suicide = self.was_suicide()
        is_check_by_dropping_pawn = self.was_check_by_dropping_pawn(move)
        self.pop()
        return is_suicide or is_check_by_dropping_pawn","def _check_king(self, king, move): """""" """""" if not self._check_skipped_polygons(): self.check_skipped_polygons(king, move) return self.skipped_polygons(king)","def _check_success(self, move_wrapper): """""" """""" if self._has_check_details: self._check_details(move_wrapper, self._check_success, self._check_details) return self._check_success(move_wrapper)",27.49890946,34.95830737
generate: Verify basic http authentification,"def check_credentials(username, password):
    '''  '''
    user = models.User.objects(
        username=username,
        password=password
    ).first()
    return user or None","s. def get_http_authentications(self, authentication_name, query_id, **kwargs): """""" """""" return self.get_http_authentications(authentication_name, query_id, **kwargs)","to authorized user. def _get_authorized_user(self): """""" """""" url = self._url_url(self._url) if not url: raise UserError(""Authorized username: {0}"".format(self._url)) return self._request_token(url, headers=self._headers, data=self._session)",18.46083985,18.15167688
generate: Set the time against which the certificates are verified.,"def set_time(self, vfy_time):
        """"""
        
        """"""
        param = _lib.X509_VERIFY_PARAM_new()
        param = _ffi.gc(param, _lib.X509_VERIFY_PARAM_free)

        _lib.X509_VERIFY_PARAM_set_time(param, int(vfy_time.strftime('%s')))
        _openssl_assert(_lib.X509_STORE_set1_param(self._store, param) != 0)","def set_time_against(self, verified_time_against): """""""""""" time_against = time.time() if time_against == verified_time_against: self.set_time_against(time_against) self.set_time_against(time_against) elif time_against == verified_time_against: self.set_time_against(time_against)","def setup_time_time_time_time(self, time_time): """""" """""" if time_time_time >= time_time: time_time = time_time - time_time self._time = time_time self._time_time = time_time self._time = time_time self._time = time_time self._time = time_time return self._time",23.18172567,22.41539225
generate: Update the proxy widget when the Widget data    changes.,"def _update_proxy(self, change):
        """""" 
        """"""
        #: Try default handler
        if change['type'] == 'update' and self.proxy_is_active:
            handler = getattr(self.proxy, 'set_' + change['name'], None)
            if handler is not None:
                handler(change['value'])
            else:
                self.proxy.set_attribute(change['name'], change['value'])
            self._notify_modified(change)","def update(self, changes, changes, **kwargs): """""""""""" if not isinstance(changes, dict): raise TypeError(""changes must be a dict or list of dicts."") if not isinstance(changes, dict): raise TypeError(""changes must be a dict or list of dicts."") self.update(changes, changes, **kwargs) self.update(changes, changes, **kwargs)","def _update_widget(self): """""" """""" widget_id = self.widget_id proxy = self.proxy if not self.is_widget_id: raise Exception(""Widget is not a valid widget."") widget_id = self.widget_id widget_id = widget_id self.proxy = widget_id self.widget_id = widget_id self.proxy = widget_id self.widget_id = widget_id self.widget_id = widget_id self.widget_id = widget_id self.widget_id = widget_id",34.82346821,25.21347199
generate: Returns a single message activity containing an attachment.,"def attachment(attachment: Attachment, text: str = None, speak: str = None,
                   input_hint: Union[InputHints, str] = None):
        """"""
        
        """"""
        return attachment_activity(AttachmentLayoutTypes.list, [attachment], text, speak, input_hint)","def get(self, attachment): """""""""""" if attachment: if attachment.exponent: return attachment.exponent else: return None","def message_type(self, message, data): """""" """""" self.data = message.get_data() if not self.error_messages: return None if not self.error_message: return self.error_messages.get(message, data) return None",25.52174106,20.42426573
generate: Gets a list of supported U2F versions from the device.,"def get_supported_versions(self):
        """"""
        
        """"""
        if not hasattr(self, '_versions'):
            try:
                self._versions = [self.send_apdu(INS_GET_VERSION).decode()]
            except exc.APDUError as e:
                # v0 didn't support the instruction.
                self._versions = ['v0'] if e.code == 0x6d00 else []

        return self._versions","def get_supported_versions(self, version_name): """""""""""" version_name = version_name or self.version_version_name version_versions = self.version_versions or self.version_versions if version_versions: return version_versions return self.version_versions","def get_supported_versions(self, supported_versions, supported_versions, supported_versions): """""" """""" return self.get_supported_versions(supported_versions, supported_versions, supported_versions)",40.80384768,34.50450289
generate: Start n instances of the program using mpiexec.,"def start(self, n):
        """"""""""""
        self.n = n
        return super(MPILauncher, self).start()","def start(self): """""""""""" self.state = self.program_state self.program_state = self.program_state self.state = self.state","def start(self): """""" """""" no_doc = self._get_no_doc(self.doc_name) if no_doc: self._setup_doc(self._created_doc, no_doc) self._setup_doc(self._setup_doc, no_doc) self._setup_doc(self._setup_doc, no_doc) self._setup_doc(self._setup_doc, no_doc)",31.47928386,15.10022735
"generate: r""""""  Return the hyperbolic arc tangent of a waveform's dependent variable vector.","def atanh(wave):
    
    """"""
    pexdoc.exh.addex(
        ValueError,
        ""Math domain error"",
        bool((min(wave._dep_vector) < -1) or (max(wave._dep_vector) > 1)),
    )
    return _operation(wave, ""atanh"", """", np.arctanh)","def vector(self, dependent=False): """""" if self.tangent: return self.vector elif self.tangent: return self.tangent else: return self.vector","def get_hyperbolic_variable(self, dependent_variable): """""" """""" dependent_variables = self._get_dependent_variable(dependent_variable) if not dependent_variables: raise ValueError(""Dependent_variables must be an instance."") return dependent_variables",18.84884574,19.22857674
generate: Total time since the timer is started.,"def since_start(self):
        """"""
        """"""
        if not self._is_running:
            raise TimerError('timer is not running')
        self._t_last = time()
        return self._t_last - self._t_start","def time_since(self, timer): """""" """""" self.timer = timer.get(timer) if self.timer is not None: self.timer.set(self.timer.get(timer))","def _get_time_since(self, time_since): """""" """""" if self._time_since is not None: return self._time_since.get(time_since, None) else: return self._time_since.get(time_since, None)",41.92489092,41.80371885
generate: Delete a container group,"def delete(self, resource_group, name):
        """"""
        
        """"""
        self.connection.container_groups.delete(resource_group, name)","s. def delete_container_groups(self, name, container_groups, container_groups): """""" """""" self.delete_container_groups(name, container_groups)",". def delete_container(self, username, username): """""" """""" return self.container.delete_container(username, username, username)",51.70613761,47.48637746
generate: Used to make a remote file upload to openload.co,"def remote_upload(self, remote_url, folder_id=None, headers=None):
        """"""

        """"""

        kwargs = {'folder': folder_id, 'headers': headers}
        params = {'url': remote_url}
        params.update({key: value for key, value in kwargs.items() if value})

        return self._get('remotedl/add', params=params)","m and update lines. def remote(self, lines, lines, client_name=None): """""" """""" lines = lines.splitlines() if lines: remote = lines.replace('\n', '') lines = lines.splitlines() return lines","m file. def load_file(self, file_name): """""" """""" remote_file = os.path.exists(file_name) if not os.path.exists(remote_file): return if not os.path.isdir(remote_file): os.makedirs(remote_file) os.makedirs(remote_file) self.add_file(remote_file)",25.19524451,29.25741659
generate: HEADs the object and returns the results.,"def head_object(self, container, obj, headers=None, query=None, cdn=False):
        """"""
        
        """"""
        path = self._object_path(container, obj)
        return self.request(
            'HEAD', path, '', headers, query=query, cdn=cdn)","def get_object_or_before(self, obj): """""""""""" results = self.get_object_or_before(obj) if not results: return None if results: return results return obj","def _handle_object_list(self, object_id): """""" """""" if not isinstance(object_id, types.Series): return object_id if not isinstance(object_id, Metadata): return object_id return self._get_object_list(object_id, object_id)",28.50500487,29.85174112
"generate: The Get Management Certificate operation retrieves information about    the management certificate with the specified thumbprint. Management    certificates, which are also known as subscription certificates,    authenticate clients attempting to connect to resources associated    with your Windows Azure subscription.","def get_management_certificate(self, thumbprint):
        '''
        
        '''
        _validate_not_none('thumbprint', thumbprint)
        return self._perform_get(
            '/' + self.subscription_id + '/certificates/' + _str(thumbprint),
            SubscriptionCertificate)","def get_management_certs(self, certs, thumbprint, urls=None): """""" """""" super(Certificate, self).get_management_certs( certs, thumbprint, urls=urls) return certs","This is to manage the ManagementCode. def get_management_certificate_certificate(self, *args, **kwargs): """""" """""" url = self._url + '/certificate/certificate/{0}/certificate'.format(self._url) return self._get(url, data=kwargs, **kwargs)",37.17394653,42.87596968
generate: Invoke a dry-run of the scheduler for the job.,"def plan_job(self, id, job, diff=False, policy_override=False):
        """""" 
        """"""
        json_dict = {}
        json_dict.update(job)
        json_dict.setdefault('Diff', diff)
        json_dict.setdefault('PolicyOverride', policy_override)
        return self.request(id, ""plan"", json=json_dict, method=""post"").json()","def scheduler_descriptor(self, job_id, descriptor_id, descriptor_id, job_id, **kwargs): """""" """""" if job_id not in self.job_ids: raise ValueError(""job_ids must be added."") job_ids = self.job_ids.get(job_id, descriptor_id) self.job_ids.setdefault(job_ids, {}) self.job_ids[job_id] = job_ids","def invoke_job(self, job_id, dry_run=None): """""" """""" if job_id is None: job_id = self._create_job_id(job_id, dry_run) else: job_id = job_id return self._client.decode(job_id, dry_run=dry_run, job_id=job_id, dry_run=dry_run)",26.18216488,25.90596585
generate: Handler for size command,"def du_handler(self, args):
    ''''''
    for src, size in self.s3handler().size(args[1:]):
      message('%s\t%s' % (size, src))","s. def handle(self): """""""""""" if self.size is None: return if self.size is None: return try: self.size = self.size except ValueError: return return self.size","line. def _remove_handler(self, handler): """""" """""" if self._handler_connection_handler: self._handler.remove_handler(handler) else: self._handler_connection_handler(handler)",22.03626834,20.64604853
"generate: Return an iterable of all prefix directories of path, descending from root.","def prefix_dirs(path):
    """"""
    
    """"""
    _dirname = posixpath.dirname
    path = path.strip('/')
    out = []
    while path != '':
        path = _dirname(path)
        out.append(path)
    return reversed(out)","def get_all_prefix_directories(self, path, pk=None): """""" """""" for name in path: if name.startswith('__'): continue if pk and name.startswith('__'): return pk return None","def get_issue_names(self): """""" """""" path = self._dirname_path if self._get_path_path(path): return self._get_path(path) else: return self._get_issue_names(path)",33.74253858,41.01551934
generate: Creates a copy of this request context with the same request object.    This can be used to move a request context to a different greenlet.    Because the actual request object is the same this cannot be used to    move a request context to a different thread unless access to the    request object is locked.,"def copy(self):
        """"""
        """"""
        return self.__class__(self.app,
            environ=self.request.environ,
            request=self.request
        )","def _response_create(self, request): """""" """""" code = request.query.get('code') if code == 0: self.logger.info(""No code {} searched."".format(code)) return self.response_create(request, request) else: return self.response_create(request)","def copy(self, request, context): """""" """""" response = self.call_response(request, context) return self._call(response)",28.05527978,50.78438643
generate: Set an attribute on self if it exists in the ConfigParser.,"def set_attr_from_config_option(self, cp, attr, where, type_=''):
        """"""""""""
        section, option = where.split("":"")
        if cp.has_option(section, option):
            method = getattr(cp, 'get'+type_)
            setattr(self, attr, method(section, option))","def set_attribute(self, attribute, params): """""" """""" attribute = self._attribute if attribute is None: raise ValueError(""Attribute argument '{0}' is not available."".format(attribute)) return attribute","def set_attribute(self): """""""""""" if self.has_env(): self.set_attribute(""ConfigParser"", self.env_args.get(""ConfigParser"")) self.set_attribute(""ConfigParser"", self.set_attribute) else: self.set_attribute(""ConfigParser"", self.set_attribute)",25.4451395,26.7539033
generate: Selects odd-even nuclei from the table,"def odd_even(self):
        """"""
        
        """"""
        return self.select(lambda Z, N: (Z % 2) and not(N % 2), name=self.name)",". def odd_nuclei(self, table, old, old, old_nuclei): """""" """""" self.super().add_nuclei(table, old, old_nuclei) self.super().add_nuclei(table, old)","s. def serialize_eveni(self, table, region): """""" """""" self.product_nuclei(table, region) self.product_nuclei(table, region)",24.82945221,28.20358568
generate: Submits a callable to be executed with the given arguments.,"def submit(self, fn, *args, **kwargs):
        """"""
        """"""
        future = super().submit(fn, *args, **kwargs)
        work_queue_size = self._work_queue.qsize()
        if work_queue_size > self.max_queue_size_reached:
            self.max_queue_size_reached = work_queue_size
        return future","def submit(self, arg, *args, **kwargs): """""" """""" if arg == 'callable': arg = self.submit_arg(arg, *args, **kwargs) else: arg = self.submit_arg(arg, *args, **kwargs) return arg","def _call_call_callback(self, *args, **kwargs): """""" """""" if self._process_run: self._process_run = kwargs.pop('process_run') if self._process_run: self._process_run = self._process_run self._process_run = self._process_run return self._process_run",37.01328195,33.76664095
generate: Convert an Enum value into a string for the database,"def get_prep_value(self, value):
        """"""
        
        """"""
        if value is None:
            return None
        if isinstance(value, self.enum):
            return value.name
        raise ValueError(""Unknown value {value:r} of type {cls}"".format(
            value=value, cls=type(value)))",". def convert(self, value): """""" """""" if value is not None: try: value = self._string_value(value) except KeyError: return value else: return value",". def to_string(database, value): """""" """""" if isinstance(value, (str, bytes, tuple)): enum = 80 else: enum = 3 if enum is None: enum = 60 enum = 3 return enum + 10",42.70140124,33.62971786
generate: Gets the AwsGlueCatalogHook,"def get_hook(self):
        """"""
        
        """"""
        if not hasattr(self, 'hook'):
            from airflow.contrib.hooks.aws_glue_catalog_hook import AwsGlueCatalogHook
            self.hook = AwsGlueCatalogHook(
                aws_conn_id=self.aws_conn_id,
                region_name=self.region_name)

        return self.hook","s instance. def get_attribute(self): """""""""""" aws_attribute = getattr(self, ""AwsGlueCatalogHooksInstance"", self) if not aws_attribute: return for attribute in AwsGlueCatalogHooksInstance.objects.filter(**attribute): if attribute.get(attribute): return attribute.get(attribute) else: return attribute","s to the GlueCollection. def get_atom_glue_catalog_hook(self, aws_id): """""" """""" aws_id = aws_id[0] if not aws_id: raise ValueError(""AwsGlueCatalogHooks does not include the AWs glues."") self._catalog_hooks.add_atom(self._catalog_hook_id) return self._catalog_hooks.get(AWS_ID, None)",35.67706218,47.01621497
generate: Find the pooled sample variance for two samples.,"def pooled_sample_variance(sample1, sample2):
    """"""
    """"""
    deg_freedom = len(sample1) + len(sample2) - 2
    mean1 = statistics.mean(sample1)
    squares1 = ((x - mean1) ** 2 for x in sample1)
    mean2 = statistics.mean(sample2)
    squares2 = ((x - mean2) ** 2 for x in sample2)

    return (math.fsum(squares1) + math.fsum(squares2)) / float(deg_freedom)","def get_pooled_sample_variance(self, sample_variance, poled_sample_variance, limit_variance, sample_variance, limit_variance, limit_variance): """""""""""" sample_variance = self.get_sample_variance(sample_variance, poled_sample_variance, limit_variance) sample_variance = self.get_sample_variance(sample_variance, poled_sample_variance, limit_variance, limit_variance) return sample_variance","def find_samples(self, samples, two_vectors, samples): """""" """""" if not self._find_simples(): raise ValueError(""Argument must have samples, got {}"".format(samples)) # The samples of the left must be first. samples = find_samples(samples, samples) return samples",28.04026931,28.75925732
generate: Returns a specific volume,"def _get_volume(self, volume_id):
        """"""""""""
        if self._data is not None:
            for volume in self._data[""volumes""]:
                if volume[""id""] == volume_id:
                    return volume","of the HTML document. def get_volume(self, document): """""""""""" if self.volume is not None: volume = self.volume return volume","to another one. def save_volume(self, volume): """""" """""" if not volume: return None if not self._is_cloned: return self._is_cloned_cloned(volume) else: return self._is_cloned(volume)",57.38231687,46.59558988
generate: Renders the reports based on data.content_type's value.,"def render(self, data):
        ''' 

        '''
        renderers = {
            ""text/csv"": self._render_as_csv,
            ""text/html"": self._render_as_html,
            None: self._render_as_html,
        }
        render = renderers[data.content_type]
        return render(data)","def render_render_render(self, value, render_type, value): """""" """""" if render_type == 'Version': self.render_render_render_render(value, render_type, value) else: self.render_render_render_render(value, render_type)","def render_report_to_report(self, data): """""""""""" if data.get('response_type') is None: return self._response_to_response(data.response_type) else: return self._response_to_response(data)",41.42475956,37.95207625
generate: Delete the exons collection,"def drop_exons(self, build=None):
        """"""""""""
        if build:
            LOG.info(""Dropping the exons collection, build %s"", build)
            self.exon_collection.delete_many({'build': build})
        else:
            LOG.info(""Dropping the exons collection"")
            self.exon_collection.drop()",". def delete(self, exons, **kwargs): """""""""""" collection = self.get_collection(exons, **kwargs) if collection.collection: if collection.name == 'collection': collection.name = 'collection.name' else: collection.name = 'collection.name' return collection",". def delete_exons(self, application_id): """""""""""" collection_id = application_id.get('collection_id') url = application_id.get('url') if application_id not in self.exons: raise errors.Unimplemented() return self.exons[api_id]",38.19395597,39.57286091
generate: Returns an IAgent that makes requests to this fake server.,"def get_agent(self, reactor=None, contextFactory=None):
        """"""
        
        """"""
        return ProxyAgentWithContext(
            self.endpoint, reactor=reactor, contextFactory=contextFactory)","def get_iagent_id(self): """""" """""" if self.is_sentency_event_for_requests(): return self.get_iagent_id(self.requests.get_iagent_id()) return self.get_iagent_id()","def get_iam_server(self, request): """""" """""" if request.get('supportedID'): return self._get_iam_server(request) else: return None",28.78350151,28.63549347
generate: Parses the given DSL string and returns parsed results.,"def parse(input_string, prefix=''):
  """"""

  """"""

  tree = parser.parse(input_string)
  visitor = ChatlVisitor(prefix)

  visit_parse_tree(tree, visitor)

  return visitor.parsed","def parse_dsl_results(self, results): """""" """""" results = self.parse_results(results) if results is None: return None return results","def parse_parsed_results(self, data_string): """""" """""" if data_string is None: return '\n'.join(data_string) else: return ''.join(data_string)",25.02505462,33.71548708
generate: Replace child nodes on original function call with their partials,"def update_child_calls(self):
        """"""""""""

        for node in filter(lambda n: len(n.arg_name), self.child_list):
            self.data[""bound_args""].arguments[node.arg_name] = node.partial()
        self.updated = True",". def replace_child_nodes(self, child_nodes): """""" """""" if child_nodes: for node in nodes: if node.is_null(): child_nodes.append(node) else: return child_nodes",". def _print_child_nodes(self): """""" """""" if not self._has_exists(): raise ValueError(""Not available for child nodes"") if not self._child_nodes: raise ValueError(""No child nodes"") self._child_nodes()",31.03398428,34.75854766
generate: Add a data set to the graph,"def add_data(self, data_descriptor):
		""""""
		
		""""""
		pairs = itertools.zip_longest(self.data, data_descriptor['data'])
		self.data = list(itertools.starmap(robust_add, pairs))",". def add(self, ds, dataset, state): """""""""""" if self.req is None: self.req = ds self.req = state self.graph.add(self.graph, self.state) self.graph.add(self.graph)",". def add_dataset(self, dataset): """""" """""" if dataset.has_graph: self._add_dataset(dataset.get('graph'), dataset.get('graph', None)) self._add_dataset(dataset)",30.00073872,38.95029883
generate: Parse the rank score,"def parse_rank_score(rank_score_entry, case_id):
    """"""
    """"""
    rank_score = None
    if rank_score_entry:
        for family_info in rank_score_entry.split(','):
            splitted_info = family_info.split(':')
            if case_id == splitted_info[0]:
                rank_score = float(splitted_info[1])
    return rank_score","def parse_rank_score(self, rank_score): """""""""""" # TODO: can only read score score score = rank_score if self.score: rank_score = rank_score + self.score else: rank_score = rank_score return rank_score + self.score + self.score","filename. def parse_rank(self): """""" """""" self.rank_score_filename = self.rank_score_filename self.rank_score_filename = os.path.exists(self.rank_score_filename) self.rank_score_filename = os.path.join(self.rank_score_filename, self.rank_score_filename) self.rank_score_filename = os.path.join(self.rank_score_filename, self.rank_score_filename)",42.91626693,32.88511568
generate: expression_terminal = identifier              | terminal              | option_group              | repetition_group              | grouping_group              | special_handling ;,"def expression_terminal(self, text):
    """"""
    """"""
    self._attempting(text)
    return alternation([
      self.identifier,
      self.terminal,
      self.option_group,
      self.repetition_group,
      self.grouping_group,
      self.special_handling
    ])(text)",| repetition_group | grouping_terminal | grouping_terminal | repetition_grouping_terminal | grouping_terminal | special_handling | grouping_terminal | grouping_terminal | grouping_terminal | grouping_terminal | grouping_terminal | grouping_terminal | grouping_terminal | grouping_terminal | grouping_terminal | grouping_terminal grouping_terminal | grouping_terminal | grouping_terminal grouping_terminal | grouping_terminal grouping_terminal | grouping_terminal grouping_terminal grouping_terminal | grouping_terminal grouping_terminal | grouping_terminal grouping_terminal | grouping_terminal grouping_terminal | grouping_terminal grouping_terminal grouping_terminal | grouping_terminal grouping_terminal grouping_terminal grouping_terminal grouping_terminal grouping_terminal | grouping_terminal grouping_terminal | grouping_terminal grouping_terminal grouping_terminal grouping_ter,"|group_terminal |grouping_group[0] |= grouping_group |= grouping_group[1] |= grouping_group |= grouping_group |= grouping_group |= grouping_group |= grouping_group |= grouping_group |= grouping_group |= grouping_group return special.get_project_group(grouping_group, grouping_group)",9.20728727,19.37198184
generate: Returns MS Bot Framework compatible state of the Button instance.,"def ms_bot_framework(self) -> dict:
        """"""
        """"""
        card_action = {}
        card_action['type'] = 'postBack'
        card_action['title'] = self.name
        card_action['value'] = self.callback = self.callback
        return card_action","def button_state(self, button): """""" """""" self.button_state = button self.button_state = button self.button_state = self.button_state self.button_state = button self.button_state = self.button_state self.button_state = self.button_state","def get_merge_state(self): """""" """""" if self.get_merge_state(""merge_state"", None): return self.get_merge_state(""merge_state"", None) return self.get_merge_state(""merge_state"", None, None)",20.48215457,22.81817924
generate: Raise errors encountered by the server.,"def raise_server_error(self):
        """"""  """"""
        if self.server and self.server.error:
            try:
                if capybara.raise_server_errors:
                    raise self.server.error
            finally:
                self.server.reset_error()","def _req_exception(self): """""""""""" errors = [] for error in self.errors: error = errors.get(error) if error: errors.append(error) else: errors.append(error) if errors: raise errors","def _print_error(self, error): """""" """""" if self.response_type =='stream': raise ValueError(""Error when setting error: %s"" % self.response_type) return self._exception.fetchone()",37.87107379,43.27441879
generate: Return an instance of a backend from its class.,"def _get_backend_instance(self, backend_cls):
        """"""
        
        """"""
        # Verify that the backend can be instantiated.
        try:
            backend_instance = backend_cls(provider=self)
        except Exception as err:
            raise QiskitError('Backend %s could not be instantiated: %s' %
                              (backend_cls, err))

        return backend_instance","def get_backend_class(self, backend, spec): """""" """""" if backend is None: return None # Use this to spec. filter_class = self.get_backend_class(backend) if filter_class is None: return filter_class return filter_class","def instance_for_class(self, classname, instance_class, classname): """""" """""" instance_class = self._get_instance_for_class(classname) if not instance_class.lower().lower() == 'class' and not instance_class.lower().lower() in classname: raise ValueError('Invalid class name: %s' % instance_class.lower()) instance_class = self._get_instance_for_class(classname, classname) return instance_class(instance_class, classname, classname)",32.34423881,26.55299266
generate: Sends the DELETE request to the Route53 endpoint.,"def _send_delete_request(self, path, headers):
        """"""
        
        """"""

        r = requests.delete(self.endpoint + path, headers=headers)
        return r.text","def send_request(self, request, request, url, headers=None): """""" """""" if request.status_code == 200: return self.request(request, request, request, headers) else: return self.request(request, request, headers)","def _send_response(self, request): """""""""""" # Create any response messages response = request.POST(url=url_path=self.url) response.raise_for_status() response.raise_for_status() return response.raise_for_status()",37.20400036,28.33626553
generate: Check that a list of wires is compatible with a node to be replaced.,"def _check_wires_list(self, wires, node):
        """"""
        """"""
        if len(set(wires)) != len(wires):
            raise DAGCircuitError(""duplicate wires"")

        wire_tot = len(node.qargs) + len(node.cargs)
        if node.condition is not None:
            wire_tot += node.condition[0].size

        if len(wires) != wire_tot:
            raise DAGCircuitError(""expected %d wires, got %d""
                                  % (wire_tot, len(wires)))","def check_wires(self, node, node, node): """""""""""" if node is not None: node = node.get_wires() if node is not None: node.remove(node) if node is not None: node.remove(node) if node is not None: node.remove(node) if node is not None: node.remove(node) if node is not None: node.remove(node)","def _compatible_nodes(self, nodes): """""" """""" if not isinstance(nodes, list): raise TypeError(""nodes must be a list of nodes."") if not isinstance(nodes, list): raise TypeError(""nodes must be a list of nodes."") self._nodes = nodes self._nodes = nodes self._nodes = self._nodes return nodes",29.25449453,32.29290359
generate: Reimplemented to paint the background panel.,"def paintEvent(self, event):
        """""" 
        """"""
        painter = QtGui.QStylePainter(self)
        option = QtGui.QStyleOptionFrame()
        option.initFrom(self)
        painter.drawPrimitive(QtGui.QStyle.PE_PanelTipLabel, option)
        painter.end()

        super(CallTipWidget, self).paintEvent(event)","def _check_background_panel(self, panel_id, idx): """""" """""" if panel_id in self._background_panels: self._background_panels[panel_id] = panel_id else: self._background_panels[panel_id] = panel_id","def get_panel(self, panel_name, panel): """""" """""" panel_name = panel_name.split('.')[0] if panel_name.endswith('.panel'): panel_name = panel_name.split('.panel') else: panel_name = panel_name[0] panel_name = panel_name[1] return panel_name",17.9260042,18.70654802
generate: return a readonly proxy for the `obj`.,"def readonly(obj, *, error_on_set = False):
    '''
    
    '''
    base_cls = type(obj)

    class ReadonlyProxy(base_cls):
        def __getattribute__(self, name):
            return getattr(obj, name)

        def __setattr__(self, name, value):
            if error_on_set:
                raise AttributeError('cannot set readonly object.')

    update_wrapper(ReadonlyProxy, base_cls, updated = ())
    return ReadonlyProxy()","def get_readonly_proxy(self, obj): """""""""""" obj = obj.get_readonly_proxy() # FIXME: FIXME: If it's the object, it's an object, # we can assign the object to the object, we can assign it. obj = obj.get_readonly_proxy() # If the object is an object, we assign the object, we # an object, we can't be an object, we # no object, we can't assign the object, we # include the object, we can't create an object, we # an object, we can't be an object, we # include the object, we can't have an object, we can # be added. obj.set_object(obj) obj.objects = obj return obj","def get_readonly_proxy(self, obj, *args, **kwargs): """""" """""" if not self._is_readonly_proxy(): raise TypeError(""Invalid readonly proxy: %s"" % self._is_readonly_proxy()) try: return self._read_proxy(obj, *args, **kwargs) except TypeError: raise TypeError(""Invalid readonly proxy: %s"" % self._is_readonly_proxy)",17.24837318,35.55613533
"generate: Return a signal name for a signal name or signal  number. Return None is name_num is an int but not a valid signal  number and False if name_num is a not number. If name_num is a  signal name or signal number, the canonic if name is returned.","def canonic_signame(name_num):
    """"""""""""
    signum = lookup_signum(name_num)
    if signum is None:
        # Maybe signame is a number?
        try:
            num = int(name_num)
            signame = lookup_signame(num)
            if signame is None:
                return None
        except:
            return False
        return signame

    signame = name_num.upper()
    if not signame.startswith('SIG'): return 'SIG'+signame
    return signame","def _get_signal_name_by_name(name, signal_name, signal_name, signal_name, signal_name): """""" """""" signal_name = signal_name + signal_name + signal_name if signal_name in ('sgnal', 'bgnal', 'degrees'): raise ValueError(""Signal name '%s' does not exist. Use '%s'"" % (name, signal_name)) return signal_name, signal_name","If the signal name is a signal name or not a number of signal name. def _get_signal_name_number(signal_name, number): """""" """""" if not signal_name: return None try: signal_name = signal_name[signal_name] except KeyError as e: raise ValueError(""signal name is not a signal name. Uses a signal name signal name: %s"" % signal_name) except GraphQLError as e: signal_name = signal_name[signal_name] return signal_name",41.35409294,44.34001609
generate: Computes the outer product of two possibly batched vectors.,"def _tensor_product(t1, t2):
  """"""
  """"""
  return tf.matmul(tf.expand_dims(t1, axis=-1), tf.expand_dims(t2, axis=-2))","def compute_outer_product(self, vectors): """""""""""" return self.compute_outer_product(vectors)","def _compute_outer_product(self, vectors, compute_x, center_vectors, vectors): """""" """""" product_vectors = [] for vector in vectors: if vector == vectors: self._scale_vectors(vectors, self._scale_vectors) else: self._scale_vectors(vectors, vectors, compute_x) else: self._scale_vectors(vectors, vectors) self._scale_vectors(vectors, center_vectors, vectors, center_vectors, vectors) self._scale_vectors(vectors, self._scale_vectors) return self._scale_vectors(vectors, vectors, vectors)",27.26198272,8.055566355
generate: Returns a file handle which is used to record audio,"def _create_file():
    """"""
    
    """"""
    f = wave.open('audio.wav', mode='wb')
    f.setnchannels(2)
    p = pyaudio.PyAudio()
    f.setsampwidth(p.get_sample_size(pyaudio.paInt16))
    f.setframerate(p.get_default_input_device_info()['defaultSampleRate'])
    try:
        yield f
    finally:
        f.close()","git. def get_file_handler(filename, code, code=None): """""" """""" try: code = code or '', '', '', '' except ValueError: return None try: if filename.startswith(code): return os.path.basename(filename) except IOError: return None",". def __parse_file(filename, parent): """""" """""" filename = os.path.dirname(filename) if not os.path.exists(filename): os.makedirs(filename) elif os.path.isfile(filename): os.makedirs(filename) else: os.makedirs(filename) os.makedirs(filename)",19.56676688,17.52985229
generate: Retrieve bulk devices    It accepts accepts a list of parameters    In case of failure it throws Exception,"def _makeApiCall(self, parameters=None):
        """"""
        
        """"""
        r = self._apiClient.get(self._url, parameters)
        if r.status_code == 200:
            return r.json()
        else:
            raise Exception(""HTTP %s %s"" % (r.status_code, r.text))","if the failure. def get_bulk_devices(self, failure_id=None): """""" """""" if failure_id is None: raise ValueError('No failure id') return self.get_bulk_devices(failure_id)",". def get_exception_list(self, event_id, bulk_devices=False): """""" """""" url = ""/v1/events/%s"" % event_id response = self.get(url, headers=self.headers, data=data, headers=headers) return self.response(response, response=response)",28.79356938,35.21734758
generate: Removes a snapshot,"def remove(name):
    """"""""""""
    app = get_app()

    snapshot = app.get_snapshot(name)
    if not snapshot:
        click.echo(""Couldn't find snapshot %s"" % name)
        sys.exit(1)

    click.echo(""Deleting snapshot %s"" % name)
    app.remove_snapshot(snapshot)
    click.echo(""Deleted"")","s from the event. def remove_snapshots(self, snapshots): """""" """""" snapshots = [] for snapshot in snapshots: if snapshot.snapshot is not None: snapshots.append(snapshot) if snapshots: self.remove_snapshots()","of the snapshot region. def remove_snapshot(self): """""" """""" snapshot = self.get_snapshot_snapshot() snapshot = self.get_snapshot() if snapshot is None: return None snapshot.remove_snapshot(self.snapshot_name, self.snapshot) snapshot.remove_snapshot(snapshot) snapshot.remove_snapshot(snapshot)",41.57425188,40.80887024
generate: Returns the ConnectorDB object that the logger uses. Raises an error if Logger isn't able to connect,"def connectordb(self):
        """"""""""""
        if self.__cdb is None:
            logging.debug(""Logger: Connecting to "" + self.serverurl)
            self.__cdb = ConnectorDB(self.apikey, url=self.serverurl)
        return self.__cdb","to the client. def get_connector_info(self): """""""""""" self.logger.debug('ConnectorDB.logger.info(""ConnectorDB.logger.info(""%s"") % (self.connector_info)) return self.connector_info","or. def _get_logger_and_logger(self, logging): """""" """""" logger.debug(""Connection %s, db"", logging.DEBUG) return self.set_logger(logging.DEBUG)",44.79631967,32.26536606
generate: Return a basic meaningful name based on device type,"def name(self):
        """"""  """"""
        if (
            self.device_type and
            self.device_type.code in (DeviceType.MOBILE, DeviceType.TABLET)
        ):
            return self.device
        else:
            return self.browser",". def get_meaning_full_name(self, meaning_type, device_type, name=None): """""""""""" meaning_type = self.meaning_type name = self.name if name is None: name = self.name return name",". def basic_meaning(self): """""" """""" device_type = self.get_device_type(self.device_type) if not device_type: raise ValueError(""Device type must be a basic meaning meaning meaning device type."") return device_type",37.45582285,40.69922135
generate: Compute a set of topological measures over a mesh,"def measure_topology(script):
    """""" 
    """"""
    filter_xml = '  <xmlfilter name=""Compute Topological Measures""/>\n'
    util.write_filter(script, filter_xml)
    if isinstance(script, mlx.FilterScript):
        script.parse_topology = True
    return None",". def topological_mesh(self, mesh, view_mesh=False, view_mesh=True): """""" """""" mesh = self.mesh(mesh) if view_mesh is None: view_mesh = self.mesh(mesh) self.mesh(mesh) else: return self.topological_mesh(mesh)",". def topological_mesh(self, mesh_mesh_id, topology, other_mesh): """""" """""" mesh_mesh_mesh_mesh_mesh(mesh_mesh, topology, topology) mesh_mesh_mesh(mesh_mesh, mesh_mesh_mesh)",26.50127814,20.07899096
generate: Post save receiver for when a Project is saved.,"def prj_post_save_handler(sender, **kwargs):
    """""" 

    """"""
    prj = kwargs['instance']
    if not kwargs['created']:
        add_userrnd_shot(prj)
        return

    add_default_deps(prj)
    add_default_atypes(prj)
    add_default_sequences(prj)","def save_receiver(self, receiver_filename=None): """""" """""" return self.save_receiver(receiver_filename=receiver_filename)","def post_receiver(self, save_receiver): """""" """""" if save_receiver.is_duplicated(): return self.print_receiver( save_receiver, save_receiver ) else: return self.print_receiver( save_receiver.receiver( save_receiver.receiver, save_receiver.receiver.receiver ) )",14.13180757,19.49125382
generate: initialize VCGWriter for a UML graph,"def set_printer(self, file_name, basename):
        """"""""""""
        self.graph_file = open(file_name, ""w+"")
        self.printer = VCGPrinter(self.graph_file)
        self.printer.open_graph(
            title=basename,
            layoutalgorithm=""dfs"",
            late_edge_labels=""yes"",
            port_sharing=""no"",
            manhattan_edges=""yes"",
        )
        self.printer.emit_node = self.printer.node
        self.printer.emit_edge = self.printer.edge",". def init_vcgwriter(self, vcgwriter, scgwriter, flags, flags, flags, flags, flags): """""""""""" if scgwriter: raise VCGWriterError(""Invalid VCGWriter to initialize VCGWriter. Ignoring."") if not flags: raise VCGWriterError(""Invalid VCGWriter to initialize VCGWriter."") self.vcgwriter = VCGWriter(vcgwriter, scgwriter, flags, flags) self.vcgwriter = VCGWriter(vcgwriter, scgwriter, flags)","of a MSG, including the single periods. def _serial_package(self, url): """""""""""" if self._merge_token is None: url = self._merge_token_url(url) if self._merge_token is not None: url += '{}:{}'.format(self._merge_token, url) if self._merge_token is None: url += '{}:{}'.format(self._merge_token, url) url += '{}:{}'.format(self._merge_token, url) return self._serial_request(url, self._merge_token, self._merge_token, url)",21.83035983,22.57150638
generate: Estimate variance using samples.,"def variance(x, sample_axis=0, keepdims=False, name=None):
  """"""
  """"""
  with tf.compat.v1.name_scope(name, 'variance', values=[x, sample_axis]):
    return covariance(
        x, y=None, sample_axis=sample_axis, event_axis=None, keepdims=keepdims)","def _sample_variance(self, variance, samples): """""""""""" samples = np.fliplr(variance, samples) if self.sample_variance: samples = np.fliplr(variance) else: samples = np.fliplr(variance, samples) if self.sample_variance: return samples else: return None","def _ensure_samples(self, variance, inplace_samples): """""""""""" variance_num = self.samples.get(variance_num) if self.is_samples(variance): return self.samples[variance] else: return self.samples[variance]",35.16918814,33.39498942
generate: Deletes an item from this checklist.,"def remove_item(self, item_id):
        '''
        
        '''
        return self.fetch_json(
            uri_path=self.base_uri + '/checkItems/' + item_id,
            http_method='DELETE'
        )","def delete(self, item, checklist=False): """""""""""" item = self.checklist(item, None) item = self.delete(item, checklist) if item: item.delete(item)","def delete_item(self): """""""""""" if self._check_key_is_valid(): return if self._check_key_is_valid(): return return self._check_key_is_valid()",26.88686504,30.53001802
generate: Return True if value is a literal or a name.,"def is_literal_or_name(value):
    """"""""""""
    try:
        ast.literal_eval(value)
        return True
    except (SyntaxError, ValueError):
        pass

    if value.strip() in ['dict()', 'list()', 'set()']:
        return True

    # Support removal of variables on the right side. But make sure
    # there are no dots, which could mean an access of a property.
    return re.match(r'^\w+\s*$', value)","def _is_literal(self, value): """""""""""" if not value: return False if value.startswith('_'): return False if not value.startswith('_'): return False if not value.startswith('_'): return False if not value.startswith('_'): return False return True","def is_alive_alive_alive(self, value): """""""""""" if not isinstance(value, str): raise ValueError(""value {} is not an an empty string."".format(value)) if not isinstance(value, str): raise TypeError(""value cannot an Union of type string."") if not isinstance(value, (str, tuple)): raise TypeError(""value is not a string."") if not isinstance(value, bytes): raise TypeError(""value must be a string."") if not isinstance(value, str): raise TypeError(""value should be an an UTC. Use an an UTC."") return self.create_alive(value)",28.86372446,24.35282659
"generate: Remove an interval, if no interval is found nothing happens.","def remove_interval(self, time):
        """"""
        """"""
        if self.tier_type != 'IntervalTier':
            raise Exception('Tiertype must be IntervalTier.')
        self.intervals = [i for i in self.intervals
                          if not(i[0] <= time and i[1] >= time)]","def remove(self, test, filter_class): """""""""""" if test is None: return False for filter_class in self.filter_classs: if not isinstance(filter_class, NamedType): return False raise NotImplementedError(""Type cannot be removed in an interval"")","def remove_interval(self): """""" """""" if self.has_has_interval(self.interval): # TODO: no need to let's adding any no need to this self.has_interval(self.interval, self.interval, self.interval, self.has_interval(self.interval)) else: # We'll return an editor self.has_interval(self.interval, self.has_interval, self.interval)",36.33100065,30.61361064
generate: Gets the label to display for a specified object.,"def get_label ( self, object ):
        """""" 
        """"""
        label = self.label
        if label[:1] == '=':
            return label[1:]

        label = xgetattr( object, label, '' )

        if self.formatter is None:
            return label

        return self.formatter( object, label )","def get_label(self, obj): """""""""""" obj = obj if obj is None: obj = self.label label = obj label = obj label = obj if label is None: label = obj if label is None: label = obj label = obj label = obj label = obj return label","def get_label(self, object_id, label=None, fields=None): """""" """""" url = self.get_object_id(object_id, fields, label=label, label=label) if label: return self.get_object(object_id, label, fields=fields) else: return self.get_object(object_id, label, fields=fields)",50.12983646,47.38227753
generate: Sort keys for xpi files,"def file_key(filename):
    '''
    '''
    prio = 4
    if filename == 'install.rdf':
        prio = 1
    elif filename in [""chrome.manifest"", ""icon.png"", ""icon64.png""]:
        prio = 2
    elif filename in [""MPL"", ""GPL"", ""LGPL"", ""COPYING"",
                      ""LICENSE"", ""license.txt""]:
        prio = 5
    return (prio, os.path.split(filename.lower()))",". def list_files(self): """""""""""" files = [] for filename in self.files: filename = os.path.basename(filename) filename = os.path.basename(filename) if filename not in files: continue files.append(filename) return files",". def _create_files(self, filename): """""" """""" filename = filename if not os.path.isfile(filename): return None with open(filename, 'wb') as f: file_obj = f.read() for line in f: if not line.endswith(('.', '.'): f.write(line) continue if not line.endswith('.'): f.write(line) return file_obj",30.84682106,34.47900858
generate: Generates zero-sampled `SamplePulse`.,"def zero(duration: int, name: str = None) -> SamplePulse:
    """"""
    """"""
    return _sampled_zero_pulse(duration, name=name)","def zero_sample_zero_sample(self, zero_sample, pulse, cample, multi_pulse_cache=False): """""""""""" if pulse_cache: return zero_sample else: return zero_sample","def generate_zero_sample(zero_samples, distribution): """""" """""" if distribution is None: distribution = distribution.get_zero_samples() elif distribution is None: distribution = distribution.get_zero_samples() else: distribution = distribution.get_zero_samples() return distribution",32.23376054,19.67310442
generate: Creates a NS record attached to this hosted zone.,"def create_ns_record(self, name, values, ttl=60):
        """"""
        
        """"""

        self._halt_if_already_deleted()

        # Grab the params/kwargs here for brevity's sake.
        values = locals()
        del values['self']

        return self._add_record(NSResourceRecordSet, **values)","def _get_record_attached(self, spec, record_attached=False, hosted_zone=False): """""" """""" # FIXME: Could be called by specific non-Environments if spec.startswith('http'): return 'https://' + spec.split('.')[1:] elif spec.startswith('http'): return 'http://' + spec.split('/')[0] else: raise ValueError('Unknown hosted zone.')","def create_record_attached_record(self, name, host_id): """""" """""" url = '/create/records/{0}/records/{1}'.format(name, host_id) return self._create_record(url, host_id)",20.76460858,32.81781274
generate: Deprecated after 0.8,"def two_qubit_kak(unitary_matrix, verify_gate_sequence=False):
    """"""
    """"""
    warnings.warn(""two_qubit_kak function is now accessible under ""
                  ""qiskit.quantum_info.synthesis"", DeprecationWarning)
    return synthesis.two_qubit_kak(unitary_matrix)",". def get_float(self): """""""""""" if self.is_complete: return self.get_float(self.get_complete) else: return self.get_float(self.get_float(self.get_complete))",". def after_constructor(self, *args, **kwargs): """""" """""" if self._depth == '': return self._depth elif self._depth == 'frame': return self._depth else: raise TypeError(""Attribute %s `depth` not found"" % self.frame)",11.59733533,17.71816995
generate: Convenience function that fits the provided data then constructs predictions from the provided features.,"def fit_predict(self, features, class_labels):
        """"""

        """"""
        self.fit(features, class_labels)
        return self.predict(features)","def _provided_fit(self, features): """""" """""" if not features: return features = [features] features = self._provided_fits(features) features = [features] return features, features","def features(self, features): """""" """""" self.features.pop(features) self.features.pop(features)",37.55977553,50.57143688
generate: signatures are non deterministic,"def hash(self):
        """"
        if self.sender is None:
            raise MissingSignatureError()

        class HashSerializable(rlp.Serializable):
            fields = [(field, sedes) for field, sedes in self.fields
                      if field not in ('v', 'r', 's')] + [('_sender', binary)]
            _sedes = None
        return sha3(rlp.encode(self, HashSerializable))","s. def signatures(self, signatures, signatures, signatures): """""""""""" signatures = signatures.get(signatures) if signatures is None: return signatures = signatures.get(signatures) if signatures is None: return self.signatures = signatures self.signatures = signatures self.signatures = signatures self.save(signatures)","coordinates. def signature(self, num_data): """""" """""" if num_data > 1: raise ValueError(""num_data is not None: {}"".format(num_data)) return self._signature_to_signature(num_data, num_data)",27.57772409,21.84787955
generate: Translate SPIDEX annotation to human readable string.,"def spidex_human(variant_obj):
    """"""""""""
    if variant_obj.get('spidex') is None:
        return 'not_reported'
    elif abs(variant_obj['spidex']) < SPIDEX_HUMAN['low']['pos'][1]:
        return 'low'
    elif abs(variant_obj['spidex']) < SPIDEX_HUMAN['medium']['pos'][1]:
        return 'medium'
    else:
        return 'high'","def create_html(self, text): """""""""""" text = self.get_new_text(text) # We assume the same as annotation is assumed. if self.get_new_text(text)!= text: self.sources.append(text) else: self.sources.append(text)","def validate_sps(self, code): """""" """""" url = self._get_url('URL', code) response = self.get_response(url) if response.status_code == 200: self.logger.warning(""The URL is not an iterable."") return False else: raise UnicodeException(""Unicode error: {0}"".format(code)) return True",14.37286463,23.2078761
generate: Refer all _public_ interns from another namespace.,"def __refer_all(cls, refers: lmap.Map, other_ns_interns: lmap.Map) -> lmap.Map:
        """"""""""""
        final_refers = refers
        for entry in other_ns_interns:
            s: sym.Symbol = entry.key
            var: Var = entry.value
            if not var.is_private:
                final_refers = final_refers.assoc(s, var)
        return final_refers","def refer_public_interns(self, public_namespace): """""""""""" self.public_interns = public_namespace.get_public_interns(public_namespace) self.public_interns = public_namespace.get_public_interns(public_namespace) self.public_interns = public_interns","def refer_public_intervals(self, public_intervals): """""" """""" url = self.client.get(""public_intervals"") if url.startswith("".""): url = self._url + ""/public_intervals"" else: url = url return self.client.post(url, params=params, headers=self._headers)",20.0141474,22.33926169
generate: Add run_id into DynamoDB manifest table,"def add_to_manifest(dynamodb_client, table_name, run_id):
    """"""
    """"""
    dynamodb_client.put_item(
        TableName=table_name,
        Item={
            DYNAMODB_RUNID_ATTRIBUTE: {
                'S': run_id
            }
        }
    )","def add_manifest_table(self, run_id, table_name, page_name): """""" """""" if table_name not in self.tables: raise ValueError(""Unexpected table name, '%s'"" % run_id) self.tables[table_name] = table_name",". def add_run_id(self, table): """""" """""" if self.is_valid(): return self._add_run_run(table) elif self.is_valid(): return self._add_run_run(table) else: return self._add_run(table)",38.07529796,25.34892333
generate: Converts the input arg to a list if it is not a list already.,"def _ensure_list(tensor_or_list):
  """"""
  """"""
  if isinstance(tensor_or_list, (list, tuple)):
    return list(tensor_or_list), True
  return [tensor_or_list], False","def get_input(self, arg): """""" """""" arg = self._input_args.get(arg) if arg is not None: return arg.split(arg) else: return []","def _get_input_list(self, input_list): """""" """""" # Check for the MetadataFrame inputs if input_list and input_list: return input_list else: return input_list",25.97143044,40.00764365
"generate: Much like parse.quote in that it returns a URL encoded string  for the given value, protecting the safe characters; but this  version also ensures the value is UTF-8 encoded.","def quote(value, safe='/:'):
    """"""
    
    """"""
    if isinstance(value, six.text_type):
        value = value.encode('utf8')
    elif not isinstance(value, six.string_types):
        value = str(value)
    return parse.quote(value, safe)","def parse(self, value): """""" """""" if isinstance(value, bytes): return value if value.encode('utf-8').strip(): return value.encode('utf-8') else: return value","def _validate_parse(value, encoding): """""" """""" encoding = UTF-8 try: result = encoding.encode(encoding) except UnicodeError: result = encoding.encode('utf-8') return result",49.14907474,30.30963802
generate: This can be called from the main thread to safely stop this thread.,"def stop(self):
        """"""""""""
        self.stop_now = True
        self.history_manager.save_flag.set()
        self.join()","def main(self): """""" """""" if self._main: self.main = main self.main.main.main = main","def stop(self, key, context): """""" """""" if not isinstance(key, basestring): key = self.context.get(key, None) self._stop(key, context) return self._stop(key, None)",35.45606779,27.33794054
generate: Return a summary of the results.,"def result_summary(self, result):
        """"""
        

        """"""

        return ""{} examples, {} errors, {} failures\n"".format(
            result.testsRun, len(result.errors), len(result.failures),
        )","def _get_results(self, results): """""" """""" results = [] for result in results: if results: results.append(result) return results","def get_results(self): """""" """""" if self._is_active: results = [] else: results.append(self._is_active) results.append(self._is_active) return results",40.74171136,35.42432023
"generate: Internal callback for messages that have not been handled by any of the specific internal callbacks, these    messages are not passed on to any user provided callback","def _onUnsupportedMessage(self, client, userdata, message):
        """"""
        
        """"""
        self.logger.warning(
            ""Received messaging on unsupported topic '%s' on topic '%s'"" % (message.payload, message.topic)
        )","s. def callbacks_handled(self, messages, event_messages): """""" """""" # Set the messages that have been called by any of the same handled by any messages # and then use the daemons. self.set_message_message(messages, event_messages)","s. def _process_messages(self, message, message): """""" """""" message.pop('message', None) return message.message",31.25249918,28.20381378
generate: Determine whether two samples differ significantly.,"def is_significant(sample1, sample2):
    """"""
    """"""
    deg_freedom = len(sample1) + len(sample2) - 2
    critical_value = tdist95conf_level(deg_freedom)
    t_score = tscore(sample1, sample2)
    return (abs(t_score) >= critical_value, t_score)","def _is_two_samples_diff(self, two_samples): """""""""""" if two_samples: # If we're given, the samples will find the samples # of the samples if self.samples_diff: return self.samples_diff else: return self.samples_diff else: return False","def plot_samples(self, sigma): """""" """""" # We need to start plott files sample_two_ax.plot(sigma, sigma) return sample_two_ax",27.73938472,18.61546556
generate: Set the revocation timestamp.,"def set_rev_date(self, when):
        """"""
        
        """"""
        dt = _lib.X509_REVOKED_get0_revocationDate(self._revoked)
        return _set_asn1_time(dt, when)","def set_revocation_timestamp(self, timestamp): """""" """""" self.revocation_timestamp = timestamp self.revocation_timestamp = timestamp self.revocation_timestamp = revocation_timestamp","def set_timestamp(self, revocation): """""" """""" if revocation is None: revocation = self._get_revocation(revocation) return self._get_timestamp(revocation)",28.33411427,40.54001627
generate: Can be overridden by a subclass to hook into the matching    of the request.,"def match_request(self):
        """"""
        """"""
        try:
            url_rule, self.request.view_args = \
                self.url_adapter.match(return_rule=True)
            self.request.url_rule = url_rule
        except HTTPException as e:
            self.request.routing_exception = e","def get_subclass_from_subclass(self, url, url=None, headers=None): """""" """""" url = url or ''.join([ self.subclass, 'https://', self.url, self.request, self.request, self.request, self.request, self.request, ] return self.get_subclass_from_url(url, url)","def get_subclass(self): """""" """""" try: return self._get_subclass(self._callback) except AttributeError: # In the subclass is a subclass, which is called # when there is a valid subclass return None",37.1512266,28.20771118
generate: Load a new case from a Scout config.,"def load_scout(adapter, config, ped=None, update=False):
    """"""

    """"""
    log.info(""Check that the panels exists"")
    if not check_panels(adapter, config.get('gene_panels', []),
                        config.get('default_gene_panels')):
        raise ConfigError(""Some panel(s) does not exist in the database"")
    case_obj = adapter.load_case(config, update=update)
    return case_obj","def load_case_from_config(case, config_file): """""" """""" config = load_config(config_file) try: with open(config_file, 'rb') as input_file: for line in input_file: input_file.write(line) return input_file except IOError: raise IOError(""Could not find input file: %s"" % line)","def _load_case_from_scope(self, case_file): """""" """""" if not case_file.endswith('.png', '.png'): raise GraphQLImportError('Could not load case', Loading an any cases.') if case_file.endswith('.png'): case_file.close() return case_file",31.48379628,26.48862153
generate: Create a vector of randomly-initialized values.,"def random_vector(size, mean=0, std=1, rng=None):
    '''
    '''
    if rng is None or isinstance(rng, int):
        rng = np.random.RandomState(rng)
    return (mean + std * rng.randn(size)).astype(FLOAT)","def create_vec(self, vec, random=None): """""" """""" vec = self._vec if random is None: random = random() if vec.size < random: random = random() return random","def _get_vector_values(self): """""""""""" if self._vector is None: return self._vector_values elif self._vector_values is None: return self._vector else: return self._vector_values",32.53614137,21.49669872
generate: Class decorator that makes sure the passed apps are not present in  INSTALLED_APPS.,"def without_apps(*apps):
    """"""
    
    """"""
    apps_list = [a for a in settings.INSTALLED_APPS if a not in apps]
    return override_settings(INSTALLED_APPS=apps_list)","def on_apps_inst_apps(apps_method): """""""""""" @wraps(apps_method) def wrapper(*args): try: return apps_method(*args) except AttributeError: return apps_method(*args) return wrapper","def __create_apps(apps): """""" """""" # We have apps. # This is applies into apps on the service. # This is a valid service. if isinstance(apps, (list, tuple)): apps = service_apps(apps) else: apps = service_apps(apps) return apps",28.36729882,24.81675443
generate: Return potential locations of IACA installation.,"def serach_path():
    """"""""""""
    operating_system = get_os()
    # 1st choice: in ~/.kerncraft/iaca-{}
    # 2nd choice: in package directory / iaca-{}
    return [os.path.expanduser(""~/.kerncraft/iaca/{}/"".format(operating_system)),
            os.path.abspath(os.path.dirname(os.path.realpath(__file__))) + '/iaca/{}/'.format(
                operating_system)]","def get_iam_potential_locations(self, iam_potential_locations=None): """""""""""" # Locations is an installation iam_potential_locations = [] # Implemented from template for template_list = [] for iam_potential_location in self.iam_potential_locations: template_list.append(iam_potential_location) template_list.append(template_list) return template_list","def get_potential_locations(self): """""""""""" potential_locations = self.potential_locations potential_locations = [ potential_locations, potential_locations, potential_locations, potential_locations, potential_locations, ] url = self.get_potential_url(url) if potential_locations: return self.potential_url(url) else: return self.get_potential_locations(url)",17.19045522,13.97967782
generate: Retrive an album with a spotify ID.,"async def get_album(self, spotify_id: str, *, market: str = 'US') -> Album:
        """"""
        """"""
        data = await self.http.album(to_id(spotify_id), market=market)
        return Album(self, data)","def get_album(self, id, descriptor=None): """""" """""" album = id if not id: raise NotImplementedError(""Invalid implemented"") descriptor = self.get_album(id, id) return descriptor.get_album(id)","def get_sotify_album(self, sotify=True, release=False): """""" """""" if not self.is_sotify_album(sotify): return None return None",37.49551396,34.25054799
generate: Check scene name and whether remote file exists. Raises    WrongSceneNameError if the scene name is wrong.,"def validate_sceneInfo(self):
        """"""
        """"""
        if self.sceneInfo.prefix not in self.__satellitesMap:
            raise WrongSceneNameError('USGS Downloader: Prefix of %s (%s) is invalid'
                                      % (self.sceneInfo.name, self.sceneInfo.prefix))","def check_scene_name(self, remote_name): """""" """""" if remote_name not in self.scene_name: raise ValueError(""Cannot check scene name "" + self.scene_name) self.scene_name = remote_name self.scene_name = remote_name","def clean_name(self): """""" """""" if not self.config.get('print_name', None): self.config.get('print_name', None) raise errors.WrongSceneNameError(""Could not clean "" ""file "" + str(self.config)) self.config.update(self.config.get('print_name', None)) self.config.update(self.config)",42.42041373,32.84020498
generate: Read the pure water scattering from a csv formatted file,"def read_pure_water_scattering_from_file(self, file_name):
        """"""
        """"""
        lg.info('Reading water scattering from file')
        try:
            self.b_water = self._read_iop_from_file(file_name)
        except:
            lg.exception('Problem reading file :: ' + file_name)",". def read_scatter_scatter(self, filename, formatter=None): """""" """""" # get the scatter from a JSON-like object pysv_list = [] for line in filename.splitlines(): if line.startswith('.py'): pysv_list.append(line) return pysv_list",". def read_file_path(self, file_name): """""""""""" if not self.file_exists(): raise ValueError('Cannot read filename: {}'.format(file_name)) if not self.file_exists(): raise ValueError('Cannot read file_path: {}'.format(file_name)) self.file_exists()",35.13955245,39.14897901
generate: Calls the frontend handler associated with the message type of the      given message.,"def _dispatch(self, msg):
        """""" 
        """"""
        msg_type = msg['header']['msg_type']
        handler = getattr(self, '_handle_' + msg_type, None)
        if handler:
            handler(msg)","def _calls(self, message): """""" """""" if self.handler is not None: self.handler = handler return self","def frontend_message(self, message): """""" """""" if not message: raise ValueError(""message must be of type'message'"") return message",32.94434424,23.93856694
generate: Resolve a request to a wildcard or regex route handler.,"def _resolve_non_literal_route(self, method, path):
        """"""
        """"""
        for route_dict in (self._wildcard, self._regex):
            if method in route_dict:
                for route in reversed(route_dict[method]):
                    callback_data = route.match(path)
                    if callback_data is not None:
                        return callback_data
        return None","def _resolve_request(self, request, route, timeout=None): """""""""""" route = request.route if timeout is None: timeout = self.timeout self.create_request(request, route, timeout) if route is None: route = request.route return self.resolve_request(request, route, timeout)","def route_request(self, request, method='GET', auth=None, headers=None, include_regex=False): """""" """""" if not auth.is_active: raise ValueError( 'The request to route handler: %s' % auth, headers=auth.headers, headers=headers, ) if request.method!= 'POST': raise ValueError( 'The request is an Handler: %s' % request.method) request.method = auth.get_method(request) self._request(self.url, request, method=method) return request",37.24571262,27.08259387
generate: Prepare sys.path for running the linter checks.,"def fix_import_path(args):
    """"""
    """"""
    orig = list(sys.path)
    changes = []
    for arg in args:
        path = _get_python_path(arg)
        if path in changes:
            continue
        else:
            changes.append(path)
    sys.path[:] = changes + ["".""] + sys.path
    try:
        yield
    finally:
        sys.path[:] = orig","def get_sys_path(self, path): """""" """""" if path.startswith('/'): return self.sys_path_for_range(path, self.path_for_range(path)) else: return self.sys_path_for_range(path, self.path_for_range(path))","def _process_sys_path(self, check_exists): """""" """""" self.set_event_system_exists(check_exists) if self.settings.platform_exists(): self.set_event_system_exists(settings.settings) self.set_event_system_exists(create_handler=self.settings)",30.82209367,19.11128733
generate: get the albums tracks from spotify.,"async def get_tracks(self, *, limit: Optional[int] = 20, offset: Optional[int] = 0) -> List[Track]:
        """"""
        """"""
        data = await self.__client.http.album_tracks(self.id, limit=limit, offset=offset)
        return list(Track(self.__client, item) for item in data['items'])","def get_albums_tracks(self, fb_tracks, tracks, tracks): """""" """""" fb_tracks = [] fb_tracks = [] for fb_track in self.tracks: fb_tracks.append(fb_track) return fb_tracks","def get_all_tracks(self, albums=1): """""" """""" # The some of there is necessary. albums = [albums[0] for album in self.allbums if albums[0]] # The albums are in the supported by added albums = albums[0] for album in albums: albums.append(album) albums = [albums[0] for album in albums if album in albums] return albums",25.29333351,23.27769954
"generate: Delete old prices, leaving just the last.","def prune(symbol: str, all: str):
    """"""  """"""
    app = PriceDbApplication()
    app.logger = logger
    count = 0

    if symbol is not None:
        sec_symbol = SecuritySymbol("""", """")
        sec_symbol.parse(symbol)

        deleted = app.prune(sec_symbol)
        if deleted:
            count = 1
    else:
        count = app.prune_all()

    print(f""Removed {count} old price entries."")","def delete(self, just_dir=None): """""" """""" # check whether there is an empty directory. if self.directory is not None: self.directory.remove(self.directory) else: self.directory.remove(self.directory) if not os.path.exists(just_dir): self.directory.remove(self.directory) else: self.directory.remove(self.directory) self.directory.remove(self.directory) self.directory.remove(self.directory)","def delete_prices(self, url, port): """""" """""" if self.public_url is None: return None # The url is a public_url public_url = self.get_public_url(url, public_url) if self.public_url is None: public_url = self.public_url else: public_url = self.public_url return self.delete_public_url(url, public_url, public_url)",21.55495118,25.14705969
generate: Convert an AST terminal to python source code.,"def _ast_terminal_to_code(self, terminal, **kwargs):
    """"""""""""
    value = _replace(terminal.value)
    if self.use_terminal_shorthand:
      return [value]
    else:
      return [""terminal({})"".format(value)]","def to_python_terminal(terminal, terminal_class): """""" """""" # If the ast terminal is already available, then create a new source code. if terminal_class is None: terminal_class = ""application/create"" super(Terminal, terminal_class) = get_spec(terminal_class) if not super(Terminal, Terminal): return None if terminal_class == Terminal: return None else: return None","def to_dict(self, terminal): """""" """""" if not self._valid_trigger: return None if not self._valid_trigger: return None if not self._valid_trigger: return None else: return self._valid_trigger",26.2954231,35.7572333
generate: Pauses the thread for a specified time.,"def wait(self, time):
        """"""
        """"""
        self._wait = Event()
        return not self._wait.wait(time)","def _wait_for_wait(self, timeout, *args, **kwargs): """""" """""" self._wait_for_wait(timeout, *args, **kwargs) return self._wait_for_wait(timeout, *args, **kwargs)","def flatten(self, timeout=None): """""" """""" if self.timeout is None: return None return self.timeout(timeout=timeout)",39.31204839,40.08160966
"generate: Returns the offsets values of x, y, z as a numpy array","def offsets(self):
        """""" 
        """"""
        return np.array([self.x_offset, self.y_offset, self.z_offset])",". def x_offsets(self): """""" """""" return [x.x for x in self._x_offsets if x.y <= self.x_offsets]",". def _get_offsets(self, offsets): """""" """""" if len(self._offsets) == 1: return self._offsets[0] else: return self._offsets[0]",62.20160046,48.55044373
generate: Coroutine starting point. Produces text stream and forwards to consumers,"def source(target, inputstream=sys.stdin):
    """"""
    
    """"""
    for line in inputstream:

        while len(line) > 600:
            init, sep, line = line.partition(' ')
            assert len(init) <= 600
            target.send(''.join([init, sep]))

        target.send(line)

    inputstream.close()

    return target.close()",". def coroutine_stream(self, function, spec, function, reference, link, link): """""" """""" try: function_str = self._gen_function(function, spec, function, link) except ValueError: raise ModelError( 'Could not coroutine starting point form installed.' ) return self._gen_function(function_str, link, link, link)",". def _get_stream_point(self, point): """""" """""" start_stream = self._stream_pointer.get_stream_point(pointer) if start_stream.is_pointer(): start_stream = self._stream_pointer.get_stream_point(pointer) if start_stream: return start_stream else: return start_stream",24.29782942,25.32607342
generate: Export the Bazaar repository at the url to the destination location,"def export(self, location):
        """"""
        
        """"""
        temp_dir = tempfile.mkdtemp('-export', 'pip-')
        self.unpack(temp_dir)
        if os.path.exists(location):
            # Remove the location to make sure Bazaar can export it correctly
            rmtree(location)
        try:
            self.run_command(['export', location], cwd=temp_dir,
                             show_stdout=False)
        finally:
            rmtree(temp_dir)",". def export_batch_content_location(self, url, repository=None): """""" """""" content = self.get_content_location(url) if content is None: content = self.get_content_location(url) return self.export_batch_content_location(url, repository=repository)",". def _export_repository(self, url, password): """""" """""" if not self._supported_repository_destination(): raise RuntimeError( 'Unable to export repository: %s' % self._name, password ) url = self._get_url('/repository', url) self._supported_repository_destination_repository(url, password) self._support_repository(url, password)",28.93973861,27.16409929
generate: Toggle between the currently active color scheme and NoColor.,"def color_toggle(self):
        """"""""""""

        if self.color_scheme_table.active_scheme_name == 'NoColor':
            self.color_scheme_table.set_active_scheme(self.old_scheme)
            self.Colors = self.color_scheme_table.active_colors
        else:
            self.old_scheme = self.color_scheme_table.active_scheme_name
            self.color_scheme_table.set_active_scheme('NoColor')
            self.Colors = self.color_scheme_table.active_colors","def active_color_scheme_and_active(self, class_name, other_color_scheme_and_active=False): """""" """""" self.active_color_scheme_and_active = class_name self.active_color_scheme_and_active = class_name self.active_color_scheme_and_active = other_color_scheme_and_active","def tag_color(self, color, no_color): """""" """""" if self.frame.is_valid(): self.scheme = no_color self.color_color = no_color self.scheme = no_color self.new_color = no_color self.scheme = no_color self.frame.scheme = self.scheme self.scheme = no_color self.scheme = no_color self.scheme = no_color",40.56425484,42.13406058
"generate: Query for if date_field is within number of ""days"" ago.","def get_date_greater_query(days, date_field):
    """"""
    
    """"""
    query = None
    days = get_integer(days)
    if days:
        past = get_days_ago(days)
        query = Q(**{""%s__gte"" % date_field: past.isoformat()})
    return query","def get_days(self, query_field, date_field=None): """""" """""" if date_field is None: date_field = self.get_days(query_field) date_field = self.get_days(query_field, date_field) return self.get_days(query_field, date_field)","def validate_field_values(self, query_params): """""" """""" if query_params.get('date_fields'): if query_params.get('date_fields'): return self.date_fields[query_params.get('date_fields')] else: return self.date_fields",45.78172362,35.3640701
generate: Find out BAI file by extension given the BAM file.,"def find_bai_file(bam_file):
    """"""""""""
    bai_file = bam_file.replace('.bam', '.bai')
    if not os.path.exists(bai_file):
        # try the other convention
        bai_file = ""{}.bai"".format(bam_file)
    return bai_file","def find_bam_file(self, filename, local_bam_filename=None): """""" """""" # Find out BAI file bam_filename = self.bam_filename if bam_filename == '': return bam_filename else: return None","def find_baifile(self, baifile): """""""""""" baifile_file = os.path.join(self.filename, 'baifile_file', baifile) if os.path.exists(baifile_file): return baifile_file else: raise ValueError(""Baifile not found"")",42.72852708,52.29205688
generate: Handles the user attempting to exit Godot.,"def on_exit(self, info):
        """""" 
        """"""
        if self.prompt_on_exit:# and (not is_ok):
            retval = confirm(parent  = info.ui.control,
                             message = ""Exit Godot?"",
                             title   = ""Confirm exit"",
                             default = YES)
            if retval == YES:
                self._on_close( info )
        else:
            self._on_close( info )","def validate_godot(self, godot): """""" """""" # Set the user if godot.get_user_attribute(godot): return self.godot_attribute_attribute(godot) else: return self.godot_attribute","def exit(self, key=None, user_name=None): """""" """""" if key is None: key = '{}.{}'.format(key) if user_name is None: user_name = user_name if user_name is None: user_name = user_name else: user_name = user_name self.exit(key)",21.34642262,25.85781071
generate: Return a response with a list of jsonapi data objects,"def make_data_response(data, status=200):
    ''' 
    '''
    content = {'data': ensurelist(data)}
    return make_response(jsonify(content), status)",". def response_by_request(self, request, single_data): """""""""""" response = self._get_request(single_data) if response.json: if response.json: return response.json() return None",". def _get_response(self, response): """""" """""" response = self._get_response(response) response.raise_for_status() return response",26.53453113,30.51202584
generate: Patch a method onto an object if it isn't already there.,"def patch_if_missing(obj, name, method):
    """"""
    
    """"""
    setattr(obj, name, getattr(obj, name, method))","def catch_method(self, obj): """""""""""" if obj.get_id() == obj.get_id(): return obj.get_id() return obj","def patch_method_list(self, method, source_file): """""""""""" method_list = self._method_list[method] method_list.add(method, source_file) return method_list",26.98127547,23.62857878
generate: Prepare for rendering,"def prepare(self, **kwargs):
        """"""  """"""
        for k, v in kwargs.items():
            setattr(self, k, v)
        if not self.is_initialized:
            self.initialize()
        if not self.proxy_is_active:
            self.activate_proxy()","templates. def prepare_templates(self, templates): """""" """""" self.templates = templates self.templates = templates self.render = self.render self.clear()","instance. def render_instance(self, request): """""""""""" if not request.is_active: return None if self.active: return self._active_instance(request) self._active_instance(request) return self._active_instance(request)",31.43400959,33.61099844
generate: Cancel a task,"def cancel(self):
        """"""  """"""
        _status = self.status
        self.status = ""canceled""
        try:
            self.save()
        except:
            # Reset status to what it was before
            # status update failure
            self.status = _status
            raise","to loop with the task to this task. def cancel_task(self): """""" """""" self.task = self.task self.task_stop() self.task_stop()",". def cancel(self, task_id, disk_id): """""" """""" if self.is_execution(task_id): self._add_token(task_id) else: self._add_token(task_id, disk_id) self._add_token(task_id, disk_id, disk_id)",28.63400596,29.63680449
generate: Send a Tensor Event to Riemann,"def sendEvents(self, events):
        """"""""""""
        self.pressure += 1
        self.sendString(self.encodeMessage(events))","er VID def create_tensor(self, tensor): """""" """""" self.tensor = tensor self.tensor = tensor","er. def random_error(self, event): """""" """""" self._connection.put(event)",31.14233464,32.37735521
generate: Set the passphrase callback. This function will be called    when a private key with a passphrase is loaded.,"def set_passwd_cb(self, callback, userdata=None):
        """"""
        
        """"""
        if not callable(callback):
            raise TypeError(""callback must be callable"")

        self._passphrase_helper = self._wrap_callback(callback)
        self._passphrase_callback = self._passphrase_helper.callback
        _lib.SSL_CTX_set_default_passwd_cb(
            self._context, self._passphrase_callback)
        self._passphrase_userdata = userdata","def set_passphrase_callback(self, passphrase_callback): """""" """""" callback = self.set_passphrase_callback(passphrase_callback) if callback is not None: callback = self.set_passphrase_callback(passphrase_callback) if not callback is not None: raise StatementError('No passphrase callback') if not self.passphrase_callback(passphrase_callback): raise StatementError('No passphrase callback') self.set_passphrase_callback(passphrase_callback) return self","def callback(self, key, passphrase, passphrase, offset=None): """""" """""" if not key.startswith(""callback""): raise ValueError(""Please set the passphrase callback"") if self._callback: raise ValueError(""Please set the callback"") self._callback(key, passphrase, passphrase, offset) self._callback(key, passphrase)",49.75505968,50.7676486
generate: Return the length of the indentation on the given token's line.,"def _get_indent_length(line):
    """"""""""""
    result = 0
    for char in line:
        if char == "" "":
            result += 1
        elif char == ""\t"":
            result += _TAB_LENGTH
        else:
            break
    return result","def _indentation(self, lineno, token): """""""""""" if token == ""tuple"": return self.tuple elif token == ""indentation"": return self.tuple else: return self.tuple","def match_token(self, line): """""" """""" if self.is_relative: return self.match_token_length(line) else: return self.match_token(line)",37.56751085,32.6512065
"generate: For bold, italics and underline. Simply checking to see if the various tags  are present will not suffice. If the tag is present and set to False then  the style should not be present.","def style_is_false(style):
    """"""
    
    """"""
    if style is None:
        return False
    w_namespace = get_namespace(style, 'w')
    return style.get('%sval' % w_namespace) != 'false'","def set_various_table(table, table): """""" """""" if table in table: table = table.get(table) if table in ['-', '-']: table.pop(table) if table in ['-', '-']: table.pop(table) return table","The user is first. def _find_tag(tag, various, user, password, user_name, various): """""" """""" if various.tag =='modified': return create_tag(tag, various) else: raise ValueError(""Various tags is a user, or less than one."")",28.56080745,21.44492211
generate: The name of the application. This is usually the import name    with the difference that it's guessed from the run file if the    import name is main. This name is used as a display name when    Flask needs the name of the application. It can be set and overridden    to change the value.,"def name(self):
        """"""
        """"""
        if self.import_name == '__main__':
            fn = getattr(sys.modules['__main__'], '__file__', None)
            if fn is None:
                return '__main__'
            return os.path.splitext(os.path.basename(fn))[0]
        return self.import_name","It will be added. If the value is then can be a difference this. def get_application(self): """""" """""" if self.application is None: raise FlaskNegotiationError('No available.') return self.application","def _get_application(self, application): """""" """""" application_name = application.name if self._is_api_config: if self._is_api_config: return self._get_application(api_name) else: return None",32.026681,34.59180185
generate: Set local cookies by initialising the delivery system on the remote.    Requires a store ID and a delivery postcode.,"def set_delivery_system(self, store, postcode, fulfilment_method=FULFILMENT_METHOD.DELIVERY):
        '''
        
        '''
        method = 'delivery' if fulfilment_method == FULFILMENT_METHOD.DELIVERY else 'collection'

        params = {
            'fulfilmentMethod': method,
            'postcode': postcode,
            'storeid': store.store_id
        }

        return self.__post('/Journey/Initialize', json=params)","def get_local_cookies(self, cookies): """""" """""" # FIXME: We have any posteriority. # Avoid the cookies. We have the other cookies, we # avoid the initial cookies are required. cookies = self.cookies for cookies in cookies: cookies = cookies.pop('cookies', []) cookies.append(cookies) return cookies","def set_postcode(self): """""" """""" if self._delivery_system == '': self._delivery_system = self._delivery_system self._delivery_system = self._delivery_system self._delivery_system = self._delivery_system else: self._delivery_system = self._delivery_system self._delivery_system = self._delivery_system self._delivery_system = self._delivery_system return self._delivery_system",16.62791898,22.84631667
generate: Load java messages that can be ignored pickle file into a dict structure g_ok_java_messages.,"def load_dict():
    """"""
    
    """"""
    global g_load_java_message_filename
    global g_ok_java_messages

    if os.path.isfile(g_load_java_message_filename):
            # only load dict from file if it exists.
        with open(g_load_java_message_filename,'rb') as ofile:
            g_ok_java_messages = pickle.load(ofile)
    else:   # no previous java messages to be excluded are found
        g_ok_java_messages[""general""] = []","def _load_java_messages(self, file_messages, sava_messages, java_messages, java_messages, java_messages, java_messages): """""" """""" for java_message in file_messages: if not java_message: self.load_java_message(java_message, file_message, java_message) else: self.load_java_message(java_message, java_message)","def java_messages(self, java_messages, file_path=None): """""" """""" java_messages = { 'messages': java_messages, 'file_path': file_path, 'file_path': file_path, } self.read_java_messages(java_messages, java_messages, java_messages) return self.read_java_messages(java_messages, java_messages, java_messages)",39.22971382,36.52103598
generate: Retrieves the number of members of the organization.,"def get_mems_of_org(self):
        """"""
        
        """"""
        print 'Getting members.'
        counter = 0
        for member in self.org_retrieved.iter_members():
            self.members_json[member.id] = member.to_json()
            counter += 1
        return counter","def get_members_by_options(self): """""" """""" members_by_options = self.get_members_by_options(self.options) return self.get_members_by_options(self.options)","def get_members(self): """""" """""" if self.has_active_members(self.active_members): return self.active_members(self.active_members) else: return self.active_members(self.active_members)",37.50465152,42.44264444
generate: Sets up HTTP connector and starts queue timer,"def createClient(self):
        """"""
        """"""

        server = self.config.get('server', 'localhost')
        port = int(self.config.get('port', 9200))

        self.client = elasticsearch.ElasticSearch(self.url, self.user,
            self.password, self.index)

        self.t.start(self.inter)","def setup(self, url, start_timeout=None): """""" """""" if self.queue: url = self.queue.get(url) self.queue.set(url) self.queue.set(url, start_timeout) self.queue.set(self.queue) else: self.queue.set(self.queue) self.queue.set(self.queue) self.queue.set(self.queue) self.queue.set(self.queue)",". def set_handler(self, port): """""" """""" if not self.is_client(): return None if self.client: return self.client self.client = port self.client = client self.client = client self.client = self.client return self",31.27117283,38.87973995
"generate: From user input, grab the jenkins job name and saved it in g_failed_test_info_dict.  In addition, it will grab the jenkins url and the view name into g_jenkins_url, and  g_view_name.","def extract_job_build_url(url_string):
    """"""
    
    """"""
    global g_failed_test_info_dict
    global g_jenkins_url
    global g_view_name
    
    tempString = url_string.strip('/').split('/')

    if len(tempString) < 6:
        print ""Illegal URL resource address.\n""
        sys.exit(1)
        
    g_failed_test_info_dict[""1.jobName""] = tempString[6]
        
    g_jenkins_url = tempString[2]
    g_view_name = tempString[4]","def _generate_jenkins_url(jenkins_url, url, url, url, url, url_params): """""" """""" jenkins_url = url.rstrip('/') url_params = url.rstrip('/').split(""/') url_params = url_params.split('/')[-1] url_params = url_params.split(""/')[0] url_params = url_params.split(""/')[0] url_params = url_params.split(""/"")[0] url_params = url_params.split(""/"")[1] url_params = url_params.split(""/"")[0] url_params = url_params.split(""/"")[1] url_params = url_params.split(""/"")[0] url_params = url_params.split(""/"")[0] url_params = url_params.split(""/"")[0] url_params = url_params.split(""/"")[0] url_params = url_params.split(""/"")[1] url_params = url_params.split(""/"")[1] url_params = url_params.split(""/"")[1] url_params = url_params.split(""/"")[1] url_params =","def function_jenkins_url(self, user_name, save_dir=True): """""" """""" try: response = self._call_and_update(user_name, save_dir=save_dir, jenkins_url=self._jenkins_url, save_dir=save_dir) except Fault as e: if e.errno!= e.errno: raise e return None else: return response",13.25069842,21.60563447
generate: Base pprint for all functions and builtin functions.,"def _function_pprint(obj, p, cycle):
    """"""""""""
    if obj.__module__ in ('__builtin__', 'exceptions') or not obj.__module__:
        name = obj.__name__
    else:
        name = obj.__module__ + '.' + obj.__name__
    p.text('<function %s>' % name)","def func(self): """""""""""" func_methods = [] for func in self.func_methods: if func.__name__ == '__name__': func_methods.append(func) else: func_methods.append(func) return func_methods","def build_functions(self, query, function_ids): """""" """""" if function_ids: self._process_list(query, function_ids) else: self._process_list(query, function_ids)",26.20784786,22.08618232
generate: Context manager for recording interceptable executions onto a tape.,"def tape():
  """"""

  """"""
  tape_data = collections.OrderedDict({})

  def record(f, *args, **kwargs):
    """"""Records execution to a tape.""""""
    name = kwargs.get(""name"")
    output = interceptable(f)(*args, **kwargs)
    if name:
      tape_data[name] = output
    return output

  with interception(record):
    yield tape_data","def _interceptable_execution(self, execution_id): """""" """""" if execution_id in self.task_tasks: self.task_tasks[execution_id] = self.task_tasks[execution_id] else: self.task_tasks[execution_id] = self.task_tasks[execution_id]","def manager(self, target): """""" """""" target_data = self.get_target_data(target) if not target_data: return None if not target_data: return None if not isinstance(target, (target, target_data)): return target else: return target",22.20971981,24.71702126
generate: Return a dictionary of circuit properties.,"def properties(self):
        """"""""""""
        summary = {""size"": self.size(),
                   ""depth"": self.depth(),
                   ""width"": self.width(),
                   ""bits"": self.num_cbits(),
                   ""factors"": self.num_tensor_factors(),
                   ""operations"": self.count_ops()}
        return summary","def circuit(self, circuit=None, fields=None): """""" """""" self.circuit = circuit self.fields = fields self.fields = fields self.fields = fields self.fields = fields self.fields = fields return self","def get_properties(self, name): """""" """""" if name == 'properties' and name == 'properties' and not circuit_properties: return self.get_properties(self.properties, name) else: return self.get_properties(self.properties, name)",27.07389705,28.82082656
generate: Retrieve all cells from the spreadsheet.,"def get_cells(self):
        """"""""""""

        logger.info(""Retrieving all cells spreadsheet data ..."")
        logger.debug(""MozillaClub client calls API: %s"", self.base_url)
        raw_cells = self.fetch(self.base_url)

        return raw_cells.text","def cells(self): """""""""""" cells = [] for field in self.cells: if field == self.fields[field]: cells.append(field) return cells","def _clear_cells(self, spread_list): """""" """""" # All cells are cells from such cell cell for spread in spread_list: if spread not in self.spreadsheets: spread_list.append(spread) return spread_list",26.52594819,34.72352137
generate: Scans through a string for substrings matched some patterns.,"def matchall(text, patterns):
    """"""
    """"""

    ret = []
    for pattern in patterns:
        match = re.findall(pattern, text)
        ret += match

    return ret","def canvas_substrings(self, patterns): """""" """""" # Scans through the substrings matched. substrings = [] for pattern in patterns: substrings.append(pattern) return ''.join(substrings)","def scan_substrings(substrings, patterns, skip_patterns=(substrings, substrings))): """""" """""" pattern = substrings[substrings] for pattern in substrings: pattern.append(pattern) return pattern",43.11655219,36.10852134
generate: Return system CPU times as a namedtuple.,"def get_system_cpu_times():
    """"""""""""
    user, nice, system, idle = _psutil_osx.get_system_cpu_times()
    return _cputimes_ntuple(user, nice, system, idle)","def times_as_system_cpu_times(self): """""" """""" system_cpu_times = self.times_as_system_cpu_times return self.times_as_system_cpu_times","def get_system_times(self, cpu, datetime, cfg=None): """""" """""" if not cpu: cpu = self._get_cpu_system_times() if not cpu: cpu = cpu.get_cpu_system_time() if not cpu: cpu = cpu.get_cpu() if not cpu: return cpu if cpu: return cpu else: return cpu",49.08547458,32.25094154
generate: Annotate a function using information from its docstring.,"def docannotate(func):
    """"""
    """"""

    func = annotated(func)
    func.metadata.load_from_doc = True

    if func.decorated:
        return func

    func.decorated = True
    return decorate(func, _check_and_execute)","def get_function_utils(self, function, use_func=False): """""""""""" func = get_func(func) if not use_func: func = utils.get_function_utils(func) return func","def _information_to_docstring(docstring): """""""""""" func = docstring.strip() if func.endswith('_'): return func(docstring.strip()) else: return func(docstring.strip(), ""_"", ""_"", ""_"", ""_"")",33.78523786,33.02254918
generate: Event handler for the button click.,"def OnTimeToClose(self, evt):
        """"""""""""
        print(""See ya later!"")
        sys.stdout.flush()
        self.cleanup_consoles(evt)
        self.Close()
        # Not sure why, but our IPython kernel seems to prevent normal WX
        # shutdown, so an explicit exit() call is needed.
        sys.exit()","def event_handler(self, button, **kwargs): """""""""""" if button.button_id is not None: raise ValueError('button_id is not None or button_id is not None') if button.button_id is not None: return button.button_id else: return self.button_id","def event_handler(self, button): """""" """""" if not self.handler_handler: raise MissingAlreadyException(""Button %s"" % button) self.handler = button.event_handler(button) self.logger.error(""Dispatcher canceling button: %s"" % button)",22.00534245,23.24897903
"generate: Gets rid of args with value of None, as well as select keys.","def trim_args(kwds):
    """"""""""""
    reject_key = (""type"", ""types"", ""configure"")
    reject_val = (None, ())
    kwargs = {
        k: v for k, v in kwds.items() if k not in reject_key and v not in reject_val
    }
    for k, v in kwargs.items():
        if k in (""to"", ""cc"", ""bcc"", ""attachments""):
            kwargs[k] = list(kwargs[k])
    return kwargs","def get_rid(self, key, select_key=None): """""""""""" if not self.rid: raise ValueError('{} is not a rid of rid'.format(key)) rid = self.get_rid(key) if rid is None: raise ValueError('{} is not a rid of rid'.format(key)) rid_key = self.get_rid(key) if rid_key is not None: rid_key = self.get_rid(key) return rid_key","def get_rid_key_list(self, key_list, classes): """""" """""" if isinstance(key_list, list): key_list = [key_list[key] for key in key_list] elif isinstance(key_list, list): key_list = [key] else: key_list = [key] return {k: v for k, v in key_list}",24.1702626,25.59143306
generate: Decode AQICN observation response JSON into python object.,"def parse_observation_response(json):
    """"""""""""
    logging.debug(json)

    iaqi = json['iaqi']
    result = {
        'idx': json['idx'],
        'city': json.get('city', ''),
        'aqi': json['aqi'],
        'dominentpol': json.get(""dominentpol"", ''),
        'time': json['time']['s'],
        'iaqi': [{'p': item, 'v': iaqi[item]['v']} for item in iaqi]
    }

    return result","def decode_json(self, request, req=None): """""""""""" if req is None: raise UnknownOrder(""Requirement JSON"") json = json.decode(""utf-8"") if json is None: json = json.decode(""utf-8"") return json.decode(""utf-8"")","def decode_object(cls, python_json_data=None, auth_response=None): """""" """""" if auth_response is None: python_json_data = { 'api_response': auth_response, 'response': auth_response } elif auth_response is not None: python_json_data = { 'response': auth_response } return python_json_data else: return cls._decode_object(json, auth_response)",19.40759437,22.10558225
generate: Returns true if node is inside the name of an except handler.,"def is_inside_except(node):
    """"""""""""
    current = node
    while current and not isinstance(current.parent, astroid.ExceptHandler):
        current = current.parent

    return current and current is current.parent.name","def is_handler(self, node): """""""""""" if node.is_handler: return False if node.is_local_address: return False handler = node.get_handler() if handler is not None: return True if handler is not None: return True return False","def _is_supported_node(node): """""" """""" return _is_supported_node(node) and not isinstance(node, Iterable): return False if not isinstance(node, Iterable): raise TypeError(""node must be an element of type {}"".format(node))",27.19262797,31.77566046
generate: Translate a glob PATTERN to a regular expression.,"def _translate_glob(pat):
    """"""""""""
    translated_parts = []
    for part in _iexplode_path(pat):
        translated_parts.append(_translate_glob_part(part))
    os_sep_class = '[%s]' % re.escape(SEPARATORS)
    res = _join_translated(translated_parts, os_sep_class)
    return '{res}\\Z(?ms)'.format(res=res)","def translate_regular_expression(self, template_name): """""""""""" if template_name in self.translated_regular_expressions: self.translated_regular_expressions[template_name] = self.translated_regular_expressions[template_name]","def get_global_pattern(pattern, pattern): """""""""""" global _pattern global _pattern_session = pattern try: global _pattern_session = global_pattern.get_global_pattern(pattern, pattern) except KeyError as e: raise GlobalAlgorithmError(""Unable to get pattern: %s"" % pattern) global_pattern_session.set_session(_pattern, pattern) return global_pattern",28.75097456,19.4572421
generate: Retrieve the Hit Ratios.,"def hit_ratio_table(self, train=False, valid=False, xval=False):
        """"""
        
        """"""
        tm = ModelBase._get_metrics(self, train, valid, xval)
        m = {}
        for k, v in zip(list(tm.keys()), list(tm.values())): m[k] = None if v is None else v.hit_ratio_table()
        return list(m.values())[0] if len(m) == 1 else m","def _get_hit_ratios(self, uri): """""" """""" if self._hit_ratios is None: uri = self._get_uri_for_url(uri) self.db.set_uri(uri) return self.db.set_uri(uri) self.db.set_uri(uri) self.db.set_uri(uri)","def _get_hit_ratios(self, hit_ratios): """""" """""" hit_ratios = self._get_hit_ratios() if hit_ratios == ""hit_ratios"": hit_ratios = self._get_hit_ratios(hit_ratios) else: hit_ratios = hit_ratios return hit_ratios",23.35915799,24.25387569
generate: Checks the status of an app-setups build.,"def check_build_status(self, build_id):
        """"""
        """"""
        data = self.api_request('GET', '/app-setups/%s' % build_id)

        status = data.get('status')

        if status == 'pending':
            return False
        elif status == 'succeeded':
            return True
        else:
            raise BuildError(str(data))","def check_status(self, func): """""" """""" if func is None: func = self.check_status() func = self.get_status() if func is None: func = self.get_status() if not func is None: func = self.check_status() return func","def check_status(self): """""" """""" if self.status == 'application/json': return # check for application/json if self.status == 'application/json': self.error_handling_status() return self.error_handling_status() # check for application/json self.error_handling_status() return",34.28648872,38.8599922
"generate: Removes the file with the virtual column etc, it does not change the current virtual columns etc.","def remove_virtual_meta(self):
        """"""""""""
        dir = self.get_private_dir(create=True)
        path = os.path.join(dir, ""virtual_meta.yaml"")
        try:
            if os.path.exists(path):
                os.remove(path)
            if not os.listdir(dir):
                os.rmdir(dir)
        except:
            logger.exception(""error while trying to remove %s or %s"", path, dir)","def remove_virtual_columns(self): """""" """""" if self.virtual_columns is not None: self.virtual_columns = virtual_columns else: self.virtual_columns = self.virtual_columns self.virtual_columns = self.virtual_columns self.virtual_columns = self.virtual_columns","def remove_file_name(self, file_name): """""" """""" file_name = self._get_file_name() if not os.path.exists(file_name): raise error.ProgramException(""Could not remove files"") if not os.path.exists(file_name): raise error.ProgramException(""Could not remove file "" ""virtual on file %s"" % file_name) return file_name",23.82635059,40.60292995
generate: Write the raw header content to the out stream,"def write_to(self, out):
        """""" 
        """"""

        out.write(bytes(self.header))
        out.write(self.record_data)",". def write_header(self, stream): """""""""""" self.write_header(stream) self.write_header(stream) self.write_header(stream) self.write_header(stream)",". def _write_header_header_header(self, handler, raw_header): """""" """""" self.write_header(raw_header) self.write_header_header(raw_header) self.write_header(raw_header)",31.72033455,27.72943529
generate: Uploads the file to Google cloud storage,"def execute(self, context):
        """"""
        
        """"""
        hook = GoogleCloudStorageHook(
            google_cloud_storage_conn_id=self.google_cloud_storage_conn_id,
            delegate_to=self.delegate_to)

        hook.upload(
            bucket_name=self.bucket,
            object_name=self.dst,
            mime_type=self.mime_type,
            filename=self.src,
            gzip=self.gzip,
        )",". def upload(self, filename): """""""""""" if self.filename == '.png': self.png = os.path.join(self.png, filename) self.storage = upload elif self.filename == '.png': self.png = os.path.join(self.png, filename) self.storage = upload else: self.storage = upload self.storage = upload",". def google_storage_to_file(self): """""" """""" if self.file_path is None: filename = self.filename else: filename = self.filename if self.filename is None: filename = self.filename else: filename = self.filename if filename is None: filename = self.filename return filename",32.31296721,29.58761295
generate: Unregister the FilteredImage subclass currently assigned to attr_name.,"def unregister_filter(self, attr_name):
        """"""
        
        """"""
        if attr_name not in self._filter_registry:
            raise NotRegistered(
                'No FilteredImage subclass is registered to %s' % attr_name
            )
        else:
            del self._filter_registry[attr_name]","def unregister_filtered_image(self, filtered_image_name): """""""""""" self.filtered_image_name = filtered_image_name self.filtered_image_name = filtered_image_name self.filtered_image_name = filtered_image_name","def register_attribute_subclass(self, instance_name, filter_name): """""" """""" if instance_name is not None: self._filter_subclass_name(instance_name, filter_name) self._filter_subclass_name(instance_name, filter_name)",42.21147238,50.08392779
generate: Set the input text data.,"def input(self, data):
        """"""""""""
        self.data = data
        self.lexer.input(data)","def _set_input(self, text, event, output): """""" """""" self._input = text self._input = output","def set_text_data(self, data): """""" """""" self.set_text_data(data) self.set_text_data(data) self.set_text_data(data)",39.60514534,36.39135816
generate: Return a list of non-empty lines from `file_path`.,"def get_file_lines(file_name):
    """"""""""""
    file_path = path.join(path.dirname(path.abspath(__file__)), file_name)
    with open(file_path) as file_obj:
        return [line for line in file_obj.read().splitlines() if line]","def get_lines_from_file_paths(file_path, **kwargs): """""" """""" lines = [] lines = [] for line in file_path: lines.append(line) lines = [] for line in lines: line = lines.pop('line', None) if line: lines.append(line) return lines","def get_non_empty_file_path(file_path): """""" """""" non_empty_file_path = os.path.exists(file_path) if not os.path.exists(non_empty_file_path): os.makedirs(non_empty_file_path) return os.path.exists(non_empty_file_path)",41.0078452,41.77953478
generate: Unsigns the given string.,"def unsign(self, signed_value):
        """"""""""""
        signed_value = want_bytes(signed_value)
        sep = want_bytes(self.sep)
        if sep not in signed_value:
            raise BadSignature('No %r found in value' % self.sep)
        value, sig = signed_value.rsplit(sep, 1)
        if self.verify_signature(value, sig):
            return value
        raise BadSignature('Signature %r does not match' % sig,
                           payload=value)","def unsigned_string(self, string): """""""""""" if self._string_type == 'PID': if self._string_type == 'SABLE': return string if self._string_type == 'SABLE': return string return string return string","def unpack_string(self, string): """""" """""" if self.lstrip_string is None: raise ValueError(""Not a valid string for the string."") if self.lstrip_string is not None: raise ValueError(""Not a valid string: %s"" % string) if self.lstrip_string is not None: raise ValueError(""Not a valid string: %s"" % string) self.lstrip_string = string return string",18.39453346,32.90535119
"generate: call a function on each element of a sequence remotely.    This should behave very much like the builtin map, but return an AsyncMapResult    if self.block is False.","def map(self, *sequences):
        """"""
        """"""
        # set _map as a flag for use inside self.__call__
        self._map = True
        try:
            ret = self.__call__(*sequences)
        finally:
            del self._map
        return ret","def call_remote(self, sequence): """""" """""" self.call_remote = builtin_builtin_map(self.block) self.documents.pop(sequence) self.documents.pop(sequence) self.documents.pop(sequence)","def callback(self, position=100, position=100): """""" """""" self.models[position] = position self.models[position] = position return self.callback(self.handler, position)",39.43930728,32.34498755
generate: Cancels the current editing task ala Ctrl-G in Emacs.,"def _keyboard_quit(self):
        """""" 
        """"""
        if self._temp_buffer_filled :
            self._cancel_completion()
            self._clear_temporary_buffer()
        else:
            self.input_buffer = ''","def cancel(self): """""""""""" if self.batch is not None: self.batch = self.batch self.cancel() self.batch = self.cancel() self.batch = self.batch","def _cancel_g(self, current_emacs): """""" """""" emacs = self._emacs_ensure_editing_task_admin_emacs(current_emacs) if emacs: self._add_emacs(emacs) else: self._add_emacs(emacs) self._add_emacs(emacs) self._add_emacs(emacs)",35.87397334,30.14547292
"generate: Get all instances of the `object` from Salesforce.    For each model, only get the fields specified in fields.","def get_object_from_salesforce(self, obj, fields):
        """"""
        
        """"""
        query = ""SELECT {} FROM {}"".format("","".join(fields), obj)

        self.log.info(""Making query to Salesforce: %s"",
                      query if len(query) < 30 else "" ... "".join([query[:15], query[-15:]]))

        return self.make_query(query)","If `object` is a valid object, only then the sales of the sales of the fields. For each model, only the fields is a valid fields. def get_sales(self, obj, query, fields=None, query=None): """""" """""" query = self.get_query(query) return self.get_sales(query)","If there is an instance. def get_instances(self, object_id): """""" """""" url = self.build_url(object_id) if ""object"" not in url: url = ""/{object_id}"".format(object_id=object_id) else: url = url_to_object(object_id) return self.session.get(url)",45.20498535,31.9679209
"generate: Given an X.509 certificate, extract and return the extendedKeyUsage  extension.","def get_extended_key_usage_from_certificate(certificate):
    """"""
    
    """"""
    try:
        return certificate.extensions.get_extension_for_oid(
            x509.oid.ExtensionOID.EXTENDED_KEY_USAGE
        ).value
    except x509.ExtensionNotFound:
        return None","def get_x(self, certificate=None): """""" """""" if not certificate: return None if not self.skipped_core: raise ValueError(""Cannot get core model from certificate"") if self.skipped_core: return self.skipped_core return self.skipped_core","def get_key_name(self, key, author): """""" """""" if self.certificated: return self.certificated elif self.user.certificated: return self.certificated else: raise UsageError('Usage key must be valid.')",37.34463462,37.63294178
generate: Climbs up the site tree to resolve root item for chosen one.,"def get_ancestor_item(self, tree_alias, base_item):
        """"""
        """"""
        parent = None

        if hasattr(base_item, 'parent') and base_item.parent is not None:
            parent = self.get_ancestor_item(tree_alias, self.get_item_by_id(tree_alias, base_item.parent.id))

        if parent is None:
            return base_item

        return parent","def get_chosen_tree(self, root, site_id, site_id, site_id, **kwargs): """""" """""" root = self.get_root_item(root, site_id, site_id, site_id, **kwargs) if root is not None: return self.get_root_item(root, site_id, site_id, **kwargs) else: return self.get_root_item(root, site_id, site_id, **kwargs)","def _climb(self, class_name): """""""""""" if not class_name: return None if not class_name: return None if not class_name: return None try: if not isinstance(class_name, list): return class_name except ClassNotFound: return class_name return None",40.54686443,26.23963298
generate: Prints each item from an iterable.,"def pfprint_all(iterable, end='\n', file=None):
    """"""

    """"""

    for item in iterable:
        pfprint(item, end=end, file=file)","def print_item(item): """""""""""" for item in iter(item): if item.get_item() == item: print(item) return","def perform(self, item): """""" """""" try: item = self.item_map[item] except TypeError: raise InvalidItem(""No elements not found."") return item",41.91609804,25.58282857
generate: Return the average log-likelihood of data under a standard normal,"def gaussian_cost(X):
    '''
    '''

    d, n = X.shape

    if n < 2:
        return 0

    sigma = np.var(X, axis=1, ddof=1)

    cost = -0.5 * d * n * np.log(2. * np.pi) - 0.5 * (n - 1.) * np.sum(sigma)
    return cost","function. def get_loglik_loglik_loglik_loglik_loglik(self, data): """""" """""" if data is not None: return self.loglik_loglik(data) return self.loglik_loglik(data)","elements. def align_need_log_likelihood(self, elements, normal_log): """""" """""" def align_log(log): """"""Align the normal elements."""""" if not self.allow_elements: return None if elements.is_alive: return elements[elements.alive] else: return elements[elements.alive] return elements.alive return None",18.72035283,13.0129728
generate: Converts the text category to a tasks.Category instance.,"def parse_category(self, item, field_name, source_name):
        """"""
        
        """"""
        # Get and checks for the corresponding slug
        slug = category_map.get(self.get_value(item, source_name), None)
        if not slug:
            return None
        # Load the category instance
        try:
            return Category.objects.get(slug=slug)
        except Category.DoesNotExist:
            pass","def to_tasks(self, text, block_name, text_idx=None): """""" """""" if text_idx is not None: text_idx = text_idx[0] text_idx = text_idx[1:] if text_idx < block_name: return text_idx else: return text_idx","def category_to_task(self): """""""""""" if not self.is_supported_category(): return None self._setup_supported_category() if self.is_supported_category(): return if self.is_supported_category(): return self.setup_supported_category() self.setup_supported_category()",20.86674978,32.99824636
generate: Visualizes sequences as TensorBoard summaries.,"def image_summary(seqs, name, num=None):
  """"""
  """"""
  seqs = tf.clip_by_value(seqs, 0., 1.)
  seqs = tf.unstack(seqs[:num])
  joined_seqs = [tf.concat(tf.unstack(seq), 1) for seq in seqs]
  joined_seqs = tf.expand_dims(tf.concat(joined_seqs, 0), 0)
  tf.compat.v2.summary.image(
      name,
      joined_seqs,
      max_outputs=1,
      step=tf.compat.v1.train.get_or_create_global_step())","def sequences(self, summary=None, domain=None, verbosity=1): """""""""""" # Implemented from templates. if verbosity > 0: verbosity = 1 # Find the X-summary if verbosity > 1: verbosity = 1 # Get the visualizes visualizes = [] if verbosity < 1: verbosity = 1 if verbosity < 1: verbosity += 1 # Get the visualizes visualizes = [] visualizes = [] for summary in self.sequences: verbosity += 1 verbosity += 1 if verbosity > 1: visualizes += 1 return visualizes","def _sequences_sequences_sequences(self, other): """""" """""" sequences = other.sequences[0] other_board = other.sequences[1] other_board_sequences = self.get_board_sequences(other) if not other.sequences_sequences(sequences): other_board_sequences = other.sequences.sequences[1] else: other.sequences[1] = other.sequences[1] return other",16.56614861,19.45969397
generate: Return line ending.,"def get_line_ending(line):
    """"""""""""
    non_whitespace_index = len(line.rstrip()) - len(line)
    if not non_whitespace_index:
        return ''
    else:
        return line[non_whitespace_index:]","def line_ending(self, line): """""""""""" if not line: return line if self.public_link_line: return self.public_link_line return self.public_link_line","def _get_line_event(self, event_id, state): """""" """""" try: response = self.event_request( self.client.get( 'POST', 'URL', response.text, 'POST', state.value ) ) except Exception as e: response = self.event_request(e) return response except Exception as e: return e.text.strip()",40.00081975,22.1484188
generate: Write the text to the stream and flush immediately.,"def show(self, text):
        """"""
        

        """"""

        self.stream.write(text)
        self.stream.flush()","def write(self, flush_text, flush_text): """""" """""" if flush_text == ""db"": return self.write(flush_text, flush_text) else: return self.write(flush_text)","def flush(self, stream, stream): """""" """""" stream.write(stream) stream.write(stream)",30.8888313,53.68981865
generate: Processes a scheduled consumption request that has completed,"def process_scheduled_consumption(self, token):
        """"""
        """"""
        scheduled_retry = self._tokens_to_scheduled_consumption.pop(token)
        self._total_wait = max(
            self._total_wait - scheduled_retry['time_to_consume'], 0)",". def process_schedule(self, scheduled_consumption=None): """""" """""" scheduled_consumption = self.get_consumption_request(scheduled_consumption) return self.process_schedule(scheduled_consumption)","in another scheduled on the scheduled consumption. def _process_consumption_consumption_consumption(self, scheduled_consumption): """""" """""" # This is not a pull consumption consumption. if self.process_consumption_consumption: self.process_consumption_consumption(scheduled_consumption) return else: self.process_consumption(scheduled_consumption)",57.05083081,34.32125633
generate: quit command when several threads are involved.,"def threaded_quit(self, arg):
        """"""  """"""
        threading_list = threading.enumerate()
        mythread =  threading.currentThread()
        for t in threading_list:
            if t != mythread:
                ctype_async_raise(t, Mexcept.DebuggerQuit)
                pass
            pass
        raise Mexcept.DebuggerQuit","def quit(self, section, name, timeout=None, involved=None): """""""""""" try: self.section = quit(section) except QueueException as e: self.section = quit(e) self.section = quit(e)","def __quit_and_thread(self): """""" """""" if self.debug: self._output_thread(self.debug) self._output_thread(self._output_thread) self._output_thread(self._output_thread) self._output_thread(self._output_thread, self._output_thread) self._output_thread(self._output_thread) self._output_thread(self._output_thread) self._output_thread(self._output_thread)",19.10914893,21.38491919
"generate: r""\?","def t_QMARK(self, t):
        ""
        t.endlexpos = t.lexpos + len(t.value)
        return t",""" methods. def rb(self): """""" """""" # FIXME: This is a function for each FIXME: # Can be independent if self.fixes: return self.fixes[0].fixes[0] else: return self.fixes[0]","' in community and sets the valid community of the current community. def _get_community(self, community): """""" """""" if community <= self.current_community: return self.community else: return self.community",11.98302501,11.79449378
"generate: Hook for type-checking, invoked during assignment. Allows size 1    numpy arrays and lists, but raises TypeError if value can not    be cast to a scalar.","def check_type(self, value):
        """"""

        """"""
        try:
            scalar = asscalar(value)
        except ValueError as e:
            raise TypeError(e)

        super(Parameter, self).check_type(scalar)","def _hook_for_type(self, type_): """""""""""" return ( ( ( ""Type"", type_) or ( ""Unknown type"" or ( ""Unknown type"" or ""Unknown type""), ""Value"": type_ )), ""Unknown type"" ), ""Value"": type_ }, )","def _get_during_type_checking(self, name, value): """""" """""" if not isinstance(value, (list, tuple)): raise TypeError(""Can't instantiate a valid value"") return self._get_during_type(value)",21.78951952,40.58083554
generate: Send termination string to implicit current meter.,"def serialPostEnd(self):
        """""" """"""
        ekm_log(""Termination string sent ("" + self.m_context + "")"")

        try:
            self.m_serial_port.write(""0142300375"".decode(""hex""))
        except:
            ekm_log(traceback.format_exc(sys.exc_info()))

        pass","def set_terminal(self, terminal_string, entry): """""" """""" if terminal_string not in self._terminal_strings: raise ValueError(""Terminal terminal terminal is not supported."") self.terminal_strings.setdefault(terminal_string, []) self.terminal_strings.setdefault(terminal_string, [])","def send_meter(self, meter, *args, **kwargs): """""" """""" if meter is None: raise InvalidTimeout(meter) self.logger.debug(""Sending meter %s"", meter) self.logger.debug(""Sending meter"") meter.send(meter, *args, **kwargs)",23.39310007,23.72635104
generate: Returns the block information associated with a specific hash value or block index.,"def get_block(self, block_hash, verbose=True, **kwargs):
        """""" 

        """"""
        return self._call(
            JSONRPCMethods.GET_BLOCK.value, params=[block_hash, int(verbose), ], **kwargs)","def get_block(self, block, value): """""" """""" if value is None: return block block_value = block_value block_value = self.get_block_value(block_value) return block_value","def get_block(self, block_name, **kwargs): """""" """""" if self._hash_project: block_name = self._hash_project_key(block_name) return block_name else: return block_name",38.08830128,47.72458717
generate: Script interface to read a command. `prompt' is a parameter for    compatibilty and is ignored.,"def read_command(self, prompt=''):
        ''''''
        self.input_lineno += 1
        line = self.readline()
        if self.verbose:
            location = ""%s line %s"" % (self.script_name, self.input_lineno)
            self.msg('+ %s: %s' % (location, line))
            pass
        # Do something with history?
        return line","def load_command(self, command, command, compatibiltin=False): """""" """""" if self.compatibiltin: self.compatibiltin = command else: self.compatibiltin = command if self.compatibiltin: self.compatibiltin = compatibiltin return self","Useful for the prompt. `dest`. def read_cmd_prompt(self, limit=None, limit=None): """""" """""" if limit is None: limit = limit else: limit = self.read_limit(limit) return self.read_cmd(limit, limit=limit, compatible=limit)",30.74785113,29.68623572
generate: Closes the client connection to the database.,"def _close(self):
        """"""
        
        """"""
        if self.connection:
            with self.wrap_database_errors:
                self.connection.client.close()","def close(self): """""" """""" try: self.conn.close() except StopIteration: self.close() self.close()","def close(self): """""" """""" self._close() self._close() self._close()",54.44453424,35.96564807
generate: Adds a new custom completer function.,"def set_custom_completer(self, completer, pos=0):
        """"""""""""

        newcomp = types.MethodType(completer,self.Completer)
        self.Completer.matchers.insert(pos,newcomp)","def add_completer(self, completer): """""" """""" if isinstance(completer, Completer): self.completer = completer self.completer = Completer(completer)","def add_custom_completer(self, custom_completer): """""" """""" self.add_custom_completer(custom_completer) self.add_custom_completer(custom_completer)",54.85842225,52.9763213
generate: Turn a quoted collection literal of Lisp forms into Python AST nodes.,"def _collection_literal_to_py_ast(
    ctx: GeneratorContext, form: Iterable[LispForm]
) -> Iterable[GeneratedPyAST]:
    """"""""""""
    yield from map(partial(_const_val_to_py_ast, ctx), form)","def node_forms_forms(self, node_form): """""""""""" # Detect nodes from the Lisp, remove Lisp form for node_form in node_form: # Update form for form in node_form: if node_form.is_valid(): self.node_form.add_all_form(form) return node_form","def quoted_collection_policy(self, platform, platform, collection): """""" """""" if platform == ""quoted_collection"": return self._quoted_collection else: return self._quoted_collection",18.62562227,22.66520637
generate: Deletes a Cloud SQL instance.,"def delete_instance(self, instance, project_id=None):
        """"""
        
        """"""
        response = self.get_conn().instances().delete(
            project=project_id,
            instance=instance,
        ).execute(num_retries=self.num_retries)
        operation_name = response[""name""]
        self._wait_for_operation_to_complete(project_id=project_id,
                                             operation_name=operation_name)","def delete_instance(self, instance, colour=None): """""""""""" self.instance = instance self.instance = self.instance self.colour = colour self.region_name = self.region_name self.pkg_name = self.pkg_name self.region_name = self.region_name self.colour = colour","def delete_instance(self, target): """""" """""" if self.cloud_instance.get('cloud_instance'): cloud_instance = cloud_instance.get('cloud_instance') else: cloud_instance = cloud_instance.get('cloud_instance') self.cloud_instance = cloud_instance self.cloud_instance = cloud_instance",39.82484462,31.96939874
generate: Handle closing of websocket connection.,"def on_close(self, *args, **kwargs):
        """"""""""""
        if self.connection is not None:
            del self.pgworker.connections[self.connection.pk]
            self.connection.delete()
            self.connection = None
        signals.request_finished.send(sender=self.__class__)
        safe_call(self.logger.info, '- %s %s', self, args or 'CLOSE')","def handle(self): """""""""""" if self.plugin_name == 'null': connection = self.plugin_name elif self.plugin_name == 'null': connection = self.null elif self.plugin_name == 'null': connection = self.null else: connection = self.null return connection","def closing(self, connection, closing=True): """""""""""" try: self._writer.closing(connection, self._writer) except Exception as e: if self._writer is None: raise Exception(""Unable to closing closing connection: %s"" % e) connection = writer.writer() self._writer.closing(connection, self._writer) self._writer.closing(connection, self._writer) self._writer.close()",38.87356726,39.37620157
generate: An alternative translate implementation that uses a geometric function.  This is more accurate than the built-in version.,"def translate(script, value=(0.0, 0.0, 0.0)):
    """"""""""""
    # Convert value to list if it isn't already
    if not isinstance(value, list):
        value = list(value)
    vert_function(script,
             x_func='x+(%s)' % value[0],
             y_func='y+(%s)' % value[1],
             z_func='z+(%s)' % value[2])
    return None","def calculate_target_function(function, translate, builtin_version=None, builtin_version=None): """""" """""" return translate.translate(function, translate, builtin_version=builtin_version)","def _to_geometric(geometric): """""" """""" function = getattr(geometric, 'GeometricFunction', None) if function is None: function = 'Geometric' if function is None: function = getattr(geometric, function) else: function = getattr(geometric, function) return function",20.72360821,21.12335507
generate: Generate a default timescale legend. No arguments.,"def builtin_timescale(cls, name):
        """"""
        
        """"""
        names = {
                 'isc': TIMESCALE__ISC,
                 'usgs_isc': TIMESCALE__USGS_ISC,
                 'dnag': TIMESCALE__DNAG,
                 }
        return cls.from_csv(text=names[name.lower()])","def _generate_timescale_ligend(self, ligend_date, date, date_date): """""""""""" if date_date > date_date: return date_date - date_date else: return date_date","def default_timescale(self): """""" """""" self._timescale = datetime.utcnow() self._timescale = datetime.utcnow() self._time = datetime.utcnow() self._time = datetime.utcnow()",18.91239529,20.09985862
generate: Take json as dictionary parameter,"def check_dict(self, opt, value):
    ''''''
    try:
      return json.loads(value)
    except:
      raise optparse.OptionValueError(""Option %s: invalid dict value: %r"" % (opt, value))","s. def _dict_params(self, parameters, session): """""""""""" try: return json.loads(self._query_params) except ValueError: return None","s. def _make_dict(self, response): """""""""""" try: response = self._create_dict_from_json_dict(response) except Exception as e: log.warning(""Error: %s"" % response) return None except Exception as e: log.warning(""Error: %s"" % response) raise return response",37.57486137,28.20570899
generate: Normalizes features such that each vector is between floor to 1.,"def min_max_normalize(F, floor=0.001):
    """"""""""""
    F += -F.min() + floor
    F = F / F.max(axis=0)
    return F","def normalize(features): """""" """""" if features.normalize: features = features.normalize return features","def _geoflt_features(features): """""" """""" features = features.Features() features.set_features(features) return features",30.12857161,19.06076448
"generate: Checks if the attribute name is in the list of attributes to protect. If so, raises    TranspilerAccessError.","def _check_if_fenced(self, name):
        """"""
        
        """"""
        if name in object.__getattribute__(self, '_attributes_to_fence'):
            raise TranspilerAccessError(""The fenced %s has the property %s protected"" %
                                        (type(object.__getattribute__(self, '_wrapped')), name))","def check_attributes(self, attributes): """""" """""" if not isinstance(attributes, list): raise TranspilerAccessError('attributes must be a list of list of attributes.') self.attributes_as_dict[attributes] = attributes","def is_attribute_name(self): """""" """""" try: try: return self._attribute_name.get_attribute_name(self._attribute_name) except TypeError: return self._attribute_name except KeyError: raise IOError('Could not get attribute name for %s' % self._attribute_name)",41.11464321,36.25345672
"generate: a light excepthook, adding a small message to the usual traceback","def crash_handler_lite(etype, evalue, tb):
    """"""""""""
    traceback.print_exception(etype, evalue, tb)
    
    from IPython.core.interactiveshell import InteractiveShell
    if InteractiveShell.initialized():
        # we are in a Shell environment, give %magic example
        config = ""%config ""
    else:
        # we are not in a shell, show generic config
        config = ""c.""
    print >> sys.stderr, _lite_message_template.format(email=author_email, config=config)",". def add_message(self, message, page, traceback, errors=None): """""" """""" if traceback is None: traceback = self.traceback message = self.request.message_process(message) if message is None: raise RuntimeError(message) self.request.message_process(message) self.request.message_process(message)",". def add_message(self, message): """""" """""" # If we want to check if there are successful, there is not # to the error is necessary if self.is_exception(): self.error_message = message.get_error_message() else: self.error_message = message.get_error_message() return self.error_message()",14.95722315,19.40572812
generate: Helper function to print connection status messages when in verbose mode.,"def _print(self, msg, flush=False, end=""\n""):
        """"""""""""
        if self._verbose:
            print2(msg, end=end, flush=flush)","def print_status(message, msg=None): """""" """""" if not msg: msg = '%s: %s' % (message, msg) log.debug('Helper function to %s', msg) try: msg = '%s: %s' % (msg, msg) except IOError: msg = '%s: %s' % (msg, msg) log.debug('Helper function to %s', msg) log.debug('Helper function to %s', msg) log.debug('Helper function to %s', msg) return True","def _fprint(self, verbose): """""""""""" self.verbose = False self.ui_in_status = False self.db_db.send(self.db_db.send_mode, self.db_db.send_mode, verbose)",10.78772127,30.74677303
generate: Take a string or list of strings and try to extract all the emails,"def parse_emails(values):
    '''
    
    '''
    emails = []
    if isinstance(values, str):
        values = [values]
    # now we know we have a list of strings
    for value in values:
        matches = re_emails.findall(value)
        emails.extend([match[2] for match in matches])
    return emails","def extract_emails(emails): """""""""""" emails = [] for email in emails: if isinstance(email, str): email = email emails.append(email) else: emails.append(email) return emails",". def extract_list(self, key): """""" """""" if not isinstance(key, str): raise TypeError('Invalid values into string.') if key in self.email_dict: raise TypeError('Invalid string.') return self.email_dict[key]",33.96566872,28.99463666
generate: get label rdd from ImageFrame,"def get_label(self):
        """"""
        
        """"""
        tensor_rdd = callBigDlFunc(self.bigdl_type, ""distributedImageFrameToLabelTensorRdd"", self.value)
        return tensor_rdd.map(lambda tensor: tensor.to_ndarray())",". def get_label(self, label_name): """""" """""" label = label_name.rstrip('_') if not label: return None rdf = self.get_label(label_name) if not self.name: return None return self.get_label(label_name, label)",". def get_label(self, label): """""" """""" labels = self.label_rdd_label(label) labels[label] = label labels[label] = label return self._get_label(labels, labels)",31.15993832,30.29999637
generate: Call the OpsgenieAlertHook to post message,"def execute(self, context):
        """"""
        
        """"""
        self.hook = OpsgenieAlertHook(self.opsgenie_conn_id)
        self.hook.execute(self._build_opsgenie_payload())",". def call(self, *args, **kwargs): """""" """""" if self.hook is not None: self.hook = self.hook else: self.hook = None",". def post(self, *args, **kwargs): """""" """""" if self.hook is None: return None return self.hook.post(self.hook, *args, **kwargs)",36.37469335,34.99221272
generate: Check if any events are cancelled on the given date 'd'.,"def check_for_cancelled_events(self, d):
        """"""""""""
        for event in self.events:
            for cn in event.cancellations.all():
                if cn.date == d:
                    event.title += ' (CANCELLED)'","def cancel(self, date, event): """""""""""" if self.schema is None: raise ValueError(""Cancelled date '{}'."".format(self.schema)) return self.cancel(date, event)","def is_date(self, event): """""" """""" events = self._get_events(event) if events: return event if event.timestamp is not None: return self._get_date(event.timestamp) return True",40.5669038,38.64677668
generate: Creates a custom setup.py command.,"def create_command(text, commands):
    """"""""""""

    class CustomCommand(BaseCommand):
        description = text

        def run(self):
            for cmd in commands:
                subprocess.check_call(cmd)

    return CustomCommand","def custom_setup(self, command): """""""""""" self.setup_py_setup(command) self.setup_py_setup(command) self.setup_py_setup(command) self.setup_py_setup(command)","def create_cmd(self, command): """""" """""" if self._setup_config: if self._setup_config.get('_setup_setup_setup'): return self._setup_setup_setup_setup(command) else: return self._setup_setup_setup(command)",32.16660605,31.2649706
generate: Remove a value from multiple value parameter.,"def remove(self, name, value):
        """"""  """"""
        clone = self._clone()
        clone._qsl = [qb for qb in self._qsl if qb != (name, str(value))]
        return clone","def delete(self, value): """""" """""" if self.is_tuple(value): return self.delete(value) return self.delete(value)","def remove_value(self, value): """""" """""" if not isinstance(value, bytes): value = value.strip() return value",38.81793823,38.63588364
generate: Create perm-vm if not exist and insert into FAB security model for all-dags.,"def create_perm_vm_for_all_dag(self):
        """"""
        
        """"""
        # create perm for global logical dag
        for dag_vm in self.DAG_VMS:
            for perm in self.DAG_PERMS:
                self._merge_perm(permission_name=perm,
                                 view_menu_name=dag_vm)","def get_page_form(self, vm): """""" """""" if not vm: return page = self.get_page_form(vm) page_form = self.get_page_form(vm) page_form = self.get_page_form(page_form) if page_form: return page else: return None","def failed(cls, *args): """""""""""" if not self.security_missing: raise ValueError(""Unable to find failed. "" ""assumed to find permissions:"" ""When inserting failed."") for perm in cls._permissions: if perm == 'ERRM_METHOD': perm_key = cls._perm_key if perm.security_missing: cls._permissions[perm.security_missing] = perm self._permissions.append(cls._permissions[perm.security_missing]) return cls._permissions",28.06124608,18.7396295
generate: Generates the key associated with the specified address.,"def get_key_for(self, address):
        """"""
        
        """"""
        return self.get_key(
            index=address.key_index,
            iterations=address.security_level,
        )","def get_key_address(self, address): """""""""""" return self.get_key_address(address)","def _get_key_address(self, key, key, value): """""" """""" key = key.replace(""%s"" % key, value) return self._get_key_address(key, value)",48.04176543,45.75427338
generate: Used to replace a matched string with another.,"def replace(self):
        """"""
        
        """"""

        if self.replace_with:  # pylint: disable=no-member
            return substrings(
                self.regex,
                self.replace_with,  # pylint: disable=no-member
                self.data,
                self.occurences,  # pylint: disable=no-member
            )

        return self.data","def _replace(self, string): """""""""""" # Match the filter if self.filter is not None: self.filter = self.filter if self.is_called: self.is_called = False return self","def replace_matches(self, string): """""" """""" matches = [self.submission.replace("":"", """") for i in string] if matches[0] == '\n': return matches[1] else: return matches[0]",31.44785936,29.46334774
generate: Return an argument list node that takes only ``self``.,"def takes_only_self(self):
        """"""
        

        """"""

        return ast.arguments(
            args=[ast.arg(arg=""self"")],
            defaults=[],
            kw_defaults=[],
            kwonlyargs=[],
        )","def only_argument(self, arg): """""" """""" if arg in self.arguments: arg = self.arguments[arg] return arg","def get_node_list(self, node): """""" """""" if node.endswith('_'): return self.get_node_list(node) else: return self.get_node_list(node)",37.27645259,26.1073506
generate: Sets the current encoder output to Python `str` and returns    a row iterator.,"def to_str(self, delimiter='|', null='NULL'):
        """"""
        
        """"""
        self.export.set_null(null)
        self.export.set_delimiter(delimiter)
        self.options(""delimiter"", escape_string(delimiter), 2)
        self.options(""null"", null, 3)
        return self._fetchall(ENCODER_SETTINGS_STRING, coerce_floats=False)","def set_encoder(self, encoder): """""""""""" if isinstance(encoder, bytes): self.encoder = encoder if self.encoder == ""utf-8"": self.encoder = encoder if self.decoder: self.decoder = decoder self.text = self.encoder","def _update_encoder_output(self, encoder_list): """""" """""" self.set_encoder_output(encoder_list) self._update_encoder_output(encoder_list) self._update_encoder_output(encoder_list) self._update_encoder_output(encoder_list) self._update_encoder_output(encoder_list)",21.9295902,25.95428872
generate: Notify all subscribers of an action status change.,"def action_notify(self, action):
        """"""
        
        """"""
        message = json.dumps({
            'messageType': 'actionStatus',
            'data': action.as_action_description(),
        })

        for subscriber in list(self.subscribers):
            try:
                subscriber.write_message(message)
            except tornado.websocket.WebSocketClosedError:
                pass","def notify(self, subscribers): """""""""""" notify = { 'message': 'Failed to load an actions.'} if subscribers is None: subscribers = {} actions = { 'message': 'Failed to load an actions.'} actions[subscribers] = {} return actions","def action_change(self, subscribers): """""" """""" self.logger.info(""Action %s."", subscribers) self.logger.debug(""Action %s."", subscribers) self.logger.debug(""Action %s."", subscribers) self.logger.debug(""Action %s"", subscribers)",41.7693782,33.82431267
generate: Returns a list of the positions in the text where all new lines occur. This is used by get_line_and_char to efficiently find coordinates represented by offset positions.,"def get_newline_positions(text):
  """"""
  """"""
  pos = []
  for i, c in enumerate(text):
    if c == ""\n"":
      pos.append(i)
  return pos","def get_lines(self, lines): """""" """""" lines = [] for lines in lines: lines.append(lines) return lines","def get_positions(self): """""" """""" if self.lt is None: return None return self.get_positions(self.position, self.position, self.lt)",42.72992252,35.79461017
generate: Login either with resume token or password.,"def login(self, params):
        """"""""""""
        if 'password' in params:
            return self.login_with_password(params)
        elif 'resume' in params:
            return self.login_with_resume_token(params)
        else:
            self.auth_failed(**params)","def login(self, url, **kwargs): """""" """""" self.login(url) if not self.login: self.login(url) if self.login: self.login(url) self.login(url) if self.authorize: self.login(url) else: self.login(url) self.login(url)","def _get_resume_resume_resume(self, resume_resume, password, password): """""" """""" if self._session.get(""resume"", None) is None: return self._session.get(resume_resume, None, password) else: return self._session.get(""resume"", None)",35.56352764,39.54591174
generate: Horizontally flip detections according to an image flip.,"def hflip_detections(label, w):
    """"""
    
    """"""
    for k in label.keys():
        if k.startswith(""detection""):
            detections = label[k]
            for detection in detections:
                detection.cx = w - detection.cx
                if k == ""detections_2.5d"":
                    detection.theta = math.pi - detection.theta","def flip_flip_detection(self, flip_flip_detection_ids=None): """""" """""" if flip_flip_detection_ids: # If we've flip flip_flip_detection_ids are passed, # we need to flip the FlipDetectionIds, it is # the FlipDetectionIds, but they are passed. if flip_flip_detection_ids: return flip_flip_detection_ids else: return flip_flip_detection_ids else: return flip_flip_detection_ids","def add_image(self, other, image, normalization): """""" """""" # Implemented from template for # osid.resource.ResourceBinAdminSession.get_bin_image_id if self._catalog.is_for_catalog(): # TODO: handledown self._catalog.create_image(other, image, normalization) return self._catalog.add_image(other, image, normalization)",31.22294589,16.18951053
generate: Register monitors they should be tuple of name and Theano variable.,"def register_monitors(self, *monitors):
        """"""
        
        """"""
        for key, node in monitors:
            if key not in self._registered_monitors:
                node *= 1.0 # Avoid CudaNdarray
                self.training_monitors.append((key, node))
                self.testing_monitors.append((key, node))
                self._registered_monitors.add(key)","def register(self, monitor, name, monitor_name): """""" """""" if monitor_name is not None: monitor_name = monitor_name + monitor_name if monitor_name is not None: monitor_name = monitor_name + monitor_name self.register(monitor_name) self.register(monitor_name) self.register(monitor_name)","def register_monitors(self, name, monitors): """""" """""" if not monitors: monitors = self.register_monitors(monitors) else: monitors = self.register_monitors(monitors) if monitors: if not monitors: monitors = register_monitors(monitors) else: monitors = self.register_monitors(monitors) return monitors",41.44269109,45.867249
generate: Wait until the user accepted or rejected the request,"def _wait_for_response(self):
		""""""
		
		""""""
		while not self.server.response_code:
			time.sleep(2)
		time.sleep(5)
		self.server.shutdown()","ed process. def wait_for_rejected(self, requested_user, timeout=None): """""" """""" if requested_user is None: timeout = self.requested_user return requested_user.get(requested_user, timeout)","ed function. def wait_for_callback(self): """""" """""" if self.when: self._callback(""Calling request"", self.when) return self.when = wait_for_callback(self.when) self._callback(""Waiting for %s"" % self.when)",27.67258722,23.47140763
generate: Reject attributes not defined in ATTR_WHITELIST.,"def parse_attrs(self, tag):
        """"""
        
        """"""
        if tag.name in ATTR_WHITELIST.keys():
            attrs = copy(tag.attrs)
            for attr, value in attrs.items():
                if attr in ATTR_WHITELIST[tag.name]:
                    tag.attrs[attr] = self._parse_attr(tag.name, attr, value)
                else:
                    del tag.attrs[attr]
        else:
            tag.attrs = {}","def _set_whitelist_whitelist(self, actions): """""" """""" for action in ATTR_WHITELIST.items(): if action.id == action.id: if action.id == ATTR_WHITELIST.id: raise AttributeError(""Attribute not found"") else: if action.id == ATTR_WHITELIST.id: raise AttributeError(""Attribute not found"") return self","def reject(self, auto_name, old_name, old_name, old_name, old_name, old_name): """""" """""" if old_name == 'ATTR_WHITELIST_NODES': self._reject_attr(self, old_name, old_name, old_name, old_name) else: self._reject_attr(self, old_name, old_name, old_name, old_name) return old_name",35.44830058,28.66343369
generate: Save a Network's data to a Pandas HDFStore.,"def network_to_pandas_hdf5(network, filename, rm_nodes=None):
    """"""
    

    """"""
    if rm_nodes is not None:
        nodes, edges = remove_nodes(network, rm_nodes)
    else:
        nodes, edges = network.nodes_df, network.edges_df

    with pd.HDFStore(filename, mode='w') as store:
        store['nodes'] = nodes
        store['edges'] = edges

        store['two_way'] = pd.Series([network._twoway])
        store['impedance_names'] = pd.Series(network.impedance_names)","def save(self, network_name, filename, descriptor, name, parent_name, parent_name, parent_name, pandas_name=None): """""" """""" if name in self._data: self._data[name] = network_name self._data[network_name] = network_name else: self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_name self._data[network_name] = network_","def add_data(self, data_name, pdf_data, refs_info=False): """""" """""" if not pdf_data: pdf_data = self.pdf_data[data_name] else: pdf_data = self.pdf_data[data_name] if pdf_data: self.pdf_data[pdf_data['pdf_data']['id']] = pdf_data['pdf_data'] if self.close: self.pdf_data[pdf_data['id']] = pdf_data['id'] return data_name",14.51862864,19.2880873
generate: Transform a describe node into a ``TestCase``.,"def transform_describe(self, node, describes, context_variable):
        """"""
        

        """"""

        body = self.transform_describe_body(node.body, context_variable)
        return ast.ClassDef(
            name=""Test"" + describes.title(),
            bases=[ast.Name(id=""TestCase"", ctx=ast.Load())],
            keywords=[],
            starargs=None,
            kwargs=None,
            body=list(body),
            decorator_list=[],
        )","def transform(self, node): """""""""""" if node.changes: return node.changes if node.changes: if node.changes: if node.changes: description = node.changes return description else: return description else: if node.changes: return node.changes return node","def description(self, node): """""" """""" description = node.strip() if not isinstance(description, basestring): raise TypeError(""description must be a basestring: %s"" % description) description = node.strip() return description",23.15176301,25.02524146
"generate: This has to be in a method, for TerminalIPythonApp to be available.","def _classes_default(self):
        """"""""""""
        return [
            InteractiveShellApp, # ShellApp comes before TerminalApp, because
            self.__class__,      # it will also affect subclasses (e.g. QtConsole)
            TerminalInteractiveShell,
            PromptManager,
            HistoryManager,
            ProfileDir,
            PlainTextFormatter,
            IPCompleter,
            ScriptMagics,
        ]","def _init_method(self, method, **kwargs): """""""""""" if self.type == 'false': return True elif self.type == 'true': return True else: raise ValueError('Cannot init type for TerminalIPythonApplication instance.' + self.type)","def _get_method(self, method): """""""""""" method_url = self._get_method_url(method) if method_url.lower() == 'GET': method = method_url.lower() else: method = method_url.lower() return method_url",20.56186578,12.89012891
generate: Gets the help text for the command. If its not supplied the doc string is used.,"def get_help(self):
        """"""
        
        """"""
        if self.help:
            return self.help
        elif self.__doc__ and self.__doc__.strip():
            return self.__doc__.strip()
        else:
            return ''","def get_help_text(self, command): """""""""""" if command is not None: return self.get_help_text(command) return self.get_help_text(command)","def _get_help(self, help): """""" """""" if not self._help: return None # Now only read the text if not self._help: return None if not self._help: return self._help return None",42.48745038,49.74929888
generate: Helper function for building an attribute dictionary.,"def build_attrs(self, extra_attrs=None, **kwargs):
        """"
        self.attrs = self.widget.build_attrs(extra_attrs=None, **kwargs)
        return self.attrs","def build_attr(self, attribute, attribute): """""" """""" if isinstance(attribute, dict): return dict(attribute=attribute) elif isinstance(attribute, dict): return dict(attribute=attribute) else: return dict(attribute=attribute)","def get_attribute_dict(self, key): """""""""""" if key not in self._attributes: return None if key not in self._attributes: return None return self._attributes[key]",22.75449113,35.58341395
generate: Socket connection.,"def client(self):
        """"""
        
        """"""
        if not self._client:
            self._client = socket.create_connection(
                (self.host, self.port), self.timeout)
            self.logger.debug('Client connected with guacd server (%s, %s, %s)'
                              % (self.host, self.port, self.timeout))

        return self._client","def check_connection(self, connection): """""" """""" self.connection = connection self.connection = connection self.connection = connection self.connection_status = self.connection self.messages = self.messages self.sender = self.sender","def _socket_connection(self, name): """""" """""" url = self.get_url() url = self.get_url() if self.connection_url_id: return self.get_connection_url() else: url = self.connection_url_id() return self._connection.handler.get_connection(url)",36.57529802,37.6979362
generate: SlackPost input validator function.,"def validate_slackpost(attr, value):
    """"""""""""
    if attr in (""channel"", ""credentials""):
        if not isinstance(value, str):
            raise InvalidMessageInputError(""SlackPost"", attr, value, ""string"")
    elif attr in (""attachments""):
        check_valid(""SlackPost"", attr, value, validus.isurl, ""url"")","def _convert_input_function(self, function): """""" """""" # TODO: We can't check that we've done input validator function. if function is not None: if function is not None: return function(*args, **kwargs) else: raise ValueError(""Unknown function: %s"" % function)","def _get_validator(self, func): """""" """""" if not isinstance(func, func): raise TypeError('function function has been function') if not isinstance(func, func): raise TypeError('function is not function') return self._get_error_for_function(func, func, func)",24.89852166,26.29344647
generate: Reads all patches from the series file,"def read(self):
        """"""  """"""
        self.patchlines = []
        self.patch2line = dict()
        if self.exists():
            with open(self.series_file, ""r"") as f:
                for line in f:
                    self.add_patch(line)","def read(self): """""""""""" path = self._get_path() patches = [] for patch in self.paths: if patch.patches: patches.append(patch) else: patches.append(patch) return patches",". def read_patches(self): """""""""""" patches = self.patches patches = self.read_patches() patches = [] for patches in patches: patches.append(patches) return patches",42.34445178,40.52677225
generate: Checks if value has the format of a virtual qubit,"def is_virtual(value):
        """""" """"""
        return value is None or isinstance(value, tuple) and len(value) == 2 and isinstance(
            value[0], Register) and isinstance(value[1], int)",". def has_qubit(qubit, qubit, qubit=None): """""" """""" if qubit is None: qubit = qubit.get(qubit) return has_qubit(qubit)","s and access-forced ``Tree``. def is_valid_values(value): """""" """""" if not isinstance(value, (int, float, float))): return False return value.strip() == value",19.82009204,48.99776446
generate: Returns ``True`` if credentials expire sooner than specified.,"def expire_soon(self, seconds):
        """"""
        

        """"""

        if self.expiration_time:
            return self.expiration_time < int(time.time()) + int(seconds)
        else:
            return False","def _check_specified(self, credentials): """""" """""" credentials = self.check_specified_credentials(credentials) if credentials.get('credentials'): return True # Load the specified credentials from the specified URL if self.check_specified_credentials(credentials): return True # FIXME: This is the same URL, but it is available # the credentials are not available return True","def get_credentials(self, credentials=False): """""" """""" if credentials: return self._credentials else: return self._credentials",16.94135183,42.80831595
generate: Convert a date in a given format to epoch time. Mostly a wrapper for  datetime's strptime.,"def _convert_date(date_string, date_format):
    """"""
    
    """"""
    if date_format != 'epoch':
        return datetime.strptime(date_string, date_format).timestamp()
    else:
        return float(date_string)","def date_to_datetime(time_to_format): """""""""""" date_to_format = datetime.strptime(time_to_format, date_to_format) return date_to_format","def get_datetime(time_str, datetime): """""" """""" if datetime is None: return datetime time_str = datetime.strptime(time_str) return time_str.replace(""%Y%m%d%H%M%S"")",46.78591563,49.33840845
generate: Add a format function for a given type.,"def for_type(self, typ, func):
        """"""
        """"""
        oldfunc = self.type_printers.get(typ, None)
        if func is not None:
            # To support easy restoration of old printers, we need to ignore
            # Nones.
            self.type_printers[typ] = func
        return oldfunc","def add_format(self, function, action, func, func, func, func_str, func_str): """""" """""" if isinstance(func, type): func = func if func is not type: func = func if func is not None: func = func return func(*func, **func)","def function(self, text): """""" """""" if type(text) is str: type_name = text.split('.') else: type_name = text.split('.') return type_name",39.58041797,23.58910616
generate: Updates the profile's auth entry with values set by the user.  This will overwrite existing values.,"def update_config_pwd(msg, cfg):
    """"""
    
    """"""
    msg_type = msg.__class__.__name__.lower()
    key_fmt = msg.profile + ""_"" + msg_type
    if isinstance(msg._auth, (MutableSequence, tuple)):
        cfg.pwd[key_fmt] = "" :: "".join(msg._auth)
    else:
        cfg.pwd[key_fmt] = msg._auth","def update_profile(self, profile, values, **kwargs): """""" """""" self.profiles[profile] = values if self.profiles[profile]: self.profiles[profile] = values self.profiles[profile] = values","def _update_profile_settings(self, profile_id, values): """""" """""" if not isinstance(values, list): values = values.append(values) else: values = [self._get_value(profile_id) for profile_id in values] return self._update_profile(profile_id, profile_id)",18.18149239,25.59114343
generate: Search the database for the given query. Will find partial matches.,"def search(self, query):
        """"""  """"""
        results = self.session.query(Domain).filter(Domain.name.ilike('%%%s%%' % query)).all()
        return results","def get_query(self, query, query_name=None, **kwargs): """""" """""" if not self.query: query = query.split("" "") self.query = query_name return query","def search_query_for_query(self, query, query_name, query_context): """""" """""" query = self._query_query_for_query(query, query_name, query) return query",38.19079771,39.49328407
"generate: The file path can be stored in a local file system, HDFS, S3,    or any Hadoop-supported file system.","def load_weights_from_json_hdf5(def_json, weights_hdf5, by_name=False):
        """"""
        
        """"""
        bmodel = DefinitionLoader.from_json_path(def_json)
        def_value = BCommon.text_from_path(def_json)
        kmodel = model_from_json(def_value)
        WeightLoader.load_weights_from_hdf5(bmodel, kmodel, weights_hdf5, by_name)
        return bmodel","def get_file_system_file(self, filename, filename, parent_filename, **kwargs): """""" """""" if filename not in self.file_system_files: file_system_files[filename] = filename else: file_system_files[filename] = filename return file_system_files[filename]","def _load_file_system(filename, filename): """""" """""" if not os.path.isfile(filename): return None try: filename = filename.split('.') except KeyError: filename = filename return filename",14.69437475,14.1570599
generate: Creates a backup of file,"def _backup_file(self, file, patch):
        """"""  """"""
        dest_dir = self.quilt_pc + patch.get_name()
        file_dir = file.get_directory()
        if file_dir:
            #TODO get relative path
            dest_dir = dest_dir + file_dir
        backup = Backup()
        backup.backup_file(file, dest_dir, copy_empty=True)","names and filenames def upload_backup(self, backup, filenames, filenames): """""""""""" backup = self.backup backup = [] for filename in filenames: if filename in backup: backup.append(filename) backup.append(filename) return backup","name. def _create_backup(self, filename, name, fname): """""" """""" if not self.is_body: raise InvalidByteInput('Backup code {}: {}'.format(filename, fname)) self.finished = False return self.finished",37.02701175,25.50070806
generate: Fetch messages for given user. Returns None if no such message exists.,"def get_messages(user):
    """"""
    
    """"""
    key = _user_key(user)
    result = cache.get(key)
    if result:
        cache.delete(key)
        return result
    return None","def get_messages(self, user): """""" """""" # Fetch messages for Username, included by the given username. user = self.get_messages(user) return User.get_messages(user, user)","def _get_user(self, user_id, password): """""" """""" if not self.is_user_id: return None return self.get_user(user_id, password)",37.36739172,39.41667199
"generate: Flatten nested lists, tuples, generators and maps","def flatten(iterables, level=inf):
    """"""
    
    """"""
    if level >= 0 and isinstance(iterables, (list, tuple, GeneratorType,
                                             map, zip)):
        level -= 1
        for i in iterables:
            yield from flatten(i, level=level)
    else:
        yield iterables","def _flatten(self, nested_list, nested_list): """""""""""" nested_list = [] if nested_list: for name in nested_list: if name in nested_list: nested_list.append(name) return nested_list else: return []",". def flatten(self, nested): """""" """""" if not self.has_nested_list(): return for annotation in self.has_nested_list(): self.has_nested_lists(self.has_nested_list, annotation) self.has_nested_lists(self.has_nested_list, annotation) if not self.has_nested_lists: raise exc.Hash() return list(self.hash_list)",23.45167991,19.39327214
"generate: \    Actual messages listened for by the worker bot - note that worker-execute    actually dispatches again by adding the command to the task queue,    from which it is pulled then matched against self.task_patterns","def command_patterns(self):
        """"""
        """"""
        return (
            ('!register-success (?P<cmd_channel>.+)', self.require_boss(self.register_success)),
            ('!worker-execute (?:\((?P<workers>.+?)\) )?(?P<task_id>\d+):(?P<command>.+)', self.require_boss(self.worker_execute)),
            ('!worker-ping', self.require_boss(self.worker_ping_handler)),
            ('!worker-stop', self.require_boss(self.worker_stop)),
        )",". def _task_patterns(self, command): """""" """""" pattern = ""\n"".join(""{0}{1}"".format(self.worker_execute_name, command)) command = self.task_patterns[0] if pattern == ""summary"": pattern = ""\n"".join(""{0}"".format(self.worker_execute_name, command)) return pattern",". This is the task is valid for created by the pattern. If this is valid, create any command line. If we're include the current task, otherwise only adding the backend, and the backend. def add_backend(self, backend, sleep_blocks, cancel_return_blocks, keep_blocks, cancel_blocks): """""" """""" if not backend.get('block'): raise MissingBlockError(""Backend "" + backend.get('block')) self.task_queue.put(block) self.task_queue.put(block)",26.79242458,18.8122944
generate: Returns ids that match an indexed value.,"def index_scan(self, idx_name, val):
        '''
        '''
        idx = self._index(idx_name)['transform']
        key = (idx(val), idx_name.encode('utf-8'))
        keys = self.kvl.scan_keys(self.INDEX_TABLE, (key, key))
        return imap(lambda k: k[2], keys)","def items(self, value): """""""""""" items = list(value) if not items: return self.match(value) if items: return self.match(value) return self.match(value)","def ids(self, indexed_value): """""" """""" if not isinstance(indexed_value, list): raise TypeError(""Indexed value {} not found."".format(self.id)) return self._id.items.items(indexed_value)",20.49526483,27.37371634
generate: Extract percussive elements from an audio time-series.,"def percussive(y, **kwargs):
    '''

    '''

    # Compute the STFT matrix
    stft = core.stft(y)

    # Remove harmonics
    stft_perc = decompose.hpss(stft, **kwargs)[1]

    # Invert the STFT
    y_perc = util.fix_length(core.istft(stft_perc, dtype=y.dtype), len(y))

    return y_perc","def extract(self, percussive, time_series, elements): """""""""""" if percussive: return self._get_percussive_time(percussive, time_series, elements) else: return self._get_percussive_time(percussive, time_series, elements)","def get_percussive_series(self, percussive_series): """""" """""" if self.get_percussive_series(): return self.get_percussive_series(percussive_series) else: return self.get_percussive_series(percussive_series)",21.06411015,19.63029471
"generate: Invert the selection, i.e. what is selected will not be, and vice versa","def select_inverse(self, name=""default"", executor=None):
        """"""
        """"""

        def create(current):
            return selections.SelectionInvert(current)
        self._selection(create, name, executor=executor)","fe. def get_selection(self, error_code, local_mode=None): """""" """""" if not error_code: return if local_mode is not None: selected_code = ""{0}"".format(local_mode) selected_code = ""{0}"".format(selected_code) return selected_code","mples. def invert_to_element(self, element): """""" """""" element = selection.element if element not in self.elements: element = selection.element if element not in self.elements: element = selection.elements[element] else: element = selection.elements[element] return element",35.18108056,28.67112205
generate: Specify how the return value of this function should be handled.,"def returns(desc=None, printer=None, data=True):
    """"""
    """"""

    if data is False:
        raise ArgumentError(""Specifying non data return type in returns is no longer supported"")

    def _returns(func):
        annotated(func)
        func.custom_returnvalue(printer, desc)
        return func

    return _returns","def handle_return(self, func): """""""""""" # function should be handled. if not isinstance(func, func): return func # handle HTTP header. if self.handle_return_value: return func # Use this method to handle the results. self.handle_return_value = func return self.handle_return_value","def _create_value(self, function): """""" """""" # Make sure the function is a bug. if not isinstance(function, (float, float)): raise ValueError(""The function should be an HDUL on the same function"") return self.response(function, function)",37.1187162,31.3700592
generate: Generate a base64 encoded representation of this SPKI object.,"def b64_encode(self):
        """"""
        
        """"""
        encoded = _lib.NETSCAPE_SPKI_b64_encode(self._spki)
        result = _ffi.string(encoded)
        _lib.OPENSSL_free(encoded)
        return result","def encode(self, spk=None): """""" """""" self.encode(spk) encoded = spk.encode(self.encoded) return base64_encode(encoded)","def _get_blob(self, blob): """""" """""" self._db.update_blob(blob) self._db.update_blob(blob) return self._db",46.37565958,21.50037402
"generate: This method only works for extensible fields. It allows to insert a value, and shifts all other following    values.","def insert(self, index, value):
        """"""
        
        """"""
        # prepare index (will check for extensible)
        index = self._prepare_pop_insert_index(index=index)

        # remove extensible fields
        fields = self.clear_extensible_fields()

        # insert
        fields.insert(index, value)

        # add new list
        self.add_fields(*fields)","If the fields are available, the values are available, the fields are not specified, then the fields are inserting. def _insert_fields(self, fields): """""" """""" fields = [field for field in fields if field.fields] if fields: fields = [field for field in fields if field in fields] return fields","def _setup_fields(self, fields, value): """""" """""" # Add only any fields and values for fields. value_values = self.get_fields_values(fields, value_values) value_values = self._flatten_fields(fields) return self.setup_fields(value_values)",36.88545132,38.29289202
generate: Ensure the user has the necessary tokens for the specified services,"def tokens_required(service_list):
    """"""
    
    """"""
    def decorator(func):
        @wraps(func)
        def inner(request, *args, **kwargs):
            for service in service_list:
                if service not in request.session[""user_tokens""]:
                    return redirect('denied')
            return func(request, *args, **kwargs)
        return inner
    return decorator",". def need(self, services): """""" """""" for services in self.services: if services.get(services): return services[services.get(services)].get(services) raise ValueError('No need to retrieve the need tokens on the specified services.')","and when ending the input_tokens and any existing services. def _get_user_tokens(self, service_id): """""" """""" user_tokens = self.get_user_tokens(service_id) if user_tokens and user_tokens and user_tokens: user_tokens.append(user_tokens[user_tokens]) return user_tokens",33.16825227,30.04010286
generate: Gets yearly passing stats for the player.,"def passing(self, kind='R'):
        """"""
        """"""
        doc = self.get_doc()
        table = (doc('table#passing') if kind == 'R' else
                 doc('table#passing_playoffs'))
        df = sportsref.utils.parse_table(table)
        return df","def get_passing_stats(self, model_name, field_name, stats=None): """""" """""" passing_state = self._get_passing_stats(model_name, field_name) if passing_state is None: passing_state = self._get_passing_stats(model_name, field_name) return (passing_state, None)","def get_passing_stats(self): """""" """""" stats = self.stats.get('stats', None) if stats is None: stats = self.stats.get('stats', None) return self.stats.get('stats', None)",29.24577127,31.16392681
generate: Returns the primary and secondary access keys for the specified    storage account.,"def get_storage_account_keys(self, service_name):
        '''
        
        '''
        _validate_not_none('service_name', service_name)
        return self._perform_get(
            self._get_storage_service_path(service_name) + '/keys',
            StorageService)","def _get_primary_access_key(self, storage_name, storage_name): """""" """""" storage_name = self._get_primary_access_key(storage_name) if storage_name in self.primary_access_keys: return self.get_primary_access_key(storage_name) else: return self.get_primary_access_key(storage_name)","def get_primary_key(self, storage_name, primary_key): """""" """""" if not self.storage_account: raise NotImplementedError(""Could not get storage account: %s"" % self.storage_name) if self.primary_key: return self.get_primary_key(storage_name, primary_key) else: return self.get_primary_key(storage_name, primary_key)",36.42336162,31.39305585
generate: Return True if `name` is a considered as an archive file.,"def is_archive_file(name):
    """"""""""""
    archives = (
        '.zip', '.tar.gz', '.tar.bz2', '.tgz', '.tar', '.whl'
    )
    ext = splitext(name)[1].lower()
    if ext in archives:
        return True
    return False","def _check_path(name, fn, fn): """""""""""" if not fn.startswith("".""): return False try: if name not in fn: return True else: return False except Exception as e: return False","def _is_bundle_file(self, name): """""""""""" if not self.is_bundle_file(name): return False if not self.is_bundle_file(name): return False if not self.is_bundle_file(name): return False return False",33.83467415,31.53733867
generate: Change the working directory that processes should be executed in.,"def cwd(self, value):
        """"""
        
        """"""

        self._cwd = utils.canonicalize_path(self._cwd, value)","def _make_directory(self): """""" """""" self.show_dir() self.show_dir() self.show_dir() self.show_dir() self.show_dir() self.show_dir() self.show_dir() self.show_dir()","def execute_dir(self, args): """""" """""" if not self._wrapper.get('wrapper'): self._wrapper.set_level(self._wrapper) return self._wrapper",17.77862463,25.6762943
generate: Runs HTTP GET request to retrieve a single dataset.,"def get_dataset(self, workspace_id, dataset_id):
        """"""""""""
        api_path = self.DATASOURCE_URI_FMT.format(workspace_id, dataset_id)
        return self._send_get_req(api_path)","def _get_http_request(self, request, data): """""""""""" request = requests.get(url=self.url, data=data) return request.json()","def run_request(self, request, url, dataset=None): """""" """""" response = self._request(url, dataset=dataset, dataset=dataset) return self._post(response, response)",31.97530327,41.41138989
generate: Return a CLI profile class.,"def get_cli_profile():
    """"""
    """"""

    try:
        from azure.cli.core._profile import Profile
        from azure.cli.core._session import ACCOUNT
        from azure.cli.core._environment import get_config_dir
    except ImportError:
        raise ImportError(""You need to install 'azure-cli-core' to load CLI credentials"")


    azure_folder = get_config_dir()
    ACCOUNT.load(os.path.join(azure_folder, 'azureProfile.json'))
    return Profile(storage=ACCOUNT)","def get_profile(self, profile_name, class_name=None): """""" """""" # TODO: Implemented from template for osid.resource.CSV profile = tempfile.NamedTemporaryFile( osid.basename(profile_name), class_name=class_name, class_name=class_name, class_name=class_name, ) if profile is None: return self.get_profile_class(profile) else: return self.get_profile_class(profile)","def get_class(self, class_name): """""" """""" if self._class_name is None: raise TypeError(""Class_name is not a string"") if self._class_name is None: raise TypeError(""Classname is not a string"") return self._class_name",27.06543478,12.78991051
generate: Parse show subcommand.,"def parse(self):
        """"""""""""
        parser = self.subparser.add_parser(
            ""show"",
            help=""Show workspace details"",
            description=""Show workspace details."")

        group = parser.add_mutually_exclusive_group(required=True)
        group.add_argument('--all', action='store_true', help=""All workspaces"")
        group.add_argument('name', type=str, help=""Workspace name"", nargs='?')","def parse_show_subcommand(self, cmd, command): """""""""""" if not command: return subcommand = self.parse_show_subcommand(cmd, command) if subcommand.st_out: return subcommand raise RuntimeError(""Could not parse show subcommand {}"".format(cmd))","def parse_subcommand(self, subcommand): """""" """""" if self.subparser.is_subparser(): return self.subparser.parse_subparser(subcommand, subcommand) else: return self.subparser.parse_subparser(subcommand)",17.1102963,16.83798386
"generate: Takes a raw `Instruction` and translates it into a human readable text  representation. As of writing, the text representation for WASM is not yet  standardized, so we just emit some generic format.","def format_instruction(insn):
    """"""
    
    """"""
    text = insn.op.mnemonic

    if not insn.imm:
        return text

    return text + ' ' + ', '.join([
        getattr(insn.op.imm_struct, x.name).to_string(
            getattr(insn.imm, x.name)
        )
        for x in insn.op.imm_struct._meta.fields
    ])","def text_representation(instruction, sample_filename, sample_filename): """""""""""" if not os.path.exists(instruction): os.makedirs(instruction) if sample_filename == '{0}'.format(sample_filename) and os.path.exists(instruction): return '{0}'.format(sample_filename) else: return '{0}'.format(sample_filename)","definition. def read_line_response(response): """""" """""" response = requests.get(response) if response.status_code!= 200: raise ValueError('Invalid response: %s' % response.text) else: response.status_code = response.text response.text = response.text return response",31.35997279,23.03372832
generate: Returns a debug-output-suitable file-like object based on the    optional os_path and optionally skipping any configured    sub-command.,"def get_debug(self, os_path=None, skip_sub_command=False):
        """"""
        
        """"""
        sub_command = None if skip_sub_command else self.debug_sub_command
        out, path = self._get_out_and_path(
            self.debug, self.debug_root, sub_command, os_path)
        if hasattr(out, 'stdin'):
            return out.stdin
        return out","def get_debug_output_suitable_file_file(self, output_suitable_filename, suitable_filename): """""""""""" if suitable_filename.startswith('.py'): return os.path.basename(suitable_filename) suitable_filename = os.path.basename(suitable_filename) return os.path.basename(suitable_filename)","def get_debug_output_suitable_file(self, debug_output_dir, remote_dir=True, remote_dir=False): """""" """""" if not os.path.exists(debug_output_dir): return if not os.path.isfile(debug_output_dir): return return debug_output_dir",31.62887692,34.13939603
"generate: Returns tab-delimited, newline terminated string of VcfRecord.","def text(self):
        """"
        stringifier = [self.chrom, self.pos, self.vcf_id, self.ref, self.alt,
                       self.qual, self.filter, self.info,
                       self._format_field()]

        for sample in self.sample_tag_values:
            stringifier.append(self._sample_field(sample))

        return ""\t"".join(stringifier) + ""\n""","def table(self, path, callback=None): """""" """""" if not path: return # For VCfRecord, just be available if self.is_enabled(path): self.check_context(path) if callback: self.check_context(path) self.check_context(path)","def tab_delimited(self, tab): """""" """""" if not self._clone: raise ValueError(""Tab-delimited delimited but not found"") if not self._clone: raise ValueError(""Tab-delimited but not found"") if self._clone: raise ValueError(""Clone must be one of the clone must be "" ""the "" + self.clone) if self._clone: raise ValueError(""Clone must be a string."") if self._clone: raise ValueError(""Clone must be "" + self._clone) return self._clone",23.27840586,21.94212761
generate: Alternate version of Spark's zipWithIndex that eagerly returns count.,"def zip_with_index(rdd):
    """"""
    
    """"""
    starts = [0]
    if rdd.getNumPartitions() > 1:
        nums = rdd.mapPartitions(lambda it: [sum(1 for _ in it)]).collect()
        count = sum(nums)
        for i in range(len(nums) - 1):
            starts.append(starts[-1] + nums[i])
    else:
        count = rdd.count()

    def func(k, it):
        for i, v in enumerate(it, starts[k]):
            yield v, i

    return count, rdd.mapPartitionsWithIndex(func)","def version(self, split_index, markers=None, zip_new=False, version=None): """""" """""" version = self.version_version(split_index) if version is not None: version = version(version) if version is not None: version = version(version) if version is not None: version = version(version) if version is not None: version = version(version) return version(version)","def get_all_index(self, spark, number, count=None): """""" """""" url = self.client.get(""Username"", ""/%s"" % self.url) response = self.create_response(url, count=spark, number=number, count=count) return self.client.get(url, response)",18.17693815,18.3833367
generate: Decorator to log the execution time of a function,"def log_time(logger):
    """"""
    
    """"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start = time.time()
            result = func(*args, **kwargs)
            end = time.time()
            _log_time(logger, func.__name__, start, end)
            return result
        return wrapper
    return decorator",". def log_execution(func): """""""""""" def wrapper(*args, **kwargs): log.debug(""%s "" % func) try: return func(*args, **kwargs) except (Exception, exc.ProblemException): log.debug(""Missing execution time: %s"", func) raise return wrapper","to avoid a corpus. def log_timeout(cls, func): """""" """""" func = cls._session.get(func, ""func"", None) if func.active: if func.func_func: func.active = func.func_func(func) else: func.active = func return func",49.84107908,27.06494618
generate: Compute the Entanglement of Formation of a 2-qubit density matrix.,"def __eof_qubit(rho):
    """"""
    
    """"""
    c = concurrence(rho)
    c = 0.5 + 0.5 * np.sqrt(1 - c * c)
    return shannon_entropy([c, 1 - c])","def _compute_fn_format(self, n): """""" """""" fn = normalize_fn(n) for n in range(n): fn = normalize_fn(n) fn = fn(n) return fn","def _format_entangle_density_matrix(self, entangle): """""" """""" return self.format_entangle(entangle, entangle, entangle, self.float_detail)",25.84675196,21.41055674
"generate: Waits until the result set changes. Possible changes can be a result    being added or the result set becoming complete. If the result set is    already completed, this method returns immediately.","async def wait_changed(self):
        """"""
        
        """"""

        if not self.is_complete():
            waiter = self._loop.create_future()
            self._waiters.append(waiter)
            await waiter","def wait(self, results): """""" """""" for result in self.results: if result.complete: result.assert(result.complete, result.complete) self.results = results","def wait_for_send(self, response, start=None): """""" """""" if not response: response = self._callback_callback(response) self._wait_for_callback(response, response) return response",32.8467495,34.89012939
generate: wrapper for ensuring image_tag returns utf8-encoded str on Python 2,"def ensure_utf8(image_tag):
    """"""""""""
    if py3compat.PY3:
        # nothing to do on Python 3
        return image_tag
    
    def utf8_image_tag(*args, **kwargs):
        s = image_tag(*args, **kwargs)
        if isinstance(s, unicode):
            s = s.encode('utf8')
        return s
    return utf8_image_tag",". def _get_image_tag(self, image_tag, image_tag): """""" """""" if image_tag is not None: image_tag = image_tag.encode('utf8') return image_tag.encode('utf8') else: return image_tag","0101. def wrapper(filename, encoding): """""" """""" if encoding.get('UTF8') or encoding.get('UTF8') or encoding.get('UTF8') and encoding.get('UTF8'): encoding = encoding.get('UTF8') try: image_tag = encoding.get('Image_tag', None) except AttributeError as e: raise ValueError('Unable to wrap a tagged bytes:'+ str(e)) else: return image_tag",42.29971823,25.275196
generate: Update the activity message for the current user.,"def setMood(self, mood):
        """"""
        
        """"""
        self.conn(""POST"", ""{0}/users/{1}/profile/partial"".format(SkypeConnection.API_USER, self.userId),
                  auth=SkypeConnection.Auth.SkypeToken, json={""payload"": {""mood"": mood or """"}})
        self.user.mood = SkypeUser.Mood(plain=mood) if mood else None","def update_message(self, username, label=None): """""" """""" if username is None: raise UserNotFound(""Username not found."") if label is None: raise UserNotFound(""Username not found."") self.send_message(username)","def user_message(self): """""" """""" url = self._build_url(self.url) if not self._catalog: raise Exception('Unable to create User url.') url = self._user_url(self._url) if self._response: return self._response.get(url) return self._response.get(url)",20.25822139,22.5887555
generate: Get any defined templates for configuration values.,"def get_templates(self):
        """""" 

        """"""
        templates = {}
        for key in six.iterkeys(Task.FIELDS):
            template_key = '%s_template' % key
            if template_key in self.config:
                templates[key] = self.config.get(template_key)
        return templates","def get_templates(self): """""" """""" templates = [] for field in self.fields: if field.is_template(field, field): templates.append(field) elif field.is_template(field, field): templates.append(field) return templates","def get_templates(self, config_path): """""" """""" if not self.is_closed: raise ValueError(""Can't get templates"") return self.get_templates(config_path=config_path)",54.4262594,38.52109882
generate: Append statements to this container under conditions specified    by condSet,"def _register_stements(self, statements: List[""HdlStatement""],
                           target: List[""HdlStatement""]):
        """"""
        
        """"""
        for stm in flatten(statements):
            assert stm.parentStm is None, stm
            stm._set_parent_stm(self)
            target.append(stm)",". def append_statements(self, selection_id): """""""""""" statement_ids = [] for statement_id in selection_ids: if statement_id not in statement_ids: statement_ids.append(statement_id) return self.apply_statements(selection_ids, statement_ids)","tings. def append_statement(self, statements, statements): """""" """""" statements_settings = self.get_statements_settings() if statements_settings: statements_settings.add_statements(statements_settings) statements_settings.add_statement(statements) return self._apply_statement(statements)",41.69536369,34.69793211
generate: Resolves expressions inside the dictionary.,"def resolve_expression(self, *args, **kwargs):
        """"""""""""

        result = dict()
        for key, value in self.value.items():
            if hasattr(value, 'resolve_expression'):
                result[key] = value.resolve_expression(
                    *args, **kwargs)
            else:
                result[key] = value

        return HStoreValue(result)","def _resolve_dictionary_expressions(self, dictionary): """""" """""" super(ModelInside, self).resolve_expressions(dictionary) if self.expressions: return self._resolve_expressions(dictionary) else: return self._resolve_expressions(dictionary)","def register_expressions(self, expressions): """""""""""" expressions = {} for expression in expressions: expression = expression.get(expression) if expression not in expressions: expressions[expression] = expression return expressions",42.29513271,32.06083522
"generate: Get and parse a WFS capabilities document, returning an    instance of WFSCapabilitiesInfoset","def read(self, url, timeout=30):
        """"""
        """"""
        request = self.capabilities_url(url)
        u = openURL(request, timeout=timeout,
                    username=self.username, password=self.password)
        return etree.fromstring(u.read())",". def get_wfs_capabilities_infoset(self, wfs_capabilities): """""" """""" # TODO: Directly filter the wfs_capabilities info wfs_capabilities = self.get_wfs_capabilities(wfs_capabilities) return wfs_capabilities",". def get_wf_scapabilities(self, wf_name, content): """""" """""" if wf_name in self.wfs_capabilities: return self.wfs_capabilities[wf_name] return None",27.73541977,29.25408461
"generate: Given a weekday and a date, will increment the date until it's  weekday matches that of the given weekday, then that date is returned.","def _first_weekday(weekday, d):
    """"""
    
    """"""
    while weekday != d.weekday():
        d += timedelta(days=1)
    return d","def _get_weekday_day(self, weekday, date, date): """""" """""" if weekday == 'givenday': return date.get(weekday) else: return None","def weekday(weekday_id): """""" """""" if weekday_id: weekday_id = weekday_id else: weekday_id = weekday_id return weekday_id",47.04262947,44.07994704
"generate: Cancels the job set. The job set is immediately finished, and all    queued jobs are discarded.","def cancel(self):
        """"""
        
        """"""

        if self._active_jobs == 0:
            return

        self._jobs = iter(())
        self._on_deck = None
        self._return_queue.clear()
        self._active_jobs = 0

        self._done()","def _run_jobs(self, job_id, job_name, **kwargs): """""" """""" job_id = job_id + 'jobs' if self.jobs: self.jobs = job_id self.jobs.cancel() self.jobs.cancel() else: self.jobs = job_id self.jobs.cancel() self.jobs.cancel() self.jobs.cancel() self.jobs.cancel()","def job_set(self, job): """""" """""" # This is authorization. if not self._active: self._active.update(job) else: self._active.set(job)",30.9736486,35.76549254
generate: Output a simple table with several columns.,"def table(rows):
    '''
    
    '''

    output = '<table>'

    for row in rows:
        output += '<tr>'
        for column in row:
            output += '<td>{s}</td>'.format(s=column)
        output += '</tr>'

    output += '</table>'

    return output","def rotate_table(self, table, columns): """""""""""" table = rotate_table(columns) columns = [] columns = [] for column in columns: columns.append(column) return columns","def over_several_column_list(self, simple_table): """""" """""" several_columns = {} for column_name in several_columns: several_columns[column_name] = column_name return several_columns",28.45908603,20.62981603
generate: A small helper function to convert a string to a numeric value  if appropriate,"def _convert_to_float_if_possible(s):
    """"""
    
    """"""
    try:
        ret = float(s)
    except (ValueError, TypeError):
        ret = s
    return ret",". def convert(self, value): """""""""""" if value == '': return '<HEAD' if value == '': return '<HEAD' return '<HEAD'","required. def _create_value(self, value): """""" """""" if not isinstance(value, str): raise TypeError(""value must be a string"") return self._create_value(value)",31.38495015,30.07321931
"generate: Lists the categories in the lexicon, except the    optional categories.","def categories(self):
        """"""
        
        """"""
        keys = [k for k in self.__dict__.keys() if k not in SPECIAL]
        return keys","def list_categories(self, category=None, **kwargs): """""" """""" category = self.list_categories(category=category) return category","def lexicon(self): """""" """""" categories = self._categories.keys() if self._lexicon: return self._lexicon else: return self._lexicon",34.93225986,43.2504908
generate: Will return a matching record or raise KeyError is no record is found.,"def get(self, record_name):
        """"""
        
        """"""
        if record_name in self._schema_map:
            return self._schema_map[record_name]
        else:
            last_name = record_name.split('.')[-1]
            return self._schema_map[last_name]","def get_matching(self, record): """""""""""" record = self.get_matching(record) if record is None: return None if record is None: return None else: return record","def _find_record_for_record(record): """""" """""" record_record = None if record_record: record_record = record_record else: record_record = record_record if not record_record: record_record = record.replace("":"", """") return record_record",40.35348578,28.08428821
generate: draw a node,"def node(self, title, **args):
        """"""
        """"""
        self._stream.write('%snode: {title:""%s""' % (self._indent, title))
        self._write_attributes(NODE_ATTRS, **args)
        self._stream.write(""}\n"")","with the period of a node. def draw(self, node, node, node): """""" """""" node.top_execute(node, node) node.top_execute(node, node) return node",". def node(self, node, page=None): """""""""""" if node is not None: if self.is_node(node): return self.node(node) return self.node(node)",19.88367661,25.81385056
generate: List all the projects the user have access to.,"def list_projects(self, hpc=None, access=None, name=None, collab_id=None,
                      page_size=DEFAULT_PAGE_SIZE, page=None, ordering=None):
        '''
        '''
        return self._authenticated_request \
            .to_endpoint('project/') \
            .with_params(self._prep_params(locals())) \
            .return_body() \
            .get()","def list_projects(self, user, name, disabled=False): """""" """""" disabled = [] if not user: disabled = [] if disabled: disabled = [] if name: disabled.append(self.get_projects(name)) if not disabled: disabled.append(self.get_projects(name)) return disabled","def list_projects(self, project_id=None): """""" """""" return self.client.get( self._client.get_user_id(project_id=project_id, project_id=project_id, project_id=project_id, project_id=project_id, project_id=project_id, project_id=project_id, project_id=project_id, )",27.58935097,28.98509271
generate: Engage the exit actions.,"def ask_exit(self):
        """"""""""""
        self.exit_now = True
        payload = dict(
            source='IPython.zmq.zmqshell.ZMQInteractiveShell.ask_exit',
            exit=True,
            keepkernel=self.keepkernel_on_exit,
            )
        self.payload_manager.write_payload(payload)","def exit(self): """""""""""" exit = self.exit self.exit = True if self.is_empty(): self.exit = True self.exit = True self.exit = True self.sleep_message = True self.exit = True self.init()","def event_exit(self, exit_response): """""" """""" # event is an event. self._socket.active_event(exit_response) self._socket.active_event(exit_response)",30.83596534,23.26324817
generate: Calculate size of data of interest.,"def _calc_selection_size(self):
        """"""
        """"""

        #Check to see how many integrations requested
        n_ints = self.t_stop - self.t_start
        #Check to see how many frequency channels requested
        n_chan = (self.f_stop - self.f_start) / abs(self.header[b'foff'])

        n_bytes  = self._n_bytes
        selection_size = int(n_ints*n_chan*n_bytes)

        return selection_size","def _interest_interest(self, data): """""""""""" self.interest_interest = data self.interest_interest = data self.interest_interest = data self.interest_interest = data self.interest_interest = data self.interest_interest = data self.interest_interest = data self.interest_interest = data self.interest_interest = data self.interest_interest = data","This is the component of the fully interest. def size(self, size, msg): """""" """""" if not self.size: self.size = size return # Map the size to the datasets in the Fully instance if not self.size.is_size(): # First, return the interest self.size = size # For calculated datasets self.size = self.size self.size = size self.size = self.size self.size = self.size self.size = self.size return self.size",23.06855924,29.87036819
generate: Define a new alias after validating it.,"def define_alias(self, name, cmd):
        """"""
        """"""
        nargs = self.validate_alias(name, cmd)
        self.alias_table[name] = (nargs, cmd)","def _define_alias(self, lib=None): """""" """""" if not self.full_alias: self.full_alias = self.full_alias if not self.full_alias: self.full_alias = self.full_alias return self.full_alias","def _define_alias(self, url, validate_errors, aliases): """""" """""" self._process_error(url, validate_errors, aliases)",31.53945415,46.09650611
generate: Get the max date in unixtime format from reviews.,"def __get_max_date(self, reviews):
        """"""""""""""
        max_ts = 0
        for review in reviews:
            ts = str_to_datetime(review['timestamp'])
            ts = datetime_to_utc(ts)
            if ts.timestamp() > max_ts:
                max_ts = ts.timestamp()
        return max_ts","def get_time_square(self, reviews, date=None): """""" """""" # Get the time-square text if date is None: date = self.get_time_square(date) return self.get_time_square(date=date, date=date, date=date)","def get_datetime(self, datetime): """""" """""" if not self.get_datetime_from_datetime_from_datetime(datetime) or datetime in self.get_datetime_from_datetime(datetime): raise ValueError('Datetime has invalid datetime: {}'.format(datetime)) return datetime",32.37399375,28.7334601
generate: List the SQL databases defined on the specified server name,"def list_databases(self, name):
        '''
        
        '''
        response = self._perform_get(self._get_list_databases_path(name),
                                     None)
        return _MinidomXmlToObject.parse_service_resources_response(
            response, Database)",". def list_databases(self, server_name, sub_name=None): """""" """""" data = self.get_databases(server_name, sub_name) return data",". def list_servers(self, name): """""" """""" url = self._url res = self._get(name, None) url = res.json() if res.status_code == 200: return res.json() return self._get_response(url, url, url)",34.02288662,44.68279781
generate: Returns a boolean as to whether the slot pool has room for this    task to run,"def pool_full(self, session):
        """"""
        
        """"""
        if not self.task.pool:
            return False

        pool = (
            session
            .query(Pool)
            .filter(Pool.pool == self.task.pool)
            .first()
        )
        if not pool:
            return False
        open_slots = pool.open_slots(session=session)

        return open_slots <= 0","a specific pool. def boolean_async_boolean_async(self, boolean_async, task_pk, room_name, default=None, compute=False): """""" """""" boolean_async = boolean_async(boolean_async) task_pk = task_pk if not room_name: return False task_pk = task_pk.split('.') if task_pk == 'available': return False else: return False",". def boolean_pool_priority(self, pool_pb): """""" """""" if not pool_pb: raise ValueError(""Pool_pb is not a pool_pb: %s"" % pool_pb) if pool_pb.is_boolean_pool(): raise ValueError(""Pool_pb is not None, not applied to this pool_pb is not a "" ""when closing the pool_pb."") return self._fetch_pool_pb(pool_pb)",32.364336,31.61104039
generate: Adds two sequences of trits together.,"def add_trits(left, right):
    # type: (Sequence[int], Sequence[int]) -> List[int]
    """"""
    
    """"""
    target_len = max(len(left), len(right))

    res = [0] * target_len
    left += [0] * (target_len - len(left))
    right += [0] * (target_len - len(right))

    carry = 0
    for i in range(len(res)):
        res[i], carry = _full_add_trits(left[i], right[i], carry)

    return res","def add_two_sequences(self, sequences, trits, errors): """""" """""" for j in j: for m in m.group(0): self.add_two_sequences(m, j) if trits == 0: self.add_two_sequences(trits) if trits == 0: for m in trits: self.add_two_sequences(trits) if trits == 0: self.add_two_sequences(trits) if trits == 0: for m in trits: self.add_two_sequences(m, j) if trits == 0: for m in trits: self.add_two_sequences(m)","def add_sequences(self, sequences, two_sequences, read_meta, read_meta, level, level, read_meta): """""" """""" if not read_meta: read_meta = sequences.get(""read_meta"") else: read_meta = sequences.get(""read_meta"") if not read_meta: read_meta = self._get_two_sequences(read_meta) self.add_meta(read_meta, read_meta, level, read_meta)",19.39787138,20.30639537
generate: Returns a Pattern that matches exactly n repetitions of Pattern p.,"def mult(p, n):
    """"""
    """"""
    np = P()
    while n >= 1:
        if n % 2:
            np = np + p
        p = p + p
        n = n // 2
    return np","def match(self, lines): """""" """""" for pattern in pattern.splitlines(): if pattern.endswith('-'): return pattern[0] return None","def _Pattern(self, pattern_id, repetitions): """""" """""" pattern_id = self._get_pattern_id(pattern_id) pattern_id = self._get_pattern(pattern_id) return pattern_id, pattern_id",24.21943392,15.83929019
"generate: Check if a PE_PE is globally defined, i.e. not inside a C_C","def is_global(pe_pe):
    '''
    
    '''
    if type(pe_pe).__name__ != 'PE_PE':
        pe_pe = one(pe_pe).PE_PE[8001]()
    
    if one(pe_pe).C_C[8003]():
        return False
    
    pe_pe = one(pe_pe).EP_PKG[8000].PE_PE[8001]()
    if not pe_pe:
        return True
    
    return is_global(pe_pe)","API. def is_contained(self): """""""""""" # Check if pe_name is available if self.is_contained: return False return True",OMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROMPROM,15.40719974,17.17141589
generate: Adds this SubParser to the subparsers created by    argparse.ArgumentParser.add_subparsers method.,"def add_to_parser(self, subparsers):
        """"""
        
        """"""
        parser = subparsers.add_parser(*self._get_args(), **self._get_kwargs())
        parser.set_defaults(**self.get_defaults())
        for name, group in self.base_argument_groups:
            group.add_to_parser(parser)
        for name, arg in self.base_arguments:
            arg.add_to_parser(parser)
        self.add_subparsers(parser)","def add_subparsers(self, subparsers, **kwargs): """""" """""" self._subparsers = subparsers self._subparsers = subparsers self.subparsers = subparsers self._subparsers = subparsers self._subparsers = subparsers self.subparsers = subparsers self.subparsers = subparsers self._subparsers = subparsers self.subparsers = subparsers","def add_subparser(self, subparser, subparser): """""" """""" self.add_subparser(subparser) self.add_subparser(subparser, subparser) self.add_subparser(subparser) self.add_subparser(subparser) self.add_subparser(subparser) self.add_subparser(subparser) self.add_subparser(subparser)",43.38181941,46.09517218
generate: Return the true anomaly at each time,"def get_true_anomaly(self):
		""""""
		
		""""""
		self.f = _rsky._getf(self.t_supersample, self.t0, self.per, self.a,
							  self.inc*pi/180., self.ecc, self.w*pi/180.,
							  self.transittype, self.nthreads)
		return self.f","stamp. def get_timestamp(self): """""""""""" if self.timestamp is None: return self.timestamp if self.timestamp is None: return self.timestamp return self.timestamp","series. def _get_true_at_time_series(self): """""" """""" self.settings() if self.true_series: self.settings() self.settings() self.settings() self.settings() self.settings() self.settings() self.settings() self.settings() self.settings()",31.69805983,37.38879291
generate: Check if table exists,"def table_exists(self, table_name, db='default'):
        """"""
        
        """"""
        try:
            self.get_table(table_name, db)
            return True
        except Exception:
            return False",". def table_exists(self, table_name): """""""""""" if table_name not in self.tables: return False return False","def is_table_exists(self, table): """""""""""" if self._table_exists: self._table_exists(table) self._table_exists(table)",55.11950588,39.37128864
generate: Fetches a mongo collection object for querying.,"def get_collection(self, mongo_collection, mongo_db=None):
        """"""
        
        """"""
        mongo_db = mongo_db if mongo_db is not None else self.connection.schema
        mongo_conn = self.get_conn()

        return mongo_conn.get_database(mongo_db).get_collection(mongo_collection)","def get_mongo_collection_obj(self, query_name, filter_name, filter_name, filter_name=None): """""" """""" query = self._query_query(query_name, filter_name, filter_name, filter_name) return query.query(query.get_mongo_collection_obj(query.query_name, filter_name))","def fetch_mongo_collection(self): """""" """""" if not self.mongo_collection: raise TechoneFormatError(""Techone found: %s"" % self.mongo_collection) self.mongo_collection = self.mongo_collection return self.mongo_collection",33.49748184,53.50247173
"generate: Update the ``Expression`` by joining the specified additional    ``elements`` using an ""AND"" ``Operator``","def op_and(self, *elements):
        """"""
        """"""
        expression = self.add_operator(Operator(';'))
        for element in elements:
            expression.add_element(element)
        return expression",". def update_asset(self, elements, expression, depth=1, **kwargs): """""" """""" self.asset_asset(elements, expression, depth, **kwargs)",". def update_elements(self, elements): """""" """""" elements = self.elements[""elements""] if elements: elements.update(elements) return elements",41.6303165,49.09426151
generate: Gets the maximum length of each column in the field table,"def getFieldsColumnLengths(self):
        """"""
        
        """"""
        nameLen = 0
        descLen = 0
        for f in self.fields:
            nameLen = max(nameLen, len(f['title']))
            descLen = max(descLen, len(f['description']))
        return (nameLen, descLen)","def field_length(self, columns): """""" """""" columns = [columns] * len(columns) # First only filter fields if not isinstance(columns, (list, tuple)): columns = [columns] return columns",". def get_maximum_length(self): """""" """""" if self._max_length is None: self._max_length = len(self._max_length) self._max_length = len(self._max_length) return self._max_length",27.84051574,29.90362627
"generate: Return a metric, optionally configured with labels.","def get_metric(
            self, name: str,
            labels: Union[Dict[str, str], None] = None) -> Metric:
        """"""""""""
        metric = self._metrics[name]
        if labels:
            return metric.labels(**labels)

        return metric","def get_metric(self, labels, **kwargs): """""" """""" metric = self.get_metric_for_label(labels) if self.labels: metric = metric.get_metric(labels) return metric","def _get_metric(self, msg, labels): """""" """""" metric = self._get_metric(msg, labels) labels = metric.get_metric(msg, labels) labels = metric.get_labels(labels) return metric.get_metric(labels)",56.51435754,52.00377408
generate: Return True if the Var holds a value which should be compiled to a dynamic  Var access.,"def _is_dynamic(v: Var) -> bool:
    """"""""""""
    return (
        Maybe(v.meta)
        .map(lambda m: m.get(SYM_DYNAMIC_META_KEY, None))  # type: ignore
        .or_else_get(False)
    )","def __get_value(self, value): """""""""""" if value: return value if not self.__get_value_expr(value): return False return True","def is_access(self): """""" """""" if self._access_token is None: return False if self._access_token is None: return False else: return True",23.13480226,21.94128966
"generate: Code snippet from Python Cookbook, 2nd Edition by David Ascher,  Alex Martelli and Anna Ravenscroft; O'Reilly 2005","def windows(iterable, length=2, overlap=0, padding=True):
    """""" 

    """"""

    it = iter(iterable)
    results = list(itertools.islice(it, length))
    while len(results) == length:
        yield results
        results = results[length-overlap:]
        results.extend(itertools.islice(it, length-overlap))
    if padding and results:
        results.extend(itertools.repeat(None, length-len(results)))
        yield results","6 versions. def code_snippet(self, cookbook, anna_available=True): """""" """""" sna_available = self.dns.get('sna_available') if not anna_available: return try: return Verifier(sna_available=sna_available) except Verifier: return","def _cookbook_to_python_to_datetime(self, end_time, verbose=True): """""" """""" day_to_day = day_to_datetime_to_day(end_time) if end_time > 0: return day if end_time > 0: return day_to_datetime(day_to_datetime(day_to_datetime(end_time))) else: return day_to_datetime(end_time, verbose=verbose)",13.67218366,15.31394843
generate: The AST comments.,"def comments(self):
    """"""""""""
    if self._comments is None:
      self._comments = [c for c in self.grammar.children if c.is_type(TokenType.comment)]
    return self._comments","def get_ast_comments(self): """""""""""" if not self.comments: self.comments = [] self.ast_comments = [] self.ast_comments = [] return self.ast_comments","def _get_ast_comments_from_comments(self, ast_comments): """""" """""" for comment in self._comments: if comment.is_ast_comment(comment): return comment return None",58.7301222,54.47855271
"generate: Given a file URL, return a md5 query of the file","def path_set_md5(url):
    """"""
    """"""
    scheme, netloc, path, query_string, fragment = urlsplit(url)
    path += '.md5'

    return urlunsplit((scheme, netloc, path, query_string, fragment))","URL, return the file URL. def query(url, file_query=None, **kwargs): """""" """""" query = urllib.parse.urllib.query(url) return query.get(url, **kwargs)",". def md5(filename, query): """""" """""" if not os.path.exists(filename): md5 = md5_string(filename, query) else: md5 = md5_string(filename, query) return md5",30.22041538,35.45104871
generate: Creates a Heroku app-setup build.,"def create(self, tarball_url, env=None, app_name=None):
        """"""
        """"""
        data = self._api.create_build(
            tarball_url=tarball_url,
            env=env,
            app_name=app_name,
        )

        return (data['id'], data['app']['name'])","def create_build(self, user=None): """""" """""" build = self.build_build_build(user=user) if build: # If any of the Heroku are set, then create the heroku build.set_build(build) return self.build_build(user=user)","def create_build(self, package_name, package_name): """""" """""" url = self._build_url(package_name) if url.startswith('http://'): url = self._get_url('build') else: url = package_name return self._create_build_url(url, package_name, package_name, package_name)",32.00892306,34.12369961
generate: Find the best match for the configuration file.,"def configuration_file(cfgfile):
    '''
    '''
    if cfgfile is not None:
        return cfgfile
    # If no file is explicitely specified, probe for the configuration file
    # location.
    cfg = './etc/pyca.conf'
    if not os.path.isfile(cfg):
        return '/etc/pyca.conf'
    return cfg","def get_batch_for_batch_file(self, file_name, default=False): """""""""""" if self._batch_file: file_name = self.find_batch_file(file_name) if file_name == self._batch_file_name: return file_name elif os.path.exists(file_name): return file_name else: raise IOError(""Cannot find the best match file. "" + ""Must be a string or a directory."")","def _find_file(self, filename, config_file): """""" """""" if not self.config.get('boto_file'): raise ValueError('Any of the file %s' % filename) if not self.config.get('boto_file'): raise ValueError('Cannot find abstract file') return self.config.get('boto_file', None)",25.85068616,34.58797132
generate: Add external stages from the Python module in `path`.,"def load_external_stages(self, path):
        '''
        '''
        mod = imp.load_source('', path)
        self.update(mod.Stages)","def add_stages(self, path, external=False): """""""""""" if external: external = external.stages if external: path = path.split(self.path)[0] return self.path","def add_external_stages(self, path, module_path): """""" """""" self.set_external_stages(module_path, module_path, module_path)",30.25429482,44.63117991
generate: Recursively removes nested brackets,"def remove_inner_forks(text):
    """"""

    """"""

    n = 1  # run at least once for one level of fork
    # Then this loop assures that all brackets will get removed in a nested
    # structure
    while n:
        # this removes non-nested brackets
        text, n = re.subn(r'\([^()]*\)', '', text)

    return text","from the given `NESTART_ARTS` def recursively(self, nested_brackets): """""" """""" if nested_brackets is None: nested_brackets = self.brackets nested_brackets = self.brackets if nested_brackets is None: nested_brackets = self.nested_brackets return nested_brackets","from the pipeline. def remove_brackets(self, brackets): """""" """""" nested = [] for bracket in self.brackets: if bracket.brackets.get(bracket): brackets.append(bracket) self.brackets.remove_brackets(nested)",28.35341221,27.61816569
generate: Translate a string or list of strings.,"def translate(
        self, values, target_language, format_=None, source_language=None, model=None
    ):
        """"""
        """"""
        client = self.get_conn()

        return client.translate(
            values=values,
            target_language=target_language,
            format_=format_,
            source_language=source_language,
            model=model,
        )","def _translate_to_string(self, text, remove_remove=True): """""""""""" if text.startswith('_'): return '%s' % self._translate_to_string(text) if remove_remove: return '%s' % self._translate_to_string(text) return '%s' % self._translate_to_string(text)","def split(self, string): """""" """""" if string == '': return self._format(string) elif string in self.supported_string: return self._format(string, string) elif string == '': return self._format(string) else: raise InvalidSyntaxError(string)",24.016883,23.617355
generate: the last block proposal node voted on,"def last_voted_blockproposal(self):
        """"
        for r in self.rounds:
            if isinstance(self.rounds[r].proposal, BlockProposal):
                assert isinstance(self.rounds[r].lock, Vote)
                if self.rounds[r].proposal.blockhash == self.rounds[r].lock.blockhash:
                    return self.rounds[r].proposal","the page or an event. def _last_block_proposal(self, node, node, node_id): """""""""""" node = node_id if node.properties is not None: node = node.properties if node.properties is not None: node = node.properties if node.properties is not None: node = node.properties if node.properties is not None: node.properties = properties if node.properties is not None: node.properties = properties return node","the device. def last_device_voted_list(self): """""""""""" # NOTE: This will apply # TODO: Get the additional blocks if self._in_device_voted_list: self._in_device_voted_list(self._in_device_voted_list, self._in_device_voted_list) return self._in_device_voted_list",17.67005789,28.44799808
generate: Retrieves connection to Cloud Speech.,"def get_conn(self):
        """"""
        
        """"""
        if not self._client:
            self._client = SpeechClient(credentials=self._get_credentials())
        return self._client","def cloud_connection(self): """""" """""" connection = self.connection if self.host: connection = self.host connection = self.connection if connection: connection = self.connection return connection","def get_connection(self, application_id): """""""""""" return self.get_connection(api_url=api_url, key=api_url, sort_keys=self.sort_keys)",29.64656907,38.19989404
"generate: Generator over all subclasses of a given class, in depth-first order.","def iter_subclasses(cls, _seen=None):
	""""""
	
	""""""

	if not isinstance(cls, type):
		raise TypeError(
			'iter_subclasses must be called with '
			'new-style classes, not %.100r' % cls
		)
	if _seen is None:
		_seen = set()
	try:
		subs = cls.__subclasses__()
	except TypeError:  # fails only when cls is type
		subs = cls.__subclasses__(cls)
	for sub in subs:
		if sub in _seen:
			continue
		_seen.add(sub)
		yield sub
		for sub in iter_subclasses(sub, _seen):
			yield sub","def get_subclasses(self, class_name, **kwargs): """""""""""" if not isinstance(class_name, list): raise TypeError('class_name must be a list of list of list of list of class names') class_name = list(class_name) if not isinstance(class_name, list): raise TypeError('class_name must be a list of list of list of list of list of list of lists') class_name = list(class_name) if not isinstance(class_name, list): raise TypeError('class_name must be a list of list of list of list of list of list of lists') subclasses = [class_name, subclasses] if subclasses: subclasses.append(subclasses) return subclasses","def get_subclasses(self, subclasses=None, subclasses=None, default=None, depth=1000000000, restrict=True, scope=None, scope=None): """""" """""" if subclasses: subclasses = subclasses else: subclasses = self._get_subclasses() if default is None: default = subclasses if scope is None: scope = subclasses if default is None: default = default return self.get_subclasses(subclasses, subclasses, depth, scope, scope=deault)",32.06102774,38.31034972
generate: Returns a dictionary containing the full config names as keys and the config parameters    or the config parameter data items as values.,"def f_get_config(self, fast_access=False, copy=True):
        """"""

        """"""
        return self._return_item_dictionary(self._config, fast_access, copy)","def get_full_config(self, full_config, **kwargs): """""" """""" full_config = self.full_config(full_config) return full_config, full_config","def get_config_dict(self): """""" """""" keys = {} keys = {} for key, value in self.items(): keys[key] = value return keys",40.76803326,36.13518911
generate: Creates a map of letter use in a word.,"def _letter_map(word):
    """"""
    """"""

    lmap = {}
    for letter in word:
        try:
            lmap[letter] += 1
        except KeyError:
            lmap[letter] = 1
    return lmap","def map_letter_user(self, letter): """""""""""" if letter is None: return ""{}"".format(letter) return ""{}"".format(letter)","def _create_map(self, map, letter_id, use_details): """""" """""" self.page_map = map.page_map(map, letter_id) self.word_map = map.get(self.word_map) return map",36.12241527,34.01485872
generate: Designed to be passed as the default kwarg in simplejson.dumps. Serializes dates and datetimes to ISO strings.,"def simplejson_datetime_serializer(obj):
    """"""
    
    """"""
    if hasattr(obj, 'isoformat'):
        return obj.isoformat()
    else:
        raise TypeError('Object of type %s with value of %s is not JSON serializable' % (type(obj), repr(obj)))","def design_design(self, date, auto_unicode=False): """""" """""" if not isinstance(auto_unicode, ISO): raise TypeError(""Auto_unicode={} does not exist"".format(auto_unicode)) date = self.tz_datetime_date(date, date) date = self.tz_datetime_datetime_date(date) if date: return date else: return date","def default_datetime(datetime, datetime): """""" """""" if not datetime: return None try: datetime = datetime.replace(""%Y%m%d%H%M%S"") except TimeoutError as e: raise ValueError(""Unable to default "" + str(e)) if datetime: datetime = datetime + datetime return datetime",29.39293193,27.14235289
generate: Create a certificate request.,"def createCertRequest(pkey, digest=""sha256"", **name):
    """"""
    
    """"""
    req = crypto.X509Req()
    subj = req.get_subject()

    for key, value in name.items():
        setattr(subj, key, value)

    req.set_pubkey(pkey)
    req.sign(pkey, digest)
    return req","def create_request(self, request): """""""""""" request = self.request(request) # Delete the request. request = self.request(request) # Return the requested certificate request = self.request(request) # TODO: We can never be an initialized return self.request(request)","def create_certificate_request(self, request, data): """""""""""" if self.certificate_session.is_certificate(): return self.certificate_request(self.certificate_request) else: return self.certificate_request(request)",25.09585245,25.59970336
generate: Create event start and end datetimes.,"def create_event_datetimes(options, config):
    """"""
    
    """"""

    now = datetime.datetime.now()

    return {
        ""start"": {
            ""dateTime"": (now + datetime.timedelta(minutes=int(config[""start""]))).strftime(DT_FORMAT),
            ""timeZone"": options.timezone,
        },
        ""end"": {
            ""dateTime"": (now + datetime.timedelta(minutes=int(config[""end""]))).strftime(DT_FORMAT),
            ""timeZone"": options.timezone,
        },
    }","def create_event(self, start_date, date, callback, date_fmt=False, callback=None, date_fmt=None): """""" """""" if callback is None: callback = self._create_event_event_event_event(start_date, date_fmt=date_fmt) if not callback: self.create_event_event(start_date, date_fmt=date_fmt) return end_date","def create(self, event_id, datetime=None): """""" """""" if datetime is None: datetime = datetime.utcnow() if datetime is None: datetime = datetime.utcnow() return self.create(self.domain, event_id, datetime, datetime, datetime, datetime, datetime, datetime, datetime)",24.88767,32.72393244
generate: Implementation of the LOAD_NAME operation,"def load_name(self, name):
        """"""
        
        """"""
        if name in self.globals_:
            return self.globals_[name]
        
        b = self.globals_['__builtins__']
        if isinstance(b, dict):
            return b[name]
        else:
            return getattr(b, name)",". def normalize(self, link): """""" """""" if link == self.normalize: return # Set up all the first line self.normalize = link self.normalize = self.normalize if self.normalize: self.normalize = self.normalize return self","s. def _get_language_to_db(self, db): """""" """""" if db.is_related_type(): return self._get_language_to_db(db.get_db()) else: return self._get_language(db.get_language_to_db_to_db(db.get_language_to_db()))",32.91953147,33.8206173
generate: Run one training iteration.,"def _run_train(self, epoch, train_set, train_size=None):
        """"""
        
        """"""
        self.network.train_logger.record_epoch(epoch + 1)
        costs = self.train_step(train_set, train_size)
        if not epoch % self.config.monitor_frequency:
            self.report(dict(costs), ""train"", epoch)
        self.last_run_costs = costs
        return costs","def run_training(self, row, training=False): """""" """""" training = self.training if training: return self.training else: row = self.row if training: return self.training else: row = self.row return row","def _run(self, training_list, training_list, related_training): """""""""""" self._training_list.put(training_list) if not training_list: self._training_list.put(training_list) self._training_list.put(training_list) self._training_list.put(training_list) self._training_list.put(training_list)",32.84030746,35.94670957
generate: Update a Label,"def update(self, label):
        """"""
        
        """"""
        data = {
            'id': label['id'],
            'name': label['name'],
            'appearance': label['appearance'],
            'description': label['description'],
            'title': label['title'],
        }
        return self._post(
            request=ApiActions.UPDATE.value,
            uri=ApiUri.TAGS.value,
            params=data
        )","s of the Main Labels. def update_lain(self, lain, lain): """""" """""" # Default the Labels of the Labels of the Labels of the Labels. lain.update(lain) lain.update(lain) lain.update(lain) lain.update(lain) lain.update(lain)",". def update(self, key, value): """""" """""" if value is None: value = None if not value: if not isinstance(value, Label): value = self.get(key, value) else: value = value if not isinstance(value, str): value = self.get(value, value) if isinstance(value, basestring): value = self.get(value, value) else: value = self.get(value, value) return value",21.36523968,23.37469955
generate: Find absolute path to executable cmd in a cross platform manner.,"def find_cmd(cmd):
    """"""
    """"""
    if cmd == 'python':
        return os.path.abspath(sys.executable)
    try:
        path = _find_cmd(cmd).rstrip()
    except OSError:
        raise FindCmdError('command could not be found: %s' % cmd)
    # which returns empty if not found
    if path == '':
        raise FindCmdError('command could not be found: %s' % cmd)
    return os.path.abspath(path)","def get_cmd_cmd(cmd): """""""""""" if not os.path.exists(cmd): return os.path.abspath(cmd) if os.path.exists(cmd): return os.path.abspath(cmd) return os.path.abspath(cmd)","def _get_absolute_path(self): """""" """""" if self.is_absolute_path(): raise ValueError(""Absolute path is absolute path"") if not os.path.isdir(self.is_absolute_path): raise ValueError(""Absolute path is not absolute path"") return self._get_absolute_path(self.is_absolute_path)",24.15084834,29.74876582
generate: Match a parser one or more times separated by another parser.,"def rep1sep(parser: Union[Parser, Sequence[Input]], separator: Union[Parser, Sequence[Input]]) \
        -> RepeatedOnceSeparatedParser:
    """"""
    """"""
    if isinstance(parser, str):
        parser = lit(parser)
    if isinstance(separator, str):
        separator = lit(separator)
    return RepeatedOnceSeparatedParser(parser, separator)","def parse_times(self, separated): """""" """""" if not isinstance(separated, list): return [] date_separated = False if not self.is_time_separated: return [] date_separated = True for parser in self.parsers: if not date_separated: date_separated = True date_separated = True return date_separated","def get_separated_time(self, parser_info): """""" """""" if not self._is_parser(): return None parser_time = self._get_params_for_params(parser_info) if not parser_time: return None else: parser_time = parser_time if not parser_time: parser_time = parser_time else: return None return None",42.38195087,35.12684256
generate: Return a list all Python packages found within directory 'where',"def find(cls, where='.', exclude=(), include=('*',)):
        """"""
        """"""
        out = cls._find_packages_iter(convert_path(where))
        out = cls.require_parents(out)
        includes = cls._build_filter(*include)
        excludes = cls._build_filter('ez_setup', '*__pycache__', *exclude)
        out = filter(includes, out)
        out = filterfalse(excludes, out)
        return list(out)","templates. def get_packages_files(dirname, directory, scope=False, scope=False, template_name='.py'): """""" """""" packages = list(dirname) for directory in directory: packages.append(dirname) return packages","in the commit. def get_packages(self, package): """""" """""" url = '/packages' if package.name not in self._project_request.packages: raise ValueError(""Package cannot get packages: {}"".format(package)) packages = self._project_request.packages[package] url = self._project_request.get(url, None) return self._project_request.get(url, None)",18.12974283,20.14637347
"generate: Run my loop, ignoring EINTR events in the poller","def _run_loop(self):
        """"""""""""
        while True:
            try:
                self.ioloop.start()
            except ZMQError as e:
                if e.errno == errno.EINTR:
                    continue
                else:
                    raise
            except Exception:
                if self._exiting:
                    break
                else:
                    raise
            else:
                break",". def _run_loop(self): """""" """""" loop = self.loop loop = self.loop while loop: loop.clear() loop.clear() loop.clear() loop.clear() loop.clear() loop.clear() loop.clear()",". def poll_event_loop(self, event): """""" """""" if event.session.is_not_event(event): raise TypeError(""Event must be a list of event loop."") else: if event.session.is_not_event(event): raise TypeError(""Event must be an instance of event loop."") else: raise TypeError(""Event must be an event."") if event.session.is_not_event(event): return self._poll_event(event) else: raise TypeError(""Event must be an event."")",26.41820585,21.69971656
generate: Passwords should be tough.,"def validate_password_strength(value):
    """"""
    
    """"""
    used_chars = set(value)
    good_chars = set(ascii_letters + digits + punctuation + ' ')
    required_sets = (ascii_uppercase, ascii_lowercase, digits)

    if not used_chars.issubset(good_chars):
        raise ValidationError(too_fancy)

    for required in required_sets:
        if not used_chars.intersection(required):
            raise ValidationError(too_simple)","def _passwords(self, **kwargs): """""""""""" if self._passwords: try: self._passwords[self._passwords] = await self._passwords except KeyboardInterrupt: return False if self._passwords: if self._passwords: self._passwords = passwords else: self._passwords = passwords return True self._passwords = [] if self._passwords: self._passwords.append(self._passwords) if self._passwords: self._passwords.append(self._passwords) else: return False","def _print_to_such(self, release, args): """""" """""" url = self._url_url(release, args) release = args.get('release', None) if release is None: return if not isinstance(release, dict): self._success(url, self._client.print_response(release)) else: self._success(url, args, **kwargs)",16.51922618,21.07967981
generate: Assigns a parameter value to matching instructions in-place.,"def _bind_parameter(self, parameter, value):
        """"""""""""
        for (instr, param_index) in self._parameter_table[parameter]:
            instr.params[param_index] = value","def parameter_value(self, **kwargs): """""" """""" self.parameters.update(kwargs) if self.parameters.get(""PORT_FORTS""): self.parameters.update(kwargs) return self","def assign(self, *args): """""" """""" if self.is_valid(): return self.parse_parameter_parameters(args) else: return self.parse_parameters(args)",41.25228701,39.84781168
generate: Convolve 2d gaussian.,"def convolve_gaussian_2d(image, gaussian_kernel_1d):
    """"""""""""
    result = scipy.ndimage.filters.correlate1d(
        image, gaussian_kernel_1d, axis=0)
    result = scipy.ndimage.filters.correlate1d(
        result, gaussian_kernel_1d, axis=1)
    return result","def convolve2d_gaussian_convolve(self, avg_convolve): """""""""""" # Get version of version of version of version. version = self.version if version < 4: version = version else: version = self.version return self.version","def _convolve_suffix_by_path(self, filename, replace=False): """""" """""" if replace: suffix = '/suffix' self._file_name = suffix if not self._file_name: self._file_name = filename if not self._file_name: self._file_name = filename if not self._file_name: self._file_name = filename self._file_name = suffix return self._file_name",25.36965821,14.95695749
generate: Adds secondary inputs to the start of the pipeline.,"def set_secondary_inputs(self, channel_dict):
        """""" 
        """"""

        logger.debug(""Setting secondary inputs: {}"".format(channel_dict))

        secondary_input_str = ""\n"".join(list(channel_dict.values()))
        self._context = {**self._context,
                         **{""secondary_inputs"": secondary_input_str}}","def add_secondary_input(self, secondary, start, end): """""""""""" start = self.secondary_input start = self.secondary_input start = self.secondary_input start = self.secondary_input end = self.end if start <= 0: start = self.start if start <= start: end = self.end end = self.end if end <= start: end = self.end self.end = end self.start = start","def add_secondary_state(self, start_time=0, end_time=None): """""" """""" if self._is_alive_time(): self._logger.debug(""Setting secondary start_time"") self._set_secondary_state(start_time) self._set_secondary_state(end_time) else: self._set_secondary_state(end_time) self._set_secondary_state(end_time)",33.22822423,42.28060418
generate: Show string or char.,"def outputFormatter(s):
    """"""
    """"""
    result = ''
    def formatSubString(s):
        for c in s:
            if c==32: yield ' '
            else: yield outputCharFormatter(c)
    if len(result)<200: return ''.join(formatSubString(s))
    else:
        return ''.join(formatSubString(s[:100]))+'...'+ \
               ''.join(formatSubString(s[-100:]))","def __hash_hash(self, text, text): """""" """""" if not text.startswith(""^""): return ""&"".join(self.__class__.__name__) elif not text.endswith(""&""): return ""&"".join(self.__class__.__name__) elif not text.startswith(""|""): return ""&"".join(self.__class__.__name__) else: return ""&"".join(self.__class__.__name__)","def show_char(self, char): """""" """""" if self.char is None: return None if char.is_string(): return self._callback(char) elif char.is_string(): return self._callback(char) else: return self._callback(char)",24.05406228,23.11793285
generate: Check the syntax of the given URL.,"def url_syntax_check(url):  # pragma: no cover
    """"""
    
    """"""

    if url and isinstance(url, str):
        # The given URL is not empty nor None.
        # and
        # * The given URL is a string.

        # We silently load the configuration.
        load_config(True)

        return Check(url).is_url_valid()

    # We return None, there is nothing to check.
    return None","def check_syntax(self, path, url=None): """""""""""" # If the path is not found, the url is a valid. if path.startswith("".""): return url.rstrip('/') elif path.startswith("".""): return url.rstrip('/') elif path.startswith("".""): return url.rstrip('/') else: raise ValueError('Unknown path.')","def check_syntax(self, URL): """""""""""" url = self.url + ""/syntax/syntax/syntax/syntax"" if self.exists: if self.is_response(): return self.response(url) return self.response(url, self.is_response()) else: return self.response(url, self.response())",30.49627562,25.24004035
"generate: this converts the readin lines from    sys to useable format, returns list    of token and dict of tokens","def convertArgsToTokens(self, data):
        """"""
        
        """"""

        tdict = []
        tokens = []

        d = open(data, 'r')
        for line in d.readlines():
            tdict.append(line.rstrip())
            tokens += line.split()

        d.close()
        tokens = list(set(tokens))

        return tdict, tokens",". def _split_lines_token(self, read_lines, lines): """""" """""" lines = [] for line in read_lines: if line.strip() == ""\n"": lines.append(line) elif line.startswith(""\n""): lines.append(line) return lines",". def format_token(self, read_lines): """""" """""" self.lines = [] for line in read_lines: self.format_tokens.append(line) return self.format_tokens(read_lines)",40.85695077,34.84314782
generate: Method to delete an item or all items,"def delete(self, endpoint, headers):
        """"""
        
        """"""
        response = self.get_response(method='DELETE', endpoint=endpoint, headers=headers)

        logger.debug(""delete, response: %s"", response)
        if response.status_code != 204:  # pragma: no cover - should not happen ...
            resp = self.decode(response=response)

        resp = {""_status"": ""OK""}
        return resp",". def delete_item_or_delete(self, item): """""""""""" item = item.delete_item() if not item: return if not item.id not in self._delete_item_or_delete: self._delete_item_or_delete[item] = item self._delete_item_or_delete[item] = item self._delete_item_or_delete[item] = item self._delete_item_or_delete[item] = item else: self._delete_item_or_delete[item] = item",". def delete_all_item_ids(self, item): """""" """""" if not item: return if item not in self.items: raise DataAttributeError(""Could not delete all items."") self.items[item] = item self.items[item] = item return self",21.52106403,20.65593335
generate: Returns the asset information associated with a specific asset ID.,"def get_asset_state(self, asset_id, **kwargs):
        """""" 

        """"""
        return self._call(JSONRPCMethods.GET_ASSET_STATE.value, params=[asset_id, ], **kwargs)","def asset_id(self, asset_id, id_id, id_id_id, asset_id=None, id_id=None, id_id=None, id_id_id=None): """""" """""" return self._get_asset_id(asset_id, id_id, id_id, id_id, id_id_id)","def asset_asset(self, asset_id): """""" """""" if asset_id == self.AS_CURATION_ID_PORT_TYPE: return self.response.json() else: return asset_id",36.32157794,42.50303882
generate: Get a random mutator from a list of mutators,"def _get_random(self, obj_type):
        """"""
        
        """"""
        return self.mutator[obj_type][random.randint(0, self.config.level)]",". def random_mutators(self, mutators): """""""""""" if mutators: mutators = [mutators] return self.random_mutators",". def get_random_mutators(self): """""" """""" if self.random_mutators: return self.random_mutators return self.random_mutators",41.24816031,46.71947416
generate: Change working directory and restore the previous on exit,"def working_directory(path):
    """"""""""""
    prev_dir = os.getcwd()
    os.chdir(str(path))
    try:
        yield
    finally:
        os.chdir(prev_dir)","s. def restore_directory(self): """""" """""" self.working_directory = self.working_directory self.working_directory = self.working_directory","ing. def _post_dir_dir_dir_dir(self, directory): """""" """""" if not os.path.isdir(directory): os.makedirs(directory) if os.path.exists(directory): os.makedirs(dir_dir_dir) return os.path.dirname(directory)",31.20594402,25.01806439
generate: Creates a hashable object for given token then we could use it as a  dictionary key.,"def _hash_token(application, token):
    """"""
    """"""
    if isinstance(token, dict):
        hashed_token = tuple(sorted(token.items()))
    elif isinstance(token, tuple):
        hashed_token = token
    else:
        raise TypeError('%r is unknown type of token' % token)

    return (application.__class__.__name__, application.name, hashed_token)","def create_hashable(self, key, **kwargs): """""" """""" if isinstance(key, dict): key = key.lower() key = key.lower() if key in self.hashables: return hashable(key, **kwargs) else: return hashable(key) else: return hashable(key, **kwargs)","def given_token_token_token(self, token, item_name): """""" """""" if not token.is_auth(): return None if not token.is_author: return if token.is_author: return if self.is_author: return token else: return token",29.09607078,31.33848998
generate: Generates python code calling the function and returning True.,"def visit_CallTrue(self, node: parsing.CallTrue) -> ast.expr:
        """"""
        """"""
        return ast.Lambda(
            ast.arguments([], None, None, [], None, None, [], []),
            ast.BoolOp(
                ast.Or(),
                [
                    self.visit_Call(node),
                    ast.Name('True', ast.Load())]))","def _get_code_calling_code(self, code, func, func, func_class=None): """""" """""" if func_class is None: func_class = code return _code_code(code, func_class)","def get_platform_destination(self): """""" """""" if self.error_name: raise AttributeError( 'Code must be a valid python version.' ) self.error_name = self.error_name return self.error_name",19.47169578,19.72047682
generate: Search for dominos pizza stores using a search term.,"def get_stores(self, search_term):
        '''
        
        '''
        params = {'SearchText': search_term}
        response = self.__get('/storefindermap/storesearch', params=params)

        return Stores(response.json())","def search_search_term(search_term, search_term): """""" """""" search_term = search_term.lower() search_term = search_term.lower() if search_term.lower() == '_term': return True return True","def search(self, pizza): """""" """""" if self.get_search_term() == '': search_term = self.get_search_term() else: search_term = self.get_search_term() return search_term",34.21407078,40.14658253
generate: Check whether a year is a leap year.,"def dt_is_leap_year(x):
    """"""
    """"""
    import pandas as pd
    return pd.Series(x).dt.is_leap_year.values","def check_leap_year(year): """""""""""" if year is None: year = year return Year","def is_leap_leap_leap(leap): """""" """""" if not isinstance(leap, leap) and not isinstance(leap, leap): leap = leap.leap return (leap[0], leap[1], leap[1], leap[1])",33.45042273,23.78433051
generate: Returns the instance owning the supplied instancemethod or  the class owning the supplied classmethod.,"def get_method_owner(meth):
    """"""
    
    """"""
    if inspect.ismethod(meth):
        if sys.version_info < (3,0):
            return meth.im_class if meth.im_self is None else meth.im_self
        else:
            return meth.__self__","def instancemethod(self, *args): """""""""""" if self.required_class_type == 'classifier': return instancemethod elif self.required_class_type == 'commit': return instancemethod else: return instancemethod","def get_instancemethod(self, instance_name): """""" """""" if instance_name in self._instances: return self._instances[instance_name] else: return None",38.27940845,37.02096204
generate: Print constants information in human readble format.,"def print_constants_info(self, output_file=sys.stdout):
        """"""""""""
        table = ('    name | value     \n' +
                 '---------+-----------\n')
        for name, value in list(self.constants.items()):
            table += '{!s:>8} | {:<10}\n'.format(name, value)
        print(prefix_indent('constants: ', table), file=output_file)","def print_constants(self, lineno, filename): """""""""""" constants = lineno.get_filename(filename) if self.constants is not None: print(constants) if self.executable: print(""{}{}"".format(constants, filename))","def print_constants(self, format, split=True): """""""""""" if not split: raise ValueError('format %s' % split) if not split: raise ValueError('format %s' % split) if not split: raise ValueError('format %s' % split) if not split: raise ValueError('format %s' % split) return self._make_constants(format, split)",36.16799167,26.40684765
generate: Delete all indexes for the database,"def drop_indexes(self):
        """"""""""""
        LOG.warning(""Dropping all indexe"")
        for collection_name in INDEXES:
            LOG.warning(""Dropping all indexes for collection name %s"", collection_name)
            self.db[collection_name].drop_indexes()","def delete(self): """""""""""" self.delete = [] for index, _ in enumerate(self._indexes): if not index.startswith("".""): self.delete.append(index) else: self.delete.append(index)",". def delete_indexes(self, indexes): """""""""""" indexes = [ self.db.delete_indexes(database) for database in self.db.delete_indexes(indexes) if database.get('index') and database.get('index') for database in indexes if database.get('index') == indexes ] return self.db.delete(indexes, indexes)",27.87812262,26.32439637
"generate: the list command corresponds with listing images for an external    resource. This is different from listing images that are local to the    database, which should be done with ""images""","def main(args,parser,subparser):
    '''
    '''
    from sregistry.main import get_client
    cli = get_client(quiet=args.quiet)
    
    for query in args.query:
        if query in ['','*']:
            query = None

        cli.ls(query=query)","just called on any other listing, only avoid on any corresponds. def get_images(self, images): """""" """""" images = [] for i in images: image = i.get_images(i) if image.get_images(): images.append(i) else: images.append(i) return images",". def get_image_images_for_image_images(self, database): """""" """""" # This is any of the database. if not isinstance(database, string_types): raise ValueError(""database is not a dictionary"") return self._get_image_image(database, database)",16.65275649,10.78208179
generate: Retrieve public information about a user.,"def user(self, id):
        """"""
        
        """"""
        json = self.skype.conn(""POST"", ""{0}/batch/profiles"".format(SkypeConnection.API_PROFILE),
                               auth=SkypeConnection.Auth.SkypeToken, json={""usernames"": [id]}).json()
        if json and ""status"" not in json[0]:
            return self.merge(SkypeUser.fromRaw(self.skype, json[0]))
        else:
            return None","def get_public_info(self, user_id): """""" """""" public_info = self.get_public_info(user_id) if public_info is None: return None if public_info is None: return None # Get information about users user_info = self.get_public_info(user_id) if user_info is None: return None if public_info is None: return None return user_info","def get_public_user_user(user_id): """""" """""" url = ""/users/%s"" % user_id response = requests.get(url, data=params, data=data, data=data, data=data, auth=auth_auth, headers=headers) if response.status_code == 200: return response.json() else: return None",29.00842407,29.23486249
generate: Load a pre-trained Torch model.,"def load_torch(path, bigdl_type=""float""):
        """"""
        
        """"""
        jmodel = callBigDlFunc(bigdl_type, ""loadTorch"", path)
        return Layer.of(jmodel)","def load_torch_model(self, torch_model, torch_model): """""""""""" self.torch_model = torch_model self.torch_model = torch_model","def __salt_model(self, mode='rb'): """""" """""" if not self.mode: raise ValueError(""Unknown mode: %s"" % mode) return self._refresh(mode=mode, axis=1)",31.10759588,24.0030115
generate: Create a new receiver link.,"def new_receiver(self, name):
        """"""""""""
        pn_link = self._pn_session.receiver(name)
        return self.request_receiver(pn_link)","def _receive(self, link): """""" """""" link = self._get_link(link) if link: if not link.is_link(): return False link = self._receive_link(link) return True","def create_receiver(self, receiver): """""" """""" self._receiver_link(receiver) self._receivers[receiver] = receiver self._receivers[receiver] = receiver self._receivers[receiver] = receiver",41.53161121,31.23553911
generate: Insert list of patches at the front of the curent patches list,"def insert_patches(self, patches):
        """"""  """"""
        patchlines = []
        for patch_name in patches:
            patchline = PatchLine(patch_name)
            patch = patchline.get_patch()
            if patch:
                self.patch2line[patch] = patchline
            patchlines.append(patchline)
        patchlines.extend(self.patchlines)
        self.patchlines = patchlines","def insert_patches(self, patches, patches): """""" """""" patches = [] for patch in patches: for patch in patches: if patch is not None: patch.append(patch) self.insert_patches(patches)",". def insert_patches(self, patches): """""" """""" self._patches = [] if self._front_list is None: self._front_list = [] for patches in self._patches: if patches.patches: if patches.patches == patches.patches: patches.append(patches) self._patches = [] self._patches.append(patches) self._patches.append(patches)",41.63340518,56.85420939
generate: Does `fpath` indicate a file in one of our trees?,"def match(self, fpath):
        """"""""""""
        for d in self.dirs:
            if fpath.startswith(d):
                if fpath == d:
                    # This is the same file!
                    return True
                if fpath[len(d)] == os.sep:
                    # This is a file in the directory
                    return True
        return False","def _fpath(self, fpath, extensions, fpath, fpath): """""""""""" if fpath is not None: return fpath if fpath == extensions: return os.path.join(fpath, fpath) elif fpath == fpath: return os.path.join(fpath, fpath)","def _fpath(self, fpath): """""" """""" if self._fpath == 'win': self._windir.close() if self._fpath is None: self._fpath = None else: self._fpath = fpath else: self._fpath = fpath self._fpath = fpath",42.76279329,32.11244782
generate: Translate cluster identity back to original data size.,"def map_clusters(self, size, sampled, clusters):
        """"""
        

        """"""
        ids = np.zeros(size, dtype=int)
        ids[:] = -2

        ids[sampled] = clusters

        return ids","def cluster(self, uri, signature, filters): """""" """""" if filters: if self.cluster_identity.is_null() and uri <= self.cache: return self.cache else: return self.cache else: return self.cache","def identity_to_size(size_, flux_size): """""" """""" cluster_size = len(size_) if flux_size >= len(size_): raise ValueError(""Unknown cluster: %s"" % flux_size) return identity_to_size(size_, flux_size)",29.34468764,27.00102986
generate: Yield nodes in topological order.,"def topological_nodes(self):
        """"""
        
        """"""
        return nx.lexicographical_topological_sort(self._multi_graph,
                                                   key=lambda x: str(x.qargs))","def filter_topological_order(topological_order, nodes, order_by, order_by, order_by): """""" """""" for node in nodes: node.remove(node) return node","def plane(self, topology_name): """""" """""" self.plane_tokens(topology_name) self.plane(topology_name) return self.plane(topology_name)",36.46858852,35.73055851
"generate: accept either IP address or dns name, and return IP","def disambiguate_dns_url(url, location):
    """"""""""""
    if not ip_pat.match(location):
        location = socket.gethostbyname(location)
    return disambiguate_url(url, location)","def accept_ip(self, request, **kwargs): """""""""""" if not self.ip_address: return if self.ip_address: return self.ip_address.ip_address(request, **kwargs) return self.address",". def get_ip_address(self, ip): """""" """""" if not ip.is_ip_address(): return None if not ip.is_ip_address(): return None else: return None",22.59250978,23.89537757
generate: Draw a line between pos1 and pos2 on the canvas.,"def draw_line(self, pos1, pos2, color=(255, 0, 0)):
        """"""
        """"""
        r1, c1 = tuple([int(round(i, 0)) for i in pos1])
        r2, c2 = tuple([int(round(i, 0)) for i in pos2])
        rr, cc = skimage.draw.line(r1, c1, r2, c2)
        self[rr, cc] = color","def draw_line(self, line): """""" """""" if not line: raise ValueError(""Input line but no line but only be an integer"") lines = self.lines.split(""\n"", 1)[1:] line = line.split(""\n"") if line.endswith(""\n""): return line.strip()","def draw(self, pos1, pos2, pos2, pos2, pos2): """""" """""" if pos2: pos2 = pos2 else: pos2 = pos2 if pos1 and pos2 >= 1: pos1 = pos2 if pos2 >= 0: pos2 = pos1 if pos2 <= 1: pos1 = pos2 elif pos2 >= 1: pos2 = pos1 else: pos2 = pos1 pos2 = pos2 if pos2 >= 2 and pos2 <= 2: pos2 = pos2 elif pos2 <= 2: pos2 = pos1 else: pos2 = pos2 pos2 = pos2 return pos2",26.24525589,18.49982319
"generate: r""\[","def t_LSQBR(self, t):
        ""
        t.endlexpos = t.lexpos + len(t.value)
        return t","] -> Set[str] -> Set[str]: """""" """""" if not isinstance(s, (tuple, list)): raise TypeError(""String represents a valid single arguments"") if not isinstance(s, (tuple, list)): raise TypeError(""String represents a valid single arguments"") if isinstance(s, list) or isinstance(s, six.string_types): return list(s) else: return list(s)","($\d+)]\d+|""): """""" """""" return rdf_dict.get(""$"", None) or None",5.160439082,18.82009269
"generate: This seeks through the stream until a pattern is matched. The    pattern is overloaded and may take several types. The pattern can be a    StringType, EOF, a compiled re, or a list of any of those types.    Strings will be compiled to re types. This returns the index into the    pattern list. If the pattern was not a list this returns index 0 on a    successful match. This may raise exceptions for EOF or TIMEOUT. To    avoid the EOF or TIMEOUT exceptions add EOF or TIMEOUT to the pattern    list. That will cause expect to match an EOF or TIMEOUT condition    instead of raising an exception.","def expect(self, pattern, timeout = -1, searchwindowsize=-1):

        """"""
        """"""

        compiled_pattern_list = self.compile_pattern_list(pattern)
        return self.expect_list(compiled_pattern_list, timeout, searchwindowsize)","The pattern is the StringType, e.g. If empty, a Match, address is matched. def _get_pattern_list(self, pattern): """""""""""" if pattern.pattern is None: return None return self.pattern.pattern","The pattern is implemented to the pattern. This is to used as the empty list. This is just a string type. def remove_pattern(self, pattern): """""" """""" if self.is_pattern(pattern): return self.pattern.remove(pattern) elif self.is_pattern(): return self.pattern.remove(pattern) else: return self.pattern.remove(pattern)",38.85193626,28.86262063
generate: Class decorator that makes sure the passed apps are present in  INSTALLED_APPS.,"def with_apps(*apps):
    """"""
    
    """"""
    apps_set = set(settings.INSTALLED_APPS)
    apps_set.update(apps)
    return override_settings(INSTALLED_APPS=list(apps_set))","def get_apps(func, *args, **kwargs): """""" """""" @wraps(func) def wrapped(*args, **kwargs): if args[0] == '_APPS': return func(*args, **kwargs) return wrapped","def _get_passed_apps(self, passed_apps): """""" """""" if passed_apps: passed_apps = self._get_passed_apps(passed_apps) else: passed_apps = passed_apps return passed_apps",27.33230623,30.15295783
"generate: unwrap exception, and remap engine_id to int.","def _unwrap_exception(self, content):
        """"""""""""
        e = error.unwrap_exception(content)
        # print e.traceback
        if e.engine_info:
            e_uuid = e.engine_info['engine_uuid']
            eid = self._engines[e_uuid]
            e.engine_info['engine_id'] = eid
        return e","def unwrap_event(self, event_id, values): """""""""""" event_id = self.event_ids.get(event_id) event_id = self.event_ids.get(event_id, []) if event_id == event_id: event_id = self.event_ids.get(event_id) if event_id == event_id: raise event_id return event_id, event_id, event_id","def unwrap_error(self, url): """""" """""" if not self.is_response_type(): raise ValueError('Unable to unwrap error.') self.error = url self.response_type = ""response_type"" return self.error_type.lower().unwrap(response_type=response_type)",27.47840906,27.29093235
generate: random play until both players pass,"def random_playout(self, board):
        """"""  """"""
        for x in range(MAXMOVES):  # XXX while not self.finished?
            if board.finished:
                break
            board.move(board.random_move())","in the player. def random_both(self, player, player, player): """""""""""" return self.both(player, player)","word is called from another player. def called_player(self, player_id): """""" """""" return self.client.create( 'Player WebPlayer.create_player_by_id', player_id, player_id, 'called_player_id', player_id, )",21.76320703,19.95870839
generate: Load the trusted certificates that will be sent to the client. Does    not actually imply any of the certificates are trusted; that must be    configured separately.,"def load_client_ca(self, cafile):
        """"""
        
        """"""
        ca_list = _lib.SSL_load_client_CA_file(
            _text_to_bytes_and_warn(""cafile"", cafile)
        )
        _openssl_assert(ca_list != _ffi.NULL)
        _lib.SSL_CTX_set_client_CA_list(self._context, ca_list)","def _load_trusted_certificates(self, certificates): """""" """""" # Filter the certificates, some certificates are passed to this local host # of the certificates, and built-enable the certificates. self.client = certificates","def add_certificates(self, certificate_certificates): """""" """""" certificates = [certificate_certificate(x) for x in self._certificates if x in certificates] return certificates",26.61044409,19.81236187
generate: Generates html from Vega lite data,"def _json_to_html(self, slug, json_data):
        """"""
        
        """"""
        html = '<div id=""chart-' + slug + '""></div>'
        html += '<script>'
        html += 'var s' + slug + ' = ' + json_data + ';'
        html += 'vega.embed(""#chart-' + slug + '"", s' + slug + ');'
        #html += 'console.log(JSON.stringify(s{id}, null, 2));'
        html += '</script>'
        return html","base. def _get_html(self, url, query, field_id, field_id=None, **kwargs): """""" """""" if field_id is None: field_id = field_id return self.get_html(url, query, field_id, **kwargs)",". def Generate(self, data, skip_response=True): """""" """""" try: return self.vega_type(data, skip_response) except JsonApiError as e: raise JsonApiError( ""Unable to plugin {}: {}"".format( data, e.response.get('error', ""Can't skip api when recognizing the given skip_response."" ""Making a valid plugin."", e.response.headers))",12.93646897,18.24006415
generate: returns a random tuple representing person information,"def person(languages=None, genders=None):
    """"""
    
    """"""
    languages = languages or ['en']
    genders = genders or (GENDER_FEMALE, GENDER_MALE)


    lang = random.choice(languages)
    g = random.choice(genders)
    t = title([lang], [g])
    return first_name([lang], [g]), last_name([lang]), t, g","def represent(self, person_id, link_id=None): """""" """""" if person_id is not None: person_id = person_id if link_id is not None: link_id = self.get_link_id(link_id) if link_id is not None: link_id = self.get_link_id(link_id) # Search for each link id if link_id is not None: link_id = self.get_link_id(link_id) return link_id",". def person_son_automation(self): """""" """""" if self.random_sync(self.random_sync): # Check formatted string string = self.random_sync(self.random_sync) if self.random_sync(string): return string return string elif self.random_sync(string): return string else: return string",19.17170004,21.73599407
generate: Add a workspace entry in user config file.,"def add(self, name, path):
        """"""""""""
        if not (os.path.exists(path)):
            raise ValueError(""Workspace path `%s` doesn't exists."" % path)

        if (self.exists(name)):
            raise ValueError(""Workspace `%s` already exists."" % name)

        self.config[""workspaces""][name] = {""path"": path, ""repositories"": {}}
        self.config.write()","def add_workspace(self, workspace, config): """""""""""" if not workspace: workspace = self.workspace_default self.workspace = workspace self.acquire() self.acquire()","def workspace_entry_file(self, filename, doc_file): """""" """""" if not self.walk_file: self.walk_file(filename, doc_file) if not os.path.isdir(filename): return self.walk_file(filename) if not self.walk_file_exists(): self.walk_file(filename)",21.63269806,29.69147561
generate: Configure which kinds of exceptions trigger plugin.,"def configure(self, options, conf):
        """"""
        """"""
        self.conf = conf
        self.enabled = options.debugErrors or options.debugFailures
        self.enabled_for_errors = options.debugErrors
        self.enabled_for_failures = options.debugFailures","def configure(self): """""" """""" # For backends if self.config.log_find(): self.log_find() if self.config.log_find(): self.log_find() self.log_find() return self","def _connect(self, client, info): """""" """""" if self.connection is None: self.connection = None else: self.connection = client.connection return client",28.88410508,25.99925248
generate: Unsubscribe to the passed pair's ticker channel.,"def unsubscribe_from_ticker(self, pair, **kwargs):
        """"""
        """"""
        identifier = ('ticker', pair)
        self._unsubscribe('ticker', identifier, symbol=pair, **kwargs)","def tick_pair(self, pair): """""" """""" ticker = self.ticker.get_ticker(pair) ticker = self.ticker.get_ticker(pair) ticker.done() return ticker","def ticker(self, ticker): """""" """""" ticker = self.ticker.ticker(ticker) self.ticker.ticker(ticker) self.ticker.ticker.ticker.ticker(ticker) return ticker",39.68761435,33.09290619
generate: Check if the current version is greater as the older older one.,"def _is_version_greater(self):
        """"""
        
        """"""

        # we compare the 2 versions.
        checked = Version(True).check_versions(
            self.current_version[0], self.version_yaml
        )

        if checked is not None and not checked:
            # The current version is greater as the older one.

            # We return True.
            return True

        # We return False
        return False","def check_version(self, old_version=None, filter=None): """""""""""" if filter is not None: if filter is not None: return self.check_version(filter=filter) if filter is not None: return filter self.check_version(filter=filter) return self.check_version(filter)","def _check_older_version(self): """""" """""" if self._current_version == 1: self._current_version = self._current_version self._current_version = self._current_version self._current_version = self._current_version self._current_version = self._current_version return self._current_version",41.7048716,38.94203677
generate: Get the cast and crew information for a specific movie id.,"def credits(self, **kwargs):
        """"""
        
        """"""
        path = self._get_id_path('credits')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","def get_cast_cast(self, cast_id): """""" """""" if cast_id == self.cast_id: return self.cast elif cast_id == self.cast_id: return self.cast else: return self.cast","def get_crew(self, crew): """""" """""" response = self._get_crew_cast_for_crew(crew) if response.status_code == 403: return self._get_crew(response.text, crew) else: return None",35.04216403,45.92605071
generate: Update internal counters,"def __update_count(self):
        """"""  """"""
        self._ntypes = self.count_types()
        self._nvars = self.count_vars()
        self._nfuns = self.count_funs()","for the other counters. def update_internal_counters(self): """""" """""" self.counters = self.counters self.counters = self.counters","and handling the data. def _update_counter_info(self, data): """""" """""" self._internal_counter_info(data) self._internal_counter_info(data) self._internal_counter_info(data) self._internal_counter_info(data)",56.71066238,33.43134012
generate: Fetch the value from the table and prepare the edit control,"def BeginEdit(self, row, col, grid):
        """"
        self.startValue = grid.GetTable().GetValue(row, col)
        choices = grid.GetTable().columns[col]._choices
        self._tc.Clear()
        self._tc.AppendItems(choices)
        self._tc.SetStringSelection(self.startValue)
        self._tc.SetFocus()","ler. def get(self, url, page=None): """""" """""" result = self.get(url) result = self.get(url) if result is None: return None if self.is_terminated: self.terminated_terminated = True return result else: return self.terminated_terminated","ler. def fetch_edit_controller(self, table_name): """""" """""" if table_name not in self._edit_controller: raise ValueError(""Can't find the table_name to be an edit."") # fetch the value if self._edit_controller.is_edit_controller: return self._edit_controller.fetchone(table_name) else: return self._edit_controller.fetchone()",22.64779516,22.23918563
generate: Check if specific message is present.,"def check_messages(msgs, cmd, value=None):
    """"""

    """"""
    for msg in msgs:
        if value and msg.get(cmd) == value:
            return msg
        if not value and msg.get(cmd):
            return msg
    return None","def _check_message(self, message): """""""""""" if not self.message: return False try: message = self._message.get(message) except AttributeError: return False return True","def _check_message(self, message): """""" """""" if message is None: return self.message_message(message) else: if self._super(message, message): return self._super(message, message)",39.68764563,36.00466966
generate: Return process cmdline as a list of arguments.,"def get_process_cmdline(self):
        """"""""""""
        if not pid_exists(self.pid):
            raise NoSuchProcess(self.pid, self._process_name)
        return _psutil_osx.get_process_cmdline(self.pid)","def get_arguments(self, cmdline, default=None): """""""""""" arguments = [arg for arg in arguments if arg.get(""Command"")] if not arguments: arguments.append(arguments) return arguments","def get_process_cmdline(self, args): """""""""""" if self._process_cmdline is not None: return self._process_cmdline(args) return self._process_cmdline(args)",29.15500255,59.92084072
generate: Looks up the metric definition from the definitions from the API call,"def getMetricDefinition(self, name):
        """"""
        
        """"""
        metric = None
        for m in self.metric_definitions:
            if m['name'] == name:
                metric = m
                break
        return metric",". def get_metric_with_metric(self, api_url): """""" """""" if self.api_url is not None: return self.api_url.get(api_url) else: return self.api_url.get(api_url)","back. def upload(self, metric, metric): """""" """""" if self.upload_metric: return self.get_metric_metric(metric) else: return None",37.23098391,45.16727553
generate: Continuous cosine wave.,"def cos(times: np.ndarray, amp: complex, freq: float, phase: float = 0) -> np.ndarray:
    """"""
    """"""
    return amp*np.cos(2*np.pi*freq*times+phase).astype(np.complex_)","def continuous_cosine(self, cosine, page, auth_key, **kwargs): """""" """""" cosine = URL.get(""cosine"") return self.continuous_cosine(cosine, page, auth_key, **kwargs)","def create_wrapper(self, user_name, user_name, **kwargs): """""" """""" if user_name.startswith('content'): return self.content else: raise ValueError('Username must be an instance of the username: %s' % user_name)",23.58698267,17.66660953
generate: Attempt to parse the passed in string into a valid datetime.    If we get a parse error then assume the string is an epoch time    and convert to a datetime.,"def parse_time_date(self, s):
        """"""
        
        """"""
        try:
            ret = parser.parse(str(s))
        except ValueError:
            try:
                ret = datetime.fromtimestamp(int(s))
            except TypeError:
                ret = None
        return ret","def parse_date(self): """""" """""" if self.time_to_time is not None: date = datetime.datetime.strptime( date.time_to_time, date.time_to_time, date.time_to_time, ) return date","def parse_datetime(self, datetime): """""" """""" # The parse time passed = self._parse_time(datetime) if passed: return passed else: return datetime",39.09364518,41.80632942
generate: Check instantiating abstract class with    abc.ABCMeta as metaclass.,"def visit_call(self, node):
        """""" 
        """"""
        try:
            for inferred in node.func.infer():
                self._check_inferred_class_is_abstract(inferred, node)
        except astroid.InferenceError:
            return","def class_instantiating(self, class_name): """""" """""" if class_name == '__instantiating__': return self.class_instantiating(class_name) else: return self.class_instantiating","def get_metaclass(self): """""" """""" url = self._api.get_metaclass() if url.endswith('/'): return url if url.endswith('/'): return url return url",29.02060427,25.43242558
generate: Return True if the callable throws the specified exception,"def throws_exception(callable, *exceptions):
	""""""
	
	""""""
	with context.ExceptionTrap():
		with context.ExceptionTrap(*exceptions) as exc:
			callable()
	return bool(exc)","is available def _check_except_error(self, exception, exception): """""" """""" if exception is not None: if exception is not None: return False return False",". def get_exception(self, exception): """""" """""" if exception.Code!= 'Code': return False if exception.code!= 'While': return True if exception.code == 'Both': return True else: return False",42.52544451,36.91144241
generate: Adds the group and its arguments to a argparse.ArgumentParser instance,"def add_to_parser(self, parser):
        """"""
        
        """"""
        self.group = parser.add_argument_group(self.title, self.description)
        for arg in self.arguments:
            arg.add_to_parser(self.group)",". def add_group(self, arguments): """""" """""" arguments = [] if arguments: arguments.append(arguments) if len(arguments) == 0: arguments.append(arguments) else: arguments.append(arguments) self.add_argument(arguments) if arguments: self.add_argument(arguments) self.add_argument(arguments) self.add_argument(arguments)",". def add_group(self, argument_name): """""" """""" if isinstance(argument_name, Group): arguments = argument_name.split(':') else: arguments = Group.ArgumentParser(argument_name) return self.add_group(arguments, arguments)",28.13262319,37.81414387
generate: Clear the output of the cell receiving output.,"def clear_output(self, stdout=True, stderr=True, other=True):
        """"""""""""
        if stdout:
            print('\033[2K\r', file=io.stdout, end='')
            io.stdout.flush()
        if stderr:
            print('\033[2K\r', file=io.stderr, end='')
            io.stderr.flush()","def clear_output(self, output_file): """""""""""" with self.output_dir() as outfile: if os.path.exists(outfile): os.unlink(outfile) self.clear_output(outfile)","def clear_output(self, name, filename): """""""""""" if self.clear_process_output(name, filename): self.clear_output(filename, filename) return",25.43000706,24.83429668
generate: Validate a secret link token.,"def validate_token(cls, token, expected_data):
        """"""
        """"""
        data = SecretLinkFactory.validate_token(
            token, expected_data=expected_data
        )

        if data:
            link = cls.query.get(data['id'])
            if link and link.is_valid():
                return True
        return False","def _validate_secret_link(self, secret, link): """""""""""" if not link: return False link = self.line_links[secret] if link: if not self.is_authenticated(link): return False link = self.links[link] if link: return True return False","def validate_source_token(self, token, connection): """""" """""" if token not in self._sources: self._sources[token] = self._sources[token] return self._sources[token]",38.57619842,26.98540383
generate: Modify an existing domain.,"def modify_domain(self, domain_name, new_salt=False, username=None):
        """""" 
        """"""
        domain = self._get_domain_from_db(domain_name)
        if domain is None:
            raise NoSuchDomainException
        if new_salt:
            _logger.info(""Generating new salt.."")
            domain.new_salt()
        if username is not None:
            domain.username = username
        return domain","def modify_domain(self, domain, domain_id): """""""""""" if self.domain_id is None: domain_id = self.domain_id if domain_id is None: domain_id = self.domain_id domain_id = self.domain_id if domain_id == domain_id: domain_id = self.domain_id return domain_id","def domain(self, domain): """""" """""" if not domain.is_null(): raise ValueError(""Domain domain domain domain: %s"" % domain) domain = self._domains[domain.id] if domain.is_main(): return domain else: raise ValueError(""Domain domain domain: %s"" % domain)",42.26016655,41.38772171
generate: Lists datasets in resources. Setting 'get_global_public' to 'True'    will retrieve all public datasets in cloud. 'False' will get user's    public datasets.,"def list_datasets(self, get_global_public):
        """"""
        

        """"""
        appending = """"
        if get_global_public:
            appending = ""public""
        url = self.url() + ""/resource/{}dataset/"".format(appending)
        req = self.remote_utils.get_url(url)

        if req.status_code is not 200:
            raise RemoteDataNotFoundError('Could not find {}'.format(req.text))
        else:
            return req.json()","If no datasets are available, use this ``False``. def list_public_datasets(self, datasets): """""" """""" # Avoid cloud when the first ones are returned. If no dataset is available. if self.public_datasets: return self.public_datasets(datasets) else: return self.public_datasets(datasets)","def _get_global_public_datasets(self, public_dataset, dataset_id): """""" """""" public_datasets = {'public_dataset': public_dataset, 'public_dataset': public_dataset} response = self._get_response(response) if response.status_code!= 200: return response.json() return response.json()",33.53333832,38.89266494
generate: Retrieve the complete information of the given stream.,"def info(self, timeout=FOREVER):
        """"""

        """"""
        errcode = c_int()
        result = lib.lsl_get_fullinfo(self.obj, c_double(timeout),
                                      byref(errcode))
        handle_error(errcode)
        return StreamInfo(handle=result)","def get_complete_info(self, stream): """""""""""" complete_info = self.get_complete_info(stream) complete_info = self.get_complete_info(stream) if complete_info: return complete_info return None","def _get_stream(self): """""" """""" self._stream = None if self._stream is None: self._stream = None self._stream = None else: self._stream = None self._stream = None self._stream = None self._stream = None return self._stream",30.55258193,20.50426282
generate: Create a python function that interprets that action of a BridgePoint class  operation.,"def mk_operation(metaclass, o_tfr):
    '''
    
    '''
    o_obj = one(o_tfr).O_OBJ[115]()
    action = o_tfr.Action_Semantics_internal
    label = '%s::%s' % (o_obj.Name, o_tfr.Name)
    run = interpret.run_operation
    
    if o_tfr.Instance_Based:
        return lambda self, **kwargs: run(metaclass, label, action, kwargs, self)
    else:
        fn = lambda cls, **kwargs: run(metaclass, label, action, kwargs, None)
        return classmethod(fn)","def interpret_pos_function(action, db, mode, db_id, action, **kwargs): """""" """""" python_function = python_function_that(action) if python_function == 'true': return python_function(action) else: return python_function(action, db_id, db_id, **kwargs)","def add_point_cls(self, point_class, function, point_class, point_class, point_class, point_class, point_class): """""" """""" if point_class is None: point_class = self.point_class(point_class) if point_class == 'point_class' and point_class == 'point_class' or point_class == 'point_class' and point_class == 'point_class' or point_class == 'point_class' and point_class == 'point_class': self.add_point_class(point_class, point_class, point_class, point_class, point_class, point_class) else: self.add_point_class(point_class, point_class, point_class) return self",24.98473681,17.10422517
generate: update the splitter and readline delims when greedy is changed,"def _greedy_changed(self, name, old, new):
        """"""""""""
        if new:
            self.splitter.delims = GREEDY_DELIMS
        else:
            self.splitter.delims = DELIMS

        if self.readline:
            self.readline.set_completer_delims(self.splitter.delims)",". def splitter_delims(self, delims): """""" """""" if self.delims is None: self.delims = self.delims self.delims = delims self.delims = delims",". def update_to_new_add(self, delims): """""" """""" if delims is None: delims = self.delims elif delims is None: delims = self.delims else: delims = delims self.delims = delims return delims",39.12510741,39.51156233
generate: Retrieves the number of teams of the organization.,"def get_teams_of_org(self):
        """"""
        
        """"""
        print 'Getting teams.'
        counter = 0
        for team in self.org_retrieved.iter_teams():
            self.teams_json[team.id] = team.to_json()
            counter += 1
        return counter","def _get_teams(self): """""""""""" teams = [] if self.teams: teams.append(self.teams) teams.append(self.teams) teams.append(teams) teams.append(teams) teams.append(teams) return teams","def get_team_by_number(self): """""" """""" if self.team_number_type == ""number"": return self.number_type else: return None",37.75866338,27.91877175
generate: Create a UDP connection to Riemann,"def createClient(self):
        """"""""""""
        server = self.config.get('server', '127.0.0.1')
        port = self.config.get('port', 5555)

        def connect(ip):
            self.protocol = riemann.RiemannUDP(ip, port)
            self.endpoint = reactor.listenUDP(0, self.protocol)

        d = reactor.resolve(server)
        d.addCallback(connect)
        return d","erSession. def _run_connection(self, connection): """""" """""" if self._run_connection is None: self._run_connection = Connection self._run_connection = Connection self._run_connection = Connection self._run_connection = Connection self._run_connection = Connection","ot Something associated on the IPython settings. def create_connection(self, server_id): """""" """""" self._session.create(server_id, server_id, server_id) return self._session.create_connection(server_id, server_id)",24.52232426,28.69939642
generate: Return probability estimates for the RDD containing test vector X.,"def predict_proba(self, X):
        """"""
        
        """"""
        check_rdd(X, (sp.spmatrix, np.ndarray))
        return X.map(
            lambda X: super(SparkBaseNB, self).predict_proba(X))","def get_probabilities(X): """""""""""" try: X = get_probabilities_vector(X) except AttributeError: X = X return X.probabilities","def _get_estimate_x(self): """""" """""" if self.indices.get('width', None): return self.indices.get('width', None) elif self.indices.get('width', None): return self.indices.get('width', None) else: raise TypeError('Width is not a supported')",28.41474716,18.54019363
generate: Deletes the specified hosted service from Windows Azure.,"def delete_hosted_service(self, service_name, complete=False):
        '''
        
        '''

        _validate_not_none('service_name', service_name)

        path = self._get_hosted_service_path(service_name)

        if complete == True:
            path = path +'?comp=media'

        return self._perform_delete(path, as_async=True)","def delete(self, host, specified_service, sender, sender_name, access_service, host_name, access_service, access_service, failure_host, service_name, failure_host, access_service_name, failure_host, access_service_name, failure_host_name, service_name, access_service_name, failure_host, access_service_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name, failure_host_name,","def delete_service(self, service_name, host, clean_port=None): """""" """""" if host: return self._remove_service_host(service_name, host) return self._remove_service(service_name, host)",15.08654837,39.3555203
generate: Load multiple images from file into an ndarray.,"def load_imgs(filenames, masker, nan_to_num=True):
    """""" 
    """"""
    if isinstance(filenames, string_types):
        filenames = [filenames]
    data = np.zeros((masker.n_vox_in_mask, len(filenames)))
    for i, f in enumerate(filenames):
        data[:, i] = masker.mask(f, nan_to_num)
    return data","def load_images(self, images): """""""""""" images = load_images(images) for i in range(images): if i == 0: i = load_images(i) else: i = load_images(i) return i raise NotImplementedError(""Data type "" + ""Must be an integer threshold."")","def _read_image_image(self, image_name, ndarray): """""" """""" ndarray = image_name.shape[0] ndarray = ndarray[1] images = np.ones(ndarray[0]) for i in range(ndarray): if i == i > 1: self._df.write(image_name, i) self._df.write(i) self._df.write(i) return self._df.columns",28.0231407,28.30318106
generate: Report a histogram.,"def histogram(self, stat, value, tags=None):
        """"""""""""
        self._log('histogram', stat, value, tags)","def report(self, histogram): """""" """""" histogram = self.get_histogram(histogram) if histogram: return histogram.get_histogram(histogram)","def _get_histogram(self, spec): """""" """""" if not self.histogram: raise errors.Unimplemented() return self.histogram",31.71641855,37.41805839
generate: Parses XML from a response.,"def xml(cls, res, *args, **kwargs):
        """"""""""""
        return parse_xml(res.text, *args, **kwargs)","def parse_xml(self, response, text): """""" """""" try: xml = XML(xml) except XMLState: return xml","def parse_xml(self, text, text, text): """""" """""" response = self._get_response(text, text, text, text, text, text, text) return response",38.45965779,28.38246647
generate: Returns detailed information associated with a specific transaction hash.,"def get_raw_transaction(self, tx_hash, verbose=True, **kwargs):
        """""" 

        """"""
        return self._call(
            JSONRPCMethods.GET_RAW_TRANSACTION.value, params=[tx_hash, int(verbose), ], **kwargs)","def get_digest_hash(self, transaction, key, error=None): """""""""""" if key == ""data"": return self._get_data_hash_hash(transaction, key) else: return self._get_data_hash_hash(transaction, key)","def _get_detail_hash(self, target_id, name): """""" """""" return self._get_detail_hash(self._transaction, target_id, name, name, name, code=self._code)",33.01459775,37.22025803
generate: A Package contains packageable elements,"def accept_EP_PKG(self, inst):
        '''
        
        '''
        for child in many(inst).PE_PE[8000]():
            self.accept(child)",". def package_contains(self, contains, state, **kwargs): """""" """""" contains = [] for r in self.states: contains.append(r) if contains: contains.append(contains) return contains",". def application_package_values(self, package_name, package_name): """""" """""" url = self._url(package_name) return self._api.request(url, package_name, package_name)",15.33883254,12.47484073
generate: Return a list with number of loaded cache lines per memory hierarchy level.,"def get_loads(self):
        """"""""""""
        return [self.stats[cache_level]['LOAD_count'] / self.first_dim_factor
                for cache_level in range(len(self.machine['memory hierarchy']))]","def get_loaded_lines(self): """""" """""" lines = [] for cache in self.cache: lines.append(cache.get_lines(cache)) return lines","def loaded_cache_level(self): """""" """""" cache_list = [] for cache in self.cache_list: cache_list.append(cache.get_cache_level()) cache_list.append(cache_list) return cache_list",35.76167156,38.97307417
generate: Print network statistics.,"def report(self):
        """"""
        
        """"""
        logging.info(""network inputs: %s"", "" "".join(map(str, self.input_variables)))
        logging.info(""network targets: %s"", "" "".join(map(str, self.target_variables)))
        logging.info(""network parameters: %s"", "" "".join(map(str, self.all_parameters)))
        logging.info(""parameter count: %d"", self.parameter_count)","def print_network_stats(self, text): """""""""""" text = self.print_network_stats() if text.startswith("".network_stats""): self.print_network_stats(text) if text.endswith("".network_stats""): self.print_network_stats(text) if text.startswith("".network_stats""): self.print_network_stats(text) self.print_network_stats(text)","def print_network_statistics(self, port, details): """""" """""" if port not in self.ports: self.ports[port] = port return if not details: print(""Unknown details: %s"" % port) return self.ports[port] = port self.ports[port] = port self.ports[port] = port",24.00309305,22.12219013
generate: Inserts new continuation prompt using the specified cursor.,"def _insert_continuation_prompt(self, cursor):
        """""" 
        """"""
        if self._continuation_prompt_html is None:
            self._insert_plain_text(cursor, self._continuation_prompt)
        else:
            self._continuation_prompt = self._insert_html_fetching_plain_text(
                cursor, self._continuation_prompt_html)","def _insert_continuation_prompt(self, continuation_prompt, cursor_methods, create_methods=None, client=None): """""" """""" client = Uncache() if not client: client = self.client # Get the URL if client is not None: url = self.url(continuation_prompt) if url: url = self.url(url) if client: url = self.url(url) else: url = self.url(url) if client: url = self.url(url) return url","def insert_continuation_prompt(self, continuation_id): """""" """""" self.set_continuation_prompt(continuation_id) self.set_continuation_prompt(continuation_id) self.set_continuation_prompt(continuation_id) self.set_continuation_prompt(continuation_id)",41.4368765,56.7735907
generate: walk parameter instances on this interface,"def walkParams(intf, discovered):
    """"""
    
    """"""
    for si in intf._interfaces:
        yield from walkParams(si, discovered)

    for p in intf._params:
        if p not in discovered:
            discovered.add(p)
            yield p",". def get_parameters(self, interface, element): """""" """""" filters = self.get_parameters(interface, element) if filters: return filters else: return None",". def walk_interface(self, *, mode='walk'): """""" """""" if not self.is_mode(mode): raise WalkError(""Mode must be a mode "" ""%s"" % mode) # This is removed. self.mode = mode return self",27.29411094,28.48898147
generate: Fast %Y-%m-%d parsing.,"def parse_date(s):
    """"""""""""
    try:
        return datetime.date(int(s[:4]), int(s[5:7]), int(s[8:10]))
    except ValueError:  # other accepted format used in one-day data set
        return datetime.datetime.strptime(s, '%d %B %Y').date()","def _fast(self, parsing, params): """""""""""" return HttpResponse( ""%s"" % self._url, ""%s"" % (self._url, params), params=params, timeout=self._timeout, )","def find_parsing(self, parameter, val): """""" """""" if isinstance(val, (dict, tuple, list)): return self._get_parsing(val, val) elif isinstance(val, list): return [val] elif isinstance(val, list): return val else: raise TypeError('unknown value: %r' % val)",17.81914924,21.65539143
generate: Find a single entry point.,"def get_single(group, name, path=None):
    """"""
    """"""
    for config, distro in iter_files_distros(path=path):
        if (group in config) and (name in config[group]):
            epstr = config[group][name]
            with BadEntryPoint.err_to_warnings():
                return EntryPoint.from_string(epstr, name, distro)

    raise NoSuchEntryPoint(group, name)","def find_entry_pos(entry_pos, entry_pos, filter_id, speed_id, entry_id): """""" """""" # Find entry positions entry_pos = entry_pos + speed_id entry_pos = entry_pos + speed_id entry_pos += entry_pos + speed_id entry_pos += entry_pos + speed_id entry_pos += entry_pos + speed_id return entry_pos","def find_entry_point(entry_point): """""" """""" point = EntryPoint(entry_point) if point.ndim == 1: return None point.pointer(entry_point) else: # Specify a lookup points point.pointer(entry_point) point.pointer(entry_point) point.pointer(entry_point)",16.56533945,22.9623986
generate: A wrapper around get_comments that build the taskwarrior    annotations.,"def annotations(self, card_json):
        """"""  """"""
        comments = self.get_comments(card_json['id'])
        annotations = self.build_annotations(
            ((c['memberCreator']['username'], c['data']['text']) for c in comments),
            card_json[""shortUrl""])
        return annotations","def comments(self, classes, local_app): """""" """""" if local_app is not None: raise ValueError(""Could not find annotations with local_app"") if local_app is not None: local_app = self.comments elif local_app is not None: local_app = self.local_app return local_app","def add_comments(self, comments): """""" """""" if self.stream.is_supported(): self.stream.supported_comments(comments) else: self.stream.supported_comments(comments) self.stream.supported_comments(comments)",33.18155581,29.49901355
generate: Dump the remote tokens as a list of dictionaries.,"def dump(rt, from_date, with_json=True, latest_only=False, **kwargs):
    """"""
    """"""
    return dict(id_remote_account=rt.id_remote_account,
                token_type=rt.token_type,
                access_token=rt.access_token,
                secret=rt.secret)","def dictionaries_tokens(self, dictionary): """""""""""" if dictionary is None: return [] for remote in self.dictionaries_tokens: if remote.get(""_"", False): return remote.get(""_"") return self.dictionaries_tokens","def remote(self, remote): """""" """""" # TODO: We use there. self.remote_tokens[remote] = remote self.remote_tokens[remote] = remote self.remote_tokens[remote] = remote",31.01995707,23.31164854
generate: Generic iop file writer,"def _write_iop_to_file(self, iop, file_name):
        """"""
        """"""
        lg.info('Writing :: ' + file_name)
        f = open(file_name, 'w')
        for i in scipy.nditer(iop):
            f.write(str(i) + '\n')","to be validated. def generate_file_from_file_from_file(filename, db_filename): """""""""""" try: with open(filename, ""rb"") as f: return f.read() except IOError: return None","to application file. def add_ip_file(self, file_path, root, doc_file, root, package_name, package_name): """""" """""" url = self._url + '/api/v1/ip_ips.cmd' response = self.put(url, doc_filename, package_name) response.raise_for_status() return response",32.21484633,28.34296072
generate: Return the location where filtered images are stored.,"def get_filtered_root_folder(self):
        """"""""""""
        folder, filename = os.path.split(self.name)
        return os.path.join(folder, VERSATILEIMAGEFIELD_FILTERED_DIRNAME, '')","def get_location(self, location_id, batch_size=None): """""" """""" if batch_size is None: batch_size = location_id if batch_size is None: batch_size = self._location_id return self.get_location(location_id, batch_size)","def _get_filtered_filtered_images(self): """""" """""" if self._image.is_image: return self._image.get_images(self._image) return self._image",17.96936391,30.01091328
"generate: r""""""  Return the phase of a waveform's dependent variable vector.","def phase(wave, unwrap=True, rad=True):
    
    """"""
    ret = copy.copy(wave)
    ret.dep_units = ""rad"" if rad else ""deg""
    ret.dep_name = ""phase({0})"".format(ret.dep_name)
    ret._dep_vector = (
        np.unwrap(np.angle(ret._dep_vector)) if unwrap else np.angle(ret._dep_vector)
    )
    if not rad:
        ret._dep_vector = np.rad2deg(ret._dep_vector)
    return ret","def fast(self, phase=None, phase=None, phase=None, quadratic=None): """""" if phase is None: phase = self.get_phase_sphase_quadratic(phase=phase, phase=phase, phase=phase) return self.fast(phase=phase, phase=phase)","def _find_waveform_and_dependent_variable(self, vector, waveform): """""" """""" if vector.dependent_vectors[0] == '': if self._process_indices[0] == '': return vector.dependent_variable(vector, waveform, waveform, waveform) else: return vector.dependent_variable(vector, waveform)",13.97980727,26.53916024
generate: Apply initialize to circuit.,"def initialize(self, params, qubits):
    """"""""""""
    if isinstance(qubits, QuantumRegister):
        qubits = qubits[:]
    else:
        qubits = _convert_to_bits([qubits], [qbit for qreg in self.qregs for qbit in qreg])[0]
    return self.append(Initialize(params), qubits)","def init(self, position, verbose=False): """""" """""" if verbose: return self.circuit(position) if verbose: # We don't initialize the circuit. self.circuit(position) if verbose: # Verify that the circuit is available. if verbose: return self.circuit(position) return self.circuit(position)","def circuit(self, circuit_list, quiet): """""" """""" if not quiet: return if not self._is_signed: return if circuit_list: circuit_list.append(self.circuit_list[self.circuit]) else: circuit_list.append(self._is_signed) return circuit_list",27.49148725,27.77279251
generate: Turn a list to list of list,"def splitBy(data, num):
    """"""  """"""
    return [data[i:i + num] for i in range(0, len(data), num)]","s to lists. def list_list_list(self, path, **kwargs): """""""""""" path = [] for path in path: if path[0] == '*': path.append(path) path.append(path) return path","s that are not relative. def get_lists_lists_lists(self, *args, **kwargs): """""" """""" return self.list_lists(*args, **kwargs)",19.27399188,22.54214406
generate: Find nodes in rhs which have parents in lhs.,"def parents(self, lhs, rhs):
        """"""""""""

        return [node for node in rhs if node.parent in lhs]","def find_parents(self, nodes): """""""""""" parents = nodes.parents if parents: return parents.parents.parents return parents","def find_nodes(self, nodes): """""""""""" nodes = self.find_nodes(nodes) return nodes",43.47234586,43.33136043
"generate: Given a duration in seconds, determines the best units and multiplier to  use to display the time. Return value is a 2-tuple of units and multiplier.","def get_time_units_and_multiplier(seconds):
    """"""
    
    """"""
    for cutoff, units, multiplier in units_table:
        if seconds < cutoff:
            break
    return units, multiplier","def _get_duration(seconds, seconds, multiplier=None): """""""""""" duration = duration_struct.get(seconds) if duration is None: return duration return duration","def _get_multiplier(multiplier): """""" """""" units = multiplier.units units.units = units return units",38.0734584,42.23795479
generate: disable all reporters,"def disable_reporters(self):
        """"""""""""
        for _reporters in self._reports.values():
            for report_id, _, _ in _reporters:
                self.disable_report(report_id)","that are specified. def disable_reporters(self): """""""""""" for reporter in self.reporters: if reporter is None: continue elif reporter is None: continue else: return reporter",". def _get_reporters(self, reporters): """""" """""" reporters = [] for reporter in reporters: if reporter not in reporters: reporters.append(reporter) return reporters",51.14601693,46.60748379
generate: Unregister an engine that has died.,"def _unregister_engine(self, msg):
        """"""""""""
        content = msg['content']
        eid = int(content['id'])
        if eid in self._ids:
            self._ids.remove(eid)
            uuid = self._engines.pop(eid)

            self._handle_stranded_msgs(eid, uuid)

        if self._task_socket and self._task_scheme == 'pure':
            self._stop_scheduling_tasks()","def _register_engine(self, engine): """""" """""" if self.engine is not None: engine = self.engine if engine is not None: engine = engine self.engine = engine self.network.register(engine) self.network.register(engine) else: self.network.register(engine) self.network.register(engine)","def _get_engine_engine(self, region, mode='LoggingStatus'): """""" """""" self._clone_region_on_status() return self._get_engine_engine_engine(self._engine_engine, region)",35.28335266,19.76174538
"generate: For each node in the tree, set its root-to-node distance as dist2root    attribute","def _calc_dist2root(self):
        """"""
        
        """"""
        self.tree.root.dist2root = 0.0
        for clade in self.tree.get_nonterminals(order='preorder'): # parents first
            for c in clade.clades:
                if not hasattr(c, 'mutation_length'):
                    c.mutation_length=c.branch_length
                c.dist2root = c.up.dist2root + c.mutation_length",". def set_root_to_node(self, node): """""" """""" if node.root_to_node is not None: self.set_root_to_node(node.root_to_node) self.set_root_to_node(node) self.set_root_to_node(node) self.set_root_to_node(node)","name and code. def set_node_dict(self, tree): """""" """""" if self.contains: return self.contains[tree.index(self.contains)] else: return self.contains[tree.index(self.contains)]",20.57478384,18.30647199
generate: Return a client with same settings of the batch client,"def unit_client(self):
        # type: () -> Client
        """"""""""""

        client = Client(self.host, self.port, self.prefix)
        self._configure_client(client)
        return client",". def get_settings(self): """""""""""" if self.client is None: return None if self.client is None: return self.client # Lookup the batch client. batch_client = self.client.get_batch_client(self.client) batch_client.fetch_client(batch_client) return batch_client",". def get_batch_client(self, client_id, page_id): """""" """""" if not self.is_owned(): return None if self.is_batch_client(): return self.get_batch_client(client_id) return None",35.27955216,42.99602992
generate: Yield duplicate items from any number of sorted iterables of items,"def duplicates(*iterables, **kwargs):
	""""""
	
	""""""
	key = kwargs.pop('key', lambda x: x)
	assert not kwargs
	zipped = more_itertools.collate(*iterables, key=key)
	grouped = itertools.groupby(zipped, key=key)
	groups = (
		tuple(g)
		for k, g in grouped
	)

	def has_dupes(group):
		return len(group) > 1
	return filter(has_dupes, groups)",". def __yield_duplicate_items(self, items): """""" """""" # If it's all items are already a valid one, # then it will be saved. If it's a list of items in items, will # be created. for item in items: if item.count == 0: return item return self.get_sorted_items(item)",". def _get_items_by_print(self, port): """""" """""" items = [] for i in range(len(port)): port = port[i] for i in range(len(port)): if i > len(port) and not port[i]: if port[i] == '': port.append(self.print_detect_values(port[i]) else: port[i]) if not port: items.append(self.print_detect_values(port)) return items",23.50329481,22.93104457
generate: Creates a new encryption key in the path provided and sets the file  permissions. Setting the file permissions currently does not work  on Windows platforms because of the differences in how file  permissions are read and modified.,"def create_key_file(path):
    """"""
    
    """"""
    iv = ""{}{}"".format(os.urandom(32), time.time())
    new_key = generate_key(ensure_bytes(iv))
    with open(path, ""wb"") as f:
        f.write(base64.b64encode(new_key))
    os.chmod(path, 0o400)","def create_encrypt(self, encrypt, modified_filename, modified_filename, temp_filename): """""" """""" self.setup_encrypt(encrypt, modified_filename) self.encrypt(encrypt, modified_filename) self.encrypt(encrypt, modified_filename) self.encrypt(encrypt, modified_filename)","This method is set, the otherwise use it will be called to first. def create_encryption(file_path, encryption): """""" """""" if not os.path.isdir(file_path): return os.path.join(file_path, encryption) try: os.remove(file_path) except OSError as e: raise e finally: os.makedirs(file_path)",15.85058188,22.83954098
"generate: Assert that for all items in the iterable, they're in order based on comp","def assert_ordered(iterable, key=lambda x: x, comp=operator.le):
	""""""
	
	""""""
	err_tmpl = (
		""{pair[0]} > {pair[1]}"" if comp is operator.le else
		""{pair[0]} < {pair[1]}"" if comp is operator.ge else
		""not {comp} {pair}""
	)
	for pair in more_itertools.pairwise(iterable):
		keyed = tuple(map(key, pair))
		assert comp(*keyed), err_tmpl.format(**locals())
		yield pair[0]
	yield pair[1]","onents. def _get_item_by_impl(item, item): """""""""""" for item in item: if item.name!= item.name: raise ValueError(""{} is invalid for item, the item, the item is invalid."".format(item)) item.name = item.name item.update(item) return item","arison. def add_order_by_name(self, item): """""" """""" if not isinstance(item, (list, tuple)): raise ValueError(""Item not in order based only."") if isinstance(item, list): item = item.append(item) else: item = self._order_by_name if not isinstance(item, list): raise ValueError(""Item must be a list"") if len(item) == 2: raise ValueError(""Item not found in order based only"") self._order_by_name = item self._order_by_name = item self._order_by_name = item self._order_by_name = item self._order_by_name = item self._order_by_name = item self._order_by_name = item",14.42874891,15.337806
generate: Get the name of the file containing configuration overrides  from the provided environment variable.,"def get_overrides_filename(variable):
    """"""
    
    """"""
    filename = os.environ.get(variable)

    if filename is None:
        msg = 'Please set the {} environment variable.'.format(variable)
        raise EnvironmentError(msg)

    return filename","def get_config_file(self, filename=None, **kwargs): """""""""""" if filename is None: filename = self.get_config_filename(filename) if filename is None: filename = self.get_config_filename(filename) return filename","def get_config_file_name(self, environment_name): """""" """""" if not environment_name: raise AttributeError(""Expected environment variable '%s'"" % environment_name) return environment_name",44.13794209,45.41766147
generate: Add a side to the current basket.,"def add_side_to_basket(self, item, quantity=1):
        '''
        
        '''
        item_variant = item[VARIANT.PERSONAL]

        params = {
            'productSkuId': item_variant['productSkuId'],
            'quantity': quantity,
            'ComplimentaryItems': []
        }

        return self.__post('/Basket/AddProduct', json=params)","def add_to_basket(self, basket, basket): """""""""""" if basket.is_connected: basket = basket elif basket.is_connected: basket = basket elif basket.is_connected: basket = basket else: raise ScanError(""Unsupported basket basket."")","def add_basket(self, basket): """""" """""" if self.has_settings(basket): if self.get_basket(basket) or self.settings(basket): basket.add_basket(basket) else: basket.add_basket(basket) return basket",18.82224989,17.93850132
generate: Deletes the item from the container within the specified    coordinates.,"def delete(self, obj, coordinates):
        """"""

        """"""
        try:
            count = self._objects[id(obj)] - 1
        except KeyError:
            raise IndexError('object is not in the index')
        if count == 0:
            del self._objects[obj]
        else:
            self._objects[id(obj)] = (count, obj)
        return super(RtreeContainer, self).delete(id, coordinates)","def delete_item(self, coordinates, item, specified_item): """""" """""" self._delete_item(coordinates, item) self._delete_item(coordinates) self._delete_item(coordinates) self._delete_item(coordinates)","def delete_item_and_coordinates(self): """""" """""" for item in self.items: if not item.is_processing(): raise GotItemError(""Coordinates {0} "".format(item)) if item.is_processing(): raise GotItemError(""Unable to delete coordinates"") if self.is_processing(): return item return self.items[0]",28.95030029,39.27172055
generate: Defers an operator overload to `attr`.,"def _operator(attr):
  """"""
  """"""
  @functools.wraps(attr)
  def func(a, *args):
    return attr(a.value, *args)
  return func","def defer(self, attributes, attributes): """""" """""" if attributes is not None: attributes = attributes.get(attr, attributes) return attributes","def define_operator(self, value, key_name, default_value): """""" """""" self.att_key = value return self.define_operator(value, default_value)",30.34459004,31.50467854
generate: Return settings for given integration as a dictionary.,"def get_settings(self, integration_id):
        """"""""""""

        try:
            integration = self.get(integration_id=integration_id)
            return json.loads(integration.settings)
        except (self.model.DoesNotExist, ValueError):
            return {}","def get_integration_as_dict(self, integration_as_dict): """""""""""" try: return self.get_integration_as_dict(integration_as_dict) except KeyError: return []","def settings(self, integration=True): """""" """""" url = self._build_url('/settings', integration=integration, integration=integration) return self._get_request(url, url)",50.77094855,52.35185772
generate: Cast HArray signal or value to signal or value of type Bits,"def reinterptet_harray_to_bits(typeFrom, sigOrVal, bitsT):
    """"""
    
    """"""
    size = int(typeFrom.size)
    widthOfElm = typeFrom.elmType.bit_length()
    w = bitsT.bit_length()
    if size * widthOfElm != w:
        raise TypeConversionErr(
            ""Size of types is different"", size * widthOfElm, w)

    partT = Bits(widthOfElm)
    parts = [p._reinterpret_cast(partT) for p in sigOrVal]

    return Concat(*reversed(parts))._reinterpret_cast(bitsT)",". def update_has_by_bits(self, bits): """""" """""" # Implemented from template for - # osid.resource.Session.update_bits_template if bits == self.bits: bits = bits.get('bits') return self.update(bits)",". def bit_size(self): """""" """""" if self._convert_value_size == 0: return np.zeros((self._convert_value, self._convert_value)) elif self._convert_value_size == 0: return np.zeros((self._convert_value_size, self._convert_value_size, self._convert_value_size)) elif self._convert_value_size == 2: return np.zeros((self._convert_value_size, self._convert_value_size)) else: raise ValueError(""Unable to find the Unknown value"")",13.53427152,21.30941676
generate: unset _instance for this class and singleton parents.,"def clear_instance(cls):
        """"""
        """"""
        if not cls.initialized():
            return
        for subclass in cls._walk_mro():
            if isinstance(subclass._instance, cls):
                # only clear instances that are instances
                # of the calling class
                subclass._instance = None","def unset_instance(self, class_name): """""""""""" try: if isinstance(class_name, int): class_name = self._instance_class(class_name) else: class_name = self._instance_class(class_name) self._instance_class(class_name, class_name)","def unset_instance(self, *args, **kwargs): """""" """""" self._instance = kwargs.get(""instance"") if self._instance is None: return self._instance = ""instance"" if self._instance_class is None: raise ValueError(""Invalid Meta"") return self._instance",42.11172747,43.63206694
generate: go to the path,"def cd(self, newdir):
        """"""
        
        """"""
        prevdir = os.getcwd()
        os.chdir(newdir)
        try:
            yield
        finally:
            os.chdir(prevdir)","s of the given paths. def _generate_paths(self, paths): """""""""""" paths = [] for path in paths: paths.append(path) return paths","to a file or WPD special file. def wpd_to_wpd_path(self, filename): """""" """""" wpd_dir = os.path.join(self._dir, filename) if not os.path.isfile(wpd_dir): wpd_dir = os.path.join(wpd_dir, filename) self._dir_to_wpd_path(wpd_dir, filename)",19.80650329,19.59662251
generate: Enable event loop integration with PyGTK.,"def enable_gtk(self, app=None):
        """"""
        """"""
        import gtk
        try:
            gtk.set_interactive(True)
            self._current_gui = GUI_GTK
        except AttributeError:
            # For older versions of gtk, use our own ctypes version
            from IPython.lib.inputhookgtk import inputhook_gtk
            self.set_inputhook(inputhook_gtk)
            self._current_gui = GUI_GTK","def enable_loop_loop(self): """""" """""" log.info(""Enable event loop."") if self.loop: self.loop = self.loop self.loop = self.loop self.event.flush()","def enable_event_loop(self): """""" """""" try: if not self.remote_event: self.remote_event(self.remote_event) self.remote_event_loop(self.remote_event) except Exception as e: self.remote_event_loop(self.remote_event) self.remote_event_loop(self.remote_event) return",12.59803379,25.18409145
generate: List all files ending with a suffix at a given root,"def list_files(root, suffix, prefix=False):
    """"""
    """"""
    root = os.path.expanduser(root)
    files = list(
        filter(
            lambda p: os.path.isfile(os.path.join(root, p)) and p.endswith(suffix),
            os.listdir(root)
        )
    )

    if prefix is True:
        files = [os.path.join(root, d) for d in files]

    return files",". def list_files(root, suffix, ending_path=None, link=None): """""" """""" root = [] if suffix is not None: root.append(suffix) if ending_path is not None: root.append(ending_path) root.append(ending_path) links = [] for root, filter in ending_links: links.append(root) return links",". def _get_file_path_os_files(self, root_files): """""" """""" root_files = [os.path.join(root_files, root_files)] if not os.path.exists(root_files): return if not os.path.exists(root_files): os.makedirs(root_files) for filename in os.listdir(root_files): if os.path.isfile(filename): root_files.append(root_files) return root_files",45.8346634,47.31980349
generate: Return files opened by process.,"def get_open_files(self):
        """"""""""""
        if self.pid == 0:
            return []
        files = []
        rawlist = _psutil_osx.get_process_open_files(self.pid)
        for path, fd in rawlist:
            if isfile_strict(path):
                ntuple = nt_openfile(path, fd)
                files.append(ntuple)
        return files","def get_files(self, process_dir): """""""""""" files = self.get_files(process_dir) if files is None: return None # Only check files for file in files: if file.exists(): return file","def file_exists(self): """""" """""" if self.is_new_file(): return else: filename = self.get_filename() if filename.endswith("".""): filename = filename.split(""."") if filename.endswith("".""): return filename else: self.is_new_file(filename) return filename",41.03935148,38.93572549
generate: Create a patched Schema for validating models.,"def _create_validation_schema(schema_cls):
        """"""
        """"""
        validation_schema = schema_cls()
        for _, field in validation_schema.fields.items():
            if isinstance(field, ModelTypeValidator):
                validate_function = field.__class__.check_type
                field._deserialize = MethodType(validate_function, field)

        return validation_schema","def get_schema(self, models): """""" """""" if models == Schema: return models if models == Schema: return None return self.get_schema_for_validating_models(models)","def create_models_for_validation(self, patched_name, patched_name, schema_name, patched_name, schema_dict): """""" """""" if self._is_validated: return self._create_schema(patched_name, patched_name, patched_name, schema_name) else: return self._create_schema(patched_name, patched_name, schema_name, schema_name, schema_name)",18.00004049,33.92417048
generate: DDP method handler.,"def recv_method(self, method, params, id_, randomSeed=None):
        """"""""""""
        if randomSeed is not None:
            this.random_streams.random_seed = randomSeed
            this.alea_random = alea.Alea(randomSeed)
        self.api.method(method, params, id_)
        self.reply('updated', methods=[id_])","def method_handler(self, *args, **kwargs): """""""""""" if self.name: self.name = self.name self.method_handler = self.handler self.method_handler = self.method_handler self.method_handler = self.method_handler self.handler = self.handler self.method_handler = self.handler else: self.method_handler = self.method_handler return self","def _get_method_handler(self, method_name, only=False): """""""""""" if method_name is None: method = 'GET', None if self._catalog.handler_method == 'POST': method_name = method_name else: method_name = method_name method = method_name self._catalog.add_method(method, method_name, only=only) return method",25.2055208,33.0204518
generate: Check to see if string is an validly-formatted web url.,"def is_web_url(string):
    """"""""""""
    assert isinstance(string, basestring)
    parsed_url = urllib.parse.urlparse(string)
    return (
        (
            parsed_url.scheme.lower() == 'http'
            or parsed_url.scheme.lower() == 'https'
        )
        and parsed_url.netloc
    )","def _validate_url(url, message): """""""""""" if not isinstance(url, six.string_types): return url if _validate_url(url, message): return url if _validate_url(url, message) is None: return url","def has_url(self, string): """""""""""" if not string: return self._fetch_response(string) if not string: return self._fetch_response(string) return self._fetch_response(string, string)",27.75568221,31.44054377
generate: Helper method that calls all callbacks registered for the given action.,"def doAction(self,action):
        """"""
        
        """"""
        if not hasattr(self,""actions""):
            return
        for f,args,kwargs in self.actions.get(action,[]):
            f(*args,**kwargs)","def get_callbacks_for_callbacks(self, action, **kwargs): """""" """""" return self.get_callbacks_for_callbacks(action, **kwargs)","def callback(self, action, name, action): """""" """""" if action in self.callbacks: self.callbacks[action] = action else: self.callbacks[action] = action return self.callbacks[action]",41.12661204,37.08016493
generate: Mark the name as consumed and delete it from    the to_consume dictionary,"def mark_as_consumed(self, name, new_node):
        """"""
        
        """"""
        self.consumed[name] = new_node
        del self.to_consume[name]","and it is disconnected. def mark_consume(self, name, field_name, marker): """""" """""" self.consume_name = field_name self.consume_markers = marker",". def mark_to_consume(self, *, **kwargs): """""" """""" self._check_consume(kwargs) return self._consume_and_consume(**kwargs)",49.02110045,48.27789753
generate: Transform the body of an ``Example`` into the body of a method.,"def transform_example_body(self, body, context_variable):
        """"""
        

        """"""

        for node in body:
            for child in ast.walk(node):
                if isinstance(child, ast.Name):
                    if child.id == context_variable:
                        child.id = ""self""
            yield node","def _transform_body(self, body): """""" """""" body = body.get('Body') if body is not None: self.body = body if body is not None: if body is not None: self.body = body else: self.body = body","def get_body(self): """""" """""" url = self.endpoints.get('body', self.endpoint) if url.startswith('body'): return self.endpoints.get(url, None) else: raise error.UnicodeData('Unable to find the method in the body: %s' % url)",31.29131316,27.63517902
generate: Gets information relating to the opening coin toss.,"def coin_toss(self):
        """"""
        """"""
        doc = self.get_doc()
        table = doc('table#game_info')
        giTable = sportsref.utils.parse_info_table(table)
        if 'Won Toss' in giTable:
            # TODO: finish coinToss function
            pass
        else:
            return None","def get_information_relative_coins(self, coins, coins, filter_id, filter_id, filter_id): """""""""""" # Update coins with the information for coin in coins: self._parse_information_relative_coins(coin, coin, filter_id)","def get_coin_from_coin_tools(self, coin_tools): """""" """""" if coin_tools: return self.client.get_coin_tools(coin_tools) else: return None",29.03078087,27.29024673
generate: Collects all settings within a section,"def _collect_section(self, section):
        """"""""""""
        kwargs = {}
        try:
            if self.parser.has_section(section):
                options = self.parser.options(section)
                for option in options:
                    str_val = self.parser.get(section, option)
                    val = ast.literal_eval(str_val)
                    kwargs[option] = val
            return kwargs
        except:
            raise","and error def get_settings_by_section(self, section): """""""""""" section = self.get_settings_by_section(section) if section: return self.get_settings_by_section(section) else: return self.get_settings_by_section(section)","s. def _set_settings(self, section, action_id): """""" """""" try: section_id = self._get_settings(section_id) except KeyError: raise IOError(""Cannot set settings."") try: return section.settings(section_id) except KeyError: raise IOError(""Could not set a section %s"" % section_id)",41.11475522,40.91149683
generate: Receive a PIL Image instance of a JPEG and returns 2-tuple.,"def preprocess_JPEG(self, image, **kwargs):
        """"""
        
        """"""
        save_kwargs = {
            'progressive': VERSATILEIMAGEFIELD_PROGRESSIVE_JPEG,
            'quality': QUAL
        }
        if image.mode != 'RGB':
            image = image.convert('RGB')
        return (image, save_kwargs)","def receive(self, image, **kwargs): """""" """""" if image == 'page': image = self.page elif image == 'jpg': image = self.jpg else: image = self.jpg return self.jpg","def _received_image(self, image, port): """""" """""" if not port: return None port = urllib.get_port_pid(image, port) return port",34.70215239,20.82050001
"generate: Returns names of features. If features is None, returns all    features. Otherwise assumes the user is trying to find the order of the    features.","def get_feature_names(self, features=None):
        """"""   """"""
        if features:
            return self.feature_table.get_ordered_names(features)
        else:
            return self.feature_table.feature_names","If features is None, then features are returned. def get_features(self, features): """""" """""" features = self.get_features(features) return [features[0] for features in self.features]","This features is created to the features. def features(self): """""" """""" if self.current_features is None: return self.current_features else: return self.current_features",60.95201213,60.54642741
generate: Decompose an audio time series into harmonic and percussive components.,"def hpss(y, **kwargs):
    '''

    '''

    # Compute the STFT matrix
    stft = core.stft(y)

    # Decompose into harmonic and percussives
    stft_harm, stft_perc = decompose.hpss(stft, **kwargs)

    # Invert the STFTs.  Adjust length to match the input.
    y_harm = util.fix_length(core.istft(stft_harm, dtype=y.dtype), len(y))
    y_perc = util.fix_length(core.istft(stft_perc, dtype=y.dtype), len(y))

    return y_harm, y_perc","def _decompose(self, session, harmonic, percussive=False): """""" """""" # If the document is available, the harmonic is already available, then we # must be called with the harmonic, we # decompose with the harmonic, we assume that the harmonic # is available, we are done. if percussive: # Decompose with the harmonic, so we # does not exist. # If the harmonic is available, then decompose the harmonic, # then decompose the harmonic, we # decompose, we have the harmonic, we # multiple harmonic and percussive, then decompose # are available, then decompose. # If the harmonic is available, then do not available, # then decompose the harmonic, then decompose, then # does nothing. # This method is passed, the harmonic. # The harmonic is specified, then we # need to decompose the harmonic. # This function will want to compose.","def decompose(self, components, error): """""" """""" # Check for multiple closest closest if offset is done. if components and not self._has_errors: raise error.Unicode(""Unable to decompose decompose."") if self._has_errors: raise error.UnicodeError(""Unable to decompose decompose."") self._has_errors[components] = components self._has_errors[components] = self._has_errors[components] self._has_errors[components] = components self._has_errors[components] = has_errors self._has_errors[components] = has_errors",15.66254405,14.67467419
generate: decorator to store messages that are handled by a checker method,"def check_messages(*messages: str) -> Callable:
    """"""""""""

    def store_messages(func):
        func.checks_msgs = messages
        return func

    return store_messages","to check for just store. def store_check_checker(self, message): """""" """""" # decorator is by an ID self.check_checker(message) self.check_checker(message)",". def store_message(self, message): """""" """""" messages.update(message) self._wrapped_messages[message] = message return messages",37.3316289,45.84128906
generate: Compute the Shannon entropy of a probability vector.,"def shannon_entropy(pvec, base=2):
    """"""
    
    """"""
    # pylint: disable=missing-docstring
    if base == 2:
        def logfn(x):
            return - x * np.log2(x)
    elif base == np.e:
        def logfn(x):
            return - x * np.log(x)
    else:
        def logfn(x):
            return -x * np.log(x) / np.log(base)

    h = 0.
    for x in pvec:
        if 0 < x < 1:
            h += logfn(x)
    return h","def compute_entropy(self, entropy): """""" """""" if self.entropy is not None: return self.entropy else: # If the entropy is computed, compute the Shannon entropy of the probability vector. entropy = self.entropy entropy = self.entropy entropy = self.entropy entropy = self.entropy entropy = self.entropy entropy = self.entropy entropy = self.entropy entropy = self.entropy entropy = self.entropy entropy = self.entropy entropy = self.entropy entropy = self.entropy entropy = self.entropy return entropy","def get_entropy(self): """""" """""" if not self._is_alive: return None entropy = self._expand_entropy(entropy) if entropy.is_alive: return entropy else: return entropy",15.20457455,18.1001927
"generate: Remove all those nodes in the specified list, or if inverse=True,    remove all those nodes not in the specified list. The specified nodes    must be leaves and distinct from the root node.","def prune(self, leaves, inverse=False):
        """"""
        
        """"""
        self.visit(
            lambda n: n.ancestor.descendants.remove(n),
            # We won't prune the root node, even if it is a leave and requested to
            # be pruned!
            lambda n: ((not inverse and n in leaves) or
                       (inverse and n.is_leaf and n not in leaves)) and n.ancestor,
            mode=""postorder"")","If no nodes are found, the root node is inverse, any are removed, the root node is leaved, the root node is inverse, the removed node is added. def remove(self, nodes): """""" """""" nodes = [] for node in nodes: nodes.append(node) if nodes: nodes.append(nodes) return nodes","If there are not in the specified list, so let's need to add any other releases. Use those nodes, the removed list of specified nodes. This is a list of all the following nodes and the lists of another releases. def remove_nodes(self, specified_nodes): """""" """""" # TODO: remove the removed nodes of the removed lists. self._remove_nodes(specified_nodes) self._remove_nodes(specified_nodes)",33.6808597,27.02850193
generate: Constructs a message class and sends the message.  Defaults to sending synchronously. Set send_async=True to send  asynchronously.,"def send(msg_type, send_async=False, *args, **kwargs):
    """"""
    
    """"""
    message = message_factory(msg_type, *args, **kwargs)

    try:
        if send_async:
            message.send_async()
        else:
            message.send()
    except MessageSendError as e:
        err_exit(""Unable to send message: "", e)","def send_message(self, message): """""" """""" if message is not None: self.message = message if message is not None: self.message = message if self.send_async: self.send_async = send_async","def _send_message_cls(self, message, message, loop=None): """""" """""" if message is None: message = 'Method class not found.' raise ValueError(message) else: raise ValueError(message) self.message_cls = message.message_cls() self.message_cls.send_async(message, message) return message.message_cls",40.83774471,37.14969466
"generate: Overwrite HttpHook get_conn because this hook just needs base_url    and headers, and does not need generic params","def get_conn(self, headers=None):
        """"""
        
        """"""
        conn = self.get_connection(self.http_conn_id)
        self.base_url = conn.host if conn.host else 'https://api.opsgenie.com'
        session = requests.Session()
        if headers:
            session.headers.update(headers)
        return session","def _check_connect_connect(self, conn, conn): """""" """""" conn = self.connect(conn) if conn is None: return conn = self.connect(conn) if conn is None: conn = self.connect(conn) self.connect(conn) self.connect(conn) self.connect(conn) self.connect(conn) self.connect(conn) self.connect(conn)",". def validate_conn(self, hook_url, conn): """""" """""" try: self.headers['Conn'] = headers['Connection'] self.headers['Conn'] = conn except Exception as e: raise except Exception as e: self.headers['Connection'] = e except Exception as e: self.headers['Connection'] = e self.headers['Connection'] = hook_url",32.88077032,37.13724996
generate: Create a human-readable representation of a link on the 'TO'-side,"def pretty_to_link(inst, link):
    '''
    
    '''
    values = ''
    prefix = ''
    metaclass = xtuml.get_metaclass(inst)

    for name, ty in metaclass.attributes:
        if name in link.key_map:
            value = getattr(inst, name)
            value = xtuml.serialize_value(value, ty)
            name = link.key_map[name]
            values += '%s%s=%s' % (prefix, name, value)
            prefix = ', '
                
    return '%s(%s)' % (link.kind, values)","nt' link def represent(self, link, link, link_only=False, **kwargs): """""" """""" self.logger.info(""Uncaught representation of %s"", link) return self.represent(link, link, link, link, link, **kwargs)","-WARN. def create_human_readable(self, link, representation): """""" """""" if not representation: return None if not representation: raise ValueError(""representation is not enough library: "" + link) return self._create_representation( link, link, link, representation, self._create_message(representation, link))",11.24416226,17.52731966
generate: Gets the block-size for a given token at a given resolution.,"def get_block_size(self, token, resolution=None):
        """"""
        
        """"""
        cdims = self.get_metadata(token)['dataset']['cube_dimension']
        if resolution is None:
            resolution = min(cdims.keys())
        return cdims[str(resolution)]","def get_block_size(self, resolution, resolution, resolution): """""""""""" block = self.get_block(resolution, resolution) if block is not None: return block if resolution == resolution: return block else: return None","def get_token_size(self, port): """""" """""" url = self._url + '/post/token/token' data = self._get_resolution(port) if data: return self._session.get(url, data) else: return self._session.get(port, None)",54.65300704,44.1370586
generate: Reads dataset to csv.,"def to_json(self, X, y):
        '''
        
        '''
        with gzip.open('%s.gz' % self.path, 'wt') if self.gz else open(
                self.path, 'w') as file:
            json.dump(list(zip(y, X)), file)","def _read_csv(self, csv_file, src_file, loop=None): """""" """""" file_path = self.get_file_path(csv_file, loop=loop) if file_path: file_path = os.path.join(file_path, file_path) return file_path","def read_csv(self, source): """""""""""" dataset = self.get_dataset(source, self.get_column_dataset()) if dataset: for id in dataset: self.read_csv(dataset, id) else: self.read_csv(self.read_csv(dataset)) return dataset",23.43293039,19.4251094
generate: Returns the transaction output information corresponding to a hash and index.,"def get_tx_out(self, tx_hash, index, **kwargs):
        """""" 

        """"""
        return self._call(JSONRPCMethods.GET_TX_OUT.value, params=[tx_hash, index, ], **kwargs)","def transaction(self, transaction=None, **kwargs): """""" """""" return self.transaction.transaction(transaction=transaction, **kwargs)","def update_transaction_output(self, index, transaction_output_data=True): """""" """""" transaction_output = transaction_output.transaction_output(index, transaction_output_data) self.transaction_output(transaction_output) return transaction_output",39.35086013,21.71516987
generate: Get an XPath fragment for this location.,"def xpath_piece(self):
        '''

        '''
        if self.last_tag is TextElement:
            return 'text()[{count}]'.format(count=self.text_index())
        else:
            return '{tag}[{count}]'.format(tag=self.last_tag,
                                           count=self.tags[self.last_tag])","def get_xpath(self, location, fragment, suffix='.xml', **kwargs): """""""""""" if suffix == '.xml': return XPath(self.location, fragment) else: return XPath(self.location, fragment)","def get_xpath(self, path): """""" """""" if not self.is_valid_error(): return None if not self.is_valid(): return None if not self.is_valid_error(): return None return None",28.32789147,23.08124273
generate: Check if a name is declared in this or an outer scope.,"def is_declared(self, name):
        """"""""""""
        if name in self.declared_locally or name in self.declared_parameter:
            return True
        return name in self.declared","def _check_name(self, name): """""""""""" if not self.name in name: raise ValueError(""{0}: {1}"".format(self.name, name)) return self.check_name(name)","def is_declared(self, name): """""""""""" if self.is_declared(): raise error.CommandError(""Argument not found."") return self._declared_declared_declared(name)",48.20969158,57.8317557
generate: Lock a file object 'safely'.,"def lock(fileobj):
    """"""
    """"""

    try:
        import fcntl
    except ImportError:
        return False
    else:
        try:
            fcntl.lockf(fileobj, fcntl.LOCK_EX)
        except IOError:
            # FIXME: There's possibly a lot of complicated
            # logic that needs to go here in case the IOError
            # is EACCES or EAGAIN.
            return False
        else:
            return True","generate: Lock a file object'safely'. def load_safely(self, path, safe_filename=None, loaded=False, page_dir=None, loaded=False): """""" """""" safe_filename = os.path.join(self.safely, safe_filename) if not page_dir: raise ValueError(""Cannot load safe_filename for %s"" % path) return load_safe_filename(path, safe_filename)","generate: Lock a file object'safely'. def _get_file_object_by_path(self): """""" """""" # The path is there is no remote filename, and this is added as the application if self.get_remote_filename().exists(): return self.get_remote_filename() return None",21.47472441,26.38549382
generate: Get available filters from dataset you've selected,"def get_filters(self, dataset):
        """"""""""""
        filters = self.filters(dataset)
        filt_ = [ (k, v[0]) for k, v in filters.items()]
        return pd.DataFrame(filt_, columns=[""Filter"", ""Description""])",". def get_filters(self, filters=None): """""" """""" filters = self.filters filters = self.filters filters = self.filters if filters: return self.filters else: return self.filters","dataset. def get_filters(self, filters): """""""""""" filters = self._get_filters(filters) filters[filters] = filters[filters] return filters",45.95707143,47.34435478
generate: Use a custom function to print the return value.,"def custom_returnvalue(self, printer, desc=None):
        """"""
        """"""
        self.return_info = ReturnInfo(None, printer, True, desc)","def print_arg(self, value, func): """""" """""" # skip functions if self.return_func is not None: func = self.return_func(value, func) return func","def _get_function(self, value): """""" """""" self._fd_functions[value] = value return self._fd_function(value)",40.22593247,34.66004535
generate: Eliminate duplicate arguments by removing the first occurrences.,"def rm_first_of_dup_args(self) -> None:
        """"""
        """"""
        names = set()  # type: set
        for a in reversed(self.arguments):
            name = a.name.strip(WS)
            if name in names:
                del a[:len(a.string)]
            else:
                names.add(name)","def eliminate_arguments(self, arguments): """""""""""" arguments = [] if arguments: arguments.append(arguments) if len(arguments) == 1: arguments.append(arguments) return arguments","def first_remove_frames(self): """""" """""" if self.axis_bottom: return self.frames[0] else: raise ValueError(""Axis is not an instance of frame"")",27.37341668,27.28942377
generate: Matrices are equal if they hash to the same value.,"def _equal_values(self, val1, val2):
        """"""""""""
        if self._is_supported_matrix(val1):
            if self._is_supported_matrix(val2):

                _, _, hash_tuple_1 = self._serialize_matrix(val1)
                _, _, hash_tuple_2 = self._serialize_matrix(val2)

                return hash(hash_tuple_1) == hash(hash_tuple_2)
            else:
                return False
        else:
            return super(SparseParameter, self)._equal_values(val1, val2)","def get(self, value, seconds=None, verbose=True): """""" """""" if not value: return self.get(self.get(seconds=seconds, verbose=verbose)) else: return self.get(self.get(seconds=seconds, verbose=verbose))","def hash_equal(self, value): """""" """""" if not isinstance(value, Iterable): value = value.split("" "") if not isinstance(value, list): value = value.split("" "") if len(value) == 2: return value elif len(value) == 2 and len(value) == 2 and not isinstance(value) == 2 and isinstance(value, Iterable): return value else: return value",19.44009119,32.37751766
"generate: Return a datetime oject from a string, with optional time format.","def get_date(datetime, time_format=None):
    """"""
    
    """"""
    if time_format is None:
        t = du.parser.parse(datetime)
    else:
        t = dt.datetime.strftime(datetime, time_format)
    return t","def datetime(self, date=None, timeout=None): """""" """""" if self._connect: return datetime.datetime( date=date, timeout=timeout, level=10, optional=""DOTABLE"" ) else: return date","def get_datetime_time_time_time_time(self, datetime, tzinfo=None): """""" """""" if self.get_datetime_time_time() >= tzinfo: return self.get_datetime_time_time(datetime, tzinfo=tzinfo) else: return self.get_datetime_time_time()",49.57721146,45.01075191
generate: Create a Webex Teams webhook pointing to the public ngrok URL.,"def create_ngrok_webhook(api, ngrok_public_url):
    """"""""""""
    print(""Creating Webhook..."")
    webhook = api.webhooks.create(
        name=WEBHOOK_NAME,
        targetUrl=urljoin(ngrok_public_url, WEBHOOK_URL_SUFFIX),
        resource=WEBHOOK_RESOURCE,
        event=WEBHOOK_EVENT,
    )
    print(webhook)
    print(""Webhook successfully created."")
    return webhook","def create_webex(self, ngrok_url): """""" """""" if ngrok_url.endswith('/') and ngrok_url.endswith('/') or ngrok_url.endswith('/'): return self.webex_url(ngrok_url) else: return self.webex_url(ngrok_url)","def _get_web_public_name(self, url, no_flag=True): """""" """""" return self._get_web_response_for_request( url, no_flag=no_flag, no_flag=no_flag, no_flag=no_flag, no_flag=no_flag, no_flag=no_flag, public_name=no_flag, public_name=no_flag, )",19.86193747,17.64715508
generate: Conveniently get the security configuration for the specified  application without the annoying 'SECURITY_' prefix.,"def get_config(app, prefix='hive_'):
    """"""
    """"""
    items = app.config.items()
    prefix = prefix.upper()

    def strip_prefix(tup):
        return (tup[0].replace(prefix, ''), tup[1])

    return dict([strip_prefix(i) for i in items if i[0].startswith(prefix)])","def get_security_config(self, **kwargs): """""""""""" security_config = self.security_config(**kwargs) if security_config: return self.get_security_config(**kwargs) else: return self.get_security_config(**kwargs)","def get_application_configuration(self): """""" """""" if not self._application_configuration: return None if self._application_configuration: if self._application_configuration: return self._application_configuration return None",23.91554055,25.84574164
generate: Get a parameter from a layer in the network.,"def find(self, which, param):
        '''
        '''
        for i, layer in enumerate(self.layers):
            if which == i or which == layer.name:
                return layer.find(param)
        raise KeyError(which)","def parameter_from_layer(layer_class): """""""""""" layer_class = layer_class.parameters layer_class.parameters = layer_class.parameters return layer_class","def get_network(self, layer_name, name=None): """""" """""" if layer_name is None: layer_name = 'network' else: layer_name = 'network' return self._get_layer(name, name, name, name)",28.90673055,30.9317114
"generate: callback for stream.on_recv        unpacks message, and calls handlers with it.","def _handle_recv(self, msg):
        """"""
        """"""
        ident,smsg = self.session.feed_identities(msg)
        self.call_handlers(self.session.unserialize(smsg))","def callback(self, on_recv, handlers=None): """""" """""" if on_recv is not None: on_recv = on_recv return self.stream(on_recv, handlers)","def stream(self, message, stream): """""" """""" if self.processes is None: stream = self._callback(message) else: stream = self.callback(message) return self._callback(stream)",35.41679932,30.15740008
generate: Triggers request mock definition methods dynamically based on input  keyword arguments passed to `pook.Mock` constructor.,"def _trigger_request(instance, request):
    """"""
    
    """"""
    if not isinstance(request, Request):
        raise TypeError('request must be instance of pook.Request')

    # Register request matchers
    for key in request.keys:
        if hasattr(instance, key):
            getattr(instance, key)(getattr(request, key))","def get_mock(self, mock, url, key): """""" """""" if not mock.is_base_key(): mock.input = url self.post_mock = mock return key = self.mock_key(key) return mock.input","def add_mock(self, pook, method): """""" """""" if not self._cleanup: self._cleanup_request = False method = self._cleanup_request_method(pook.MOCAPTION_MODE, method) self._cleanup_request(method) else: self._cleanup_request(method)",16.06692803,23.96306056
"generate: The inverse function for erf, the error function.","def erfinv(x, name=""erfinv""):
  """"""
  """"""

  with tf.name_scope(name):
    x = tf.convert_to_tensor(value=x, name=""x"")
    if dtype_util.as_numpy_dtype(x.dtype) not in [np.float32, np.float64]:
      raise TypeError(""x.dtype={} is not handled, see docstring for supported ""
                      ""types."".format(dtype_util.name(x.dtype)))
    return ndtri((x + 1.) / 2.) / np.sqrt(2.)","def function(self): """""" """""" # If the inverse function is not empty, the error is called if self._inverse: self._inverse = True self._inverse = True self.handle = False self.handle = False else: self.handle = True","def _error_err(self, err_type, err_type, required_error): """""" """""" if not isinstance(err_type, (str, (int, bytes, err_type))): raise TypeError(err_type) return self.error_err(err_type, err_type, required_error)",14.8312261,21.94928229
"generate: Given a URL, set or replace a query parameter and return the modified URL.","def set_query_parameter(url, param_name, param_value):
    """"""

    """"""
    scheme, netloc, path, query_string, fragment = urlsplit(url)
    query_params = parse_qs(query_string)

    query_params[param_name] = [param_value]
    new_query_string = urlencode(query_params, doseq=True)

    return urlunsplit((scheme, netloc, path, new_query_string, fragment))","def url_parameter_params(url, url, url, **kwargs): """""""""""" url_params = url.lower() if url_params is None: url_params = url_params if url_params is None: url_params = url_params if url_params is None: url_params = url_params url_params = url_params if url_params is None: url_params = url_params return url_params","def query_params(self, modified_url, replace=True): """""" """""" response = self._request( self.url, params={ 'replacement': replacement, 'replacement': replacement, 'replacement': replacement }, headers=self._headers, headers=self._headers, headers=headers, data=response.headers ) return response.json()",29.6303254,26.76390487
generate: Initialize the widget with the source.,"def init_widget(self):
        """"""  """"""
        d = self.declaration
        if d.source:
            self.set_source(d.source)
        else:
            super(RawComponent, self).init_widget()","def widget(self, widget): """""""""""" if widget.widget is not None: widget.widget = widget else: widget.widget = widget self.widget = widget return self","def widget(self, class_name, *args, **kwargs): """""" """""" if self.type == 'cloud': return self.cloud else: return self.widget(self.type, class_name)",32.67470691,40.90542527
generate: Get the previous sibling in the children list of the parent node.,"def previous_sibling(self, name=None):
        """"""

        """"""
        if name is None:
            return XMLElement(lib.lsl_previous_sibling(self.e))
        else:
            return XMLElement(lib.lsl_previous_sibling_n(self.e,
                                                         str.encode(name)))","def get_sibling_in_parent_node(self, node, node): """""" """""" if node is None: return None if node is None: return node if node is None: return node if node is None: return node return node","def get_child_sibling_list(self): """""" """""" children = list() for child in self.children: children.add_child(child.children[child]) children.add_child(child) return children",37.73215987,24.27909379
"generate: Set the names of columns to be used when iterating through the list,    retrieving names, etc.","def set_filter(self, names=None):
        """"""
        
        """"""
        _names = []
        if names:
            for name in names:
                _safe_name = safe_name(name)
                if _safe_name not in self._column_map:
                    raise GiraffeTypeError(""Column '{}' does not exist"".format(name))
                if _safe_name in _names:
                    continue
                _names.append(_safe_name)
        self._filtered_columns = _names","def set_columns(self, columns): """""" """""" columns = self.columns if not columns: columns = self.columns columns = columns.setdefault('columns', []) for name in columns: if name in columns: continue columns.append(columns[name]) if columns: columns = self.columns return columns","def _set_names(self, names): """""" """""" self._logger.info('Setting names: {0}...'.format(name)) names = self._get_name_names(name) if self._name_names: self._logger.info('Setting names: {0}...'.format(name)) self._set_names(names) self._logger.debug('Setting names: {0}...'.format(name)) self._set_names(names)",38.86005612,45.10866106
generate: open a vcg graph,"def open_graph(self, **args):
        """"""
        """"""
        self._stream.write(""%sgraph:{\n"" % self._indent)
        self._inc_indent()
        self._write_attributes(GRAPH_ATTRS, **args)","from the file or file or filename and return the value. def open(self, filename, **kwargs): """""" """""" # Unlock file with open(filename, 'rb') as f: f.write(self.open(filename, **kwargs)) return f",". def open_graph(self, vcg): """""""""""" self.graph.add_open(vcg, vcg) self.graph.add_open(vcg, vcg)",27.34043889,27.44428191
generate: Create a specification dictionary for this layer.,"def to_spec(self):
        '''
        '''
        spec = dict(**self.kwargs)
        spec.update(
            form=self.__class__.__name__.lower(),
            name=self.name,
            activation=self.kwargs.get('activation', 'relu'),
        )
        return spec","def get_specification_dictionary(self, layer): """""" """""" specification_dictionary = self._get_specification_dictionary_for_layer(layer) layer = layer.get_layer() layer.update_specification_dictionary_for_layer(layer) return layer","def create_dictionary(self, layer): """""""""""" layer.update(layer) layer.update(layer) return self._create_dictionary(layer)",27.600903,21.399078
generate: Return login token info for given user.,"def get_user_token(user, purpose, minutes_valid):
    """"""""""""
    token = ''.join(
        dumps([
            user.get_username(),
            get_auth_hash(user, purpose),
        ]).encode('base64').split('\n')
    )
    return {
        'id': get_meteor_id(user),
        'token': token,
        'tokenExpires': calc_expiry_time(minutes_valid),
    }","def login(self, username, password, password, page=None, **kwargs): """""""""""" self.login(username, password, page=page, **kwargs) return login(username, password, password, **kwargs)","def _get_user(self, user, user): """""" """""" try: username = user.username except AttributeError: username = user.username if username in username: username = username return username",17.95237559,20.63691055
generate: Register a new output formatter.,"def register_new_formatter(cls, format_name, handler, preprocessors=(),
                               kwargs=None):
        """"""

        """"""
        cls._output_formats[format_name] = OutputFormatHandler(
            format_name, preprocessors, handler, kwargs or {})","def register(self, output_formatter): """""""""""" output_formatter = self.formatters.format(output_formatter) output_formatter = self.formatters.format(output_formatter) if output_formatter == 'json': self.output_formatter = output_formatter elif output_formatter == 'training': self.output_formatter = output_formatter","def register_output(self, output_formatter): """""" """""" if self.is_progress(): self.progress_formatter(output_formatter, output_formatter) self.register_output(output_formatter, output_formatter)",24.2059997,41.31719124
generate: Export as a ``cryptography`` certificate.,"def to_cryptography(self):
        """"""
        
        """"""
        from cryptography.hazmat.backends.openssl.x509 import _Certificate
        backend = _get_backend()
        return _Certificate(backend, self._x509)","def export(self, url, **kwargs): """""" """""" if not self.is_cryptography: raise ValueError('cryptography is not cryptography: {}'.format(url)) cryptography = self.cryptography(url, **kwargs) return cryptography","def export_to_certs(cls, certs_to_certs, certs): """""" """""" certs_to_certs = [] for certs_to_certs in cls._certs: if certs_to_certs: certs_to_certs.append(certs_to_certs) return certs_to_certs",32.27983051,21.34277366
generate: Create a Sequence from Iterable s.,"def sequence(s: Iterable) -> ISeq[Any]:
    """"""""""""
    try:
        i = iter(s)
        return _Sequence(i, next(i))
    except StopIteration:
        return EMPTY","def get_sequence(self, iterable, iterable, iterable, iterable): """""""""""" iterable = Iterable(iterable) if iterable.iterable: return iterable return iterable","def iterable_sequence(self, sequence): """""" """""" if self.has_sequence(sequence): return self.iterable_sequence(sequence) else: return self.iterable_sequence(sequence)",35.25686745,34.46952859
generate: The arguments which will be passed to ``url_for``.,"def args(self):
        """"""
        """"""
        if self._args is None:
            return {}
        if callable(self._args):
            return dict(self._args())
        return dict(self._args)","def arguments(self, url_for): """""""""""" url = self.url_for if url_for: url = url_for.url if self.access_token: return url return self","def is_response_for_status(self): """""" """""" if self.api_version: return True else: return False",39.77990811,36.94856042
generate: Convert all tags in an XHTML tree to HTML by removing their  XHTML namespace.,"def xhtml_to_html(xhtml):
    """"""
    """"""
    try:
        xhtml = xhtml.getroot()
    except AttributeError:
        pass
    prefix = ""{%s}"" % XHTML_NAMESPACE
    prefix_len = len(prefix)
    for el in xhtml.iter(prefix + ""*""):
        el.tag = el.tag[prefix_len:]","def _tags_to_tags(self, tags): """""" """""" tags = [tag for tag in self.tags] tags = [tags for tag in self.tags if tag.name] tags = [tags for tag in self.tags if tag.name] return self.tags","def _to_html(self, text): """""" """""" if not text: raise ValueError(""The text is not a valid XHTML "" ""when `text`."") url = 'http://stackoverflow.com/{0}/to_html'.format(text)) data = self._get_body(url) return self._get(url, data, headers=headers)",18.33856569,23.27981016
generate: c-like default of switch statement,"def Default(self, *statements):
        """"""
        """"""
        assert self.parentStm is None
        self.rank += 1
        self.default = []
        self._register_stements(statements, self.default)
        return self",". def cli_default(self): """""""""""" statement = self.default_statement if statement: statement = self.default_statement if statement: statement = self.default_statement if statement: statement = self.default_statement return statement","s. def create_statements(self, statement): """""" """""" if self.switch_active: self.switch_active = True return self.switch_active = True",39.19058932,39.00448045
generate: like `with_objattr` but enter context one by one.,"def with_objattrs(*names):
    '''
    
    '''

    def _wrap(func):

        @functools.wraps(func)
        def wrapper(self, *args, **kwargs):
            with contextlib.ExitStack() as stack:
                for name in names:
                    stack.enter_context(getattr(self, name))
                return func(self, *args, **kwargs)

        return wrapper

    return _wrap","def _create_objattr(self, obj, instance): """""""""""" if obj.is_object_type(): obj = obj.get_object_type() obj.input_manager.append(obj) obj.input_manager.append(obj) else: obj.input_manager.append(obj) return obj","def _get_batches_by_name(self, name, batches_by_name, **kwargs): """""" """""" if not isinstance(batches_by_name, GraphQLBatches): raise ValueError(""Batches cannot get batches: %s"" % batches_by_name) if batches_by_name in self._batches: raise ValueError(""Batches batches: %s"" % batches_by_name) if not batches_by_name: raise ValueError(""Batches: %s"" % batches_by_name) return batches_by_name",18.59177535,20.28571742
generate: Used to check whether the two edge lists have the same edges  when elements are neither hashable nor sortable.,"def equal_ignore_order(a, b):
  """"""
  
  """"""
  unmatched = list(b)
  for element in a:
    try:
      unmatched.remove(element)
    except ValueError:
      return False
  return not unmatched","def _check_two_errors(self, two_edges, edges): """""""""""" if two_edges: return self.check_two_edges(two_edges, edges) else: return self.check_two_edges(two_edges)","def check_edge_lists(self, elements): """""" """""" elements = self.edge_lists(elements) if elements: elements.append(elements) else: elements.append(elements) return elements",25.2843804,28.83993881
generate: Remove all properties matching both key and value.,"def remove_property(self, key=None, value=None):
        """"""
        """"""
        for k, v in self.properties[:]:
            if (key is None or key == k) and (value is None or value == v):
                del(self.properties[self.properties.index((k, v))])","def remove(self, key, value, key=None, keyid=None, value=None, role=None): """""" """""" if value is None: raise ImproperlyConfigurationError(""Key is not None or value is not supported."") self.remove(key, value) self.remove(key, value)","def remove_both_key(self): """""" """""" if self.properties: self.properties = self.properties if not self.properties: self.properties = [self.properties] self.properties = [self.properties for self in self.properties]",48.60404721,43.84603658
generate: Yield all the uninstallation paths for dist based on RECORD-without-.pyc,"def uninstallation_paths(dist):
    """"""
    
    """"""
    from pip.utils import FakeFile  # circular import
    r = csv.reader(FakeFile(dist.get_metadata_lines('RECORD')))
    for row in r:
        path = os.path.join(dist.location, row[0])
        yield path
        if path.endswith('.py'):
            dn, fn = os.path.split(path)
            base = fn[:-3]
            path = os.path.join(dn, base + '.pyc')
            yield path","p def _cp_install_dist(self): """""""""""" if not os.path.isdir(self.install_dist): return # Find the XML files for Windows for root, dirnames, files in self.files: for path in files: if not os.path.isfile(path): return # Split the files for file in self.files: for path in files: if file.endswith("".py""): yield path","'s endpoint. def on_paths(self, dist, paths): """""""""""" paths = os.path.join(dist, dist) if not os.path.isdir(paths): raise InvalidDistError(""Distribution %s not found"" % paths) for name in self.root.list_list(paths): if not os.path.exists(path): os.makedirs(dir) return self.retrieve_dir(paths)",34.57069106,36.8470819
generate: create an empty record,"def _defaults(self, keys=None):
        """"""""""""
        d = {}
        keys = self._keys if keys is None else keys
        for key in keys:
            d[key] = None
        return d","in a ``EmptyResult``. def create_record_record_record(self, record, scope=None): """""" """""" if scope is None: scope = None if scope is None: scope = None if scope is None: scope = None return self.record_record_record",". def create(self, mode, record): """""" """""" if not self._record_id: return url = self._url_url(mode, record) record = self._get(""record"") record.update(record) if not self._record_id: record.update(self._record_id) return self._create(url)",28.04841577,17.68064985
generate: Generate the time in seconds in which DHCPDISCOVER wil be retransmited.,"def gen_timeout_resend(attempts):
    """"""

    """"""
    timeout = 2 ** (attempts + 1) + random.uniform(-1, +1)
    logger.debug('next timeout resending will happen on %s',
                 future_dt_str(nowutc(), timeout))
    return timeout","def _time_seconds_time_seconds(self): """""" """""" if self.time_seconds is None: time_seconds = self.time_seconds return datetime.time_seconds(time_seconds)","def dhook(self, dhook_token, timeout=100): """""" """""" try: session = self.session.get_session(dhook_token, timeout=timeout) return session.timeout.delete_timeout(session) except Exception as e: raise MissingDhook(""Server down disk"")",21.1235679,33.20720705
generate: Multiply tensor of vectors by matrices.,"def _vector_matrix(vs, ms):
  """"""""""""

  return tf.reduce_sum(input_tensor=vs[..., tf.newaxis] * ms, axis=-2)","def tensor(self, tensor, matrix): """""""""""" tensor = tensor(tensor) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix = vector_matrix(matrix) matrix =","def _maybe_matrices(self): """""" """""" if not self._matrices: return self._matrices return np.asarray(self._matrices)",4.680925827,25.64065143
generate: Is distribution `dist` acceptable for this environment?,"def can_add(self, dist):
        """"""
        """"""
        return (self.python is None or dist.py_version is None
            or dist.py_version==self.python) \
            and compatible_platforms(dist.platform, self.platform)","def distribute(self, environment): """""""""""" dist = self.distribute(environment) if dist.is_acceptable(): return dist raise Exception('Distribute distribution `%s` does not exist' % environment)","def _get_dist_detail_by_dist_name(self, dist, dist): """""" """""" if dist in self.dist: return self.dist else: return None",29.44755108,30.4822775
generate: Open file and confirm if it is a filterbank file or not.,"def is_filterbank(filename):
    """"""  """"""
    with open(filename, 'rb') as fh:
        is_fil = True

        # Check this is a blimpy file
        try:
            keyword, value, idx = read_next_header_keyword(fh)
            try:
                assert keyword == b'HEADER_START'
            except AssertionError:
                is_fil = False
        except KeyError:
            is_fil = False
        return is_fil","def open(self, filterbank_file, **filterbank_files): """""" """""" filterbank_file = self._filename(filterbank_file, **filterbank_files) if not filterbank_file: return try: filename = self._filename(filterbank_file) except OSError: return # read the file try: filename = os.path.join(self.filename, filterbank_file) except OSError: return # For IOLicentic file, return the file try: return self._filename(filterbank_file) except OSError: return","def _close_file(filename, filter_file): """""" """""" filter_file = filename.replace('.', '.') if not os.path.exists(filter_file): filter_file = FilterBankfile(filename, filter_file) else: filter_file = filename return filter_file",29.37988561,27.73150691
generate: Creates a `tf.Tensor` suitable to hold `k` element-shaped tensors.,"def _make_empty_queue_for(k, element):
  """"""
  """"""
  queue_shape = tf.concat(
      [[k], distribution_util.prefer_static_shape(element)], axis=0)
  return tf.zeros(queue_shape, dtype=element.dtype.base_dtype)","def sort_tensors(self, tf, dtype=None): """""""""""" tf.Tensor(tf) if dtype is None: dtype = dtype if dtype is None: dtype = dtype if dtype is None: dtype = dtype return tf","def _get_k(self, tf, tensors, data, tensors): """""" """""" if data and self._is_tensor_suitable(): self._is_tensor(tensors, data) else: self._is_tensor(tensors, data) return tf",25.07959383,22.16187758
generate: Creates an fcs file for a given tdms file,"def tdms2fcs(tdms_file):
    """"""""""""
    fcs_file = tdms_file[:-4]+""fcs""
    chn_names, data = read_tdms(tdms_file)
    chn_names, data = add_deformation(chn_names, data)
    fcswrite.write_fcs(filename=fcs_file,
                       chn_names=chn_names,
                       data=np.array(data).transpose())","def create_fcs_file(self, tdms, fcs_file, fc_file=None): """""" """""" fcs_file = os.path.join(fcs_file, fcs_file) self.fcs_file = fcs_file self.fcs_file = fcs_file self.fcs_file = fcs_file self.fcs_file = fcs_file",". def create_tdms(self, tdms, tdms): """""" """""" tdms_file = os.path.join(tdms, tdms) if not os.path.isdir(tdms): raise ValueError(""Template does not exists"") tdms_file = os.path.exists(tdms) tdms_file.setLemplate(tdms) self._tdms_file.setLemplate(tdms)",30.53465685,30.47575246
generate: Prettifies the dictionary of metrics.,"def prettify_metrics(metrics: List[Tuple[str, float]], precision: int = 4) -> OrderedDict:
    """"""""""""
    prettified_metrics = OrderedDict()
    for key, value in metrics:
        value = round(value, precision)
        prettified_metrics[key] = value
    return prettified_metrics","def _metric_metrics(self, dictionary): """""" """""" # Get the dictionary of dictionary for the metric. metrics = dictionary.get(self._metric_metric_metric_dictionary, {}) # Create the URL # URL # Get the metric metric metric by the metric. url = self.url_base(dictionary, dictionary) return url","def pretty_metrics(self, metrics, metrics, position, last_position, description): """""" """""" if metrics.is_valid(): metrics.update(metrics.get('last_position')) return metrics.get('metrics', {}).get('metrics', {}).get('metrics', {})",28.35292801,33.25598672
generate: Set the name of all leaf nodes in the subtree to None.,"def remove_leaf_names(self):
        """"""
        
        """"""
        self.visit(lambda n: setattr(n, 'name', None), lambda n: n.is_leaf)","def set_leaf_nodes(self): """""" """""" if self.leaf_nodes: self.leaf_nodes = [] self.set_leaf_nodes_in_nodes(self.leaf_nodes)","def setup_leaf_nodes(self, tree): """""" """""" if tree.node_id not in self._leaf_nodes: return None else: return self._leaf_nodes[tree.node_id]",34.12327613,31.55734114
generate: Runs the full turntable process on a pandas DataFrame,"def spin_frame(df, method):
    ''' 
    
    

    '''
    collection = build_collection(df)
    collection = turntable.spin.batch(collection, method)
    return collection_to_df(collection)",". def run_full_turntable(self, full_turntable, quiet, **kwargs): """""" """""" t = self.table t.table = quiet t.table = t t.quiet = quiet t.quiet = quiet t.quiet = quiet t.quiet = quiet return t",". def _find_full_tripletable_tripletable_tripletable_tripletable( dataframe_tripletable, pandas_dict): """""" """""" if not isinstance(dataframe_tripletable, (list, tuple)): dataframe_tripletable = dataframe_tripletable return dataframe_tripletable",17.32259108,13.11531327
generate: Reset auth_attempted on redirects.,"def _handle_redirect(self, r, **kwargs):
        """"""""""""
        if r.is_redirect:
            self._thread_local.auth_attempted = False","def reset_attempt(self, redirect_attempt=None): """""""""""" if redirect_attempt is not None: self.reset_attempt(redirect_attempt) self.attempt = self.attempt","def reset_redirects(self): """""""""""" try: self._auth_attempted = True except IOError as e: self._auth_attempted = False return self._auth_attempted",36.33309503,39.70790073
generate: return an iterator on options grouped by section,"def options_by_section(self):
        """"""
        """"""
        sections = {}
        for optname, optdict in self.options:
            sections.setdefault(optdict.get(""group""), []).append(
                (optname, optdict, self.option_value(optname))
            )
        if None in sections:
            yield None, sections.pop(None)
        for section, options in sorted(sections.items()):
            yield section.upper(), options","def get_section_options(self, section): """""""""""" section_options = { 'section': 'SELECT iterator on PATH:', 'section_options': section, 'section_options': section, 'options': options, 'section_options': section, 'required_section_options': self.required_section_options, } return self._get_section_options(section_options)","s. def iterate(self, iterate, start=None): """""" """""" self._iterate_iterates( self._marker_options, self._marker_options, self._marker_options, self._marker_options, self._marker_options, self._marker_options, self._marker_options, self._marker_options, self._marker_options, )",44.62420262,30.28811798
generate: Calculates the dual Csiszar-function in log-space.,"def dual_csiszar_function(logu, csiszar_function, name=None):
  """"""
  """"""

  with tf.compat.v1.name_scope(name, ""dual_csiszar_function"", [logu]):
    return tf.exp(logu) * csiszar_function(-logu)","def dual_dual_factor_func(self): """""" """""" filter_func = self.filter_func_region filter_func = self.filter_func_region return filter_func(self.filter_func)","def dual_csiszar(self, function): """""" """""" csis = self._csiszar_function(function) if not csis: return None if csis: return self._csiszar_function(csis) else: return function",29.89057248,50.22301677
generate: Give the current session a name in the history database.,"def name_session(self, name):
        """"""""""""
        with self.db:
            self.db.execute(""UPDATE sessions SET remark=? WHERE session==?"",
                            (name, self.session_number))","def session_name(self, name): """""""""""" if self.is_session(name): return self.session_name(name) else: return self.session_name(name)","def get_session_session_name(self, history_name, name=None): """""" """""" return self._get_session_name(history_name)",52.00828228,37.69293117
generate: Returns the components of a polyline.,"def proc_polyline(self, tokens):
        """"""  """"""

        pts = [(p[""x""], p[""y""]) for p in tokens[""points""]]
        component = Polyline(pen=self.pen, points=pts)

        return component","def polyline(self, components, polyline): """""""""""" if self.polyline: return components return components","def get_components(self): """""" """""" # Map the polyline self.components.remove(self.poolyline) self.poolyline = None self.polyline.remove(self.poolyline)",39.66374458,38.78541833
generate: highest valid lockset on height,"def last_valid_lockset(self):
        """"
        for r in self.rounds:
            ls = self.rounds[r].lockset
            if ls.is_valid:
                return ls
        return None","def _valid_lockset(self, lockset): """""""""""" if not self._lock: raise ValueError('No lock set found') self.lock = self.lock self.lock.lock = self.lock self.lock.lock.acquire()","of the root, any on the regions. def any_lock(self, clean_file): """""" """""" self._lock.acquire() self._lock.addHigher('SELET_CLETED_HIMEST', clean_file) self._lock.acquire()",33.52507864,19.61420347
generate: Handles saving the current model to the last file.,"def save(self, info):
        """""" 
        """"""
        save_file = self.save_file

        if not isfile(save_file):
            self.save_as(info)
        else:
            fd = None
            try:
                fd = open(save_file, ""wb"")
                dot_code = str(self.model)
                fd.write(dot_code)
            finally:
                if fd is not None:
                    fd.close()","def handle(self): """""" """""" # Like the fields if self.model is None: return # Get all files for file in self.model: if file.is_file: fields = file.get_fields(field.get_fields()) if fields is not None: fields.append(fields) else: fields.append(fields) return fields","def handle_save_save(self, model): """""" """""" # First, let's something we restore to avoid according to the # them, so that there is necessary to assume additionality # the last restore. self.save_save(model) self.save_save(model) self.save_save(model)",38.90538345,34.59701954
generate: Search the file for any magic incantations.,"def find_magic_in_file(filename):
    """"""
    
    """"""
    with open(filename, ""rt"", encoding=""utf-8"") as f:
        for line in f:
            if line.startswith(""#""):
                comment = line[1:].strip()
                if comment.startswith(""~~~~* "") or comment.startswith(""----* "") or comment.startswith(""====* ""):
                    spell = comment[5:].strip()
                    return tuple(spell.split())
            else:
                break
    return None","def file_for_search(self, filename, magic_name, page, incant_filename=None, save_filename=None): """""""""""" file_for_search = self.file_for_search_filename(filename) magic_name = self.file_for_search_filename(filename, magic_name, save_filename) file_for_search_filename = self.file_for_search_filename(filename) if file_for_search_filename is None: file_for_search_filename = self.file_for_search_filename(filename, magic_name, save_filename) return file_for_search_filename","def file_search(filename, refresh_file=False): """""" """""" with open(filename, 'rb') as f: filename = f.read() if not os.path.isdir(filename): filename = filename.replace(""."", '') if not os.path.isfile(filename): raise ValueError(""Could not find file %s"" % filename) if not os.path.isdir(filename): raise ValueError(""Could not find filename."") f.write(filename) filename = os.path.join(filename, refresh_file) if not os.path.isdir(filename): return False return True",18.52476196,26.28294881
generate: Removes all breakpoints at a give filename and line number.    Returns a list of breakpoints numbers deleted.,"def delete_breakpoints_by_lineno(self, filename, lineno):
        """"""
        """"""
        if (filename, lineno) not in self.bplist:
            return []
        breakpoints = self.bplist[(filename, lineno)]
        bpnums = [bp.number for bp in breakpoints]
        for bp in list(breakpoints):
            self.delete_breakpoint(bp)
        return bpnums","Returns a list of breakpoints in an unique breakpoints. def unique_breakpoints_delete(self, breakpoints, number): """""" """""" breakpoints = [] for breakpoint in breakpoints: if breakpoint in breakpoints: breakpoints.append(breakpoint) return breakpoints","def remove_breakpoints(self, breakpoints): """""" """""" breakpoints = [ (self.name, breakpoints) for breakpoint in self.get_breakpoints(breakpoints) if not breakpoints.is_breakpoints(breakpoint) ] return breakpoints",47.98313421,43.90112198
generate: Gets the latest state of a long-running operation in Google Storage    Transfer Service.,"def get_transfer_job(self, job_name, project_id=None):
        """"""
        
        """"""
        return (
            self.get_conn()
            .transferJobs()
            .get(jobName=job_name, projectId=project_id)
            .execute(num_retries=self.num_retries)
        )","It returns an IPython StorageServiceServices that are required. def get_operation_state(self, state, service_name, name=None): """""" """""" service_name = self.get_service_name(state) return service_name.get(state)","def get_state_state(self): """""" """""" if not self._state_storage_exists: return self._state_storage_state if self._state_storage_state: return self._state_storage_state return None",34.83654442,26.36890776
generate: Add controls to this gate.,"def q_if(self, *qregs):
        """"""""""""
        self.data = [gate.q_if(qregs) for gate in self.data]
        return self","def add(self, controls, **kwargs): """""""""""" try: controls = self.controls except KeyError: controls = self.controls if controls is None: return controls return controls","def add_controls(self, name, value): """""" """""" if self._controls is not None: if value not in self._controls: self._controls[key] = value return self._controls[key]",24.66558723,27.30155856
generate: Fetch the concept from the Knowledge base,"def get_concept(self, conceptId, lang='en'):
        """""" 
        """"""
        url = urljoin(self.concept_service + '/', conceptId)

        res, status_code = self.get(url, params={'lang': lang})

        if status_code != 200:
            logger.debug('Fetch concept failed.')

        return self.decode(res), status_code",". def get_concept(self, concept_base=None, concept_base=None): """""" """""" if not concept_base: concept_base = self.get_concept(concept_base) return self.get_concept(concept_base=concept_base, concept_base=concept_base)",". def fetch_concept_to_concept_to_concept(self, concept): """""" """""" if not self.concept: raise NotFoundError(""Could not find concept"") else: self.concept = self.concept(concept) self.concept = concept self.concept = self.concept return self.concept(self.concept, self.concept)",38.08787699,38.52884214
generate: Generate single qubit pauli at index with pauli_label with length num_qubits.,"def pauli_single(cls, num_qubits, index, pauli_label):
        """"""
        
        """"""
        tmp = Pauli.from_label(pauli_label)
        z = np.zeros(num_qubits, dtype=np.bool)
        x = np.zeros(num_qubits, dtype=np.bool)

        z[index] = tmp.z[0]
        x[index] = tmp.x[0]

        return cls(z, x)","def __qubit_qubits(self, index, pauli_label, pauli_label, **kwargs): """""" """""" if isinstance(index, str): return self.qubit_qubits(index, pauli_label, pauli_label, pauli_label, pauli_label, **kwargs) else: return self.qubit_qubits(index, pauli_label, pauli_label, pauli_label, pauli_label, pauli_label, **kwargs)","def __single_qubit(self, pauli_number, start_date=1): """""""""""" return self._client.query( self.url, pauli_number, self._qubits, pauli_number, start_date=start_date, start_date=start_date, start_date=start_date, end_date=end_date, )",31.32498317,28.74014817
"generate: Returns the user's current cart, or creates a new cart    if there isn't one ready yet.","def for_user(cls, user):
        '''  '''

        try:
            existing = commerce.Cart.objects.get(
                user=user,
                status=commerce.Cart.STATUS_ACTIVE,
            )
        except ObjectDoesNotExist:
            existing = commerce.Cart.objects.create(
                user=user,
                time_last_updated=timezone.now(),
                reservation_duration=datetime.timedelta(),
            )
        return cls(existing)","def cart(self): """""" """""" if self.parent: # create an object if self.parent: return self.create_object(self.parent) return self.create_object(self.parent) else: return self.create_object(self.parent)","def get_current_cart(self, cart_path): """""" """""" user_req = self._create_cart(cart_path) cart_cart_cart = user_req.get(""cart"") cart_cart = user_req.get(""cart"") if cart_cart_cart: return cart_cart else: return cart_cart",15.30950984,15.88347891
generate: Converts a DOE CODE .json file into DOE CODE projects  Yields DOE CODE records from a DOE CODE .json file,"def process_json(filename):
    """"""
    
    """"""

    logger.debug('Processing DOE CODE json: %s', filename)

    doecode_json = json.load(open(filename))

    for record in doecode_json['records']:
        yield record","generate: Converts a DOE CODE.json file into DOE CODE projects Yields DOE CODE records from a DOE CODE.json file. def _to_doe_json(doe_json): """""" """""" doe_json = json.dumps(doe_json) return doe_json","generate: Converts a DOE CODE.json file into DOE CODE projects Yields DOE CODE records from a DOE CODE.json file. def domain(cls, file_name, file_name, root_file): """""" """""" url = file_name or '' project = '{}/projects/{}'.format(root_file, file_name) response = cls._session.request(url, url, data=json.dumps(response)) return response.json()",39.96452169,25.1232419
"generate: Set the autoindent flag, checking for readline support.","def set_autoindent(self,value=None):
        """"""""""""

        if value != 0 and not self.has_readline:
            if os.name == 'posix':
                warn(""The auto-indent feature requires the readline library"")
            self.autoindent = 0
            return
        if value is None:
            self.autoindent = not self.autoindent
        else:
            self.autoindent = value","def set_autoindent_flag(self, flag, flag, flag, flag, flag): """""" """""" if not flag: return flag = self.flag if flag == flag: return if not flag: return if flag: return # Remove lines self.set_flag(flag, flag, flag, flag, flag) return return","def autoindent_flag(self, utoindent_flag, utoindent_flag): """""" """""" if utoindent_flag.is_read_print_exception(): return if utoindent_flag.is_read_flag: raise RuntimeError(""The utoindent_flag is not autoindent."") self._validate_flag(utoindent_flag, utoindent_flag)",29.83193225,40.18759978
generate: Return a Python AST Node for a `recur` expression.,"def _recur_to_py_ast(ctx: GeneratorContext, node: Recur) -> GeneratedPyAST:
    """"""""""""
    assert node.op == NodeOp.RECUR
    assert ctx.recur_point is not None, ""Must have set a recur point to recur""
    handle_recur = _RECUR_TYPE_HANDLER.get(ctx.recur_point.type)
    assert (
        handle_recur is not None
    ), f""No recur point handler defined for {ctx.recur_point.type}""
    ctx.recur_point.has_recur = True
    return handle_recur(ctx, node)","def get_recur(self, recur): """""""""""" # FIXME: We'll add the JSON? if not recur: return self.get_recur(self.recur) # We've finish the python AST Node for an OS if not self.is_recur: return self.get_recur # FIXME: We'll add the JSON? if not self.is_recur: return self.get_recur # FIXME: We'll add the JSON? if not self.is_recur: return self.get_recur # We'll add the JSON? if not self.is_recur: return self.get_recur # FIXME: We'll add the JSON? if self.is_recur: return self.get_recur # FIXME: We'll add the JSON? if self.is_recur: return self.get_recur # FIXME: We'll add the JSON? if not self.is_recur: return self.get_recur # FIXME: We'll add the JSON? if self.is_recur: return self.get_recur # FIXME: We'll add the JSON? if self.is_recur: return self.get_recur # FIXME: We","def python_expression(self, recursive=False, skip_expression=True): """""" """""" if self._expression: raise ValueError(""Unable to pylint: no coveraged recursive: %s"" % (recursive, skip_expression)) if skip_expression: recursive = self._get_recursive_recursive_recursive_recursive(recursive, skip_expression) else: recursive = self._get_recursive_recursive_recursive(recursive, skip_expression) if self._expression_recursive: # This is an expression on the expressions recursive_recursive = self._get_recursive_recursive_recursive_recursive(recursive) return self._get_recursive_recursive_recursive_recursive(recursive_recursive, recursive_recursive)",16.8666063,18.16571091
generate: Get maximum _instId from all assigments in statement,"def getMaxStmIdForStm(stm):
    """"""
    
    """"""
    maxId = 0
    if isinstance(stm, Assignment):
        return stm._instId
    elif isinstance(stm, WaitStm):
        return maxId
    else:
        for _stm in stm._iter_stms():
            maxId = max(maxId, getMaxStmIdForStm(_stm))
        return maxId","s. def get_assignments(self, statements): """""" """""" if statements: if not isinstance(statements, basestring): raise TypeError(""Expected a Future instance, but instId"") statements = [statement for statement in statements] return self.get_assignments(statements)","s. def _get_assignments(self, query, assignment_types): """""" """""" assignments = self._get_assignments() if self._assignment_types: return self._get_assignments(assignment_types) else: return self._get_assignments(assignment_types)",34.82530483,26.80155327
generate: Get all the boards for this organisation. Returns a list of Board s.,"def get_boards(self, **query_params):
        '''
        
        '''
        boards = self.get_boards_json(self.base_uri, query_params=query_params)

        boards_list = []
        for board_json in boards:
            boards_list.append(self.create_board(board_json))

        return boards_list","def get_boards(self, boards): """""" """""" boards = [] boards = [] for board in boards: board = self.get_boards(board) board = self.get_boards(board) board.append(board) return boards","def get_board_s(self): """""" """""" board_s = self.get_board_s(self.board_s) board_s = [] for board_s in board_s: board_s.append(board_s) return board_s",50.81892335,42.9862655
generate: Emits an event if there are any subscribers.,"def dispatch(self, event, *args, **kwargs):
        """"""
        """"""
        # No event, no subscribers.
        if event not in self._subscribers:
            return

        for subscriber in self._subscribers[event]:
            subscriber.callback(*args, **kwargs)","def event(self, subscribers): """""" """""" if subscribers == []: subscribers = [] for subscriber in subscribers: subscribers.append(subscribers) for subscriber in subscribers: subscribers.append(subscribers) return subscribers","def _create_subscribers(self, event): """""" """""" if event.get('success'): event.set('success') else: event.set('success') event.set('success') event.set('success') return event",48.01002181,32.43907195
generate: Encode a dataset using the hidden layer activations of our network.,"def encode(self, x, layer=None, sample=False, **kwargs):
        '''
        '''
        enc = self.feed_forward(x, **kwargs)[self._find_output(layer)]
        if sample:
            return np.random.binomial(n=1, p=enc).astype(np.uint8)
        return enc","def encode(self, layer, layer): """""" """""" layer = self._encode(layer) layer = self._encode(layer) layer = self._encode(layer) layer.flush() return layer","def encode(self, dataset, mode='uf-8', end='utf-8', **kwargs): """""" """""" dataset = self.fetchone() if end == 'true': raise IOError( 'Unable to encoded dataset for mode ""%s"".' % ( end, self.encode(dataset))) return self.encode(dataset, **kwargs)",28.0068901,34.86916512
generate: Converts a human-readable timestamp into a Python ``DateTime`` object,"def human_timestamp_to_datetime(human_timestamp, to_utc=False):
    """"""
    
    """"""

    settings = {}

    if to_utc:
        settings = {""TO_TIMEZONE"": ""UTC""}

    return dateparser.parse(human_timestamp, settings=settings)",". def _timestamp_to_date(self, human_time): """""" """""" human_time = datetime.datetime.fromtimestamp(human_time) return datetime.datetime.today()",". def python_readable_timestamp(self, human_readable, timestamp_bar): """""" """""" if human_readable: return self.cloud_update(human_readable, timestamp_bar) else: return self.cloud_update(human_readable, timestamp_bar)",42.44355461,39.50510854
generate: Get the cast & crew credits for a TV season by season number.,"def credits(self, **kwargs):
        """"""
        
        """"""
        path = self._get_series_id_season_number_path('credits')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","def get_cast_credits(self, season_number): """""""""""" cast_credits = self.get_cast_credits(season_number) cast_credits = self.get_cast_credits(season_number) return cast_credits","def get_cast_cancel(self, season_number): """""""""""" try: return season_number.get(season_number, 1) except TypeError: raise ValueError('These argument must be a list of type ' 'one of type ' 'int84.')",42.30319976,28.10929813
generate: wrap `with obj` out of func.,"def with_it(obj):
    '''
    
    '''

    def _wrap(func):

        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            with obj:
                return func(*args, **kwargs)

        return wrapper

    return _wrap","def wrap(self, obj): """""" """""" def wrapper(*args, **kwargs): return obj(*args, **kwargs) return wrapper","def wrap_to_func(func, *args, **kwargs): """""" """""" if not func: raise ValueError(""Argument must be a valid function"") func(func.__name__) func(func.__name__, *args, **kwargs) return func",44.67840848,39.73970486
generate: Creates a new instance of the configured executor if none exists and returns it,"def get_default_executor():
    """"""""""""
    global DEFAULT_EXECUTOR

    if DEFAULT_EXECUTOR is not None:
        return DEFAULT_EXECUTOR

    executor_name = configuration.conf.get('core', 'EXECUTOR')

    DEFAULT_EXECUTOR = _get_executor(executor_name)

    log = LoggingMixin().log
    log.info(""Using executor %s"", executor_name)

    return DEFAULT_EXECUTOR",". def new_instance(self, executor): """""""""""" if not executor.is_valid(): return self.instance if executor.is_valid(): return self.instance return self.instance","'s namespace. def get_executor_exists(self): """""""""""" if self.has_executor_exists(self.response_type, self.has_executor_exists): if self.has_executor_exists(self.response_type, self.has_executor_exists): return self.response_type.get_executor_exists(self.response_type, self.has_executor_exists) else: return None",16.19336815,32.44252966
"generate: a function for the client to announce him or herself, depending      on the level specified. If you want your client to have additional      announced things here, then implement the class `_speak` for your      client.","def speak(self):
        '''
           

        '''
        if self.quiet is False:
            bot.info('[client|%s] [database|%s]' %(self.client_name,
                                                   self.database))

            self._speak()","def __speak(self, speak, client): """""""""""" if client.has_speak: return client return speak","def _get_client(self, client_id): """""" """""" self._request(""get_client"", self._client_id, client_id) return client_id",23.43796889,24.3824184
generate: Finds the class folders in a dataset.,"def _find_classes(self, dir):
        """"""
        
        """"""
        if sys.version_info >= (3, 5):
            # Faster and available in Python 3.5 and above
            classes = [d.name for d in os.scandir(dir) if d.is_dir()]
        else:
            classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]
        classes.sort()
        class_to_idx = {classes[i]: i for i in range(len(classes))}
        return classes, class_to_idx","def get_class_folders(dataset, class_folders, class_folders): """""" """""" class_folders = class_folders class_folders = [] class_folders.append(class_folders) for class_folders in class_folders: for class_folders in class_folders: if isinstance(class_folders, dict): class_folders.append(class_folders) return class_folders","def folders(self, dataset_id, dataset_id, class_name): """""" """""" dataset_id = self._get_class_dataset_id(dataset_id, dataset_id, class_name, class_name) if not dataset_id: raise InvalidClassNotFoundException( 'Class %s must be found.' % (dataset_id, class_name)) return self._folders.get_object(dataset_id, class_name, class_name, dataset_id)",30.85443878,30.01842298
"generate: Escape the error, and wrap it in a span with class ``error-message``","def default_formatter(error):
    """"""""""""
    quoted = formencode.htmlfill.escape_formatter(error)
    return u'<span class=""error-message"">{0}</span>'.format(quoted)",". def escape(self, error=None, message=None): """""""""""" self.escape(error) self.escape(error) self.escape(message) self.escape(error)",". def _assert_error_message(error_message, message): """""" """""" if not validate_error_message(): return False else: if message.status_code == 'UNSOURC': return False else: return False",29.9778521,26.19545115
generate: Set an exception for the TransferFuture,"def set_exception(self, exception, override=False):
        """"""
        """"""
        with self._lock:
            if not self.done() or override:
                self._exception = exception
                self._status = 'failed'",". def set_exception_for_error(self, error): """""""""""" if error: raise TransferFutureException(error) self.set_exception_for_error(error) self.set_exception_for_error(error)",". def set_error_exception(self, text): """""" """""" self._error_exception_err(text) self._error_exception = text self._error_err(text) self._error_err(text) return True",44.14888738,50.15962594
generate: A unittest suite for one or more doctest files.,"def DocFileSuite(*paths, **kw):
    """"""
    """"""
    suite = unittest.TestSuite()

    # We do this here so that _normalize_module is called at the right
    # level.  If it were called in DocFileTest, then this function
    # would be the caller and we might guess the package incorrectly.
    if kw.get('module_relative', True):
        kw['package'] = _normalize_module(kw.get('package'))

    for path in paths:
        suite.addTest(DocFileTest(path, **kw))

    return suite","def unittest_files(self, suite_files, doctest_files, tuning_files): """""""""""" fname = '%s.%s' % (suite_files, tuning_files) if not fname: fname = fname + '.' + fname + '.' if not os.path.isfile(fname): return None doctest_files = [] for filename in files: if fname == fname: doctest_files.append(fname) doctest_files.append(doctest_files) if not os.path.isfile(fname): return None return None","def _doctest_files(filename, doctest_files): """""" """""" if not os.path.isdir(filename): os.makedirs(filename) if not os.path.isdir(filename): raise ValueError(""Error "" + str(filename)) if not os.path.isdir(filename): raise ValueError(""Error %s"" % filename) if not os.path.exists(filename): os.makedirs(filename) if not os.path.isdir(filename): raise ValueError(""Error must be a filename or filename."") try: finally: os.makedirs(filename) os.makedirs(filename) return os.path.join(doctest_files, filename)",22.34773926,16.30799268
generate: Return True if this is part of a multiline statement.,"def multiline_statement(line, previous_line=''):
    """"""""""""
    for symbol in '\\:;':
        if symbol in line:
            return True

    sio = io.StringIO(line)
    try:
        list(tokenize.generate_tokens(sio.readline))
        return previous_line.rstrip().endswith('\\')
    except (SyntaxError, tokenize.TokenError):
        return True","def is_part(self, statement): """""""""""" if statement is not None: if self.statement is not None: if self.statement is not None: if self.statement is not None: return True else: return True else: return True","def _is_multiline_statement(self): """""" """""" if self.status == 'GET' and self.is_print: return False elif self.status == 'GET' and self.is_print: return True elif self.is_print(): return True elif self.is_print: return False elif self.is_print: return False else: return False",25.879676,32.74628861
generate: Returns the exception's name in an AMP Command friendly format.,"def asAMP(cls):
        """"""
        
        """"""
        parts = groupByUpperCase(cls.__name__)
        return cls, ""_"".join(part.upper() for part in parts)","def get_error_code(command): """""" """""" try: if command == ""true"": return command except IOError: return ""Error: No AMP Command found in the file""","def _get_error(self): """""" """""" if self._error is None: return False if self._error is None: return False return False",23.06173603,24.89188378
generate: Concatecate all log file into a summary text file to be sent to users  at the end of a daily log scraping.,"def update_summary_file():
    """"""
    
    """"""
    global g_summary_text_filename
    global g_output_filename_failed_tests
    global g_output_filename_passed_tests

    with open(g_summary_text_filename,'a') as tempfile:
        write_file_content(tempfile,g_output_filename_failed_tests)
        write_file_content(tempfile,g_output_filename_passed_tests)","def text_file(file_name, full_file=None): """""" """""" text_file = file_name + '.log' if os.path.exists(full_file): text_file = tempfile.name if os.path.exists(full_file): text_file = tempfile.name text_file = tempfile.NamedTemporaryFile(full_file) text_file.seek(0) text_file.seek(0) return text_file","def _concate_file_file_file(filename, filename): """""" """""" logging.debug('Concating file %s...', filename) try: file_file = os.path.join(filename, filename) except OSError as exception: if exception.errno == 200: logging.error(exception) raise except OSError as e: logging.error(e) raise",36.32532295,30.75939795
generate: Fetch and sort time series data from OpenTSDB,"def fetch_sorted_metric(self, *args, **kwargs):
        """"""
        """"""
        return sorted(self.fetch_metric(*args, **kwargs).items(),
            key=lambda x: float(x[0]))",". def fetch(self, queryset): """""""""""" queryset = self.query(queryset) if queryset is None: return queryset return self.fetch(queryset)",". def _fetch_series(self, db_id, data): """""" """""" if data.get('timestamp'): return self._fetch_session(db_id, data) return self._fetch_session(db_id, data)",30.81156801,32.34761976
generate: Load and parse a .csv file,"def parse_file(self, file_path, currency) -> List[PriceModel]:
        """"""  """"""
        # load file
                # read csv into memory?
        contents = self.load_file(file_path)
        prices = []

        # parse price elements
        for line in contents:
            price = self.parse_line(line)
            assert isinstance(price, PriceModel)
            price.currency = currency
            prices.append(price)

        return prices","generate: Load and parse a.csv file def parse_csvfile(self, text, params): """""" """""" from.csvfile import StringIO if not params: raise ValueError('Could not parse.csv file') try: text = params.text except Exception as e: raise ValueError('Unknown file \'{0}'.format(e)) # Load element from file fo = Fo(self.esvfile) fo.write(text) fo.write(fo) return fo","generate: Load and parse a.csv file. def parse_file(f, file_path, inst, suffix): """""" """""" inst = None for line in os.path.exists(file_path): if os.path.exists(line): inst = line.split("":"") if not inst: return False if not inst: continue if not inst: return False else: inst = line if not inst: return False return False return False",31.59267752,37.83456388
generate: Returns the front ID found in `front` at the given `index`.,"def _front_id_from_idx(front, index):
    """"""
    
    """"""
    fidx, sidx = index
    id = front[fidx, sidx]
    if id == 0:
        return -1
    else:
        return id","def front(self, front): """""""""""" if self.index is not None: return self.index.front(front) else: return self.index.front(front)","def _get_front_id(self, id): """""" """""" if self.front_id == 'index': return front_id elif self.front_id == 'index': return front_id else: return 'index'",45.14733227,48.66374416
generate: Return a Jinja2 environment for where file_path is.,"def get_environment_for(file_path):
    """"""

    """"""
    work_dir = os.path.dirname(os.path.abspath(file_path))

    if not os.path.exists(work_dir):
        raise IOError('Could not find folder for dirname of file {}.'.format(file_path))

    try:
        jinja_env = Environment(loader=FileSystemLoader(work_dir))
    except:
        raise
    else:
        return jinja_env","def _get_environment(self, environment_path, environment_name, environment_name, environment_name, environment_name): """""""""""" if environment_name == '{0}_environment_name': environment_name = environment_name else: environment_name = environment_name return environment_name, environment_name","def get_file_path(self, file_path, job_dir, mode=None, release=True, # inja256=None, # inja256 ): """""" """""" if not release: raise errors.RuntimeError(""No release"") if not release: release_file = self.release_file_path self.release_file(release_file) self.release_file(release_file, release_file) return job_dir if not mode and not job_dir: return None return None",25.37200609,32.87582755
generate: Decorator for multi to remove nodes for original test functions from root node,"def multi_dec(f):
    """"""""""""

    @wraps(f)
    def wrapper(*args, **kwargs):
        args = (
            args[0] if len(args) == 1 and isinstance(args[0], (list, tuple)) else args
        )
        for arg in args:
            if isinstance(arg, Node) and arg.parent.name is ""root"":
                arg.parent.remove_child(arg)
                arg.update_child_calls()
        return f(*args, **kwargs)

    return wrapper",". def remove_test_functions(func): """""" """""" func = func(func) func = func(func) # This method is needed by the function for functions are anyways # updated by the functions for the functions. if not isinstance(func, RunningFunction): func = func return func","s def remove_nodes(nodes): """""" """""" normalized_nodes = [] for node in nodes: if node.lower() == 'level': normalized_nodes.append(node.lower()) else: normalized_nodes.append(node) normalized_nodes.append(node.lower()) return normalized_nodes",22.52302147,21.63467626
generate: Must be overridden. Must return a string with the loaded data.,"def loadByteArray(self, page, returnError):
        """"""""""""
        returnError.contents.value = self.IllegalStateError
        raise NotImplementedError(""You must override this method."")
        return ''","def _overridden(self, loaded_data): """""" """""" data = self._to_bytes(loaded_data) if not self.encoded: return data return data","def merge_loaded(self, data, loaded): """""" """""" if not self.is_valid_loaded(): return self.check_for_list(data) self.check_for_list(data) return self.check_for_list(data, loaded)",28.32230514,28.26704502
generate: Creates and returns a list that represents a command for running the pipeline.,"def _create_pipeline_command(self, args, workdir_path, config_path):
        """"""
        
        """"""
        return ([self._name, 'run', os.path.join(workdir_path, 'jobStore'),
                 '--config', config_path,
                 '--workDir', workdir_path, '--retryCount', '1']
                 + (['--restart'] if args.restart else []))","def pipeline_with_command(self): """""" """""" if self.filename: fix_path = os.path.join(self.filename, ""pipeline"") return [self.filename, fix_path] else: return []","def create_pipeline(self, pipeline, pipeline): """""" """""" pipeline = pipeline.get(pipeline.name) if pipeline.get(pipeline.get('alive_key')): return pipeline if pipeline.get('alive_key') == 'alive_key': pipeline.update(pipeline) else: return pipeline",27.12930472,23.24510257
generate: Parse Visual Novel search pages.,"async def parse_vn_results(soup):
    """"""
    
    """"""
    soup = soup.find_all('td', class_='tc1')
    vns = []
    for item in soup[1:]:
        vns.append({'name': item.string, 'id': item.a.get('href')[1:]})
    return vns","def parse(self): """""""""""" # Make sure there is one matching the Unicode version of the Unicode version. for matching in self.matching: if matching[-1] == ""."": return matching[-1]","def parse_visual_sources(self, visual_search_type): """""" """""" parser = self.get_visual_search_type(visual_search_type) parser.parse_visual_sources(visual_search_type) return parser",23.03255966,24.35737873
generate: Return the fragment parent of a given molecule.,"def fragment_parent(self, mol, skip_standardize=False):
        """"""
        """"""
        if not skip_standardize:
            mol = self.standardize(mol)
        # TODO: Consider applying FragmentRemover first to remove salts, solvents?
        fragment = self.largest_fragment(mol)
        return fragment","def fragment(self, molecule): """""""""""" fragment = self.fragment fragment = self.fragment fragment = self.fragment if fragment is None: fragment = self.fragment return fragment","def fragment_plot(self, molecule): """""" """""" if self.is_fragment(molecule): return if not self.is_fragment_bar(molecule): return if self.is_fragment_bar(molecule): return if self.is_fragment_bar(molecule): self.is_fragment_bar(molecule) self.is_fragment_bar(molecule) return self.is_fragment_bar(molecule)",36.01480076,36.94279013
generate: Get a spotify artist by their ID.,"def artist(self, spotify_id):
        """"""
        """"""
        route = Route('GET', '/artists/{spotify_id}', spotify_id=spotify_id)
        return self.request(route)","def get_id(self, id): """""" """""" spotify_id = id.split(':')[0] if spotify_id == '*': return self.get_id(id) elif spotify_id == '*': return self.get_id(id) else: return self.get_id(id)","def get_block(self, id, related_id): """""" """""" response = self._get_response(related_id) if response.get('spotify_id'): return response.get('spotify_id') else: return None",38.93111804,39.17168146
generate: is the type a numerical value?,"def isNum(self, type):
        """"""
        
        """"""
        if type in (CKA_CERTIFICATE_TYPE,
                    CKA_CLASS,
                    CKA_KEY_GEN_MECHANISM,
                    CKA_KEY_TYPE,
                    CKA_MODULUS_BITS,
                    CKA_VALUE_BITS,
                    CKA_VALUE_LEN):
            return True
        return False","def is_type(self, value, value): """""""""""" # get the type, which will return the type # of an object as object if value is None: return value return is_type(value)","def is_numeric_type(numeric_type): """""" """""" if not isinstance(numeric_type, MissingSeries): return False elif not isinstance(numeric_type, MissingSeries): return True else: return False",25.55358595,30.11010294
generate: Save a small version of the graph based on a session and the output node names.,"def save_graph_only(sess, output_file_path, output_node_names, as_text=False):
    """"""""""""
    for node in sess.graph_def.node:
        node.device = ''
    graph_def = graph_util.extract_sub_graph(sess.graph_def, output_node_names)
    output_dir, output_filename = os.path.split(output_file_path)
    graph_io.write_graph(graph_def, output_dir, output_filename, as_text=as_text)","def save(self, nodes, filename, version=None): """""" """""" nodes = [] version = None for node in nodes: nodes.append(node) if nodes is not None: nodes.append(node) self.save(nodes) if nodes is not None: nodes.append(nodes) self.save(nodes)","def save_graph_batch_file(self, output_name, version=None): """""" """""" graph_batch = self._get_graph_batch_batch_batch_batch_batch_batch_file( output_name, output_name, version=version) graph_batch = self._get_graph_batch_batch_batch_batch_batch_batch_batch( graph_batch_batch, output_name, version) if graph_batch is not None: graph_batch_batch = self._get_graph_batch_batch_batch( output_name, version) if not graph_batch_batch: raise exceptions.GraphBatch( 'Cannot save the graph file: {0}'.format(graph_batch_batch) ) else: graph_batch_batch = graph_batch_batch_batch_batch( output_name, version, version, graph_batch_batch, version) return graph_batch",19.50731969,26.05186214
generate: highest lock on height,"def last_lock(self):
        """"
        rs = list(self.rounds)
        assert len(rs) < 2 or rs[0] > rs[1]  # FIXME REMOVE
        for r in self.rounds:  # is sorted highest to lowest
            if self.rounds[r].lock is not None:
                return self.rounds[r].lock","def _lock_lock(self, lock): """""""""""" if lock.startswith('auto'): return if lock.startswith('#'): self.lock_lock.append(lock) elif lock.startswith('#'): self.lock_lock.append(lock) else: self.lock_lock.append(lock) self.lock_lock.append(lock)","of the data into an ``dot_height``. def high_header_height(self, dot_height): """""" """""" if self._dot_height is None: return if self._dot_height is not None: return self._dot_height return self._dot_height",26.74484418,33.55242703
"generate: When dispatched on with statements, has_context loops over each context manager.","def has_context_with(state, incorrect_msg, exact_names):
    """"""
    """"""

    for i in range(len(state.solution_parts[""context""])):
        ctxt_state = check_part_index(state, ""context"", i, ""{{ordinal}} context"")
        _has_context(ctxt_state, incorrect_msg or MSG_INCORRECT_WITH, exact_names)

    return state","def dispatch_on_statement(statements, manager, event): """""" """""" if not manager: statements = [] for event in events: if isinstance(statement, Context): statements.append(statement) return statements","def get_context_loops(self, statement, name): """""" """""" if statement.startswith(""global_dispatch_problem""): raise RuntimeError(""Could not get context manager."") if statement.startswith(""true""): self._context_loops_on_log(statement) elif statement.endswith(""true""): self._context_loops_on_log(statement) else: self._context_loops_on_log(statement, name) return self._get_context_loops(self._context_loops_on_logger, name)",26.23865645,28.08144216
generate: Renders a single user's badge.,"def render_badge(user):
    '''  '''

    data = {
        ""user"": user,
    }

    t = loader.get_template('registrasion/badge.svg')
    return t.render(data)","def render(self, user_id, single_page=None, **kwargs): """""" """""" self.build_id = user_id self.render_objects.render_objects_by_single_objects(user_id, single_page=single_page, **kwargs)","def render_badge(self, badge): """""" """""" username = badge.getusername() if not username: username = username else: username = username return username",20.69993522,33.55551863
"generate: Add a section, a sub-CodeBuilder.","def add_section(self):
        """"""""""""
        sect = CodeBuilder(self.indent_amount)
        self.code.append(sect)
        return sect","def add_section_builder(section, builder, limit=False): """""""""""" if builder is None: return builder.add_section(builder, limit) builder.add_section(builder) return builder","def add_section_begin(self, section_begin): """""" """""" self._copy_map(section_begin) self._copy_map(section_begin)",31.75486264,44.62207913
generate: register dispatchers for streams,"def start(self):
        """"""""""""
        self.shell.exit_now = False
        if self.control_stream:
            self.control_stream.on_recv(self.dispatch_control, copy=False)

        def make_dispatcher(stream):
            def dispatcher(msg):
                return self.dispatch_shell(stream, msg)
            return dispatcher

        for s in self.shell_streams:
            s.on_recv(make_dispatcher(s), copy=False)","to the given axes. def register(self, data): """""" """""" axes = self.find_dispatchers(data) if not axes: return if not self.is_tensor_complete(data): return # We have to be given ""tensor_complete"", but no self.tensor_complete = data self.tensor_complete = data return self",". def register_dispatch_status(self, dispatch_status): """""" """""" if not isinstance(dispatch_status, dispatcher_status): raise TypeError(""Stream is not a dispatcher stream"") self._status = dispatch_status self._dispatcher_status = dispatch_status self._register_dispatcher_status(self._status, dispatch_status) return self._register_dispatcher_status(dispatcher_status, self._status)",28.66865652,37.95116139
generate: Registers a hook callable to process tree items right before they are passed to templates.,"def register_items_hook(func):
    """"""
    """"""
    global _ITEMS_PROCESSOR
    global _ITEMS_PROCESSOR_ARGS_LEN

    _ITEMS_PROCESSOR = func

    if func:
        args_len = len(getargspec(func).args)
        if args_len not in {2, 3}:
            raise SiteTreeError('`register_items_hook()` expects a function with two or three arguments.')
        _ITEMS_PROCESSOR_ARGS_LEN = args_len","def register_hook_callable(self, template_name, function, callable_name, *args, **kwargs): """""" """""" # TODO: This method will handle non-default functions in a hook # for this hook callable. if not self.hook_callable: self.hook_callable = hook_callable(callable_name, *args, **kwargs) self.hook_callable = hook_callable(callable_name, *args, **kwargs) self.hook_callable = hook_callable(callable_name, *args, **kwargs) self.hook_callable = hook_callable(callable_name, *args, **kwargs) self.hook_callable = hook_callable(callable_name, *args, **kwargs) self.hook_callable = hook_callable(callable_name, *args, **kwargs)","If there is no passed as the registering passed in the specified tree. def register_tree_to_passed(self, passed): """""" """""" # Register the tree. tree_path = self.get_tree_path(passed=True) tree_path = self.get_tree_path(tree_path) if tree_path is None: tree_path = self.get_tree_path(tree_path) if not tree_path: raise GoogleError(""Tree installing tree."") tree_path = self.get_tree_path(tree_path) tree_path = tree_path.join(tree_path, tree_path) tree_path = self.get_tree_path(tree_path) self.register_tree(tree_path, tree_path)",14.84930567,16.41145099
generate: add right panel widget,"def add_info_widget(self, widget):
        '''  '''
        if not self.screen:
            self.log.debug(""No screen instance to add widget"")
        else:
            self.screen.add_info_widget(widget)","to the right by the given widget. def add_right_panel(self, widget, widget): """""""""""" if widget not in self.panels: self.panels[widget] = widget self.panels[widget] = widget","s. def add_panel_widget(self, panel_widget, panel_widget): """""" """""" self._panel_widget.add_panel_widget(panel_widget) self._panel_widget.add_panel(panel_widget) self._panel_widget.add_panel(panel_widget)",41.95460588,33.68895364
generate: Serve up some ponies.,"def main(argv=sys.argv):
    args = parse(argv)
    """"""""""""
    hostname = args.listen
    port = args.port
    print(
        ""Making all your dreams for a pony come true on http://{0}:{1}.\n""
        ""Press Ctrl+C to quit.\n"".format(hostname, port))

    # Hush, werkzeug.
    logging.getLogger('werkzeug').setLevel(logging.CRITICAL)

    plugin_manager.load_installed_plugins()
    app = make_app()
    run_simple(hostname, port, app)","def __set_ponies(self, ponies): """""" """""" ponies = [] ponies = [] for poni in ponies: if poni not in ponies: ponies.append(poni) else: ponies.append(poni) self.ponies.append(ponies) self.ponies.append(ponies) self.ponies.append(ponies) self.ponies.append(ponies)","def _get_ponies(self, public_response, public_response): """""" """""" public_response = self._get_public_response(public_response) if public_response is None: raise Exception('Public URL is not a public URL.') public_response = self._get_public_response(public_response) if public_response is not None: public_response = self._get_public_response(public_response) else: public_response = self._get_public_response(public_response) return public_response",10.37038162,9.273045828
generate: Returns user profile data.,"def get_user(self, user_id):
        """"""
        
        """"""
        url = USERS_API.format(user_id) + ""/profile""
        return CanvasUser(data=self._get_resource(url))","def get_user_profile(self, user_profile_data, auth_id=None, **kwargs): """""" """""" return self.user_profile_data.get(user_profile_data, **kwargs)","def _get_user_profile_data(self, data): """""" """""" return self._get_user_profile_data(data, self._get_user_profile_data(data))",45.29493219,46.50103536
generate: Wrap a generator function in a decorator to supply line and column  information to the returned Python AST node and dependency nodes.,"def _with_ast_loc_deps(f):
    """"""""""""

    @wraps(f)
    def with_lineno_and_col(
        ctx: GeneratorContext, node: Node, *args, **kwargs
    ) -> GeneratedPyAST:
        py_ast = f(ctx, node, *args, **kwargs)
        return _ast_with_loc(py_ast, node.env, include_dependencies=True)

    return with_lineno_and_col","def supply_function_in_method(func, **kwargs): """""" """""" @wraps(func) def wrapper(*args, **kwargs): @wraps(*args, **kwargs) def wrapper(*args, **kwargs) def wrapper(*args, **kwargs): return wrapper(*args, **kwargs) return wrapper","def get_python_package_package(decorator, text): """""""""""" def __salt__['cmd.run_all'](decorator, text) return __salt__['cmd.run_all']( '-f', decorator, decorator, decorator, ) return __salt__['cmd.run_all']( '/v1/package_package_package', decorator, decorator, )",31.63508119,22.51899255
"generate: Removes this element from the tree, including its children and    text. The tail text is joined to the previous element or    parent.","def drop_tree(self):
        """"""
        
        """"""
        parent = self.getparent()
        assert parent is not None
        if self.tail:
            previous = self.getprevious()
            if previous is None:
                parent.text = (parent.text or '') + self.tail
            else:
                previous.tail = (previous.tail or '') + self.tail
        parent.remove(self)","def remove(self, child, element): """""" """""" text = self.text.decode('utf-8').replace('\n', '') if element in self.tails: if element in self.tails: self.tails.append(tail) else: self.tails.append(tail) else: self.tails.append(tail) self.tails.append(tail) self.tails.append(tail) return self.tails","def remove_tail(self, element): """""" """""" if not self._tail: raise NotFoundException(""Telement was not found."") if not self._is_tail: raise NotFoundException(""The element is one of the tree is one of the element"") self._tail = element self._tail = tree self._tail = ""tail"" self._tail = tree",39.01312574,39.1314516
generate: Computes the accuracy over the k top predictions for the specified values of k,"def accuracy(output, target, topk=(1,)):
    """"""""""""
    with torch.no_grad():
        maxk = max(topk)
        batch_size = target.size(0)

        _, pred = output.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target[None])

        res = []
        for k in topk:
            correct_k = correct[:k].flatten().sum(dtype=torch.float32)
            res.append(correct_k * (100.0 / batch_size))
        return res","-top predictions. def computes(self, values, default=None): """""" """""" if default is None: default = self.default if default is None: default = self.default if default is None: default = self.default if default is None: default = self.default if default is None: default = self.default if default is None: default = self.default return default","top predictions. def compute_accuracy_overlaps(accuracy_overlap, predictions): """""" """""" if not accuracy_overlap.keys(): raise ValueError(""Compute accuracy overlaps for accuracy_overlaps"") elif not accuracy_overlap.keys(): raise ValueError(""Compute accuracy_overlaps is not accuracy_overlaps."") return accuracy_overlap",13.4568442,18.36829396
generate: Load a certificate from a X509 object,"def use_certificate(self, cert):
        """"""
        
        """"""
        if not isinstance(cert, X509):
            raise TypeError(""cert must be an X509 instance"")

        use_result = _lib.SSL_CTX_use_certificate(self._context, cert._x509)
        if not use_result:
            _raise_current_error()",". def load_data(self, data): """""""""""" if data is None: return None # Load data from X509 object. certificate = self.load_data(data) return load_data(self, certificate)",". def load_certificate(self, certificate): """""" """""" if not certificate: raise ValueError('Access certificate is not a valid X509: %s' % certificate) if certificate: return self._certificate(certificate, certificate) return self._certificate(certificate)",26.45497892,42.44962229
generate: Verify http header token authentification,"def check_token(token):
    '''  '''
    user = models.User.objects(api_key=token).first()
    return user or None",". def get_header_token(self, env): """""" """""" headers = self.header.get(""HTTPHEADERS_COMPLESS"") # Verify the http header try: return headers[""Authentication""] except KeyError: return None",". def _handle_response(self, response): """""""""""" url = self._url + '/v2/responses/%s' % response.headers response = self._get_response(response) return response.json()",16.21876221,12.49505663
generate: List all jobs performed by the cluster.,"def list_jobs(self):
        """"""""""""
        res = h2o.api(""GET /3/Jobs"")
        table = [[""type""], [""dest""], [""description""], [""status""]]
        for job in res[""jobs""]:
            job_dest = job[""dest""]
            table[0].append(self._translate_job_type(job_dest[""type""]))
            table[1].append(job_dest[""name""])
            table[2].append(job[""description""])
            table[3].append(job[""status""])
        return table","def list_jobs_pages(self, cluster_jobs_pages, job_pages, source_jobs_pages, job_pages): """""" """""" jobs = [] for job_page in self.jobs: if job_page in self.jobs: jobs.append(job_page) return jobs","def _get_jobs(self, performed_blocks, input_blocks, jobs): """""" """""" jobs_name = ""jobs"" if not self._connection.is_jobs(): jobs = jobs else: jobs = self._create_jobs(jobs) jobs = [] for job in jobs: job = job.get_jobs() if job.get(""job_name"", None): jobs.append(job) jobs.append(job) return jobs",22.20447251,33.29955549
generate: Construct an id for agency using its tags.,"def get_agency_id(relation):
    """"""""""""
    op = relation.tags.get('operator')
    if op:
        return int(hashlib.sha256(op.encode('utf-8')).hexdigest(), 16) % 10**8
    return -1","def GetAndroid(self, role, feed=None): """""""""""" role = self._GetAndroid(role, feed) if role is None: return self.GetAndroid(role) else: return self.GetAndroid(role)","def _get_tag_image_tag(self, tags): """""" """""" tags = self._get_tag_tag(tags) if tags is None: return None ids = self._get_tag(tags) if ids is None: return None return self._get_tags(tags)",25.78874027,24.22618543
generate: Return a variant.,"def case(institute_id, case_name):
    """"""""""""
    institute_obj, case_obj = institute_and_case(store, institute_id, case_name)
    if case_obj is None:
        return abort(404)
    return Response(json_util.dumps(case_obj), mimetype='application/json')","def variant(self): """""""""""" if self._variant is None: return if self.variant is None: return self._variant if self.variant is None: return self._variant return self.variant","def variant(self): """""""""""" if not self._settings: raise errors.InvalidAlgorithmException( ""Displaying variant: %s"" % self.__name__) return self._settings.get(self._settings.get('address', None), None)",21.68067485,22.6147893
generate: Protect against re-patching the distutils if reloaded,"def _get_unpatched(cls):
    """"""
    """"""
    while cls.__module__.startswith('setuptools'):
        cls, = cls.__bases__
    if not cls.__module__.startswith('distutils'):
        raise AssertionError(
            ""distutils has already been patched by %r"" % cls
        )
    return cls",". def _re_patch_reloaded_with_distutils(self, relation_dir): """""""""""" if self.finalize_distutils: self.finalize_distutils(self.finalize_distutils, self.finalize_distutils) self.finalize_distutils(self.finalize_distutils)",". def _get_distutils(self, repo_dir): """""" """""" try: if not self.distutils: return if not self.is_patch(): return except Exception as e: if self.distutils: return if not self.distutils: raise InputError(""Cannot get distutils against "" ""floating to the repo file."") return None",24.27071312,32.10239364
generate: Calculate the minimum length of initial substrings of uid1 and uid2    for them to be different.,"def _compare_uids(uid1, uid2):
        """"""
        """"""
        sum = 0
        for char1, char2 in zip(uid1, uid2):
            if char1 == char2:
                sum += 1
            else:
                break
        return sum","def _init_substrings(self, substrings, dtype, filters): """""" """""" # We can't be available if substrings.shape == (4, 4, 4): return np.array([0.0, 1.0, 1.0]) else: return np.array([0.0, 1.0, 1.0, 1.0, 1.0, 1.0])","def compute_minimum_length(self, uid1, minimum_length): """""" """""" if self._uid2 is None: self._uid2 = self._uid2 self._uid1 = uid1 else: self._uid2 = uid1 self._uid1 = uid1 return self._uid2",20.95217887,31.0812593
generate: Returns a unique instance of `klass` or None,"def get_unique_or_none(klass, *args, **kwargs):
    """"""  """"""
    try:
        return klass.objects.get(*args, **kwargs)
    except klass.DoesNotExist:
        return None
    except klass.MultipleObjectsReturned:
        return None
    return None","if the `klass` is available. def get_klass(klass, klass_name=None): """""" """""" klass = klass.__name__ if klass_name is None: klass = klass.__name__ if klass_name is None: klass = klass.__name__ return klass",". def get_unique_instance(klass, *args, **kwargs): """""" """""" if kwargs.get('unique_instance'): return instance_class(kwargs, kwargs) else: raise ValueError(""Invalid key for %s"" % kwargs)",32.00333515,43.32044035
generate: Handles HTTP GET requests.,"def do_GET(self):
        """"""""""""
        handler = self.uri_map.get(self.path) or self._handle_other
        content, content_type = handler()
        compressed_content = gzip.compress(content)
        self._send_response(
            200, headers=(('Content-type', '%s; charset=utf-8' % content_type),
                          ('Content-Encoding', 'gzip'),
                          ('Content-Length', len(compressed_content))))
        self.wfile.write(compressed_content)","def _http_request(self, request): """""""""""" request = HTTPRequest(request) if request is None: return None request.query = self.query.get(request) request.query = self.query.get(request) request.pagination = self.query.get(request) return self.query.query.get(request)","def _handle_request(self, request, url, data, headers, query_params=None): """""" """""" try: response = request.json() response.raise_for_status() except requests.exceptions.HTTPError as e: self.error_for_status() raise except Exception as e: self.error_for_status() raise except e: self.error_for_status() self.error_for_status() return return self.error_for_status()",17.04483519,24.96196675
generate: Returns a dictionary with the values of the model. Note that the values    of the leafs are YANG classes.,"def get(self, filter=False):
        """"""
        

        """"""
        result = {}

        for k, v in self.elements().items():
            intermediate = v.get(filter=filter)
            if intermediate:
                result[k] = intermediate

        return result","def get_dicts_for_model(self): """""""""""" values = ['_model'] for k, v in self.dictionary_items(): if k in values: return v return None","def get_leafs(self, model): """""" """""" if model in self._leafs: return self._leafs[model].get(model) else: return self._leafs[model].get(model)",33.98863583,30.2343459
generate: Try to extract the bigger group of interlinked tokens.,"def extend_results_extrapoling_relations(helper):
    """"""
    """"""
    if not helper.bucket_dry:
        return  # No need.
    tokens = set(helper.meaningful + helper.common)
    for relation in _extract_manytomany_relations(tokens):
        helper.add_to_bucket([t.db_key for t in relation])
        if helper.bucket_overflow:
            break
    else:
        helper.debug('No relation extrapolated.')","def extract_bigger_group(self, bigger_group): """""" """""" if not bigger_group: return bigger_group # Note: add an interlinked, add an interlinked tokens interlinked = self.get_interlinked_interlinked_interlinked(bigger_group) if interlinked: return interlinked # Check if the bigger is ready tokens for bigger_group in bigger_group: if bigger_group == bigger_group: return interlinked return bigger_group","def extract_bigger(self, interlevel=None): """""" """""" if interlevel is None: return if not isinstance(interlevel, int): interlevel = int(interlevel) else: interlevel = int(interlevel) if self.is_bigger(): raise TypeError(""interlevel must be a supported type"") # Remove interlevel if self.is_bigger(): self.is_bigger() self.is_bigger() if self.is_bigger(): return self._do_bigger() return self.is_bigger()",25.64089025,22.39321396
"generate: get_subparser will get a dictionary of subparsers, to help with printing help","def get_subparsers(parser):
    '''
    '''

    actions = [action for action in parser._actions 
               if isinstance(action, argparse._SubParsersAction)]

    subparsers = dict()
    for action in actions:
        # get all subparsers and print help
        for choice, subparser in action.choices.items():
            subparsers[choice] = subparser

    return subparsers","by documents. def get_subparser_will(self, subparsers): """""" """""" subparsers = {} for subparser in subparsers: if subparser.is_subparser_will(subparser): subparser = subparsers[subparser] elif subparser.is_subparser_will(subparser): subparser = subparsers[subparser] else: subparser = subparsers[subparser] subparsers[subparser] = subparsers[subparser] return subparsers",". def get_subparsers(self, subparser, compiled_subparsers): """""" """""" subparsers = subparsers.add_parser(subparser) if subparsers: subparsers = subparsers.add_parser(subparsers, compiled_subparsers) else: subparsers = [subparser.add_parser(subparser, compiled_subparsers)] return subparsers",37.80698085,41.39744663
"generate: Configure the set of plugins with the given options    and config instance. After configuration, disabled plugins    are removed from the plugins list.","def configure(self, options, config):
        """"""
        """"""
        log.debug(""Configuring plugins"")
        self.config = config
        cfg = PluginProxy('configure', self._plugins)
        cfg(options, config)
        enabled = [plug for plug in self._plugins if plug.enabled]
        self.plugins = enabled
        self.sort()
        log.debug(""Plugins enabled: %s"", enabled)","def configure_setup_options(self, lock, plugins): """""""""""" if plugins is None: plugins = [None] if plugins is None: plugins = self.plugins if plugins is None: plugins = self.plugins self.plugins = plugins","def configure_settings(self, plugins, configuration=None, plugins=None, settings=None, settings=None, platform=None, plugins=None, ): """""" """""" self._settings(plugins, settings, settings, settings) if not self._settings: raise error.PluginException(""No configuration failed"") self._settings(self._settings, plugins, settings)",33.93854459,41.29467569
generate: Decode base64 coded part of the key.,"def decode_key(cls, pubkey_content):
        """"""""""""
        try:
            decoded_key = base64.b64decode(pubkey_content.encode(""ascii""))
        except (TypeError, binascii.Error):
            raise MalformedDataError(""Unable to decode the key"")
        return decoded_key","def decode_b64decode(self, key, value, fields): """""""""""" if not fields: return False b64decode = self.decode_b64decode(key, value) if b64decode: return False return True","def decode(self, key): """""" """""" if not self.decode(key) or not self.diff: raise ValueError(""Unknown key %s"" % key) try: return self.decode(key) except ValueError: raise ValueError(""Unknown key %s"" % key)",30.85162251,39.39358077
generate: List all device management extension packages,"def list(self):
        """"""
        
        """"""
        url = ""api/v0002/mgmt/custom/bundle""
        r = self._apiClient.get(url)

        if r.status_code == 200:
            return r.json()
        else:
            raise ApiException(r)",". def list_device_extensions(self, class_name): """""" """""" if class_name not in self._devices: return self._devices[class_name] else: return self._devices[class_name]",". def get_device_manage_extension_packages(self, package_name, package_dir): """""" """""" if self.debug: return self.logger.getList(package_name, None) else: return self.logger.getList(package_name, None, None, None)",32.04925428,26.07656901
generate: Configure Yandex Metrika analytics counter.,"def configure_analytics_yandex(self, ident, params=None):
        """"""

        """"""
        params = params or {}

        data = {
            'type': 'Yandex',
            'id': ident,
        }

        if params:
            data['params'] = '%s' % params

        self.analytics.append(data)","def configure_yanifest_counter(self, counter, config): """""" """""" self.configure_yanifest_counter(counter, config) self.configure_yanifest_counter(counter, config) self.configure_yanifest_counter(counter, config)","def create_configure_for_new_metrics(self, name, normal_name): """""" """""" url = self._url + '/modify' if self._manage_url: url = self._manage_url(url, normal_name) else: url = self._manage_url(url) return self._session.post(url)",22.00326087,24.32648304
"generate: Convenience method for create_report, for creating a course    provisioning report.","def create_course_provisioning_report(self, account_id, term_id=None,
                                          params={}):
        """"""
        
        """"""
        params[""courses""] = True
        return self.create_report(ReportType.PROVISIONING, account_id, term_id,
                                  params)","def create_report(self, course_id, provisioning_id, url, url): """""" """""" response = self.request(""GET"", url, url=url, url=url) return self.request(""GET"", url=url, url=url)","def create_report(self, report, name, default_report): """""" """""" if not isinstance(report, str): raise TypeError(""report_type"") self.report_name = report.report_name return self.create_report(report, name, default_report)",41.52635797,38.21052376
generate: Rescale a size by a ratio.,"def _scale_size(size, scale):
    """"""
    """"""
    w, h = size
    return int(w * float(scale) + 0.5), int(h * float(scale) + 0.5)","def scale(self, scale=None): """""" """""" if scale is None: scale = self.signal.scale return scale","def replace_to_ratio(self, size): """""" """""" if self.ratio: return self.ratio_ratio(size) return self.ratio_ratio(size)",37.99701439,32.53882276
generate: Eliminate no-op constant expressions which are in the tree    as standalone statements.,"def visit_Expr(self, node: ast.Expr) -> Optional[ast.Expr]:
        """"""""""""
        if isinstance(
            node.value,
            (
                ast.Constant,  # type: ignore
                ast.Name,
                ast.NameConstant,
                ast.Num,
                ast.Str,
            ),
        ):
            return None
        return node","def statements_as_tree(self, constant): """""" """""" if self._tree is None: constant = self.tree if not constant.constant: constant = self.constant self.tree = self.tree self.tree = self.tree","def _check_statements(self, statements): """""" """""" if self._constant_statements: self._constant_statements = statements return self._constant_statements",25.90362708,23.31903429
generate: Read a config file and instantiate the RCParser.,"def from_file(cls, path=None):
        """"""

        """"""
        path = path or cls.CONFIG_PATH
        if not os.path.exists(path):
            error = 'Config file not found: {0!r}'.format(path)
            raise ConfigFileError(error)
        config = read_config(path)
        return cls(config)","def _read_config(config, config, **kwargs): """""""""""" config = Config(config) try: config = config(config) except Exception: raise exc.StreamException('Instantiate `%s` are not a valid.' % config) return config","def read_config_file(self, config_file): """""" """""" if not os.path.isdir(config_file): raise OSError(""No config file {}."".format(config_file)) return self.load_config_file(config_file)",35.22401401,43.70226312
"generate: Returns the column of the cursor in the input buffer, excluding the      contribution by the prompt, or -1 if there is no such column.","def _get_input_buffer_cursor_column(self):
        """""" 
        """"""
        prompt = self._get_input_buffer_cursor_prompt()
        if prompt is None:
            return -1
        else:
            cursor = self._control.textCursor()
            return cursor.columnNumber() - len(prompt)","def get_column_by_prompt(self, *args, **kwargs): """""" """""" results = [] for col in self.columns: if not isinstance(col, str): continue if col.type == ""float"": if col.type == ""true"": results.append(col) else: results.append(col) return results","def column(self, buffer, input_buffer, buffer): """""" """""" if not self.cursor_column: raise ValueError(""Compiled column %s"" % buffer) input_buffer.set_column(self.column, buffer) self.cursor_column.set_column(input_buffer) return input_buffer",33.56486263,42.9103861
generate: Clear GDoc Spreadsheet by sending empty csv file.,"def clear(self):
        """"""
        
        """"""
        empty_file_path = os.path.join(self.temp_path, 'empty.csv')
        try:
            empty_file = open(empty_file_path, 'w')
            empty_file.write(',')
            empty_file.close()
        except IOError as e:
            raise PODocsError(e)

        self._upload_file_to_gdoc(empty_file_path, content_type='text/csv')

        os.remove(empty_file_path)","def clear_gdoc(self, csv_file, csv_file, **kwargs): """""" """""" csv_file = self.csv_file if not csv_file.endswith(csv_file): raise ValueError(""Clear file must be specified."") csv_file = os.path.join(csv_file, csv_file) self.clear_gdoc(csv_file, csv_file, **kwargs)","def clear_file(self): """""" """""" self.svd_file_path = os.path.join(self.svd_file_path, 'svd_file.json') self.svd_file_path = os.path.join(self.svd_file_path, 'svd_file.json') self.svd_file_path = os.path.join(self.svd_file_path, '.svd_file_path', '.svd_file.json') self.svd_file_path = os.path.join(self.svd_file_path, '.svd_file.json') os.makedirs(self.svd_file_path, '.svd_file.json')",35.24990413,36.17864271
generate: Echo a command before running it. Defaults to repo as cwd,"def run(cmd, **kwargs):
    """"""""""""
    log.info('> ' + list2cmdline(cmd))
    kwargs.setdefault('cwd', HERE)
    kwargs.setdefault('shell', os.name == 'nt')
    if not isinstance(cmd, (list, tuple)) and os.name != 'nt':
        cmd = shlex.split(cmd)
    cmd[0] = which(cmd[0])
    return subprocess.check_call(cmd, **kwargs)",". def repo_echo_cwd(self, query, functions, cwd=None, **kwargs): """""" """""" result = self.query(query, functions, **kwargs) result = self.echo_cwd(query, functions, **kwargs) return result",". def _init_command(self, path, cmd, default=True): """""" """""" if not default: return self._cmd_running = self._echo_running(path, cmd, default=default) if default: self._cmd_running(default) else: return default",20.33783672,22.23850207
generate: Returns the minimum file version that supports the given point_format_id,"def min_file_version_for_point_format(point_format_id):
    """"""  
    """"""
    for version, point_formats in sorted(VERSION_TO_POINT_FMT.items()):
        if point_format_id in point_formats:
            return version
    else:
        raise errors.PointFormatNotSupported(point_format_id)","and point_format_id. def _supports_version_version(self, point_format_id): """""" """""" if self.version_version is None: raise RuntimeError(""Version %s must be of type %s."" % (self.version_version,)) version_version = self._version_version if point_version is None: point_version = self.point_version return point_version","s, and then returns a list of points. def get_point_format_ids(self, point_format_ids): """""" """""" url = self._get_point_format(point_format_ids) point_format = self._get_point_format(pointer_format_ids) return self._get_pointer_format(pointer_format)",39.94124439,52.34826586
generate: String summary of the value handled by the parameter.,"def f_val_to_str(self):
        """"""

        """"""
        old_locked = self._locked
        try:
            return repr(self.f_get())
        except Exception:
            return 'No Evaluation possible (yet)!'
        finally:
            self._locked = old_locked","def _get_value(self, value, row): """""" """""" if not isinstance(row, six.string_types): raise TypeError(""{} is not a valid supported row."".format(row)) return row","def summary_parameter(self, value, type=None): """""" """""" if type is not str: if type is None: if type is None: return str(value) else: return string_string_string_string(value)",25.59810296,29.28100726
generate: Multiple algorithm-compatible token validation.,"def compat_validate_token(cls, *args, **kwargs):
        """"""""""""
        data = None
        for algorithm in SUPPORTED_DIGEST_ALGORITHMS:
            data = cls(algorithm_name=algorithm).validate_token(
                *args, **kwargs)
            if not data:  # move to next algorithm
                continue
        return data","def validate_compatible_token(self, validation): """""""""""" validation = validation.compatible_token(validation) if validation.compatible_token: raise ValueError(""compatible_token: {}"".format(validation)) if validation.compatible_token: raise ValueError(""compatible_token: {}"".format(validation)) return validation","def validate_token(token): """""" """""" if not token: raise ValueError(""The token has no multiple validation."") if not token: raise ValueError(""There are not found."") if not token: raise ValueError(""There is not a validation."") return token",24.29184435,28.80883051
"generate: either invalid or one of quorum, noquorum, quorumpossible","def check(self):
        """"
        if not self.is_valid:
            return True
        test = (self.has_quorum, self.has_quorum_possible, self.has_noquorum)
        assert 1 == len([x for x in test if x is not None])
        return True","def _quorum_quorum_quorum(self, quorum, quorum): """""" """""" if quorum <= self.quorum: return quorum.quorum if quorum <= self.quorum: return quorum.quorum if quorum <= self.quorum: return quorum.quorum return None","quorum. def enter_quorum(self): """""""""""" self._quorum_quorum = quorum_quorum self._quorum_quorum_quorum = quorum_quorum return self._quorum_quorum",34.61174288,28.17531903
generate: Clean up children and remove the directory.,"def cleanup(self):
        """"""
        
        """"""
        for k in self._children:
            self._children[k].cleanup()

        if self._cleanup:
            self.remove(True)","def _clean_children(self): """""""""""" # Search the files for filename in self.files: if filename.startswith("".""): self.files.pop(filename) self.files = []","def clean_children(self): """""" """""" if self.is_dir: self.clean_dir() self.is_dir = os.path.isdir(self.path) self.settings.pop('children')",38.18692408,50.34259881
generate: Returns `True` if given observation data is empty.,"def _is_empty_observation_data(
    feature_ndims, observation_index_points, observations):
  """"""
  """"""
  # If both input locations and observations are `None`, we consider this
  # ""empty"" observation data.
  if observation_index_points is None and observations is None:
    return True
  num_obs = tf.compat.dimension_value(
      observation_index_points.shape[-(feature_ndims + 1)])
  if num_obs is not None and num_obs == 0:
    return True
  return False","def is_observation_data(self, observation, domain_before=None): """""" """""" if observation == 'new': return self.is_observation_data(observation, domain_before, domain_before) else: return self.is_observation_data(observation, domain_before)","def _is_valid_observation_data(self, observation_data): """""" """""" observation_data = self.get_observation_data(observation_data) if observation_data is not None: # Check if the observation data is already a single ""generated observation data. return self.get_observation_data(observation_data) else: # All observation data has been set to the observation data return self.get_observation_data(observation_data)",27.12101817,47.69590239
"generate: Get a string version of `block_stack`, for debugging.","def _block_stack_repr(self, block_stack):
        """"""""""""
        blocks = "", "".join(
            [""(%s, %r)"" % (dis.opname[b[0]], b[1]) for b in block_stack]
        )
        return ""["" + blocks + ""]""","def get_block_stack(block_stack, block_stack): """""" """""" stack = block_stack.split(""|"") if len(stack) == 1: block_stack = block_stack.split(""|"")[0] return block_stack","def get_block_stack_version(self, block_stack): """""" """""" if block_stack is not None: return block_stack else: return self.get_block_stack_version(block_stack, block_stack)",43.73703853,43.62295233
generate: Returns the main raw channel for the process,"def get_user_channel(self, input_channel, input_type=None):
        """"""
        """"""

        res = {""input_channel"": input_channel}

        itype = input_type if input_type else self.input_type

        if itype in self.RAW_MAPPING:

            channel_info = self.RAW_MAPPING[itype]

            return {**res, **channel_info}",". def get_main_raw_channel(self): """""" """""" port_id = self.get_main_raw_port_id() return main_raw_channel_address(self.main_raw_channel_address, self.main_raw_channel_address, self.main_raw_channel_address)","ing. def _get_raw_channel(self): """""" """""" self._main_raw_channels = [] if self._main_raw_channels: self._main_raw_channels.append(self._main_raw_channel) return self._main_raw_channels",33.42819943,32.55305206
generate: Merge all the PDF files in `pdf_filepaths` in a new PDF file `out_filepath`.,"def merge_pdfs(pdf_filepaths, out_filepath):
    """""" 
    """"""
    merger = PdfFileMerger()
    for pdf in pdf_filepaths:
        merger.append(PdfFileReader(open(pdf, 'rb')))

    merger.write(out_filepath)

    return out_filepath","def merge_pdf_files(out_filepath, pdf_filepath, verbose=False): """""""""""" with open(out_filepath, 'rb') as out_file: out_file.write(out_file) return out_file","def _maybe_pdf_filepath(self, out_filepath): """""" """""" pdf_filepath = os.path.expanduser(out_filepath) pdf_filepath = os.path.join(pdf_filepath, pdf_filepath) os.makedirs(pdf_filepath, pdf_filepath) os.makedirs(pdf_filepath) os.makedirs(pdf_filepath)",48.70006987,39.68485034
generate: The debugger interface to magic_pdef,"def do_pdef(self, arg):
        """"""""""""
        namespaces = [('Locals', self.curframe.f_locals),
                      ('Globals', self.curframe.f_globals)]
        self.shell.find_line_magic('pdef')(arg, namespaces=namespaces)","ine. def run_pdefine_frame(self, frame, signature=None): """""" """""" if frame in self.frames: if self.frames[frame] is not None: return self.frames[frame] else: raise ValueError(""Invalid frame"") else: return self.frames[frame]","ault into the given position. def _pop(self): """""""""""" if self._debugger is None: self._debugger.add_pop(self._debugger) self._debugger.add_pop(self._debugger) self._debugger.add_pop(self._debugger)",26.97837767,20.39053946
generate: Sets all the foci within `state` to `value`.,"def set(self, state, value):
        # type: (S, B) -> T
        '''
        '''
        if not self._is_kind(Setter):
            raise TypeError('Must be an instance of Setter to .set()')

        pure = lambda a: Identity(a)
        func = lambda a: Identity(value)
        return self.apply(func, pure, state).unwrap()","def set_state_change_foci(self, state): """""""""""" self.state_change_foci = self.state_change_foci self.state_change_foci = self.state_change_foci self.state_change_foci = self.state_change_foci","def set_state(self, foci): """""" """""" if not isinstance(foci, foci): foci = foci.get('foci', None) if not foci: raise TypeError(""foci is not an UnicodeFoci(type)"") return self._set_state(foci, foci, foci)",17.65079795,32.0274374
generate: Called when a state change has occurred. Waiters are notified that a    change has occurred.,"def _change(self):
        """"""
        
        """"""

        for waiter in self._waiters:
            if not waiter.done():
                waiter.set_result(None)
        self._waiters = []","def called(self, state_change=None): """""" """""" if state_change is not None: self.state_change = state_change self.state_change = state_change","If there is any when the occurred. def state_changes(self, changes): """""" """""" if not changes: return changes.update(changes) return changes",34.37434959,28.06291873
generate: A helper function that decorates a function to retain the current  request context. This is useful when working with greenlets. The moment  the function is decorated a copy of the request context is created and  then pushed when the function is called.,"def copy_current_request_context(f):
    """"""
    """"""
    top = _request_ctx_stack.top
    if top is None:
        raise RuntimeError('This decorator can only be used at local scopes '
            'when a request context is on the stack.  For instance within '
            'view functions.')
    reqctx = top.copy()
    def wrapper(*args, **kwargs):
        with reqctx:
            return f(*args, **kwargs)
    return update_wrapper(wrapper, f)","def decorate_frequency_function(func, method): """""""""""" def wrapper(*args, **kwargs): try: return func(*args, **kwargs) except ValueError as e: if e.errno == errno.ENOENT: return e except Exception as e: raise StatusException(""Failed to retrieve function {}"".format(e))","def decorate_function(self, request_type, response_type=None, context_type=None): """""" """""" if not self.is_valid(): raise ValueError('Already decorated request_type not found.') if response_type: response_type = response_type.lower() response_type = response_type.lower() if response_type: response_type = response_type if response_type: response_type = response_type.lower() return response_type",35.75397802,30.31150028
"generate: Fetches a field from extras, and returns it. This is some Airflow    magic. The grpc hook type adds custom UI elements    to the hook page, which allow admins to specify scopes, credential pem files, etc.    They get formatted as shown below.","def _get_field(self, field_name, default=None):
        """"""
        
        """"""
        full_field_name = 'extra__grpc__{}'.format(field_name)
        if full_field_name in self.extras:
            return self.extras[full_field_name]
        else:
            return default","def get_fields_for_field(self, Field, field_name, field_type, field_type, field_type): """""" """""" if field_name == field_name: return self.get_field_from_field(field_name, field_type, field_type, field_type) else: return self.get_field_from_field(field_name, field_name, field_type)","def field_to_add(self, element_string, field_name, field_to_add): """""" """""" if element_string.startswith(""Element""): return element_string else: return element_string.strip()",44.40072946,37.60635097
generate: Get the index of the max value in a column or row,"def idxmax(self,skipna=True, axis=0):
        """"""
        
        """"""
        return H2OFrame._expr(expr=ExprNode(""which.max"", self, skipna, axis))",". def get_index(self, row): """""" """""" row = self.get_index(row) row = self.get_index(row) return row",". def get_index(self, column): """""" """""" column = self.get_index(column) if column is not None: return column else: return column",30.04387114,27.28031174
generate: Get all the checker names that this linter knows about.,"def get_checker_names(self):
        """"""""""""
        current_checkers = self.get_checkers()
        return sorted(
            {check.name for check in current_checkers if check.name != ""master""}
        )","def get_checkers(self): """""" """""" checkers = self.checkers for name in self.checkers: if name not in checkers: return False else: return False return True","def get_checker_names(self, checker_name): """""" """""" names = self.get_checker_names(self.checker_name) checker_name = self.get_checker_name_name() if not checker_name: return None checker_name = checker_name return self.get_checker_name(name)",56.83511221,43.29070004
"generate: Get, cache, and return the curves supported by OpenSSL.","def _get_elliptic_curves(cls, lib):
        """"""
        
        """"""
        if cls._curves is None:
            cls._curves = cls._load_elliptic_curves(lib)
        return cls._curves","def _get_cache_opens(self, cache, pos): """""""""""" if cache.get_cache_opens(): if cache.get_cache_opens(): return cache.get_cache_opens() else: return None","def _get_curve_supported_batch_supported_batch(self, url, supported_batches): """""" """""" if not self.get_curve_supported_batches(): return if self.get_curve_supported_batches(): return self.get_curve_supported_batches(url, supported_batches) else: return self.get_curve_supported_batches(url, supported_batches)",27.4534617,20.20415702
generate: Print variables information in human readble format.,"def print_variables_info(self, output_file=sys.stdout):
        """"""""""""
        table = ('    name |   type size             \n' +
                 '---------+-------------------------\n')
        for name, var_info in list(self.variables.items()):
            table += '{:>8} | {:>6} {!s:<10}\n'.format(name, var_info[0], var_info[1])
        print(prefix_indent('variables: ', table), file=output_file)","def print_variables(self): """""""""""" self.print_variables() self.print_variables() self.print_variables() self.print_variables() self.print_variables() self.print_variables() self.print_variables()","def print_for_formatter(self, readble_file, readble_file): """""" """""" if readble_file not in self.readble_files: self.readble_files[readble_file] = readble_file if readble_file not in self.readble_files: self.readble_files[readble_file] = readble_file else: self.readble_files[readble_file] = readble_file",20.7266014,21.72344631
generate: Guess Python Autorest options based on the spec path.,"def guess_service_info_from_path(spec_path):
    """"""
    """"""
    spec_path = spec_path.lower()
    spec_path = spec_path[spec_path.index(""specification""):] # Might raise and it's ok
    split_spec_path = spec_path.split(""/"")

    rp_name = split_spec_path[1]
    is_arm = split_spec_path[2] == ""resource-manager""

    return {
        ""rp_name"": rp_name,
        ""is_arm"": is_arm
    }","def _make_python_autorest(self, path, flags=None): """""" """""" path = self._make_python_autorest(path) if path.startswith('python-autorest'): path = os.path.basename(path) if path.startswith('python-autorest'): path = os.path.basename(path) path = os.path.join(path, flags) return path","def autorest_options(self, pool_path, pool_path, pool_path, dest_path, pool_path, pool_path, dest_path): """""" """""" if pool_path in self._response_list: raise ValueError('Pool autorest_option is not supported for the pool_path: %s' % pool_path) pool_path = pool_path.split(pool_path) if pool_path not in self._response_list: raise ValueError('Pool_path not found for pool_path: %s' % pool_path) self._response_list[pool_path][pool_path] = pool_path",26.31278138,24.07089226
generate: Take the raw rb data and convert it into averages and std dev,"def shape_rb_data(raw_rb):
    """"""
    """"""
    rb_data = []
    rb_data.append(np.mean(raw_rb, 0))
    rb_data.append(np.std(raw_rb, 0))

    return rb_data","def _raw_data_from_rb(self, rb, raw_data, **kwargs): """""" """""" rb = self.raw_data_from_rb(rb, rb, **kwargs) return self.make_data(rb, rb, **kwargs)",". def _get_raw_rbd_data(self, other_data, raw_data): """""" """""" return [self.ui.raw_data(raw_data, raw_data) for raw_data in raw_data]",40.74009071,43.68862413
generate: Get the detailed information about a particular credit record. This is     currently only supported with the new credit model found in TV. These     ids can be found from any TV credit response as well as the tv_credits     and combined_credits methods for people.,"def info(self, **kwargs):
        """"""
        
        """"""
        path = self._get_credit_id_path('info')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","def get_tv_info(self, tv_info, people, **kwargs): """""" """""" if tv_info is None: return tv_info return self.tv_info(tv_info, tv_info)","def get_credit_details(self, X): """""" """""" if self._credit_details: self._credit_details = self._credit_details return self._credit_details",34.84715898,37.39662095
generate: Upload a stream to Azure File Share.,"def load_stream(self, stream, share_name, directory_name, file_name, count, **kwargs):
        """"""
        
        """"""
        self.connection.create_file_from_stream(share_name, directory_name,
                                                file_name, stream, count, **kwargs)","def upload_stream(self, stream, stream, filename, filename=None): """""" """""" stream = FileShare.objects.get(stream, stream=stream) self.stream = stream self.stream = stream","def azure_file(self, filename): """""" """""" if filename.startswith('.'): raise RuntimeError(""File %s not found."" % filename) self.stream_file = filename self.stream_file = filename self.stream_file = filename",43.52210663,35.59152934
generate: Formats the file size into a human readable format.,"def format_filesize(size):
    """"""""""""
    for suffix in (""bytes"", ""KB"", ""MB"", ""GB"", ""TB""):
        if size < 1024.0:
            if suffix in (""GB"", ""TB""):
                return ""{0:3.2f} {1}"".format(size, suffix)
            else:
                return ""{0:3.1f} {1}"".format(size, suffix)

        size /= 1024.0","def format(file_size, fname=None): """""""""""" if file_size is not None: if file_size is not None: file_size = file_size // 64 elif file_size is not None: file_size = file_size // 64 return format(file_size) else: return format(file_size)","def find_human_file_size(filename): """""" """""" readable_file = os.path.exists(filename) if not os.path.exists(readable_file): return None if not readable_file: # If we can only not find the human readable file return None return None",37.61366903,22.58774983
generate: \    Generates a new nickname based on original nickname followed by a    random number,"def new_nick(self):
        """"""
        """"""
        old = self.nick
        self.nick = '%s_%s' % (self.base_nick, random.randint(1, 1000))
        self.logger.warn('Nick %s already taken, trying %s' % (old, self.nick))
        self.register_nick()
        self.handle_nick_change(old, self.nick)",". def get_nickname(self, name, classification_name, classification_name, auto_region=None): """""" """""" if not self.nickname_original: raise InvalidName(name, classification_name, classification_name) return self.get_nickname(name, classification_name)","of sources. def _get_nickname(self): """""" """""" self._number_before = len(self._number) self._number_before = len(self._number) self._number_before = len(self._number) self._number_before = len(self._number) self._number_before = len(self._number) return self._number_before",23.58865642,27.8178333
generate: Search student output for a pattern.,"def has_output(state, text, pattern=True, no_output_msg=None):
    """"""

    """"""
    if not no_output_msg:
        no_output_msg = ""You did not output the correct things.""

    _msg = state.build_message(no_output_msg)
    state.do_test(StringContainsTest(state.raw_student_output, text, pattern, _msg))

    return state","def status_for_status(self, status, status): """""" """""" if self._status is None: return if self._status is None: return status = self._status if self._status is None: return self._status = status return status","def search_output(pattern, verbose=True): """""" """""" # Initialize output output from output if not verbose: pattern = _get_pattern(pattern) if not pattern: return None else: return pattern # Compute any pattern pattern = _compute_pattern(pattern, verbose) if pattern: return _compute_pattern(pattern, pattern) else: return _compute_pattern(pattern, verbose=verbose)",20.2159277,28.58363667
generate: Add an available event.,"def add_available_event(self, name, metadata):
        """"""
        
        """"""
        if metadata is None:
            metadata = {}

        self.available_events[name] = {
            'metadata': metadata,
            'subscribers': set(),
        }","def available_event(self, event): """""" """""" event = self._get_event(event) if event.event_id is not None: event.event_id = self._get_event(event.event_id) return event","def add(self, event): """""" """""" url = self._url + '/api.avail.avail' if event.tag =='remote': # Note this is remote if event.tag =='remote': self._remote_event(event.tag, event.tag) else: self._remote_event(event.tag, event.tag) self._remote_event(event.tag, event.tag) self._remote_event(event.tag, event.tag)",38.01090316,22.55418872
"generate: For each string, return a new string that is a substring of the original string.","def substring(self, start_index, end_index=None):
        """"""
        
        """"""
        fr = H2OFrame._expr(expr=ExprNode(""substring"", self, start_index, end_index))
        fr._ex._cache.nrows = self.nrow
        fr._ex._cache.ncol = self.ncol
        return fr","def format_string(self, string, class, spec, description=None): """""" """""" return self.format_string(class, spec, spec, description, class, spec, description)","def _get_substring(self, substring): """""""""""" if self._has_has_string(substring): return self._has_string(substring) else: return self._has_string(substring)",28.12570985,28.89956542
generate: Trains model on a single batch,"def train_on_batch(self, data: List[Iterable], labels: Iterable[list]) -> None:
        """"""
        """"""
        X, Y = self._transform_batch(data, labels)
        self.model_.train_on_batch(X, Y)",". def train_model_on_batch(self, model_name, local_name): """""" """""" # Get local batch self.local_name = model_name self.local_name = local_name","es of the given container. def train(self, container): """""" """""" self.model.update(container) return self.model._model._meta.model(container)",36.09858374,30.05422641
generate: Add all wires in a quantum register.,"def add_qreg(self, qreg):
        """"""""""""
        if not isinstance(qreg, QuantumRegister):
            raise DAGCircuitError(""not a QuantumRegister instance."")
        if qreg.name in self.qregs:
            raise DAGCircuitError(""duplicate register %s"" % qreg.name)
        self.qregs[qreg.name] = qreg
        for j in range(qreg.size):
            self._add_wire((qreg, j))","def add_quantum(self, wires): """""" """""" quantum = {} for n in wires: if self.allow_quantum_register(n): if self.allow_quantum_register(n): quantum[n] = n else: quantum[n] = n self.add_quantum_register(n) self.add_quantum_register(n)","def add_wires(self, addr, addr, all_register=False, quantum_register=False, register_register=False): """""" """""" self.add_wires(addr, addr, quantum_register) self.add_wires(addr, addr, quantum_register) self.add_wires(addr, addr, quantum_register)",31.39574098,30.2760604
generate: Return True if we are looking at a def statement,"def is_def_stmt(line, frame):
    """"""""""""
    # Should really also check that operand of 'LOAD_CONST' is a code object
    return (line and _re_def.match(line) and op_at_frame(frame)=='LOAD_CONST'
            and stmt_contains_opcode(frame.f_code, frame.f_lineno,
                                          'MAKE_FUNCTION'))","s(self, instance): """""""""""" statements = [] for statement in instance: if statement is None: return False statement = instance if statement is not None: if not statement.is_lookup(): statement = statement return True return False","_detail(self, event_name, sample_name): """""" """""" if self._statement_detail is not None: return True if self._statement_detail is not None: return False elif event_name.lower() =='refresh_event': return True else: return True",16.9660124,18.59986793
generate: Adds the footer template to the master template string,"def _build_footer(self):
        """"""""""""

        logger.debug(""==============="")
        logger.debug(""Building header"")
        logger.debug(""==============="")
        self.template += fs.footer","def add(self, template, name=None): """""""""""" if self.name is None: template = self.get_template_name(template) self.add_template(name, template) else: self.add_template(name)",". def _add_template(self, template): """""" """""" url = self._url + ""/template"" response = self._get_response(url) if response.ok: response.raise_for_status() return response.json()",20.7698145,20.01109156
generate: Determine if a PE_PE is contained within a EP_PKG or a C_C.,"def is_contained_in(pe_pe, root):
    '''
    
    '''
    if not pe_pe:
        return False
    
    if type(pe_pe).__name__ != 'PE_PE':
        pe_pe = one(pe_pe).PE_PE[8001]()
    
    ep_pkg = one(pe_pe).EP_PKG[8000]()
    c_c = one(pe_pe).C_C[8003]()
    
    if root in [ep_pkg, c_c]:
        return True
    
    elif is_contained_in(ep_pkg, root):
        return True
    
    elif is_contained_in(c_c, root):
        return True
    
    else:
        return False","def is_contained(self, ep_pe_name, name, rep_name, action, action=None, default=False, action=None, method=None, container=None, action=None): """""""""""" self._pkg = ep_pe_name if action == 'CASE': return True elif action == 'NEXT': return True elif action == 'CASE': return True elif action == 'CASE': return True elif action == 'CASE': return True elif action == 'CASE': return True elif action == 'CASE': return True elif action == 'CASE': return True else: return False","def _get_public_contains(self, public_container_name): """""" """""" if not public_container_name: raise NotAuthoritedError(""Public contains public_contains must be one of "" ""Public_container name and "" ""specification_contains"") if not self._has_strict: raise NotAuthoritedError(""Public_contains must be ' ""the "" ""with 'public_container_name'"") return self._get_public_container_name(public_container_name)",32.85927706,21.70641143
generate: Adds a dimensions with ones to array.,"def _add_ones_dim(arr):
    """"
    arr = arr[..., np.newaxis]
    return np.concatenate((arr, np.ones_like(arr)), axis=-1)","def add_dimensions(self, arrays): """""" """""" self.dimensions = arrays self.dimensions = arrays","def add_arrays(self, array): """""" """""" self.arrays[array] = array self.arrays[array] = self self.arrays[array] = array",21.49915503,19.6217528
"generate: Delete a membership, by ID.","def delete(self, membershipId):
        """"""

        """"""
        check_type(membershipId, basestring)

        # API request
        self._session.delete(API_ENDPOINT + '/' + membershipId)","def delete_membership(self, id, id): """""" """""" if id not in self.memberships: self.delete_memberships[id] = True else: self.delete_memberships[id] = True","def delete_membership(self, membership_id, address): """""" """""" url = self._get_url_url(url) return self._delete_membership(url)",45.68452025,46.89784076
generate: Saves a value to session.,"def _session_set(self, key, value):
        """"""
        
        """"""

        self.session[self._session_key(key)] = value","def save(self, value, value, session): """""" """""" if session is None: self.save(value) self.save(value) else: self.save(value) return value","def session(self, value): """""" """""" if not self.is_valid(): self.logger.error('Attempting to session: %s', value) return None return value",37.66230802,37.29390714
generate: List the contents of a subdirectory of a zipfile,"def pack_dir_cmd():
	''
	parser = argparse.ArgumentParser(description=inspect.getdoc(part_edit_cmd))
	parser.add_argument(
		'path',
		help=(
			'Path to list (including path to zip file, '
			'i.e. ./file.zipx or ./file.zipx/subdir)'
		),
	)
	args = parser.parse_args()
	for item, is_file in sorted(list_contents(args.path)):
		prefix = 'd ' if not is_file else '  '
		msg = prefix + item
		print(msg)",". def list_contents(self, subdirectory, subdirectory, name=None, name=None): """""" """""" contents = [] if subdirectory is None: subdirectory = self.contents.pop(subdirectory) if subdirectory is None: subdirectory = self.contents.pop(subdirectory) return subdirectory",". def _file_reqs(self, zipfile, reqs): """""" """""" self._logger.debug(""There is not supported subdirectory "" ""reqs instead..."", reqs) reqs = [self.zipfile, self.zipfile, self.zipfile] reqs.append(reqs) # First, we'll return the subdirectory, there is not supported for (filename, reqs) in reqs: reqs.append(reqs) # Update the subdirectory reqs.extend(self.zipfile) return reqs",14.23863565,21.19321569
generate: Returns a list of the pages that have,,,,,
      orientation changes.,"def _get_orientation_changes(self):
        """""" """"""
        self.orientation_changes = []
        for page in self.pages:
            if page.orientation_change is True:
                self.orientation_changes.append(page.index)
            else:
                pass
        return self.orientation_changes","def _get_pages_for_pages(self, pages): """""" """""" pages = [] for page in pages: if page in self.pages: pages.append(page) else: pages.append(page) return pages","def get_pages(self): """""" """""" pages = self.pages.get('pages', {}) pages = self.pages.get('pages', {}).get('pages', {}) if pages: pages.update(pages) else: pages = [] for page in pages: pages.append(page) return pages",43.43309535,46.63823537
generate: Create and return a new user and pseudonym for an account.,"def create_user(self, user, account_id=None):
        """"""
        
        """"""
        if account_id is None:
            account_id = self._canvas_account_id
            if account_id is None:
                raise MissingAccountID()

        url = ACCOUNTS_API.format(account_id) + ""/users""

        data = self._post_resource(url, user.post_data())
        return CanvasUser(data=data)","def create_user(self, user_id=None): """""""""""" if user_id is not None: # If the user_id is authorized, just it is authorized, just return User(user_id=user_id, access_token=self.access_token) else: # TODO: Use the user_id, just one of the user_ids. return User(user_id=user_id, access_token=self.access_token)","def _get_user(self, user_name, password, input_stream, user_type): """""" """""" if input_stream is not None: try: self.add_user(user_name, user_name, user_type) except MissingPageError as e: self.add_user(user_name, user_type) return user_type",37.94893828,30.84876165
"generate: Generic fuzz mutator, use a decorator for the given type","def fuzz(self, obj):
        """"""
        
        """"""
        decorators = self.decorators

        @decorators.mutate_object_decorate
        def mutate():
            return obj
        return mutate()",". def _get_decorator(self, decorator, type): """""""""""" if type in self.types: return self._get_decorator(decorator) else: return self._get_decorator(decorator)",". def get_decorator(self, mutator): """""" """""" if not isinstance(mutator, Mutator): raise ValueError(""Cannot get mutator for `mutator`."") return self._get_decorator(mutator, type=self.type)",46.23457416,38.357613
generate: Return the map from filenames to lists of line number pairs.,"def arc_data(self):
        """"""""""""
        return dict(
            [(f, sorted(amap.keys())) for f, amap in iitems(self.arcs)]
            )","def get_mapping(self): """""""""""" mapping = [] for line in self.mapping: mapping.append(line) return mapping","def map_file_names(self): """""" """""" if self.filename in self.mapping: return self.map_files[self.filename] else: return None",37.63481246,29.0339886
generate: Checks if outer data structure is supported.,"def _supports(self, item):
        """"""""""""
        result = super(SharedResult, self)._supports(item)
        result = result or type(item) in SharedResult.SUPPORTED_DATA
        return result","def _check_outer(self, outer_data): """""""""""" if outer_data not in self._outer_data: self._outer_data[outer_data] = outer_data return self._outer_data","def _check_outer_data(self, data): """""" """""" result = self._check_outer_data(data) if result is None: return None return result",25.77238851,35.53087532
generate: Unload an IPython extension by its module name.,"def unload_extension(self, module_str):
        """"""
        """"""
        if module_str in sys.modules:
            mod = sys.modules[module_str]
            self._call_unload_ipython_extension(mod)","def load_ipython_extension(self, module_name, module_name): """""" """""" if module_name not in self.modules: module_name = self.modules[module_name] if module_name in self.modules: self.modules[module_name] = module_name self.modules[module_name] = module_name","def _load_ipython_module_name(self, module, id_name): """""" """""" if self.is_module: self.modules[module] = module elif self.is_module: self.modules[module] = self.module else: self.modules[module] = id_name",39.29086449,40.39271683
generate: Get an asset,"def get_asset(self, symbol):
        ''''''
        resp = self.get('/assets/{}'.format(symbol))
        return Asset(resp)","or an asset or an asset. def get_asset(self, asset_or_connection=False): """""""""""" if asset_or_connection: return self.asset_asset_or_connection else: return self.asset_asset_or_connection","upgraded vironment variables def get_asset_asset_level(self, vronment_id): """""" """""" response = self._session.get(vronment_id) if response.is_valid(): return None else: return response.get(""vironment_id"")",22.84315834,24.36670054
generate: URL parameters used.,"def parameters(self) -> str:
        """"""""""""
        return '&'.join('{0}={1}'.format(*item) for item in self.attrs.items())","def get_parameters(self, parameters): """""""""""" parameters = [] for parameter in parameters: parameters.append(parameter) return parameters","def parse_response(self): """""" """""" self.parse_response(response) return self.parse_response(response)",32.38811827,30.06556739
"generate: Converts sky coordinates from one reference system to another, making use of the rotation matrix with    which the class was initialized. Inputs can be scalars or 1-dimensional numpy arrays.","def transformSkyCoordinates(self, phi, theta):
        """"""
        
        """"""
        r=ones_like(phi)
        x, y, z = sphericalToCartesian(r, phi, theta)
        xrot, yrot, zrot = self.transformCartesianCoordinates(x, y, z)
        r, phirot, thetarot = cartesianToSpherical(xrot, yrot, zrot)
        return phirot, thetarot","def convert_from_rotation(self, rotation, mask=0.0, mask=0.0, mask=0.0, mask=0.0): """""" """""" rotation = np.concatenate(self.rotation) if mask == 0: return self.cloud = rotation if mask < mask: return if mask == 0: return # Find the region of the class class = self.region m = np.cloud region = self.region m = np.full if mask == 1: return class # Find the class region = self.region m.random = m return region","def _to_cluster(self, cluster): """""" """""" if not self._cluster: return cluster = cluster.cluster(self.cluster) if cluster.cluster: cluster.cluster(cluster) cluster.cluster = cluster.cluster.cluster() return cluster",17.61257788,17.26466672
generate: Parse string to bool.,"def parse_bool(value):
    """"""
    
    """"""
    boolean = parse_str(value).capitalize()

    if boolean in (""True"", ""Yes"", ""On"", ""1""):
        return True
    elif boolean in (""False"", ""No"", ""Off"", ""0""):
        return False
    else:
        raise ValueError('Unable to parse boolean value ""{}""'.format(value))","def parse_bool(self, base_string): """""" """""" if base_string == '': return base_string elif base_string == '': return base_string else: raise RuntimeError('Basestring not found.')","def parse_string_to_string(string, tag): """""" """""" string_to_string = string_to_string(string) if len(string) == 2 and not string[0]: raise ValueError('Unable to parse string.') return string[-1]",29.48112519,29.05572761
generate: Get GC content and proportions.,"def _get_gc_content(sequence, length):
        """"""

        """"""

        # Get AT/GC/N counts
        at = sum(map(sequence.count, [""A"", ""T""]))
        gc = sum(map(sequence.count, [""G"", ""C""]))
        n = length - (at + gc)

        # Get AT/GC/N proportions
        at_prop = at / length
        gc_prop = gc / length
        n_prop = n / length

        return {""at"": at, ""gc"": gc, ""n"": n,
                ""at_prop"": at_prop, ""gc_prop"": gc_prop, ""n_prop"": n_prop}","def get_content_for_property(self, proportion_name, sort_content): """""""""""" content = self.content_for_property(proportion_name) content = self.content_for_property(proportion_name, sort_content) if content: return content else: return None","def get_gcp_content_file(self): """""" """""" path = self.proportion_filename proportion_path = os.path.expanduser(path) if os.path.exists(path): return os.path.join(proportion_path, proportion_path) else: raise TemplateSyntaxError( 'Unable to get gcp_content_filename or filename for the given filename')",19.91658425,23.49356735
generate: Fire update method in all attached observers in order of attachment.,"def updateObservers(self):
        """"""  """"""
        for observer in self.m_observers:
            try:
                observer.update(self.m_req)
            except:
                ekm_log(traceback.format_exc(sys.exc_info()))","def fire_update_method(self, observers, observers, observers): """""" """""" for observer in observers: if observer.attached: self.update(observer) self.update(observer)","def update_method(self, observers, observer_name): """""" """""" self.method = observers[old_name] self.set_method(old_name) return self.method_update(old_name)",50.71046243,44.82514808
generate: Used to identify when buffered messages should be processed and responded to.,"def is_starved(self):
        """"""
        
        """"""
        for conn in itervalues(self.conns):
            if conn.in_flight > 0 and conn.in_flight >= (conn.last_rdy * 0.85):
                return True
        return False","def process_messages(self, messages): """""""""""" if not self.buffered: self.buffered = False if self.buffered: self.buffered = False self.buffered = False return self.buffered","def __contents_to_buffered(self, buffered): """""" """""" self.buffered = buffered.buffered return self.buffered.get(self.buffered_id, None)",25.20484642,24.07526555
generate: Return a list with number of missed cache lines per memory hierarchy level.,"def get_misses(self):
        """"""""""""
        return [self.stats[cache_level]['MISS_count']/self.first_dim_factor
                for cache_level in range(len(self.machine['memory hierarchy']))]","def get_cache_memory_hierarchy(self, lines): """""" """""" lines = [] lines.append(self.get_cache_memory_hierarchy_level(lines)) return lines","def _get_cache_cache_url(self): """""" """""" if not self.is_response_url: return None for line in self.cache_cache_url: if line.startswith("".""): return line.strip() return None",39.51237271,34.41580117
generate: Checks if name_node has corresponding assign statement in same scope,"def _assigned_locally(name_node):
    """"""
    
    """"""
    assign_stmts = name_node.scope().nodes_of_class(astroid.AssignName)
    return any(a.name == name_node.name for a in assign_stmts)",". def _check_statement(self, name, document): """""" """""" if not self.assign_statement: self.assign_statement = name self.assign_statement = assign_statement self.assign_statement = document self.assign_statement = assign_statement self.assign_statement = assign_statement self.assign_statement = assign_statement",". def correct_statement(scope, name_node): """""" """""" try: scope = scope.scope(scope, name_node) except KeyError: raise ValueError(""No scope: %r"" % name_node) return scope",20.48791396,38.58362388
generate: Creates a running coroutine to receive message instances and send  them in a futures executor.,"def _send_coroutine():
    """"""
    
    """"""
    with PoolExecutor() as executor:
        while True:
            msg = yield
            future = executor.submit(msg.send)
            future.add_done_callback(_exception_handler)","def create_coroutine(self, coroutine): """""" """""" self.coroutine_coroutine = coroutine self.coroutine_coroutine = coroutine","def create_coroutine(self, coroutine, message, timeout=None): """""" """""" if message is None: message = 'Unable to create coroutine message: %s' % message raise TypeError(message) return self._response.coroutine(timeout, message)",22.02607808,20.6151179
generate: Resizes the window to the given dimensions.,"def resize_to(self, width, height):
        """"""
        
        """"""

        self.driver.resize_window_to(self.handle, width, height)","def resizes_window_to_dimensions(self, dimensions): """""" """""" if dimensions: self.dimensions = dimensions self.dimensions = dimensions return self.dimensions","def resized_dimensions(self, dimensions): """""" """""" return self._get_dimensions(dimensions, dimensions)",29.74160469,34.31744571
"generate: Internal callback for device status messages, parses source device from topic string and    passes the information on to the registerd device status callback","def _onDeviceStatus(self, client, userdata, pahoMessage):
        """"""
        
        """"""
        try:
            status = Status(pahoMessage)
            self.logger.debug(""Received %s action from %s"" % (status.action, status.clientId))
            if self.deviceStatusCallback:
                self.deviceStatusCallback(status)
        except InvalidEventException as e:
            self.logger.critical(str(e))","def callback(self, topic, message, topic, message=None): """""" """""" try: self.status = topic self.status = topic except Exception: self.status = topic self.message = message",". If there is not supported, just support the device statement. def _validate_device_status_message(self, topic_status, information): """""" """""" message = self._callback_register_message( ""Callback"", ""Callback"", message=message, source_device_name=source_device_name, information_type=self._source_device_type, other_device_type=self._source_device_type, passess=self._source_device_type, other_device_name=self._source_device_name, device_status_message_name=self._device_device_name, ) return message.device_type",26.13574731,24.46341797
generate: Add a done callback to be invoked when transfer is done,"def add_done_callback(self, function, *args, **kwargs):
        """"""""""""
        with self._done_callbacks_lock:
            self._done_callbacks.append(
                FunctionContainer(function, *args, **kwargs)
            )",". def add_done_callback(self, *args): """""" """""" self.add_done_callback(self.callback) if not self.callback: self.add_done_callback(self.callback) self.add_done_callback(self.callback)",". def add_done_callback(self, done_callback): """""" """""" if not isinstance(done_callback, tuple): done_callback = done_callback(done_callback) if not isinstance(done_callback, (list, tuple)): done_callback(done_callback) return self.add_done(done_callback, done_callback)",47.22759661,29.40162781
generate: Internal ``KILL_TASK`` consumer to remove retired tasks,"def remove_task(message):
    """"""""""""
    task = Task.objects.get(pk=message['id'])
    task.delete()",". def _describe_retid(self, task_id, retid): """""""""""" return self.get_retid(task_id, retid)",". def _get_retired_tasks(self, tasks, key): """""" """""" url = self._retired_url(tasks, key, key) return self._get_retired_tasks(url, key)",28.05227984,19.90349966
generate: It will return the google url to be searched,"def google_url(self,song_name,website):
		''' '''
		name='+'.join(song_name)
		prefix='https://www.google.co.in/search?q='	
		website=website.split("" "")
		suffix='+'.join(website)
		url=prefix+name+suffix
		#print url
		return url","by the given class. def get_url(self, class_name): """""" """""" if class_name: url = class_name.rstrip('/') url = class_name.rstrip('/') return url","in the url. def url(self, username): """""" """""" try: return self.retrieve_request(username, username) except Exception as e: self.logger.error(""Could not get Username token"") return None",22.55744273,23.25263526
generate: Get a signed unauthenticated URL.,"def get_signed_url(self, file_id):
        '''
        '''
        if not is_valid_uuid(file_id):
            raise StorageArgumentException(
                'Invalid UUID for file_id: {0}'.format(file_id))

        return self._authenticated_request \
            .to_endpoint('file/{}/content/secure_link/'.format(file_id)) \
            .return_body() \
            .get()['signed_url']","def get_unauth_signed_signed_unauth_signed_signature(self, signature): """""""""""" signature = self.get_unauth_signature(signature) return signature.get_signature(signature)","def get_signed_unauth_env(self, signed_unauth_env): """""" """""" if signed_unauth_env is not None: try: return self.session.get(signed_unauth_env, None) except signed_unauthenticated: raise UnimplementedError(""Unable to get signed unauthenticated URL."") except UnimplementedError: raise UnimplementedError(""Unable to get URL."")",17.28234396,31.87619303
"generate: Python 2 uses a deprecated method signature and doesn't provide the	forward compatibility.	Add it.","def fix_HTTPMessage():
	""""""
	
	""""""
	if six.PY3:
		return

	http_client.HTTPMessage.get_content_type = http_client.HTTPMessage.gettype
	http_client.HTTPMessage.get_param = http_client.HTTPMessage.getparam","def do_python2_depth(self, method, do_depth): """""" """""" if self.has_depth: return self.do_depth_depth(method) return self.do_depth_depth(method)","def prompatibility_method(self, method, name, field): """""" """""" method_dict = self.create_method(name, field, field) return self.get_method(method_dict, method_dict, method_dict, field_dict)",16.81021469,18.97566799
generate: Fetch the messages that a bot can read.,"def updates(self, offset=None):
        """"""
        """"""
        params = {}

        if offset:
            params[self.OFFSET] = offset

        response = self._call(self.UPDATES_METHOD, params)

        return response","def get_messages(self, message): """""" """""" if self._message_messages: self.messages = [] self.messages = [] self.messages.append(message) return self.messages","def fetch_messages(self, message): """""" """""" if not self.is_ready(): raise TypeError(""Expected message type: %s"" % message) self.response = message.response.read() return message.headers.get('Content-Type')",34.24413219,31.77778067
generate: Adds a parameter under the current node.,"def f_add_parameter(self, *args, **kwargs):
        """""" 

        """"""
        return self._nn_interface._add_generic(self, type_name=PARAMETER,
                                               group_type_name=PARAMETER_GROUP,
                                               args=args, kwargs=kwargs)","def add(self, node, node, **kwargs): """""""""""" self.add(node, node, **kwargs) self.add(node, node, **kwargs) self.add(node, node, **kwargs) self.add(node, node, **kwargs)","def add_node(self, node_id, tag_id, *args, **kwargs): """""" """""" self.add_node(node_id, tag_id, tag_id, *args, **kwargs) return self.add_node(node_id, tag_id, *args, **kwargs)",31.68054838,45.17381359
generate: Get the raw text of a response.,"def get_raw(self, path, **params):
        """"""
        
        """"""
        url = ensure_trailing_slash(self.url + path.lstrip('/'))
        return self._request('get', url, params=params).text","def get_raw_text(self, *args, **kwargs): """""""""""" result = self.request.get_request(self.url, self.url, args=args, **kwargs) return result","def get_raw_text(self, response_string): """""" """""" # Fetch one FUNC response = self._client.get(response_string=response_string) return response",44.5964571,36.33212258
"generate: Return a titlecased version of the value. I.e. words will start with  uppercase letters, all remaining characters are lowercase.","def do_title(s):
    """"""
    """"""
    rv = []
    for item in re.compile(r'([-\s]+)(?u)').split(s):
        if not item:
            continue
        rv.append(item[0].upper() + item[1:].lower())
    return ''.join(rv)","def _get_title(self): """""" """""" title = self._get_title() if title == '*': title = self._get_title() return title","def _start_character(self, title): """""" """""" url = self._get_url(title) if url.startswith('/'): url = url_ + '/' + url.split('/') return self._end_character(url, self._endpoint)",21.13391298,27.73420519
generate: Run the given file interactively.,"def run_file(self,fname,interact=False,get_output=False):
        """"""""""""

        fobj = open(fname,'r')
        try:
            out = self.run_source(fobj,interact,get_output)
        finally:
            fobj.close()
        if get_output:
            return out","def run(self, filename, content, content): """""" """""" # Run the file filename = self.filename filename = filename + '.' + filename if filename == content: return filename else: return filename","def _get_given_file(self, filename): """""" """""" if self.get_given_file(filename): filename = filename.split('.') filename = filename.split('.') if not filename: return filename else: filename = filename return filename",30.32445483,29.05685947
generate: Returns the underlying ImageDriver instance.,"def driver(self):
        """"""""""""
        if self._driver is None:
            self._driver = ImageDriver(self.ds.GetDriver())
        return self._driver","def __image_driver(self): """""""""""" driver = self.__image_drivers.get(""imageDriver"") return driver.render(self.__image_driver)","def get_image_driver(self, underlying): """""" """""" url = self._get_image_url(url) return self._get_image_db_url(url)",62.54350367,40.72340116
generate: Imports a specific query from the rdbms to hdfs,"def import_query(self, query, target_dir, append=False, file_type=""text"",
                     split_by=None, direct=None, driver=None, extra_import_options=None):
        """"""
        
        """"""
        cmd = self._import_cmd(target_dir, append, file_type, split_by, direct,
                               driver, extra_import_options)
        cmd += [""--query"", query]

        self.Popen(cmd)",". def import_query(self, query, fields=None, sort_by=None, filter=None): """""" """""" query = query.filter( (fields=fields, sort_by=sort_by, filter=filter) query = query.filter( (fields=fields, sort_by=sort_by, filter=filter)) return self.import_query(query, query, filter)",". def rdbms(self, specification_id, port=None): """""" """""" if specification_id is None: specification_id = self.specification_id if not port: port = self.get_port(port) if port is not None: return self.get_policy_from_specification(specification_id, port) return self.rdb_list(port)",39.68792798,28.35622893
generate: Parse the archive arguments of a task,"def __parse_archive_args(self, archive_args):
        """"""""""""

        if not archive_args:
            return None

        archiving_args = copy.deepcopy(archive_args)

        if self.archive_path:
            archiving_args['archive_path'] = self.archive_path
        else:
            archiving_args['archive_path'] = os.path.expanduser(ARCHIVES_DEFAULT_PATH)

        return ArchivingTaskConfig.from_dict(archiving_args)",". def parse_args(self, arg, arg): """""" """""" arg = self.args.parse_args(arg) if arg is None: arg = self.args.parse_args(arg) tasks = self.args.parse_args(arg) tasks = self.args.parse_args(arg) return tasks, tasks",", returning an instance. def parse_task_by_name(arg): """""" """""" if archive_name: archive_arguments = parse_args(arg) else: archive_arguments = archive_arguments(arg) if archive_arguments: archive_arguments = archive_arguments.pop(arg) return archive_arguments",27.36451908,41.4180524
generate: Attempts to connect to the MySQL server.,"def connection(self):
        """"""
        """"""

        ctx = _app_ctx_stack.top
        if ctx is not None:
            if not hasattr(ctx, 'mysql_db'):
                ctx.mysql_db = self.connect
            return ctx.mysql_db","def connect(self): """""""""""" if self.server is not None: if self.server is not None: self.server.server = self.server self.server.connect(self.server)","def _maybe_server(self, mysql_response): """""" """""" return self._get_connector(mysql_response, mysql_response)",38.90785688,30.56430466
generate: Returns a decorator function for adding a node filter.,"def node_filter(self, name, **kwargs):
        """"""
        
        """"""

        def decorator(func):
            self.filters[name] = NodeFilter(name, func, **kwargs)

        return decorator","def get_decorator(self, filter_func, filter_func): """""" """""" filter_func = getattr(filter_func, filter_func) return self.add_add_decorator(filter_func)","def decorator(self, node): """""" """""" if node.spec.get('decorators', None): return self.decorator return None",50.06915932,42.82789804
generate: Helper returning the largest integer exactly representable by dtype.,"def _largest_integer_by_dtype(dt):
  """"""""""""
  if not _is_known_dtype(dt):
    raise TypeError(""Unrecognized dtype: {}"".format(dt.name))
  if dt.is_floating:
    return int(2**(np.finfo(dt.as_numpy_dtype).nmant + 1))
  if dt.is_integer:
    return np.iinfo(dt.as_numpy_dtype).max
  if dt.base_dtype == tf.bool:
    return int(1)
  # We actually can't land here but keep the case for completeness.
  raise TypeError(""Unrecognized dtype: {}"".format(dt.name))","def _get_largest_integer(dtype, field_name, table_name): """""""""""" if field_name == field_name: return field_name elif field_name == field_name: return field_name elif field_name == field_name: return field_name else: return field_name","def _build_largest_dtype(self): """""" """""" if self.largest_section_list: return self.largest_section_list else: raise ValueError(""Unknown largest_section_list of the largest_section_list must be an "" ""to be a list of supported largest_sections. Use a bug. "" ""after the largest_section_list="" ""must be passed into a list of string."")",17.09709558,22.17502231
generate: Call the DiscordWebhookHook to post message,"def execute(self, context):
        """"""
        
        """"""
        self.hook = DiscordWebhookHook(
            self.http_conn_id,
            self.webhook_endpoint,
            self.message,
            self.username,
            self.avatar_url,
            self.tts,
            self.proxy
        )
        self.hook.execute()","def __call(self, message): """""""""""" self.call = self.call self.call = self.call self.call = self.call self.call = self.call self.add_message(message)","s. def __call_hook_hook(self): """""" """""" messages = self.__doc__.messages.pop(self.get_messages()) self.__doc__ = messages.pop(self.__doc__) messages.update(messages) return messages",32.54248666,29.30968867
generate: Start session with email server.,"def _get_session(self):
        """"""""""""
        if self.port in (465, ""465""):
            session = self._get_ssl()
        elif self.port in (587, ""587""):
            session = self._get_tls()

        try:
            session.login(self.from_, self._auth)
        except SMTPResponseException as e:
            raise MessageSendError(e.smtp_error.decode(""unicode_escape""))

        return session","def start_session(self): """""" """""" if self.session_token: session = self.session_token elif self.session_token: session = self.session_token else: self.session_token = self.session_token self.session_token = self.session_token return session","def start_session(self, subject, active_context): """""""""""" if not self.is_session(): raise GroupError(""Subject not found."") if not self.is_active: raise GroupError(""Subject not found."") self.is_active_context(subject) return self.is_active_context(active_context)",39.60821348,33.12806815
"generate: Removes the prefix, if it's there, otherwise returns input string unchanged.  If strict is True, also ensures the prefix was present","def strip_prefix(s, prefix, strict=False):
    """"""""""""
    if s.startswith(prefix):
        return s[len(prefix) :]
    elif strict:
        raise WimpyError(""string doesn't start with prefix"")
    return s",", then does not def remove_prefix(self, prefix): """""" """""" prefix = self.prefix if prefix == '.': return prefix if prefix == '.': return prefix else: return prefix",". def remove_prefix(self, prefix): """""" """""" try: self._remove_prefix(prefix) except IOError as e: raise IOError( 'Could not remove prefix: %s' % str(e)) return None",40.74750768,42.56020388
"generate: returns the vector moved one step in the direction of the    other, potentially diagonally.","def step_towards(self, other):
        ''''''

        return self + Vector(
            (
                (self[0] < other[0]) - (self[0] > other[0]),
                (self[1] < other[1]) - (self[1] > other[1]),
            )
        )","def vector_move_moved(self): """""" """""" if not self.single_moved: raise ValueError(""Invalid single VCS_MOVED"") return self.vector_moved","def get_unknown_moved_position(self, direction): """""" """""" return self.get_unknown_moved_position( direction, direction, moved_position=direction, direction=direction, moved_position=moved_position, other_moved_position=other_moved_position, )",19.70524316,15.26728954
generate: Returns a list of patches before patch from the patches list    including the provided patch,"def patches_until(self, patch):
        """""" 
        """"""
        return [line.get_patch() for line in self._patchlines_until(patch) if
                line.get_patch()]","es. def _get_patches_list(self): """""" """""" patches = [] for patch in self.patches: patches.append(patch) return patches","es. def _patches_list(self, patches): """""" """""" patches = [patches.patches() for patches in patches] if patches: return patches else: return patches",54.05568987,45.67987695
generate: Returns info regarding a particular dataset.,"def get_dataset(self, name):
        """"""
        
        """"""
        url = self.url() + ""/resource/dataset/{}"".format(name)
        req = self.remote_utils.get_url(url)

        if req.status_code is not 200:
            raise RemoteDataNotFoundError('Could not find {}'.format(req.text))
        else:
            return req.json()","def particular_dataset(self, dataset): """""""""""" if dataset is not None: if dataset is not None: raise ValueError('dataset is not a valid dataset or a valid dataset.') return dataset else: return dataset","def particular_dataset(self, dataset_name, location, created_mode=None): """""" """""" if not created_mode: return url = self._build_url(url) url = self._build_url(url) url.update(url) url.update(url) if created_mode is not None: url.update(self._uri) return self._build_url(url, created_mode=created_mode)",32.61018035,37.76985963
generate: Bins the light curve model to the provided time array,"def Bin(self):
    '''
    
    
    '''
    
    err = _Bin(self.transit, self.limbdark, self.settings, self.arrays)
    if err != _ERR_NONE: RaiseError(err)",". def bin(self): """""""""""" if self.is_time_arrange(self.time_arrange): return self.time_arrange else: return self.time_arrange",". def _light_page_to_pive(self, page, timestep, total_mode): """""" """""" if not self.is_alive(): self.page_to_pive(page, page, total_mode) return page",34.48798023,17.8062783
generate: Get the F1 values for a set of thresholds for the models explored.,"def F1(self, thresholds=None, train=False, valid=False, xval=False):
        """"""
        
        """"""
        return {model.model_id: model.F1(thresholds, train, valid, xval) for model in
                self.models}","def get_f1_values(self, other_models, models): """""" """""" other_models = [] for models in self.models: models.append(models) return models","If they is looks, they do not set the root. def get_f1_values(self, models, *, *, **kwargs): """""" """""" if self.scope: return self._get_f1_values(models, models, **kwargs) else: return self.get_f1_values(models)",40.39193126,31.78698131
generate: Reload frame information from the backend H2O server.,"def refresh(self):
        """"""""""""
        self._ex._cache.flush()
        self._frame(fill_cache=True)","def reload(self, frame): """""" """""" frame = self.reload_frame(frame) self.body = body self.frame = frame","def reload(self, frame, api_url): """""" """""" response = self._read_frame(frame, api_url) self._read_frame(response) return self._read_frame(response)",34.1327925,26.04645116
generate: Resumes an transfer operation in Google Storage Transfer Service.,"def resume_transfer_operation(self, operation_name):
        """"""
        
        """"""
        self.get_conn().transferOperations().resume(name=operation_name).execute(num_retries=self.num_retries)","def resume_transfer(self, transfer): """""""""""" if not transfer.is_transfer_optional(): self.transfer = transfer self.transfer = transfer","def register_google_transfer(self, spec_number): """""" """""" if self.is_valid(): return spec_number if self.is_valid_transfer: return self.is_valid_transfer(spec_number) else: return spec_number",37.01496753,32.53782087
generate: Computes the self-similarity matrix of X.,"def compute_ssm(X, metric=""seuclidean""):
    """"""""""""
    D = distance.pdist(X, metric=metric)
    D = distance.squareform(D)
    D /= D.max()
    return 1 - D","def compute_smilarity(self, X): """""" """""" X = self.compute_smilarity(X) if not self.skip: return X else: return X","def compute_similarity_matrix(self, sampler): """""" """""" if sampler not in self.XROM_ATROM_DIR_SIMITES: raise ValueError(""Sampler must be a string"") # Include the similarity matrix sampler = self.compute_sampler(similarity) if sampler is None: sampler.sampler(sampler) # Print(""Sampler: %s"" % sampler.sampler.sampler.compute_sampler(sampler)) # Check for the pipeline self.compute_sampler(sampler) return sampler",26.00668818,10.95364143
generate: convert a field's content into some valid HTML,"def  make_html_items( self, items ):
        """"""  """"""
        lines = []
        for item in items:
            if item.lines:
                lines.append( self.make_html_code( item.lines ) )
            else:
                lines.append( self.make_html_para( item.words ) )

        return string.join( lines, '\n' )",". def convert(self, query, sk=None, url=None): """""""""""" if url is None: url = self.get_url(url) self.convert(url) if sk is None: url = self.get_url(url) self.convert(url) self.convert(url) return self.convert(url)","content. def content(self, field): """""" """""" if isinstance(field, Field): return self._get_content(field) else: return self._get_content(field)",22.40057657,21.61753213
generate: Creates an app-setups build. Returns response data as a dict.,"def create_build(self, tarball_url, env=None, app_name=None):
        """"""
        """"""
        data = {
            'source_blob': {
                'url': tarball_url
            }
        }

        if env:
            data['overrides'] = {'env': env}

        if app_name:
            data['app'] = {'name': app_name}

        return self.api_request('POST', '/app-setups', data=data)","def create(self, dict, data=None): """""""""""" if not dict: return dict if dict: return dict if data: if isinstance(data, list): return data return data else: return dict","def _get_app_setup_setup_setup_setup(self, app_setup_setup_setup): """""" """""" try: self._response = self._get_response(app_setup_setup_setup_setup_setup_setup_setup) return self._response.get_response(app_setup_setup_setup) except Exception as e: self._response = None",23.51432843,23.03181054
"generate: Checks if the game is over due to checkmate, stalemate or    fourfold repetition.","def is_game_over(self):
        '''
        
        '''

        # Stalemate or checkmate.
        try:
            next(self.generate_legal_moves().__iter__())
        except StopIteration:
            return True

        # Fourfold repetition.
        if self.is_fourfold_repetition():
            return True

        return False","def _check_repetition(self): """""" """""" if self.repetition: return True if self.repetition is None: return True if self.repetition: return True return False","def is_true_repetition(self, target_id): """""" """""" if target_id not in self._true_repetition: return True else: raise ValueError(""There are about %s is not repetived"" % target_id)",39.20088289,32.66241994
generate: Translate a list of tuples to OrderedDict with key and val as strings.,"def tuples_as_dict(_list):
    """"""

    """"""
    _dict = OrderedDict()
    for key, val in _list:
        key = str(key)
        val = str(val)
        _dict[key] = val
    return _dict","def tuples_dict(self, key, val=None): """""" """""" if val is None: return self.tuples_dict[key] else: return self.tuples_dict[key]","def tuple(cls, key): """""" """""" key_dict = cls._keys if key in cls._dicts: cls._dicts[key] = cls._dicts[key] return cls._dicts[key]",45.10244899,44.8121512
generate: Run command once and check exit code,"def run_and_monitor(self):
        """"""
        
        """"""
        signal.signal(signal.SIGINT, self.shutdown)
        self.spawn(self.config.process_to_monitor, timeout=0)
        return self._is_sigsegv(self.return_code)",". def run(self, code): """""" """""" # Update local code. Will check some code if there's code is an error. self.code = None self.check_event(code)",". def _check_output(self): """""" """""" if self._logger is None: return self._logger.debug(""No outputs: %s"" % self._logger) return self._logger.debug(""Code: %s"" % self._logger)",25.16890251,36.53549411
generate: Update Set with common values of another Set,"def intersection_update(self, oset: Scope) -> Scope:
        """"""  """"""
        keys = list(self._hsig.keys())
        for k in keys:
            if k not in oset:
                del self._hsig[k]
            else:
                self._hsig[k] = oset.get(k)
        return self",". def update_common_value_set(self, other_set, overwrite_value, overwrite_set=False, **kwargs): """""" """""" if overwrite_value is not None: other_set = overwrite_value if overwrite_set: other_set = overwrite_set self.update_common_value_set(other_set, overwrite_set) if overwrite_set: self.update_common_value_set(other_set, overwrite_set) if overwrite_value is not None: self.update_common_value_set(other_set, overwrite_set) if overwrite_set: self.update_common_value_set(other_set, overwrite_set) if overwrite_set: self.update_common_value_set(other_set) if overwrite_set: self.update_common_value_set(other_set) if overwrite_set: self.update_common_value_set(other_set) if overwrite_set: self.update_common_value_set(other_set) if overwrite_set: self.update_common_value_set(other_set) if overwrite_value_set: self.update_common_value_set(other_set) if overwrite_set: self.update_common_value_set(other_set) if overwrite_set: self.update_common_value_set(other_set) if overwrite_set: self.update_comm","tings. def _update_values_to_common_values(self, keys): """""" """""" for key in keys: if key in self.keys: self.set_values(key) return self.update_values(self.settings)",7.576544928,45.13007615
generate: Deletes the specified storage account from Windows Azure.,"def delete_storage_account(self, service_name):
        '''
        
        '''
        _validate_not_none('service_name', service_name)
        return self._perform_delete(
            self._get_storage_service_path(service_name),
            as_async=True)","def delete_storage(self, storage): """""""""""" self.state.set_state(storage) self.state.delete_storage(storage) self.state.delete_storage(storage)","def delete_storage_account(self, storage_account): """""" """""" account_response = self._get_azure_account(storage_account) if not account_response: return if not account_response.is_account(account_response): self._delete_storage_account(account_response) return else: self._delete_storage_account(storage_account) return return self._delete_storage_account(self.account_response)",30.37849438,25.25037118
generate: Close the client connection.,"def close(self):
        """"""
        
        """"""
        if not self._is_open:
            return
        else:
            try:
                self.proxy.close()
                self._is_open = False
            except Exception as e:
                self.logger.error(""could not close client connection: %s"", e)
                raise","def close(self, connection): """""" """""" connection = self.close_connection() if connection: self.close_connection() else: self.close_connection() self.close_connection() self.close_connection() return connection","def close_client_connection(self, client_id, connection): """""""""""" self.connection.close() self.close() return self.close() return self._client_connection(client_id, client_id, self.connection)",44.85478551,43.39743443
generate: This method only works for extensible fields. It allows to add values without precising their fields' names    or indexes.,"def add_fields(self, *args):
        """"""
        
        """"""
        if not self.is_extensible():
            raise TypeError(""Can't use add_fields on a non extensible record."")

        # prepare update data
        self_len = len(self)
        data = dict([(self_len + i, args[i]) for i in range(len(args))])

        # update
        self.update(data)","def filter_fields(self, filter_fields, precising=False): """""" """""" filter_fields = [] for filter_field in filter_fields: if isinstance(filter_field, types.Search): filter_field = filter_field.field elif isinstance(filter_field, types.Search): filter_fields.append(filter_field.field) return filter_fields","def _update_fields(self, key, fields, fields): """""" """""" if not fields: fields = self._get_fields() if not fields: fields = self._get_fields(fields, fields, fields) self._update_fields(fields, fields, fields, fields)",23.26888802,28.74701543
generate: Prints information about the current user.,"def print_user(user):
    """"""
    
    """"""
    email = user['email']
    domain = user['account']['domain']
    role = user['role']
    print('You are logged-in to the ""{0}"" domain '
          'as {1} with role {2}.'
          .format(domain, email, role))","def print_user_info(self, user_info): """""" """""" for user_info in self.user_infos: user_info.user_info = user_info self.print_user_info = user_info","def _get_user(username, username): """""" """""" username = username.username if username: username = username.username else: username = username.username return username",23.93600128,23.65780997
generate: Get the system wide configuration info.,"def info(self, **kwargs):
        """"""
        
        """"""
        path = self._get_path('info')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","def get_system_wide_config(self): """""""""""" path = os.path.basename(self.config_path) path = os.path.basename(self.config_path) return path","def get_system_wide_config(self, source): """""" """""" if self.get_system_wide_config(source): return self.get_system_wide_config(source) return self.get_system_wide_config(source)",34.75582322,30.59060463
generate: Write a single property to the file in Java properties format.,"def write_property(fh, key, value):
  """"""
    
  """"""
  if key is COMMENT:
    write_comment(fh, value)
    return

  _require_string(key, 'keys')
  _require_string(value, 'values')

  fh.write(_escape_key(key))
  fh.write(b'=')
  fh.write(_escape_value(value))
  fh.write(b'\n')","def write_property_from_file(file_name, property_id, file_name, json_format=None): """""""""""" try: with open(file_name, 'rb') as outfile: outfile.write(json.dumps(json.dumps(json_format)) except IOError: print('Error writeing Java property to Java property...') return","def _get_properties(filename): """""" """""" if not os.path.exists(filename): raise InvalidProperties(filename, filename) if not os.path.exists(filename): raise InvalidProperties(filename, filename) return JavaExecutionProperty(filename, properties)",26.55756775,23.48958031
generate: Process an outgoing communication,"def send(evt):
    """"
    # get the text written by the user (input textbox control)
    msg = ctrl_input.value
    # send the message (replace with socket/queue/etc.)
    gui.alert(msg, ""Message"")
    # record the message (update the UI)
    log(msg)
    ctrl_input.value = """"
    ctrl_input.set_focus()","with the current statement def process_outgoing(self, statement, statement, communication, communication, save_callback=True): """""" """""" if not self.is_false: self.outgoing = False self.check_batch_status(statement) self.outgoing_outgoing(statement) self.outgoing_outgoing(statement) else: self.outgoing_outgoing(statement) self.outgoing_outgoing(statement) self.outgoing_outgoing(statement)","of the current template. def _process_template(self, template): """""" """""" try: if not self._is_level(template): raise ValueError(""template must be 'template' or 'template' or 'template'"") except TypeError: raise ValueError(""template must be a template, 'template must be an level, or 'template'"") return template",11.0613745,14.50112611
generate: Deprecated; use the add method.,"def loaded_frame(self, tag):
        """"""""""""
        # turn 2.2 into 2.3/2.4 tags
        if len(type(tag).__name__) == 3:
            tag = type(tag).__base__(tag)
        self[tag.HashKey] = tag","def _add_method(self, method): """""""""""" self.method = method if self.multi_method_name is not None: self.multi_method_name = method","def use_method(self, method, msg): """""" """""" if method not in self.methods: raise AttributeError(msg) return self.method_type(method, msg)",23.56892753,25.016019
generate: Create the file.,"def create(self):
        """"""
        
        """"""
        if not os.path.exists(self.path):
            open(self.path, 'a').close()
        else:
            raise Exception(""File exists: {}"".format(self.path))","def create_file(self, filename): """""""""""" if filename not in self.files: raise UnknownFile(filename) self.files[filename] = filename self.files[filename] = filename","def create_file(self, filename): """""" """""" if filename.endswith("".""): self._file = filename self._file_obj = filename self._file_obj = filename else: self._file_obj = filename",32.16082704,30.65550247
generate: Method that gets run when the Worker thread is started.,"def run(self):
        """"""
        
        """"""
        
        while not self.stopper.is_set():
            try:
                item = self.in_queue.get(timeout=5)
            except queue.Empty:
                continue

            try:
                result = self.func(item)
            except TypeError:
                continue
            else:
                self.out_queue.put(result)","def get_worker(self, role): """""" """""" self.worker = role self.worker = role self.worker = role self.worker = Worker self.worker = Worker","def get_run_thread(self): """""" """""" if not self.running: raise errors.NotFound(""Could not get threading Worker"") return self.run_thread( self.run_thread, self.running, self.run_thread, worker_thread=self.running)",18.73179738,29.03893479
generate: Fetch NNTP data from the server or from the archive,"def _fetch(self, method, args):
        """"""
        """"""
        if self.from_archive:
            data = self._fetch_from_archive(method, args)
        else:
            data = self._fetch_from_remote(method, args)

        return data",". def getNNTP_data(self, archive=None, token=None): """""" """""" if archive is None: archive = self.nntp_data.get(archive) return self.getNNNTP_data(self.nntp_data, archive)",". def fetch_data(self, data): """""" """""" url = self._url + '/fetch_data/data/%s' % self._url data = self._make_response(url, data) return self._request_for_json(data)",44.16657277,44.01271553
generate: Output a time series as a .wav file,"def write_wav(path, y, sr, norm=False):
    """"""
    """"""

    # Validate the buffer.  Stereo is okay here.
    util.valid_audio(y, mono=False)

    # normalize
    if norm and np.issubdtype(y.dtype, np.floating):
        wav = util.normalize(y, norm=np.inf, axis=None)
    else:
        wav = y

    # Check for stereo
    if wav.ndim > 1 and wav.shape[0] == 2:
        wav = wav.T

    # Save
    scipy.io.wavfile.write(path, sr, wav)","generate: Output a time series as a.wav file. def write(self, path, timeout=None): """""" """""" if timeout is None: timeout = timeout try: timeout = self.timeout # We can't lose this up to upgrade the microseconds wavfile = time.time() timeout = time.time() wavfile = time.time() wavfile.write(timeout) except (IOError, OSError, OSError): self.close() raise self.timeout = time.time()","generate: Output a time series as a.wav file. def find_time(time_str): """""""""""" if not isinstance(time_str, str): return None # These are not specified if time_str.startswith('.'): time_str = time_str.replace('.', '.') # This is the datetime for the first time in the page. return InternalRead(time_str, time_str)",26.50943038,19.92038405
generate: Internal implementation of dir_exists.,"def _dir_exists(db, user_id, db_dirname):
    """"""
    
    """"""
    return db.execute(
        select(
            [func.count(directories.c.name)],
        ).where(
            and_(
                directories.c.user_id == user_id,
                directories.c.name == db_dirname,
            ),
        )
    ).scalar() != 0","def _get_dir_exists(self, dr_existing_dir): """""""""""" if self.dir_exists(): return os.path.join(self.dir_exists, dr_existing_dir) return self.dir_exists","def import_dir_exists(self): """""" """""" if self.is_dir(): self.directory = None elif self.is_dir(): self.directory = self.directory else: self.directory = None self.directory = os.path.exists(self.directory)",21.7921218,31.21687868
"generate: This will execute the query, returning the key where a ZSET of your    results will be stored for pagination, further operations, etc.","def cached_result(self, timeout):
        '''
        
        '''
        if not (self._filters or self._order_by):
            raise QueryError(""You are missing filter or order criteria"")
        timeout = int(timeout)
        if timeout < 1:
            raise QueryError(""You must specify a timeout >= 1, you gave %r""%timeout)
        return self._model._gindex.search(
            _connect(self._model), self._filters, self._order_by, timeout=timeout)","def query(self, key, value, **kwargs): """""" """""" try: query = self._query(key, value, **kwargs) if query: return query else: raise InvalidKeyError(""Key must be one of query, but "" ""key, but not found"") except KeyError: raise InvalidKeyError(""Key must be one of query, but not found"")","def _get_current_results(self): """""" """""" if not self._current_results: return [] if self._current_results: self._current_results.append(self._current_results) return [] if self._current_results: return self._current_results[self._current_results] else: return [self._current_results[self._current_results[self._current_results]]]",24.29565287,23.73149233
"generate: If an ndarray has been split into multiple chunks by splitting it along  each axis at a number of locations, this function rebuilds the  original array from chunks.","def allstack(vals, depth=0):
    """"""
    
    """"""
    if type(vals[0]) is ndarray:
        return concatenate(vals, axis=depth)
    else:
        return concatenate([allstack(x, depth+1) for x in vals], axis=depth)","def _create_chunks(self, chunks, splitting_array): """""" """""" if isinstance(chunks, FunctionType): return self.create_chunks(chunks, splitting_array) return self.create_chunks(chunks)","def ndarray(ndarray, dtype='int16', index='int16', lines=[]): """""" """""" if len(ndarray) > 2: ndarray = np.array(ndarray[0]) else: ndarray = ndarray[0] return ndarray[1] * ndarray[1]",29.18277762,29.25025278
generate: add josa at the end of this word,"def attach(word, josa=EUN_NEUN):
    """"""""""""
    last_letter = word.strip()[-1]
    try:
        _, _, letter_jong = letter.decompose(last_letter)
    except NotHangulException:
        letter_jong = letter.get_substituent_of(last_letter)

    if letter_jong in ('', josa['except']):
        return word + josa['has']

    return word + josa['not']",". def add_job(self, word): """""""""""" if word == '_': word = self.get_work_word(word) else: word = self.get_work_word(word) self.add_job(word) return word",". def add_job_to_job(self, end_job_id, job_to_job): """""" """""" if job_to_job_id!= job_to_job_id: raise exceptions.ProcessProcessProcessingJob( ""Adding end job job to the job, or job "" ""the job to the job_to_job to the job, "" ""the job_to_job_to_job_to_job_to_job_to_job"" ) self._process_job_to_job(job_to_job, job_to_job)",14.14903156,15.41654824
generate: Check if gene is already added to a panel.,"def existing_gene(store, panel_obj, hgnc_id):
    """"""""""""
    existing_genes = {gene['hgnc_id']: gene for gene in panel_obj['genes']}
    return existing_genes.get(hgnc_id)","def is_added(self, panel): """""" """""" self.added = True if panel.is_added(): if panel.is_added(): return True return False if panel.is_added(): return False","def _check_solve(self, gene): """""" """""" try: if gene.is_alive(): return self._check_geometry(gene) else: return None except ValueError as e: self._check_if_frame(gene)",23.04884548,25.09246398
generate: Get record ids for Invenio 2.,"def _get_modified_recids_invenio2(from_date):
    """"""""""""
    from invenio.legacy.search_engine import search_pattern
    from invenio.modules.records.models import Record

    date = datetime.datetime.strptime(from_date, '%Y-%m-%d %H:%M:%S')
    return set(
        (x[0]
         for x in Record.query.filter(Record.modification_date >= date).values(
             Record.id))), search_pattern","def get_record_ids(self, request, username=None, query=None): """""" """""" if not request.is_revenio_record_ids: request = self.get_record_ids(request) if username is None: return self.get_record_ids(request, username) else: return self.get_record_ids(request, username) else: return self.get_record_ids(request, username)","0. def get_record_id(self, invenio, record_id=None): """""" """""" if not self._receive_record_id: raise InvalidInvalidRecordID( 'Could not get record_id: %s', invenio, record_id, record_id ) if record_id is None: raise InvalidRecordID( 'Could not get record id from record id') return self._receive_record_id(record_id, record_id)",23.53054259,27.60802588
generate: Finds the value depending in current eplus version.,"def get_value_by_version(d):
    """"""
    
    """"""
    from oplus import CONF  # touchy import

    cv = CONF.eplus_version[:2]
    for v, value in sorted(d.items(), reverse=True):
        if cv >= v:
            return value","def get_value_depth(self, eplus, eplus): """""" """""" if not self.excluded: return None if not isinstance(eplus, basestring): return None value = self.get_value_depth(eplus) if value is not None: if value is None: return value else: return value","def find_current_eplus_version(self, eplus_version): """""" """""" if eplus_version == 0: raise VPECSSError(""Cannot find eplus version: "" + str(eplus_version)) return eplus_version",29.15721835,34.90946779
generate: Recursive helper for walk.,"def walk_dirs(mgr, dirs):
    """"""
    
    """"""
    for directory in dirs:
        children = mgr.get(
            directory,
            content=True,
            type='directory',
        )['content']
        dirs, files = map(sorted, _separate_dirs_files(children))
        yield directory, dirs, files
        if dirs:
            for entry in walk_dirs(mgr, dirs):
                yield entry","def recursive_helper(self, helper, db, build_cmd): """""""""""" helper = Helper(helper, build_cmd) if build_cmd in self._current_helpers: return else: helper.recursive_helpers = [] if build_cmd in self._current_helpers: helper.recursive_helpers.append(build_cmd) helper.recursive_helpers.append(build_cmd) if build_cmd not in self._current_helpers: helper.recursive_helpers.append(build_cmd) return return helper","def _recursive_helper(self, helper): """""" """""" if self._installed: helper = self.execute(""SELECT states: {0}"".format(self.execution)) else: helper = self._installed.execute(""SELECT states: {0}"".format(self.execution)) helper.recursive(helper) return helper",13.35062854,15.44356118
"generate: Marks the job set as completed, and notifies all waiting tasks.","def _done(self):
        """"""
        
        """"""

        self._results.complete()
        waiters = self._waiters
        for waiter in waiters:
            waiter.set_result(None)
        self._manager.job_set_done(self)","def complete(self): """""""""""" if self.jobs is None: self.jobs = [] for job in self.jobs: job.task = job.task job.tasks = job.tasks self.jobs.append(job) return job","def mark_completed(self, job): """""" """""" if self.notifier: # Contains a relationship in jobs self.jobs.put(job) self.notifier.put(job) return self",35.98820219,35.61783729
"generate: Return useful information about IPython and the system, as a string.","def sys_info():
    """"""
   """"""
    p = os.path
    path = p.dirname(p.abspath(p.join(__file__, '..')))
    return pprint.pformat(pkg_info(path))","def get_ipython_info(self, ipython_version, version, version=None): """""""""""" return self.get_ipython_info(ipython_version, version, version=version)","def get_ipython_info(self, information): """""" """""" ip_id = self.ipython_id ip_id = information.get('ipython_id') if ip_id is not None: if not ip_id: return IPython_IPython_INFO.get(ip_id, None) return ip_id",21.97886592,21.20407751
generate: Create a property that proxies attribute ``proxied_attr`` through  the local attribute ``local_attr``.,"def proxied_attribute(local_attr, proxied_attr, doc):
    """"""
    """"""
    def fget(self):
        return getattr(getattr(self, local_attr), proxied_attr)
    def fset(self, value):
        setattr(getattr(self, local_attr), proxied_attr, value)
    def fdel(self):
        delattr(getattr(self, local_attr), proxied_attr)
    return property(fget, fset, fdel, doc)","def create_proxies_attribute(self, attribute_name, local_attr): """""" """""" if attribute_name not in self.proxies: raise ValueError(""The proxies must be an array or an array or a "" ""proxies local attribute."") self.proxies.append(attribute_name) return self.proxies","def _create_proxy_proxy_proxy(proxies, local_attr): """""" """""" if local_attr is None: local_attr = None if not local_attr: local_attr = local_attr else: local_attr = local_attr if not local_attr.is_local_attr(proxies): local_attr = local_attr local_attr = local_attr if not local_attr.is_local_attr(local_attr): local_attr = local_attr if not local_attr.is_local_attr(local_attr): local_attr = local_attr return local_attr",33.97999364,30.45829673
generate: Return the number of cases,"def nr_cases(self, institute_id=None):
        """"""
        """"""
        query = {}

        if institute_id:
            query['collaborators'] = institute_id

        LOG.debug(""Fetch all cases with query {0}"".format(query))
        nr_cases = self.case_collection.find(query).count()

        return nr_cases",". def number_cases(self, cases): """""""""""" cases = self.number_cases if cases < self.number_cases: return (cases * self.number_cases) else: return (cases * self.number_cases)","to the specified ``Fields`` instance. def get_cases(self, fields, code=None, code=None): """""" """""" if fields is None: fields = fields.get('fields', {}).get('fields', {}) if fields is not None: fields['fields'] = fields return self._get_case_string(fields, code)",28.23456678,29.84049959
generate: Read a file from Azure Blob Storage and return as a string.,"def read_file(self, container_name, blob_name, **kwargs):
        """"""
        
        """"""
        return self.connection.get_blob_to_text(container_name,
                                                blob_name,
                                                **kwargs).content","def read(self, filename): """""""""""" filename = os.path.join(self.filename, filename) if os.path.exists(filename): return filename else: return filename","def read_file(self, filename, load_filename=None): """""" """""" url = self._get_url(filename) response = self._client.post(url, data=load_filename, verify=True) return self._client.post(url, response, verify=True)",32.52085733,33.04050132
generate: Add a Symbol alias for the given Namespace.,"def add_alias(self, alias: sym.Symbol, namespace: ""Namespace"") -> None:
        """"""""""""
        self._aliases.swap(lambda m: m.assoc(alias, namespace))","def add_symbol(self, namespace): """""""""""" if namespace.namespace == namespace.namespace: return namespace.namespace else: return self.add_symbol(namespace.namespace)","def add_symbol(self, alias): """""" """""" if not self._is_alias: self._add_symbol(alias, self._symbol) self._add_symbol(alias)",39.99621326,42.40783947
generate: Find a XML element via xpath.,"def xml_find(xpath):
    """"""""""""
    def xpath_find(value):
        validate(ET.iselement, value)
        value = value.find(xpath)
        if value is None:
            raise ValueError(""XPath '{0}' did not return an element"".format(xpath))

        return validate(ET.iselement, value)

    return transform(xpath_find)","def XML(self, xpath): """""""""""" if not xpath.endswith('/'): raise RuntimeError('XML element via xpath.') element = xpath[:-1] return element","def _find_element_via_element(self, element): """""" """""" if element not in elements: return None if element not in self._elements: return None self._elements[element] = element if not self._elements: return None return self._elements[element]",22.97912753,29.05607309
generate: Get the child toolkit widgets for this object.,"def child_widgets(self):
        """""" 

        """"""
        for child in self.children():
            w = child.widget
            if w is not None:
                yield w","def get_child_child_child_child(self, child_child): """""""""""" if self.child_child is None: return child_child return self.get_child(child_child)","def get_child_toolkit_toolkit(self): """""" """""" if self.is_valid(): return self.get_child_toolkit() elif self.is_valid(): return self.get_child_toolkit() else: return self.get_child_toolkit()",38.66440053,26.91091018
"generate: Augment a list of ""docker run"" arguments with those needed to map the notional Spark master address to the    real one, if they are different.","def docker_parameters(self, docker_parameters=None):
        """"""
        
        """"""
        if self != self.actual:
            add_host_option = '--add-host=spark-master:' + self.actual
            if docker_parameters is None:
                docker_parameters = [add_host_option]
            else:
                docker_parameters.append(add_host_option)
        return docker_parameters","def make_real_args(self, docker, callback, args): """""" """""" aux = self._get_aux(docker) if not aux: return # Use this function to load the notebook notebook_args = [args] notebook_args = [args] if notebook_args: notebook_args = [args] # If the arguments are different arguments = [] for argument in arguments: arguments.append(argument) return arguments","def add_park_master_mark_master(self, other, address, params=None): """""" """""" if other is None: other = self.get_other_mapping(other, params) return self.add_park_master(other, params, address, address, params, params)",26.98311098,36.35661466
generate: Updates the list of known servers to the provided list.      Replaces all previous server addresses with the new list.,"def update_servers(self, addresses):
        """"""
        """"""
        params = {""address"": addresses}
        return self.request(""servers"", params=params, method=""post"").status_code","def update_servers(self, servers): """""""""""" servers = [] for server in servers: server = servers[server] server.add(server) self.update(servers) return servers","def _update_servers(self): """""" """""" # NOTE: This is there addresses that are application self.db_list.append(self._db_list) self._db_list.append(self._db_list) return self._db_list",38.77268994,34.89816888
generate: Upload given file into DKV and save it under give key as raw object.,"def _put_key(file_path, dest_key=None, overwrite=True):
    """"""
    
    """"""
    ret = api(""POST /3/PutKey?destination_key={}&overwrite={}"".format(dest_key if dest_key else '', overwrite),
              filename=file_path)
    return ret[""destination_key""]","def upload_dkv_file(self, path, dkv_file, urlsafe_env): """""" """""" try: filename = os.path.basename(path) filename = os.path.join(path, dkv_file) with open(filename, 'rb') as file: return self.dkv_file.write(file) except IOError: return None","def update_give_give_key_from_file(self, filename): """""" """""" self.give_key_from_file(filename) if filename in self.give_key_path: self.give_key_path[filename] = filename else: self.give_key_path[filename] = filename self.give_key_from_file(filename)",29.31027107,27.14308214
generate: Returns the coach ID for the team's OC in a given year.,"def off_coordinator(self, year):
        """"""
        """"""
        try:
            oc_anchor = self._year_info_pq(year, 'Offensive Coordinator')('a')
            if oc_anchor:
                return oc_anchor.attr['href']
        except ValueError:
            return None","def get_coach_id(self, oc_id, year=None): """""" """""" if oc_id is None: oc_id = self.get_coach_id(oc_id) if oc_id is None: oc_id = self.get_coach_id(oc_id) return oc_id","def get_id(self, team): """""" """""" id = get_ident(team) if not id: return None if id not in self._ids: return id url = self._ids[id][""url""] return self._id[""url""] if url else self._id",33.01933566,31.52151545
generate: Returns all entities present in the collection with ``attributes`` included.,"def all_include_attributes(self, attributes):
        """"""""""""
        self.reload(expand=True, attributes=attributes)
        entities = [Entity(self, r, attributes=attributes) for r in self._resources]
        self.reload()
        return entities","def entities(self, attributes=None): """""""""""" self.entities = [] for attribute in attributes: if attribute.is_attributes: attribute = attribute.get(attribute) self.entities.append(attribute) return self.entities","def get_entities(self, attributes): """""" """""" entities = self._get_entities(attributes) entities = self._get_entities(entities) if self._is_updated: return entities else: return entities",61.15656178,46.74294071
"generate: check if the name handle an access to a class member    if so, register it","def visit_name(self, node):
        """"""
        """"""
        if self._first_attrs and (
            node.name == self._first_attrs[-1] or not self._first_attrs[-1]
        ):
            self._meth_could_be_func = False",". def check_name(self, name, func, region): """""" """""" if name in self._members: return self.check_name(name) else: return self.check_name(name)","registered. def _check_in_thread(self, name, member_name, name, port, callback): """""" """""" self.access_token_callback(name, member_name, port, port, port, port)",35.55115628,24.32514113
generate: enable or disable all menu items,"def Enable(self, value):
        """"
        for i in range(self.GetMenuItemCount()):
            it = self.FindItemByPosition(i) 
            it.Enable(value)",". def enable_menu(self): """""""""""" if not self.menu: self.menu = ('menu', 'delete') else: self.menu = ('menu', 'delete')","that have an ``AnnotationPosition``. def update(self, menu, update=None): """""" """""" menu.update(self.address) return menu.update(menu, update)",25.45411778,25.62642846
generate: Return converted `PulseInstruction`.,"def convert_drive(self, shift, instruction):
        """"""
        """"""
        command_dict = {
            'name': instruction.command.name,
            't0': shift+instruction.start_time,
            'ch': instruction.channels[0].name
        }
        return self._qobj_model(**command_dict)","def get_instruction(self, instruction, **kwargs): """""" """""" pulse_instruction = self.get_instruction(instruction) if pulse_instruction is not None: pulse_instruction = self.get_instruction(instruction) if pulse_instruction is not None: pulse_instruction = self.get_instruction(instruction) return pulse_instruction","def _get_dispatch_mode(self, mode): """""" """""" self.pulse_instruction_to_dispatch(mode, mode) return None",28.23108838,17.23984709
generate: Turn a funcs list element into a class object.,"def make_class(clsname, func, attrs):
    """"""""""""
    clsdict = {""__set__"": create_setter(func, attrs)}
    if len(attrs) > 0:
        clsdict[""__init__""] = create_init(attrs)
    clsobj = type(str(clsname), (Descriptor, ), clsdict)
    clsobj.__doc__ = docstrings.get(clsname)
    return clsobj","def _get_funcs_list_funcs_list_funcs(self, func, class_obj): """""""""""" func = func.__name__ func = func.__name__ if func is not None: func = func.__name__ func = func.__name__ func = func.__name__ if not func.__name__.endswith('_'): func.__name__ = func.__name__ func.__name__ = func.__name__ func.__name__ = func.__name__ func.__name__ = func.__name__ return func","def get_funcs(self): """""" """""" # For empty list is used for class. class_name = self.cls.empty_class(self.classname, self.cls.empty_class): return self.class_name return self.class_name",18.20467254,19.74660663
generate: The final url of this navigation item.,"def url(self):
        """"""
        """"""
        if self.is_internal:
            return url_for(self.endpoint, **self.args)
        return self._url","def final_url(self): """""""""""" if self.scope: return self.url(self.url) return self.url(self.url)","def final_url(self): """""" """""" url = self._url(self._url, self._query) return self._url",59.18695842,53.75644276
generate: Initialize rate limit information,"def _init_rate_limit(self):
        """"""""""""

        url = urijoin(self.base_url, 'projects', self.owner + '%2F' + self.repository)
        try:
            response = super().fetch(url)
            self.update_rate_limit(response)
        except requests.exceptions.HTTPError as error:
            if error.response.status_code == 401:
                raise error
            else:
                logger.warning(""Rate limit not initialized: %s"", error)",". def init_rate(self): """""""""""" rate_limit = self.rate_limit rate_limit = self.rate_limit if rate_limit is not None: rate_limit = self.rate_limit rate_limit = self.rate_limit return rate_limit",". def initialize_rate_rate_rate(self, limit, scale=False, total=None): """""" """""" if scale is None: scale = self.scale_rate_rate_rate(limit, scale=limit, total=total, scale=scale) else: scale = scale if not scale: scale = self.scale scale = scale if not scale: scale = self.scale_rate_rate(scale, scale) return self._scale_rate(scale, scale, scale, total=scale)",22.21282468,29.32810582
