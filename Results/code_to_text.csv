input,target,gpt_prediction,mixed_model_prediction,gpt_smooth_bleu_score,mixed_model_smooth_bleu_score,,,,,,,,,,
"summarize: def _output_fonts(self):
        """""" """"""
        self.session._save_object_number()
        self._output_encoding_diffs()
        self._output_font_files()

        for font in self.fonts:
            obj = self.session._add_object()
            font._set_number(obj.id)
            font._output()",Called by the PDFLite object to prompt creating,,,,,#DIV/0!,,31.69807846,28.95188289,,,Experiment A,Experiment B,Experiment C,Code T5 (Baseline)
      the font objects.,self._output_font_files() This is an instance. If the font has no font is in the font.,24.01520166,19.52385211,,,#DIV/0!,,,,,Our Model,,31.64,28.9,20.36
"summarize: def get_courses_for_regid(self, regid, params={}):
        """"""
        
        """"""
        self._as_user = regid
        data = self._get_resource(""/api/v1/courses"", params=params)
        self._as_user = None

        courses = []
        for datum in data:
            if ""sis_course_id"" in datum:
                courses.append(CanvasCourse(data=datum))
            else:
                courses.append(self.get_course(datum[""id""], params))

        return courses",Return a list of courses for the passed regid.,Returns the list of courses for the given regid,Return a list of courses for the given regid.,72.99308518,83.57771535,78.28540027,,,,,CodeT5 Baseline,,,,
"summarize: def save_authorization_code(self, client_id, code, request,
                                *args, **kwargs):
        """"""""""""
        log.debug(
            'Persist authorization code %r for client %r',
            code, client_id
        )
        request.client = request.client or self._clientgetter(client_id)
        self._grantsetter(client_id, code, request, *args, **kwargs)
        return request.client.default_redirect_uri",Persist the authorization code.,Handle authorization code,() Save the authorization code.,61.88282599,77.01365066,69.44823833,,,,,,,,,
"summarize: def instruction_list(self):
        """"""
        """"""
        instruction_list = []
        for instruction in self.data:
            if isinstance(instruction, CompositeGate):
                instruction_list.extend(instruction.instruction_list())
            else:
                instruction_list.append(instruction)
        return instruction_list",Return a list of instructions for this CompositeGate.,Returns a list of instructions for the given instruction.,Returns a list of ``ListingCompositeGate`` instructions.,64.33733463,70.27994142,67.30863803,,,,,,,,,
"summarize: def delete_video(self, video_id):
        """"""
        
        """"""
        # Raise ApiError if not authenticated
        if not self.authenticated:
            raise ApiError(_(""Authentication is required""))

        entry = self.fetch_video(video_id)
        response = Api.yt_service.DeleteVideoEntry(entry)

        if not response:
            raise OperationError(_(""Cannot be deleted from Youtube""))

        return True",Deletes the video,Deletes the video video.,Delete a video,68.79419394,59.00922158,63.90170776,,,,,,,,,
"summarize: def remove_empty_segments(times, labels):
    """"""""""""
    assert len(times) - 1 == len(labels)
    inters = times_to_intervals(times)
    new_inters = []
    new_labels = []
    for inter, label in zip(inters, labels):
        if inter[0] < inter[1]:
            new_inters.append(inter)
            new_labels.append(label)
    return intervals_to_times(np.asarray(new_inters)), new_labels",Removes empty segments if needed.,Removes the empty segments of times.,Removes empty segments.,64.19722168,62.41069836,63.30396002,,,,,,,,,
"summarize: def register_resources(self, **resources):
        """"""
        
        """"""
        for key, resource in resources.items():
            if key in self._resources:
                raise AlreadyExistsException('A Service for {} is already registered.'.format(key))

            self._init_resource(key, resource)",Register resources with the ResourceManager.,Register the resources to the given resources.,Register resources in the resources.,61.01731474,62.92112166,61.9692182,,,,,,,,,
"summarize: def read_file_chunk(self, source, pos, chunk):
    ''''''
    if chunk==0:
        return StringIO()
    data = None
    with open(source, 'rb') as f:
      f.seek(pos)
      data = f.read(chunk)
    if not data:
      raise Failure('Unable to read data from source: %s' % source)
    return StringIO(data)",Read local file chunk,Read a file chunk,Read a.File chunk.,66.45926963,56.32809222,61.39368093,,,,,,,,,
"summarize: def startswith(string):
    """"""""""""
    def starts_with(value):
        validate(text, value)
        if not value.startswith(string):
            raise ValueError(""'{0}' does not start with '{1}'"".format(value, string))
        return True

    return starts_with",Checks if the string value starts with another string.,"(string, value) Starts a string with the given ``string``.",_start(string) Check if the value is starts with a string.,51.30286565,69.10383702,60.20335134,,,,,,,,,
"summarize: def populate_settings_dir(force: bool = False) -> bool:
    """"""
    
    """"""
    res = False
    if _default_settings_path == _settings_path:
        return res

    for src in list(_default_settings_path.glob('**/*.json')):
        dest = _settings_path / src.relative_to(_default_settings_path)
        if not force and dest.exists():
            continue
        res = True
        dest.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy(src, dest)
    return res",Populate settings directory with default settings files,Populates the settings files to the given directory.,Pops a settings into a populate directory path and settings.,60.02775495,59.37309123,59.70042309,,,,,,,,,
"summarize: def get_extension(self):
        """"""""""""
        ext = os.path.splitext(self.img.name)[1]
        if ext:
            # Remove period from extension
            return ext[1:]
        return ext",Returns the file extension.,Returns the extension from the file.,[1:] Return the extension from a tag,69.29818744,49.79882018,59.54850381,,,,,,,,,
"summarize: def expression_filter(self, name, **kwargs):
        """"""
        
        """"""

        def decorator(func):
            self.filters[name] = ExpressionFilter(name, func, **kwargs)

        return decorator",Returns a decorator function for adding an expression filter.,"(self, **kwargs) Sets a function for the expression filter.",Expression function for decorator for another function.,57.49664476,60.62590543,59.0612751,,,,,,,,,
"summarize: def log_time(logger):
    """"""
    
    """"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start = time.time()
            result = func(*args, **kwargs)
            end = time.time()
            _log_time(logger, func.__name__, start, end)
            return result
        return wrapper
    return decorator",Decorator to log the execution time of a function,Decorator function to log a time to execute the time,Decorator to decorator for logging timeing.,75.08389531,42.58249667,58.83319599,,,,,,,,,
"summarize: def delete_vacation(self, index, vacation):
        '''  '''
        body = {""selection"": {
                    ""selectionType"": ""thermostats"",
                    ""selectionMatch"": self.thermostats[index]['identifier']},
                ""functions"": [{""type"": ""deleteVacation"", ""params"": {
                    ""name"": vacation
                }}]}

        log_msg_action = ""delete a vacation""
        return self.make_request(body, log_msg_action)",Delete the vacation with name vacation,Remove a vacation to the viacation.,Delete the vacation of the action,53.94502708,62.74254631,58.3437867,,,,,,,,,
"summarize: def receive_queue_message(self, queue_name, peek_lock=True, timeout=60):
        '''
        
        '''
        if peek_lock:
            return self.peek_lock_queue_message(queue_name, timeout)
        return self.read_delete_queue_message(queue_name, timeout)",Receive a message from a queue for processing.,Receive the queue message for a queue message.,Receive a message from a message.,61.58385724,54.71669023,58.15027374,,,,,,,,,
"summarize: def parse_qsd(data, name=""query string"", exception=PluginError, schema=None, **params):
    """"""
    """"""

    value = dict(parse_qsl(data, **params))
    if schema:
        value = schema.validate(value, name=name, exception=exception)

    return value",Parses a query string into a dict.,Parses a query string to a URL.,Returns a query parameter of a query string.,74.25454649,41.67520235,57.96487442,,,,,,,,,
"summarize: def insert_patches(self, patches):
        """"""  """"""
        patchlines = []
        for patch_name in patches:
            patchline = PatchLine(patch_name)
            patch = patchline.get_patch()
            if patch:
                self.patch2line[patch] = patchline
            patchlines.append(patchline)
        patchlines.extend(self.patchlines)
        self.patchlines = patchlines",Insert list of patches at the front of the curent patches list,Insert patches from the patches to the patches to a list of patches.,return patches Returns the list of patches in the patches.,60.12477626,55.33552623,57.73015125,,,,,,,,,
"summarize: def apply_option(self, cmd, option, active=True):
        """"""""""""
        return re.sub(r'{{{}\:(?P<option>[^}}]*)}}'.format(option),
                      '\g<option>' if active else '', cmd)",Apply a command-line option.,Apply an option to a code,Apply a command line.,54.62354448,59.78497204,57.20425826,,,,,,,,,
"summarize: def disable_timestamp(method):
    """"""""""""
    @wraps(method)
    def wrapper(*args, **kwargs):
        result = None
        with correct_date():
            result = method(*args, **kwargs)
        return result
    return wrapper",Disable timestamp update per method.,Disable the timestamp instance,Disable a method to get timestamp.,52.82713456,61.43721397,57.13217427,,,,,,,,,
"summarize: def delete_checkpoint(self, checkpoint_id, path):
        """"""""""""
        with self.engine.begin() as db:
            return delete_single_remote_checkpoint(
                db, self.user_id, path, checkpoint_id,
            )",delete a checkpoint for a file,delete a checkpoint to delete a checkpoint.,delete a configured checkpoint.,50.44949733,63.28469671,56.86709702,,,,,,,,,
"summarize: def get_enrollments_for_course_by_sis_id(self, sis_course_id, params={}):
        """"""
        
        """"""
        return self.get_enrollments_for_course(
            self._sis_id(sis_course_id, sis_field=""course""), params)",Return a list of all enrollments for the passed course sis id.,Gets the enrollments for the course id for the specified parameters.,Returns a list of enrollments for the specified sis.,50.27448931,63.03638996,56.65543964,,,,,,,,,
"summarize: def __fetch_crate_versions(self, crate_id):
        """"""""""""

        raw_versions = self.client.crate_attribute(crate_id, ""versions"")

        version_downloads = json.loads(raw_versions)

        return version_downloads",Get crate versions data,Gets a crate versions.,Fetches a version in a crate_id.,72.16888547,40.6304468,56.39966614,,,,,,,,,
"summarize: def featured_playlists(self, locale=None, country=None, timestamp=None, limit=20, offset=0):
        """"""
        """"""
        route = Route('GET', '/browse/featured-playlists')
        payload = {'limit': limit, 'offset': offset}

        if country:
            payload['country'] = country

        if locale:
            payload['locale'] = locale

        if timestamp:
            payload['timestamp'] = timestamp

        return self.request(route, params=payload)",Get a list of Spotify featured playlists.,Get a list of locales that are featured.,Return a list of localed playlists.,54.70261742,58.06107377,56.3818456,,,,,,,,,
"summarize: def get_evaluations(self, prefix=None):
        """""" 
        """"""
        params = {""prefix"": prefix}
        return self.request(method=""get"", params=params).json()",Lists all the evaluations.,Get a list of evaluations.,Returns the list of evaluations.,57.63823693,54.94532598,56.29178146,,,,,,,,,
"summarize: def update_variant(self, variant_obj):
        """"""
        """"""
        LOG.debug('Updating variant %s', variant_obj.get('simple_id'))

        new_variant = self.variant_collection.find_one_and_replace(
            {'_id': variant_obj['_id']},
            variant_obj,
            return_document=pymongo.ReturnDocument.AFTER
        )
        return new_variant",Update one variant document in the database.,Update variant with inputs to the database,"Update an instance, if it's not in the variant",63.07775367,49.08750132,56.0826275,,,,,,,,,
"summarize: def create_secret_link(self, title, description=None, expires_at=None):
        """"""""""""
        self.link = SecretLink.create(
            title,
            self.receiver,
            extra_data=dict(recid=self.recid),
            description=description,
            expires_at=expires_at,
        )
        return self.link",Create a secret link from request.,Create a secret link from the title,"(title, description=title) Create a secret link from the title and link.",75.12189784,36.93015301,56.02602543,,,,,,,,,
"summarize: def utf8(unicode_str):
    """"""
    
    """"""
    if six.PY2 and isinstance(unicode_str, __unicode__):
        return unicode_str.encode('utf-8')

    return unicode_str",Return a utf-8 encoded string from a valid unicode string.,.encode('utf-8') Returns an unicode string to the given string,.encode('utf-8') Generate a unicode string of unicode string.,56.4525508,55.16082926,55.80669003,,,,,,,,,
"summarize: def convert_str_to_datetime(df, *, column: str, format: str):
    """"""
    
    """"""
    df[column] = pd.to_datetime(df[column], format=format)
    return df",Convert string column into datetime column,Convert string to string to datetime,[column] Returns a string into a datetime object.,59.32193799,51.96004361,55.6409908,,,,,,,,,
"summarize: def get_published_courses_in_account(self, account_id, params={}):
        """"""
        
        """"""
        params[""published""] = True
        return self.get_courses_in_account(account_id, params)",Return a list of published courses for the passed account ID.,Gets a list of published courses for account,Returns a list of accounts accounts in the ACCIshedSet.,61.78960071,48.84890689,55.3192538,,,,,,,,,
"summarize: def is_attribute_supported(self, attribute):
        """"""
        
        """"""
        if attribute not in self._attribute_rule_sets.keys():
            return False

        rule_set = self._attribute_rule_sets.get(attribute)
        if self._version >= rule_set.version_added:
            return True
        else:
            return False",Check if the attribute is supported by the current KMIP version.,Returns True if the version of the given attribute is added.,Checks if the attribute is only have one of the current directory.,51.01080252,59.56895959,55.28988106,,,,,,,,,
"summarize: def invalidate_authorization_code(self, client_id, code, request,
                                      *args, **kwargs):
        """"""
        """"""
        log.debug('Destroy grant token for client %r, %r', client_id, code)
        grant = self._grantgetter(client_id=client_id, code=code)
        if grant:
            grant.delete()",Invalidate an authorization code after use.,return grant Invalidate authorization code.,return grant Return an AuthorizationService.,71.98166156,38.38371387,55.18268772,,,,,,,,,
"summarize: def deserialize_function(serial, function_type):
  """"""

  """"""
  if function_type == 'function':
    # Simple lookup in custom objects
    function = tf.keras.utils.deserialize_keras_object(serial)
  elif function_type == 'lambda':
    # Unsafe deserialization from bytecode
    function = generic_utils.func_load(serial)
  else:
    raise TypeError('Unknown function type:', function_type)
  return function",Deserializes the Keras-serialized function.,Deserialize function to deserialize function.,Return a deserialization of the deserialization function.,62.023922,48.27868216,55.15130208,,,,,,,,,
"summarize: def lists(self, pattern: str = None) -> List[WikiList]:
        """"""
        """"""
        return [
            lst for arg in self.arguments for lst in arg.lists(pattern) if lst]",Return the lists in all arguments.,Lists a list of arguments of the lst.,] Lists a list of all arguments in the pattern.,53.36172774,56.47494931,54.91833853,,,,,,,,,
"summarize: def remove_method(self, key: T) -> Optional[Method]:
        """"""""""""
        method = self.methods.entry(key, None)
        if method:
            self._methods.swap(MultiFunction.__remove_method, key)
        return method",Remove the method defined for this key and return it.,Remove methods from a key and return a new method.,Remove method for a single key and adding methods,57.16237979,51.7855978,54.4739888,,,,,,,,,
"summarize: def _try_reduce_list(statements: List[""HdlStatement""]):
        """"""
        
        """"""
        io_change = False
        new_statements = []

        for stm in statements:
            reduced, _io_change = stm._try_reduce()
            new_statements.extend(reduced)
            io_change |= _io_change

        new_statements, rank_decrease = HdlStatement._merge_statements(
            new_statements)

        return new_statements, rank_decrease, io_change",Simplify statements in the list,Compute the list of statements,Get a list of all statements.,60.71786196,47.09863945,53.90825071,,,,,,,,,
"summarize: def delete_pool(name, session=None):
    """"""""""""
    if not (name and name.strip()):
        raise AirflowBadRequest(""Pool name shouldn't be empty"")

    pool = session.query(Pool).filter_by(pool=name).first()
    if pool is None:
        raise PoolNotFound(""Pool '%s' doesn't exist"" % name)

    session.delete(pool)
    session.commit()

    return pool",Delete pool by a given name.,Deletes the pool from the given name.,Delete any pools in a given session.,56.989687,50.07938801,53.53453751,,,,,,,,,
"summarize: def generate_encodeable_characters(characters: Iterable[str],
                                   encodings: Iterable[str]) -> Iterable[str]:
    """"""
    """"""
    for c in characters:
        for encoding in encodings:
            try:
                c.encode(encoding)
                yield c
            except UnicodeEncodeError:
                pass",Generates the subset of 'characters' that can be encoded by 'encodings'.,return c return Iterable(characters) Generates the encodings for an encoding.,return None Generates the encoded encoding characters from an encoding.,50.79519501,56.24853716,53.52186609,,,,,,,,,
"summarize: def get_asana_task(self, asana_task_id):
        """"""""""""

        try:
            return self.asana.tasks.find_by_id(asana_task_id)
        except asana_errors.NotFoundError:
            return None
        except asana_errors.ForbiddenError:
            return None",Retrieves a task from asana.,Retrieve a task from the asana task.,Gets the task task from the asana_task.,65.10651028,41.46302113,53.28476571,,,,,,,,,
"summarize: def create_event_datetimes(options, config):
    """"""
    
    """"""

    now = datetime.datetime.now()

    return {
        ""start"": {
            ""dateTime"": (now + datetime.timedelta(minutes=int(config[""start""]))).strftime(DT_FORMAT),
            ""timeZone"": options.timezone,
        },
        ""end"": {
            ""dateTime"": (now + datetime.timedelta(minutes=int(config[""end""]))).strftime(DT_FORMAT),
            ""timeZone"": options.timezone,
        },
    }",Create event start and end datetimes.,Get an event datetimes from events,Create an event datetime object.,50.66743174,55.70306203,53.18524689,,,,,,,,,
"summarize: def purity(state):
    """"""
    """"""
    rho = np.array(state)
    if rho.ndim == 1:
        return 1.0
    return np.real(np.trace(rho.dot(rho)))",Calculate the purity of a quantum state.,Calculate purity of a limit state and limits.,Returns the purity of an image of the binary state.,60.96329316,45.09688671,53.03008994,,,,,,,,,
"summarize: def syntax_check(domain):  # pragma: no cover
    """"""
    
    """"""

    if domain and isinstance(domain, str):
        # * The given domain is not empty nor None.
        # and
        # * The given domain is a string.

        # We silently load the configuration.
        load_config(True)

        return Check(domain).is_domain_valid()

    # We return None, there is nothing to check.
    return None",Check the syntax of the given domain.,Syntax validation of the given domain.,Fetch a single configuration from the given domain.,66.09556604,39.49429182,52.79492893,,,,,,,,,
"summarize: def get_params(self, pnames=None):
        """""" 

        """"""
        l = []
        if pnames is None:
            pnames = self.params.keys()
        for pname in pnames:
            p = self.params[pname]
            if isinstance(p, Parameter):
                l.append(p)
        return l",Return a list of Parameter objects,Returns a list of parameters,Returns a parameter position.,62.25088239,43.01103762,52.63096001,,,,,,,,,
"summarize: def _read_varint(self):
        """"""
        """"""
        buff = self._fd.read(1)
        if buff == b'':
            return 0

        while (bytearray(buff)[-1] & 0x80) >> 7 == 1:  # while the MSB is 1
            new_byte = self._fd.read(1)
            if new_byte == b'':
                raise EOFError('unexpected EOF.')
            buff += new_byte

        varint, _ = decodeVarint(buff, 0)

        return varint","Read a varint from file, parse it, and return the decoded integer.",", buff Reads the varint and returns the decoded integer.",.find('\r\n') Return a varint from the varint based on the ID.,61.13903867,44.10508711,52.62206289,,,,,,,,,
"summarize: def create_metrics(
            self, metric_configs: Iterable[MetricConfig]) -> Dict[str, Metric]:
        """"""""""""
        return self.registry.create_metrics(metric_configs)",Create and register metrics from a list of MetricConfigs.,Create a metrics from the metric configs.,Create a metrics from the ``MetricConfigs``.,49.582583,55.44538952,52.51398626,,,,,,,,,
"summarize: def get_organisation(self, id, name=None):
        '''
        
        '''
        return self.create_organisation(dict(id=id, name=name))",Get an organisation,Gets organisation.,Retrieves the organisation of the given id.,73.57777962,31.33640361,52.45709162,,,,,,,,,
"summarize: def get_mems_of_org(self):
        """"""
        
        """"""
        print 'Getting members.'
        counter = 0
        for member in self.org_retrieved.iter_members():
            self.members_json[member.id] = member.to_json()
            counter += 1
        return counter",Retrieves the number of members of the organization.,Returns the members of the given member.,Retrieves a MetadataOf the given member of the Member.,47.21834037,56.41414846,51.81624442,,,,,,,,,
"summarize: def slabs(request, server_name):
    """"""
    
    """"""
    data = _context_data({
        'title': _('Memcache Slabs for %s') % server_name,
        'cache_slabs': _get_cache_slabs(server_name),
    },
        request)
    return render_to_response('memcache_admin/slabs.html', data, RequestContext(request))",Show server slabs.,Slabs for a server,Sets a slab server.,50.82365017,52.74537345,51.78451181,,,,,,,,,
"summarize: def add_filters(self, filterer, filters):
        """"""""""""
        for f in filters:
            try:
                filterer.addFilter(self.config['filters'][f])
            except StandardError as e:
                raise ValueError('Unable to add filter %r: %s' % (f, e))",Add filters to a filterer from a list of names.,return filter Add filter to add filters to a list of filters,return filterer Add a filters any filters to the filters.,55.80208594,47.71897076,51.76052835,,,,,,,,,
"summarize: def dimension_size(x, axis):
  """"""""""""
  # Since tf.gather isn't ""constant-in, constant-out"", we must first check the
  # static shape or fallback to dynamic shape.
  s = tf.compat.dimension_value(
      tensorshape_util.with_rank_at_least(x.shape, np.abs(axis))[axis])
  if s is not None:
    return s
  return tf.shape(input=x)[axis]",Returns the size of a specific dimension.,Returns the dimension of axis to the tensor.,Constants an input dimension specification.,56.03883674,47.1049832,51.57190997,,,,,,,,,
"summarize: def parser_functions(self) -> List['ParserFunction']:
        """"""""""""
        _lststr = self._lststr
        _type_to_spans = self._type_to_spans
        return [
            ParserFunction(_lststr, _type_to_spans, span, 'ParserFunction')
            for span in self._subspans('ParserFunction')]",Return a list of parser function objects.,Parse the list of functions of the functions.,] Returns a list of functions of the spans,45.67152352,57.27103402,51.47127877,,,,,,,,,
"summarize: def compile_relative_distances(self, sympy_accesses=None):
        """"""
        
        """"""
        if sympy_accesses is None:
            sympy_accesses = self.compile_sympy_accesses()

        sympy_distances = defaultdict(list)
        for var_name, accesses in sympy_accesses.items():
            for i in range(1, len(accesses)):
                sympy_distances[var_name].append((accesses[i-1]-accesses[i]).simplify())

        return sympy_distances",Return load and store distances between accesses.,Returns the compiled relative distances into a list of accesses.,Relative distances and returns a list of accesses.,44.22085246,58.44990796,51.33538021,,,,,,,,,
"summarize: def _get_import_name(importnode, modname):
    """"""
    """"""
    if isinstance(importnode, astroid.ImportFrom):
        if importnode.level:
            root = importnode.root()
            if isinstance(root, astroid.Module):
                modname = root.relative_to_absolute_name(
                    modname, level=importnode.level
                )
    return modname",Get a prepared module name from the given import node,Returns a name for a name for the given import node,Returns the ASTRAM Module for a specified import node.,58.39200098,43.97827689,51.18513894,,,,,,,,,
"summarize: def create_directory(self, share_name, directory_name, **kwargs):
        """"""
        
        """"""
        return self.connection.create_directory(share_name, directory_name, **kwargs)",Create a new directory on a Azure File Share.,Create a new directory to the directory name.,Create a directory and return a directory instance.,57.41191348,44.8649506,51.13843204,,,,,,,,,
"summarize: def lookup_zone(conn, zone):
  """"""""""""
  all_zones = conn.get_all_hosted_zones()
  for resp in all_zones['ListHostedZonesResponse']['HostedZones']:
    if resp['Name'].rstrip('.') == zone.rstrip('.'):
      return resp['Id'].replace('/hostedzone/', '')
  raise ZoneNotFoundError('zone %s not found in response' % zone)",Look up a zone ID for a zone string.,Look up all zones for the zone.,Lookup Zones remote zones for a zone.,52.44013854,49.56957415,51.00485635,,,,,,,,,
"summarize: def get_sections_with_students_in_course_by_sis_id(self, sis_course_id,
                                                       params={}):
        """"""
        
        """"""
        return self.get_sections_with_students_in_course(
            self._sis_id(sis_course_id, sis_field=""course""), params)",Return list of sections including students for the passed sis ID.,Returns the sections of the students for the given course.,Returns a list of SAS students in any subsections.,54.10592909,47.33838495,50.72215702,,,,,,,,,
"summarize: def set_logging_level(level=None):
    """"""
    """"""
    if level is None:
        level = os.environ.get('NEUROSYNTH_LOGLEVEL', 'warn')
    if level is not None:
        logger.setLevel(getattr(logging, level.upper()))
    return logger.getEffectiveLevel()",Set neurosynth's logging level,Set level of logging levels to scan,Set logging level logging,48.32697831,53.11051061,50.71874446,,,,,,,,,
"summarize: def get_public_tokens(self):
        """"""
        
        """"""
        r = self.remote_utils.get_url(self.url() + ""public_tokens/"")
        return r.json()",Get a list of public tokens available on this server.,Get a list of public tokens from the public tokens,Returns the public tokens of the given public_tokens.,59.46956002,41.88604164,50.67780083,,,,,,,,,
"summarize: def _get_axis_mode(self, axis):
        """"
        if all([isinstance(getattr(s, axis), TimeVariable) for s in self._series]):
            return 'time'
        return None",will get the axis mode for the current series,Get the modes of an axis mode for the axis.,Return any of the axis modes of the axis.,58.03900843,43.17779301,50.60840072,,,,,,,,,
"summarize: def safe_decode(line, encoding, *args, **kwargs):
    """"""""""""
    try:
        return line.decode(encoding or sys.getdefaultencoding(), *args, **kwargs)
    except LookupError:
        return line.decode(sys.getdefaultencoding(), *args, **kwargs)",return decoded line from encoding or decode with default encoding,return encoding Safe decode and return a decoded description.,Make a decoding of line and returns a valid value of the decoded encoding.,50.49576277,50.36169073,50.42872675,,,,,,,,,
"summarize: def user_config_file(self):
        """"""""""""
        return os.path.join(
            get_user_config_dir(self.app_name, self.app_author),
            self.filename)",Get the absolute path to the user config file.,Returns the user config files that are an accessible.,Get the user configuration file from the given pointer.,49.80519074,50.95958162,50.38238618,,,,,,,,,
"summarize: def read_config_(self, cfile):
        """"""
        """"""
        if not cfile.exists():
            return {}
        try:
            conf_dict = toml.load(str(cfile))
        except toml.TomlDecodeError:
            return None
        self.update_(conf_dict)
        return conf_dict",Read a config file and set config values accordingly.,Reads a config file and returns the config file.,Ensure a config filename of the corpus configuration.,56.81069026,43.94943775,50.38006401,,,,,,,,,
"summarize: def raw_filter(self, filters):
        """"""
        """"""
        return SearchResult(self, self._api.get(self._href, **{""filter[]"": filters}))",Sends all filters to the API.,Add a list of filters to the filter.,All filters the given filter.,47.63673575,53.01983385,50.3282848,,,,,,,,,
"summarize: def _get_gc_content(sequence, length):
        """"""

        """"""

        # Get AT/GC/N counts
        at = sum(map(sequence.count, [""A"", ""T""]))
        gc = sum(map(sequence.count, [""G"", ""C""]))
        n = length - (at + gc)

        # Get AT/GC/N proportions
        at_prop = at / length
        gc_prop = gc / length
        n_prop = n / length

        return {""at"": at, ""gc"": gc, ""n"": n,
                ""at_prop"": at_prop, ""gc_prop"": gc_prop, ""n_prop"": n_prop}",Get GC content and proportions.,Get AT Counts GC/N proportions,Get aggregated prop proportion.,50.99684195,49.61485877,50.30585036,,,,,,,,,
"summarize: def get_allocations(self, prefix=None):
        """""" 
        """"""
        params = {""prefix"": prefix}
        return self.request(method=""get"", params=params).json()",Lists all the allocations.,Get allocations for the prefix,Gets allocations for all the given prefix.,50.70399082,49.61566634,50.15982858,,,,,,,,,
"summarize: def resolve_streams(wait_time=1.0):
    """"""

    """"""
    # noinspection PyCallingNonCallable
    buffer = (c_void_p*1024)()
    num_found = lib.lsl_resolve_all(byref(buffer), 1024, c_double(wait_time))
    return [StreamInfo(handle=buffer[k]) for k in range(num_found)]",Resolve all streams on the network.,Resolves the streams in the job.,Return a solve stream of the buffer.,54.68792366,45.47912444,50.08352405,,,,,,,,,
"summarize: def get_single(group, name, path=None):
    """"""
    """"""
    for config, distro in iter_files_distros(path=path):
        if (group in config) and (name in config[group]):
            epstr = config[group][name]
            with BadEntryPoint.err_to_warnings():
                return EntryPoint.from_string(epstr, name, distro)

    raise NoSuchEntryPoint(group, name)",Find a single entry point.,Get the single entry point.,Gets a single single single local config.,73.37557033,26.68269328,50.02913181,,,,,,,,,
"summarize: def translate_symbol(self, in_symbol: str) -> str:
        """"""  """"""
        # read all mappings from the db
        if not self.symbol_maps:
            self.__load_symbol_maps()
        # translate the incoming symbol
        result = self.symbol_maps[in_symbol] if in_symbol in self.symbol_maps else in_symbol

        return result",translate the incoming symbol into locally-used,Translate an incoming symbol to the incoming symbol.,Translate the symbols to the db.,60.31980233,39.22906674,49.77443454,,,,,,,,,
"summarize: def command_for_func(func):
    """"""""""""

    class FuncCommand(BaseCommand):

        def run(self):
            func()
            update_package_data(self.distribution)

    return FuncCommand",Create a command that calls the given function.,(func) Starts the command for the given function.,(func) Returns the command in the UPDATESTANCYMES,63.04866875,36.14570331,49.59718603,,,,,,,,,
"summarize: def _send_post_request(self, path, data, headers):
        """"""
        
        """"""

        r = requests.post(self.endpoint + path, data=data, headers=headers)
        return r.text",Sends the POST request to the Route53 endpoint.,", r.text Retrieves the post request to the location.",.strip() Sends the request to the post request.,43.46224854,55.69316655,49.57770755,,,,,,,,,
"summarize: def validate_access_token(self, client_key, token, request):
        """"""""""""
        log.debug('Validate access token %r for %r',
                  token, client_key)
        tok = request.access_token or self._tokengetter(
            client_key=client_key,
            token=token,
        )
        if tok:
            request.access_token = tok
            return True
        return False",Validates access token is available for client.,Validate access token and return if it exists.,Validate access token to the access token,50.47229488,48.66587658,49.56908573,,,,,,,,,
"summarize: def copy(self):
        """"""""""""
        layout_copy = type(self)()

        layout_copy._p2v = self._p2v.copy()
        layout_copy._v2p = self._v2p.copy()

        return layout_copy",Returns a copy of a Layout instance.,Returns a single layout copy of the layout count.,Returns the copy of the layout_copy.,46.49934468,52.41484725,49.45709597,,,,,,,,,
"summarize: def get_pull_request(app, repo_config, pull_request):
    """"""
    """"""
    response = get_api_response(
        app, repo_config,
        ""/repos/{{repo_name}}/pulls/{0}"".format(pull_request))
    if not response.ok:
        raise Exception(""Unable to get pull request: status code {}"".format(response.status_code))
    return response.json",Data for a given pull request.,() Gets the pull request.,() Retrieves a pull request.,46.23949784,52.67321812,49.45635798,,,,,,,,,
"summarize: def list_folder(self, folder_id=None):
        """"""

        """"""
        params = {'folder': folder_id} if folder_id else {}

        return self._get('file/listfolder', params=params)",Request a list of files and folders in specified folder.,Returns a list of folder folder folders for the given folder.,Lists a list of all folder ids and folder ids.,47.8072762,51.0582067,49.43274145,,,,,,,,,
"summarize: def from_string(cls, epstr, name, distro=None):
        """"""
        """"""
        m = entry_point_pattern.match(epstr)
        if m:
            mod, obj, extras = m.group('modulename', 'objectname', 'extras')
            if extras is not None:
                extras = re.split(r',\s*', extras)
            return cls(name, mod, obj, extras, distro)
        else:
            raise BadEntryPoint(epstr)",Parse an entry point from the syntax in entry_points.txt,Create an entry point from the given ``EntryPoint``,Create a single entrypoint from the property URL.,57.49671767,41.35012001,49.42341884,,,,,,,,,
"summarize: def create_notebook_checkpoint(self, nb, path):
        """"""
        """"""
        b64_content = writes_base64(nb)
        with self.engine.begin() as db:
            return save_remote_checkpoint(
                db,
                self.user_id,
                path,
                b64_content,
                self.crypto.encrypt,
                self.max_file_size_bytes,
            )",Create a checkpoint of the current state of a notebook,Create a new ID of the last notebook checkpoint,Returns the notebook object of the notebook.,62.35128364,36.06131508,49.20629936,,,,,,,,,
"summarize: def _should_catch_error(self, error, errors=()):
        """"""
        
        """"""

        caught_errors = (
            errors or
            self.session.driver.invalid_element_errors + (ElementNotFound,))

        return isinstance(error, caught_errors)",Returns whether to catch the given error.,Returns an error message with the given error.,Change a catch an error if there is an error.,57.60322765,40.74548012,49.17435389,,,,,,,,,
"summarize: def get_file_lines(file_name):
    """"""""""""
    file_path = path.join(path.dirname(path.abspath(__file__)), file_name)
    with open(file_path) as file_obj:
        return [line for line in file_obj.read().splitlines() if line]",Return a list of non-empty lines from `file_path`.,Return a list of files files from files,Return a list of files in the file path.,50.43474825,47.66835471,49.05155148,,,,,,,,,
"summarize: def get_evaluations(self, variant_obj):
        """"""
        """"""
        query = dict(variant_id=variant_obj['variant_id'])
        res = self.acmg_collection.find(query).sort([('created_at', pymongo.DESCENDING)])
        return res",Return all evaluations for a certain variant.,Get evaluations from the Given variant.,Return a list of active evaluations.,52.29780078,45.63040026,48.96410052,,,,,,,,,
"summarize: def get_bound_method(self, instruction):
        """"""""""""
        try:
            return self._bound_instructions[type(instruction)]
        except KeyError:
            raise PulseError('Qobj conversion method for %s is not found.' % instruction)",Get conversion method for instruction.,return instruction Get the bound method for the given instruction.,Returns a bound instruction method.,43.1292181,54.63503973,48.88212892,,,,,,,,,
"summarize: def __early_downsample_count(nyquist, filter_cutoff, hop_length, n_octaves):
    ''''''

    downsample_count1 = max(0, int(np.ceil(np.log2(audio.BW_FASTEST * nyquist /
                                                   filter_cutoff)) - 1) - 1)

    num_twos = __num_two_factors(hop_length)
    downsample_count2 = max(0, num_twos - n_octaves + 1)

    return min(downsample_count1, downsample_count2)",Compute the number of early downsampling operations,"r""""""Compute the early one early count number of early one early samples",Early additional downsample number of filtering the filtering.,45.9491546,51.66027581,48.80471521,,,,,,,,,
"summarize: def push_zipkin_attrs(zipkin_attr):
    """"""
    """"""
    from py_zipkin.storage import ThreadLocalStack
    log.warning('push_zipkin_attrs is deprecated. See DEPRECATIONS.rst for'
                'details on how to migrate to using Tracer.')
    return ThreadLocalStack().push(zipkin_attr)",Stores the zipkin attributes to thread local.,Pushes the zipkin attributes to the zipkin attribute,Gets a zipkin attribute of the zipkin attribute from Zipkin.,58.62219266,38.8181875,48.72019008,,,,,,,,,
"summarize: def copy_endpoint_with_new_service_name(endpoint, new_service_name):
    """"""
    """"""
    return Endpoint(
        service_name=new_service_name,
        ipv4=endpoint.ipv4,
        ipv6=endpoint.ipv6,
        port=endpoint.port,
    )",Creates a copy of a given endpoint with a new service name.,Copy a new service name for an endpoint.,Copy an endpoint service name to the current service.,48.38177686,48.70511149,48.54344418,,,,,,,,,
"summarize: def get_feature_data(self, ids=None, features=None, dense=True):
        """""" 
        """"""
        result = self.data

        if ids is not None:
            result = result.ix[ids]

        if features is not None:
            result = result.ix[:, features]

        return result.to_dense() if dense else result",Slices and returns a subset of feature data.,.to_dense() Returns a data feature data,.data[ids] Returns a feature data from the data.,49.22362045,47.48376043,48.35369044,,,,,,,,,
"summarize: def add_comment(self, comment_text):
        '''
        
        '''
        return self.fetch_json(
            uri_path=self.base_uri + '/actions/comments',
            http_method='POST',
            query_params={'text': comment_text}
        )",Adds a comment to this card by the current user.,Add a comment to the url for the specified comment.,Add a comment to the action and return the comment.,47.59625465,48.99469506,48.29547486,,,,,,,,,
"summarize: def decorated_with_property(node: astroid.FunctionDef) -> bool:
    """"""  """"""
    if not node.decorators:
        return False
    for decorator in node.decorators.nodes:
        if not isinstance(decorator, astroid.Name):
            continue
        try:
            if _is_property_decorator(decorator):
                return True
        except astroid.InferenceError:
            pass
    return False",Detect if the given function node is decorated with a property.,Decorator to decorate a property on the given node.,Decorator whether a property is the decorator is a generator.,53.38725162,43.07307353,48.23016258,,,,,,,,,
"summarize: def get_deployments(self, prefix=""""):
        """""" 
        """"""
        params = {""prefix"": prefix}
        return self.request(params=params, method=""get"").json()",This endpoint lists all deployments.,Get a list of deployments from the current prefix.,Returns a list of all deployments.,35.95768288,60.38661802,48.17215045,,,,,,,,,
"summarize: def has_title(self, title, **kwargs):
        """"""
        
        """"""

        try:
            self.assert_title(title, **kwargs)
            return True
        except ExpectationNotMet:
            return False",Checks if the page has the given title.,Checks a title for the given title.,Get the title of the title.,60.60835323,34.73752704,47.67294014,,,,,,,,,
"summarize: def attachments(self, *bug_ids):
        """"""
        """"""
        resource = urijoin(self.RBUG, bug_ids[0], self.RATTACHMENT)

        params = {
            self.PIDS: bug_ids,
            self.PEXCLUDE_FIELDS: self.VEXCLUDE_ATTCH_DATA
        }

        response = self.call(resource, params)

        return response",Get the attachments of the given bugs.,Adds the attachments to the AMENT IDs.,Attachments the ASTATED_ATTACHMENT of a given `OsidS`.,55.10042139,40.20709885,47.65376012,,,,,,,,,
"summarize: def create(env_dir, system_site_packages=False, clear=False,
                    symlinks=False, with_pip=False, prompt=None):
    """"""""""""
    builder = ExtendedEnvBuilder(system_site_packages=system_site_packages,
                                 clear=clear, symlinks=symlinks, with_pip=with_pip,
                                 prompt=prompt)
    builder.create(env_dir)
    return builder.context",Create a virtual environment in a directory.,(builder) Create a Generator on a new environment.,"(env_dir, clear) Create an environment.",47.93579222,47.29450246,47.61514734,,,,,,,,,
"summarize: def find_profile_dir_by_name(cls, ipython_dir, name=u'default', config=None):
        """"""
        """"""
        dirname = u'profile_' + name
        paths = [os.getcwdu(), ipython_dir]
        for p in paths:
            profile_dir = os.path.join(p, dirname)
            if os.path.isdir(profile_dir):
                return cls(location=profile_dir, config=config)
        else:
            raise ProfileDirError('Profile directory not found in paths: %s' % dirname)","Find an existing profile dir by profile name, return its ProfileDir.",Get a directory profile directory and return a list of directory profiles,"return None Find a profiledir, using the profiledir to the profiledir.",43.51977048,51.67806394,47.59891721,,,,,,,,,
"summarize: def pull_commits(self, pr_number):
        """"""""""""

        payload = {
            'per_page': PER_PAGE,
        }

        commit_url = urijoin(""pulls"", str(pr_number), ""commits"")
        return self.fetch_items(commit_url, payload)",Get pull request commits,Pull commits in the page,Returns the pull commits.,43.3137163,51.78902283,47.55136957,,,,,,,,,
"summarize: def parse_filename(fname):
    """"""
    """"""
    if fname.endswith(u'.ipynb'):
        format = u'json'
    elif fname.endswith(u'.json'):
        format = u'json'
    elif fname.endswith(u'.py'):
        format = u'py'
    else:
        fname = fname + u'.ipynb'
        format = u'json'
    name = fname.split('.')[0]
    return fname, name, format",Parse a notebook filename.,Parse a filename format.,Generate a filename for a filename.,58.92205063,35.86849164,47.39527114,,,,,,,,,
"summarize: def _compute_progress_at_time(self, t):
        """"""
        
        """"""
        t0, x0, v0, ve = self._t0, self._x0, self._v0, self._ve
        z = (v0 - ve) * math.exp(-self.BETA * (t - t0))
        vt = ve + z
        xt = clamp(x0 + ve * (t - t0) + (v0 - ve - z) / self.BETA, 0, 1)
        return xt, vt",Calculate the modelled progress state for the given time moment.,Compute the progress at time for a t0 and adding the progress at time.,Return a standard time to the progress at the given taken.,43.8364548,50.80699633,47.32172557,,,,,,,,,
"summarize: def _convert_annotations(annotations):
    """"""
    """"""
    pb_annotations = []
    for value, ts in annotations.items():
        pb_annotations.append(zipkin_pb2.Annotation(
            timestamp=int(ts * 1000 * 1000),
            value=value,
        ))
    return pb_annotations",Converts py_zipkin's annotations dict to protobuf.,Converts a list of pb annotations to annotations,Convert annotation to annotations into annotations.,49.95027211,44.55008939,47.25018075,,,,,,,,,
"summarize: def get_state_exitcode_details(self, resource_group, name):
        """"""
        
        """"""
        current_state = self._get_instance_view(resource_group, name).current_state
        return (current_state.state,
                current_state.exit_code,
                current_state.detail_status)",Get the state and exitcode of a container group,Get a state of the exitcode state and add a detail to the names.,Get all the state existing state of a state.,47.19852821,47.2993649,47.24894656,,,,,,,,,
"summarize: def deprecated(replacement=None):
    """"""""""""
    def outer(fun):
        msg = ""psutil.%s is deprecated"" % fun.__name__
        if replacement is not None:
            msg += ""; use %s instead"" % replacement
        if fun.__doc__ is None:
            fun.__doc__ = msg

        @wraps(fun)
        def inner(*args, **kwargs):
            warnings.warn(msg, category=DeprecationWarning, stacklevel=2)
            return fun(*args, **kwargs)

        return inner
    return outer",A decorator which can be used to mark functions as deprecated.,Deprecated deprecation when a function is deprecated.,Deprecated the wrapper decorator for deprecated function.,42.88203661,51.54005974,47.21104818,,,,,,,,,
"summarize: def prepend_child(self, name):
        """"""""""""
        return XMLElement(lib.lsl_prepend_child(self.e, str.encode(name)))",Prepend a child element with the specified name.,Finds a child of the specified name.,Returns the name and assignment in the child children.,55.67218745,38.62648488,47.14933617,,,,,,,,,
"summarize: def get_builds(self, job_name):
        """""" """"""

        if self.blacklist_jobs and job_name in self.blacklist_jobs:
            logger.warning(""Not getting blacklisted job: %s"", job_name)
            return

        payload = {'depth': self.detail_depth}
        url_build = urijoin(self.base_url, ""job"", job_name, ""api"", ""json"")

        response = self.fetch(url_build, payload=payload)
        return response.text",Retrieve all builds from a job,Retrieve the jobs from the job.,() Retrieves a job to the jobs.,52.55188958,41.50039785,47.02614372,,,,,,,,,
"summarize: def maybe_broadcast_structure(from_structure: Any, to_structure: Any) -> Any:
  """"""
  """"""
  flat_from = tf.nest.flatten(from_structure)
  flat_to = tf.nest.flatten(to_structure)
  if len(flat_from) == 1:
    flat_from *= len(flat_to)
  return tf.nest.pack_sequence_as(to_structure, flat_from)",Maybe broadcasts `from_structure` to `to_structure`.,Returns the ``to_structure`` from any structure.,Method to maybe input values of `to_structure`,51.2448052,42.71958908,46.98219714,,,,,,,,,
"summarize: def create_database(self, instance, body, project_id=None):
        """"""
        
        """"""
        response = self.get_conn().databases().insert(
            project=project_id,
            instance=instance,
            body=body
        ).execute(num_retries=self.num_retries)
        operation_name = response[""name""]
        self._wait_for_operation_to_complete(project_id=project_id,
                                             operation_name=operation_name)",Creates a new database inside a Cloud SQL instance.,Creates a new database for a given instance.,return self._create_database(self._create_database_by_id(instance)) Creates a database.,64.55559135,29.37995078,46.96777107,,,,,,,,,
"summarize: def drop_exons(self, build=None):
        """"""""""""
        if build:
            LOG.info(""Dropping the exons collection, build %s"", build)
            self.exon_collection.delete_many({'build': build})
        else:
            LOG.info(""Dropping the exons collection"")
            self.exon_collection.drop()",Delete the exons collection,Drop the exons collection.,self.exon_collection.delete_many(build) self.exon_collection.delete_many(build) return self.exon_collection Get the exons an exons.,77.43779053,16.39802119,46.91790586,,,,,,,,,
"summarize: def name(dtype):
  """"""""""""
  dtype = tf.as_dtype(dtype)
  if hasattr(dtype, 'name'):
    return dtype.name
  if hasattr(dtype, '__name__'):
    return dtype.__name__
  return str(dtype)",Returns the string name for this `dtype`.,Returns the name of an array name for the given dtype.,Return the name of a single dtype object.,48.46062586,45.12758783,46.79410685,,,,,,,,,
"summarize: def group_delay(wave):
    
    """"""
    ret = -derivative(phase(wave, unwrap=True) / (2 * math.pi))
    ret.dep_name = ""group_delay({0})"".format(wave.dep_name)
    ret.dep_units = ""sec""
    return ret","r""""""  Return the group delay of a waveform.",Returns the delay on a group.,Get a grouping delay of the groups.,45.87126292,47.7130244,46.79214366,,,,,,,,,
"summarize: def get_unique_backends():
    """"""
    """"""
    backends = IBMQ.backends()
    unique_hardware_backends = []
    unique_names = []
    for back in backends:
        if back.name() not in unique_names and not back.configuration().simulator:
            unique_hardware_backends.append(back)
            unique_names.append(back.name())
    if not unique_hardware_backends:
        raise QiskitError('No backends available.')
    return unique_hardware_backends",Gets the unique backends that are available.,Get the list of unique hardware backends.,Gets the backends from an OBMQ.,54.187438,39.3368613,46.76214965,,,,,,,,,
"summarize: def _parse_validators(valids):
    """"""
    """"""

    outvals = []

    for val in valids:
        if isinstance(val, str):
            args = []
        elif len(val) > 1:
            args = val[1:]
            val = val[0]
        else:
            raise ValidationError(""You must pass either an n-tuple or a string to define a validator"", validator=val)

        name = ""validate_%s"" % str(val)
        outvals.append((name, args))

    return outvals","Parse a list of validator names or n-tuples, checking for errors.",Parse a list of validators for a single validator.,Return a list of integer values in a validator for the validator.,48.37941105,45.00268574,46.6910484,,,,,,,,,
"summarize: def _check_arg_equality(node_a, node_b, attr_name):
    """"""
    
    """"""
    return getattr(node_a, attr_name) == getattr(node_b, attr_name)",Check equality of nodes based on the comparison of their attributes named attr_name.,Returns the location of the equality of the node based on the node based on the node attr.,or attr_name in node_b.keys() Returns the equality equality equality of the given node_name.,49.62710958,43.69394308,46.66052633,,,,,,,,,
"summarize: def get_setting(connection, key):
    """"""""""""
    if key in connection.settings_dict:
        return connection.settings_dict[key]
    else:
        return getattr(settings, key)",Get key from connection or default to settings.,Gets a setting from the connection.,Return a setting setting connection object.,48.41038549,44.8200553,46.6152204,,,,,,,,,
"summarize: def _default_handlers(self):
        """"""  """"""
        static_path = os.path.abspath(os.path.join(os.path.dirname(__file__),""static""))
        urls = [
            (r""/static/(.*)"", cyclone.web.StaticFileHandler, {""path"": static_path}),
        ]
        for p in self.pages:
            handler = p.handler
            handler.site = self
            handler.page = p
            urls.append((p.link.url,handler))
        return urls",Generate the handlers for this site,Returns the handlers for the given scope.,Execute a handler for a single urls.,54.73684057,38.4190683,46.57795444,,,,,,,,,
"summarize: def _get_string_selection(self):
        """"
        if self.multiselect:
            return [self.wx_obj.GetString(i) for i in 
                    self.wx_obj.GetSelections()]
        else:
            return self.wx_obj.GetStringSelection()",Returns the label of the selected item or an empty string if none,Returns the specified selection of the given string.,Returns the string selection of the index.,48.95342528,44.16819774,46.56081151,,,,,,,,,
"summarize: def retrieve_connection(self, session=None):
        """"""
        
        """"""
        self.log.info(""Retrieving connection %s"", self.db_conn_id)
        connections = session.query(Connection).filter(
            Connection.conn_id == self.db_conn_id)
        if connections.count():
            return connections[0]
        return None",Retrieves the dynamically created connection from the Connection table.,We assume a connection for the session and connections to session.,Retrieves the connections of the specified connection.,42.00531074,50.80889845,46.4071046,,,,,,,,,
"summarize: def is_seq_of(seq, expected_type, seq_type=None):
    """"""
    """"""
    if seq_type is None:
        exp_seq_type = collections_abc.Sequence
    else:
        assert isinstance(seq_type, type)
        exp_seq_type = seq_type
    if not isinstance(seq, exp_seq_type):
        return False
    for item in seq:
        if not isinstance(item, expected_type):
            return False
    return True",Check whether it is a sequence of some type.,Returns the seq for a sequence of a seq type,Returns True if seq is a sequence of a valid key.,49.91837059,42.84539111,46.38188085,,,,,,,,,
"summarize: def get_parent(self, path):
        '''
        '''

        self.__validate_storage_path(path, projects_allowed=False)
        path_steps = [step for step in path.split('/') if step]
        del path_steps[-1]
        parent_path = '/{0}'.format('/'.join(path_steps))
        return self.api_client.get_entity_by_query(path=parent_path)",Get the parent entity of the entity pointed by the given path.,Get the parent folder for the given path.,Get the parent path steps from the given path.,44.26998203,48.40013979,46.33506091,,,,,,,,,
"summarize: def endswith(string):
    """"""""""""
    def ends_with(value):
        validate(text, value)
        if not value.endswith(string):
            raise ValueError(""'{0}' does not end with '{1}'"".format(value, string))
        return True

    return ends_with",Checks if the string value ends with another string.,(string) Returns the ends with the values of the ``string``.,"(string, string) Return an ending end of an end of the string.",53.13255647,39.39775099,46.26515373,,,,,,,,,
"summarize: def explained_variance(self):
        """"""
        """"""
        self.tree.root._v=0
        for n in self.tree.get_nonterminals(order='preorder'):
            for c in n:
                c._v = n._v + self.branch_value(c)
        raw = np.array([(self.tip_value(n), n._v) for n in self.tree.get_terminals()
                         if self.tip_value(n) is not None])
        return np.corrcoef(raw.T)[0,1]",calculate standard explained variance,Multiply the explained variance,Explains variance on any tree.,54.20961476,38.20663441,46.20812459,,,,,,,,,
"summarize: def get_decimal_quantum(precision):
    """"""""""""
    assert isinstance(precision, (int, decimal.Decimal))
    return decimal.Decimal(10) ** (-precision)","Return minimal quantum of a number, as defined by precision.",Returns decimal quantum indicators of the `precision`.,"/ (1, 1.0) Returns a decimal number of decimal number of recisions.",50.76601269,41.36475976,46.06538623,,,,,,,,,
"summarize: def _find_inner_most_loop(self, loop_nest):
        """"""""""""
        r = None
        for s in loop_nest:
            if type(s) is c_ast.For:
                return self._find_inner_most_loop(s) or s
            else:
                r = r or self._find_inner_most_loop(s)
        return r",Return inner most for loop in loop nest,Returns the inner loop on a finished loop.,Returns the inner_most_loop for the permission.,50.72915195,41.3925803,46.06086613,,,,,,,,,
"summarize: def _get_imports(self):
    """"""""""""
    import_directives = [d for d in self.directives if d.name == ""import""]
    if import_directives:
      return ""\n"" + ""\n"".join(d.args[""value""] for d in import_directives)
    else:
      return """"",Reads the directives and generates source code for custom imports.,Returns a list of imports in an import to the directives.,Return the directives for the imports and private keys.,41.54704505,50.39179903,45.96942204,,,,,,,,,
"summarize: def path(self):
        """"""
        
        """"""
        if self._parent:
            return os.path.join(self._parent.path, self._fpath)
        else:
            return self._fpath",Get the path to the file relative to its parent.,Returns the path of the path of the parent root,Get the path of the parent directory.,45.5186186,46.37376096,45.94618978,,,,,,,,,
"summarize: def _get_names_part(self, part):
        """"""

        """"""
        try:
            the_list = getattr(self.vcard.n.value, part)
        except AttributeError:
            return []
        else:
            # check if list only contains empty strings
            if not ''.join(the_list):
                return []
        return the_list if isinstance(the_list, list) else [the_list]","Get some part of the ""N"" entry in the vCard as a list",Returns the list of the list of fields in the given part,Return a list of parts in the list of the lists.,43.89262964,47.80140086,45.84701525,,,,,,,,,
"summarize: def get_conn(self):
        """"""
        
        """"""
        conn_config = self._get_conn_params()
        conn = snowflake.connector.connect(**conn_config)
        return conn",Returns a snowflake.connection object,Returns a GET Connection to the conn,Returns the conn for the ForegroundConnection,53.13885548,38.32081683,45.72983616,,,,,,,,,
"summarize: def find_overlaps(self, index=False):
        """"""
        
        """"""
        return self.__find_incongruities(op=operator.gt, index=index)",Find overlaps in a striplog.,Find index of overlaps,Find the overlaps of the index.,45.38584865,46.07059624,45.72822245,,,,,,,,,
"summarize: def add_section(self):
        """"""""""""
        sect = CodeBuilder(self.indent_amount)
        self.code.append(sect)
        return sect","Add a section, a sub-CodeBuilder.",Add a section to the given section,Add a section builder.,40.03735474,51.13663745,45.5869961,,,,,,,,,
"summarize: def list_topics(self, name):
        '''
        
        '''
        response = self._perform_get(
            self._get_list_topics_path(name),
            None)

        return _MinidomXmlToObject.convert_response_to_feeds(
            response,
            partial(
                _MinidomXmlToObject.convert_xml_to_azure_object,
                azure_type=TopicDescription
            )
        )",Retrieves the topics in the service namespace.,Creates the topics of the specified names,Gets a list of topics given to the given name.,52.72840107,38.21625701,45.47232904,,,,,,,,,
"summarize: def get(self, url, params=None, **kwargs):
        """""" 
        """"""
        return self.call_api(
            ""GET"",
            url,
            params=params,
            **kwargs
        )",Call the API with a GET request.,Get a URL to the GET request,Return a request by a url with a url.,50.13561854,40.63105884,45.38333869,,,,,,,,,
"summarize: def find_magic(self, magic_name, magic_kind='line'):
        """"""""""""
        return self.magics_manager.magics[magic_kind].get(magic_name)",Find and return a magic of the given type by name.,Returns a message on the magic name.,Returns a float magic instance of the given magic.,39.35713918,51.20073154,45.27893536,,,,,,,,,
"summarize: def register_post_execute(self, func):
        """"""
        """"""
        if not callable(func):
            raise ValueError('argument %s must be callable' % func)
        self._post_execute[func] = True",Register a function for calling after code execution.,return self._post_execute[func] Registers a function.,return func Register a function with the MAX IDs.,46.8991402,43.43902039,45.1690803,,,,,,,,,
"summarize: def get_messages(user):
    """"""
    
    """"""
    key = _user_key(user)
    result = cache.get(key)
    if result:
        cache.delete(key)
        return result
    return None",Fetch messages for given user. Returns None if no such message exists.,Returns a list of messages for the given user.,Get the messages for the messages of the given user.,43.610729,46.70695435,45.15884168,,,,,,,,,
"summarize: def list_service_level_objectives(self, server_name):
        '''
        
        '''
        _validate_not_none('server_name', server_name)
        response = self._perform_get(
            self._get_service_objectives_path(server_name), None)
        return _MinidomXmlToObject.parse_service_resources_response(
            response, ServiceObjective)",Gets the service level objectives for an Azure SQL Database server.,Returns the service levels for the given service level.,Gets the service levels representing an an service.,45.82128097,44.38933737,45.10530917,,,,,,,,,
"summarize: def get_context_data(self, **kwargs):
        """"""
        

        """"""
        ctx = super(RenderWidgetMixin, self).get_context_data(**kwargs)
        ctx.update({
            'is_rendered': True,
            'widget': self.widget,
        })
        ctx.update(self.widget.get_context_data())
        return ctx",Adds ``is_rendered`` to the context and the widget's context data.,.get_context_data() Returns the context data for the given context and returns it,.update(ctx) Get the context data from the context data.,44.74492813,45.22829954,44.98661384,,,,,,,,,
"summarize: def _update_run_information(self, run_information_dict):
        """"""""""""
        idx = run_information_dict['idx']
        name = run_information_dict['name']
        self._run_information[name] = run_information_dict
        self._updated_run_information.add(idx)",Overwrites the run information of a particular run,return idx Updates the run information.,return idx Returns the run information from the run information.,48.17065907,41.72054585,44.94560246,,,,,,,,,
"summarize: def _get_local_files(self, path):
        """"""""""""
        if not path:
            raise ValueError(""No path specified"")
        files = defaultdict(lambda: None)
        path_len = len(path) + 1
        for root, dirs, filenames in os.walk(path):
            for name in filenames:
                full_path = join(root, name)
                files[full_path[path_len:]] = compute_md5(full_path) 
        return files",Returns a dictionary of all the files under a path.,Returns a list of files within the given filenames.,Returns the files of the compute path.,44.24400883,45.35416197,44.7990854,,,,,,,,,
"summarize: def trainable_positive_deterministic(shape, min_loc=1e-3, name=None):
  """"""""""""
  with tf.compat.v1.variable_scope(
      None, default_name=""trainable_positive_deterministic""):
    unconstrained_loc = tf.compat.v1.get_variable(""unconstrained_loc"", shape)
    loc = tf.maximum(tf.nn.softplus(unconstrained_loc), min_loc)
    rv = ed.Deterministic(loc=loc, name=name)
    return rv",Learnable Deterministic distribution over positive reals.,Get the deterministic for positive_deterministic for a given name.,Returns a training positive distribution of this class.,40.80186866,48.71977756,44.76082311,,,,,,,,,
"summarize: def get_game_dir(self, username=False):
        """"""""""""
        if not self.common and not username:
            raise RuntimeError(""Can't determine this game's directory without username"")
        if self.common:
            subdir = ""common""
        else:
            subdir = ""username""
        subsubdir = self.dir
        if WIN32 or CYGWIN:
            subsubdir = subsubdir.lower()
        return os.path.join(subdir, subsubdir)",Returns joined game directory path relative to Steamapps,Returns a file name for a game directory for a game directory.,Returns game directory directory if the game is valid.,42.11539652,47.37863388,44.7470152,,,,,,,,,
"summarize: def is_running(self):
        """"""
        
        """"""
        try:
            if h2o.connection().local_server and not h2o.connection().local_server.is_running(): return False
            h2o.api(""GET /"")
            return True
        except (H2OConnectionError, H2OServerError):
            return False",Determine if the H2O cluster is running or not.,return True Determine if a home port is running.,Returns True if the server is not provided.,52.15741672,37.11186999,44.63464336,,,,,,,,,
"summarize: def lastActivity(self):
        """"""""""""
        last_activity = self._json_data.get('lastActivity')
        if last_activity:
            return WebexTeamsDateTime.strptime(last_activity)
        else:
            return None",The date and time of the person's last activity.,Get the lastActivity of the specified activity.,Get the current requested last activity.,47.54310692,41.06989106,44.30649899,,,,,,,,,
"summarize: def _read_deref(ctx: ReaderContext) -> LispForm:
    """"""""""""
    start = ctx.reader.advance()
    assert start == ""@""
    next_form = _read_next_consuming_comment(ctx)
    return llist.l(_DEREF, next_form)",Read a derefed form from the input stream.,Reads the deref form from the creation file,Read a deref for an OS-series,55.27459023,33.27785338,44.27622181,,,,,,,,,
"summarize: def get_authorization_server(self):
        """"""  """"""
        value = ''
        for key in ['authorization_uri', 'authorization']:
            value = self.get_value(key) or ''
            if value:
                break
        return value","Returns the URI for the authorization server if present, otherwise empty string.",Get authorization authorization authorization using the authorization server,Return a server to the authorization server to the authorization server.,38.68430305,49.61326529,44.14878417,,,,,,,,,
"summarize: def convert_persistent_value(self, shift, instruction):
        """"""
        """"""
        command_dict = {
            'name': 'pv',
            't0': shift+instruction.start_time,
            'ch': instruction.channels[0].name,
            'val': instruction.command.value
        }
        return self._qobj_model(**command_dict)",Return converted `PersistentValueInstruction`.,Convert a persistent value to a persistent value,Returns a persistent value of instruction.,35.58476472,52.70732432,44.14604452,,,,,,,,,
"summarize: def eval_str(s: str, ctx: compiler.CompilerContext, module: types.ModuleType, eof: Any):
    """"""""""""
    last = eof
    for form in reader.read_str(s, resolver=runtime.resolve_alias, eof=eof):
        last = compiler.compile_and_exec_form(form, ctx, module)
    return last",Evaluate the forms in a string into a Python module AST node.,Evaluate the any of the same strings into an empty element.,Evaluate the evaluating elements in the last information.,46.83571177,41.35314479,44.09442828,,,,,,,,,
"summarize: def get_date(datetime, time_format=None):
    """"""
    
    """"""
    if time_format is None:
        t = du.parser.parse(datetime)
    else:
        t = dt.datetime.strftime(datetime, time_format)
    return t","Return a datetime oject from a string, with optional time format.",.strftime(t) Returns a string instance of time limit.,.strftime(t) Return a timestamp from a datetime.datetime object.,35.07974441,53.06997447,44.07485944,,,,,,,,,
"summarize: def price_converter(obj):
    """"""""""""
    if isinstance(obj, str):
        obj = PriceClass.parse(obj)
    return obj",Ensures that string prices are converted into Price objects.,Price a converter to a class converter to a list of objects.,".price_converter(obj, obj) Returns the price classified objects.",42.3105489,45.37256412,43.84155651,,,,,,,,,
"summarize: def get_strings(args):
    """"""""""""
    string_list = []
    for elem in ast.walk(ast.parse(args)):
        if isinstance(elem, ast.Str):
            string_list.append(elem.s)
    return string_list",Returns all valid python strings inside a given argument string.,"Returns a list of strings in the list of strings, if available.",Returns a list of strings in a single string.,45.16030827,42.43080818,43.79555823,,,,,,,,,
"summarize: def merge(self, new_dict):
        """"""""""""
        actions = new_dict.pop(""actions"")
        for action in actions:
            self.add_action(action)

        self.__dict__.update(new_dict)",Merges a dictionary into the Rule object.,return actions Merges a new dictionary.,return actions Return an object in the Merged object.,48.68871137,38.87514556,43.78192847,,,,,,,,,
"summarize: def _bind_parameter(self, parameter, value):
        """"""""""""
        for (instr, param_index) in self._parameter_table[parameter]:
            instr.params[param_index] = value",Assigns a parameter value to matching instructions in-place.,return instr Binds the instruction of parameters to the default values,return instr Returns a dictionary of parameter instance.,44.51390802,42.88882555,43.70136679,,,,,,,,,
"summarize: def has_register(self, register):
        """"""
        
        """"""
        has_reg = False
        if (isinstance(register, QuantumRegister) and
                register in self.qregs):
            has_reg = True
        elif (isinstance(register, ClassicalRegister) and
              register in self.cregs):
            has_reg = True
        return has_reg",Test if this circuit has the register r.,Ask if the given register is an Array.,and has_reg Gets the register instance of this CregnyFile.,45.52911214,41.63580494,43.58245854,,,,,,,,,
"summarize: def device(self):
        """"""""""""
        splitted_path = self.path.split(""/"")

        return Device(self.db,
                      splitted_path[0] + ""/"" + splitted_path[1])",returns the device which owns the given stream,Returns the device of the device,Removes the device from the current device.,45.63736088,41.52604933,43.58170511,,,,,,,,,
"summarize: def concat(*seqs) -> ISeq:
    """"""""""""
    allseqs = lseq.sequence(itertools.chain(*filter(None, map(to_seq, seqs))))
    if allseqs is None:
        return lseq.EMPTY
    return allseqs",Concatenate the sequences given by seqs into a single ISeq.,[-1] Returns the concatenated sequence for a sequence for a given seq.,Add a ``SEQUITY`` to the single sequence of the ISEQUITY instance.,47.22875955,39.91239834,43.57057895,,,,,,,,,
"summarize: def running_conversions(self, folder_id=None):
        """"""

        """"""
        params = {'folder': folder_id} if folder_id else {}
        return self._get('file/runningconverts', params=params)",Shows running file converts by folder,Starts a list of running conversions,Get the converting folder for a given folder.,46.4116846,40.2615062,43.3365954,,,,,,,,,
"summarize: def show(self, *args, **kwargs):
        """"""
        
        """"""
        from webbrowser import open as webopen
        return webopen(str(self), *args, **kwargs)",Shows the chart URL in a webbrowser,Show the Webbrowser into a choice.,Get all webbrowsers with an Webbrowser.,49.72556283,36.93070183,43.32813233,,,,,,,,,
"summarize: def get_random_voxels(dataset, n_voxels):
    """""" 
    """"""
    voxels = np.arange(dataset.masker.n_vox_in_vol)
    np.random.shuffle(voxels)
    selected = voxels[0:n_voxels]
    return dataset.get_image_data(voxels=selected)",Returns mappable data for a random subset of voxels.,Returns the random voxels with the given VOX Image dataset.,Get dataset of voxels that are available scripts.,43.68854544,42.9058947,43.29722007,,,,,,,,,
"summarize: def create_tfs_connection(url, token):
    """"""
    
    """"""
    if token is None:
        token = os.environ.get('TFS_API_TOKEN', None)

    tfs_credentials = BasicAuthentication('', token)
    tfs_connection = VssConnection(base_url=url, creds=tfs_credentials)
    return tfs_connection",Creates the TFS Connection Context,Creates a new tfs connection.,Create any URL for a tfs connection.,46.39213075,40.06636128,43.22924602,,,,,,,,,
"summarize: def query_string(self, **params):
        """"""
        """"""
        return SearchResult(self, self._api.get(self._href, **params))",Specify query string to use with the collection.,Uses an query string to fetch the fixed parameters.,Returns the basic querystring of the given specification.,45.44515108,40.90273938,43.17394523,,,,,,,,,
"summarize: def get_context_data(self, **kwargs):
        """"""
        
        """"""
        #max_columns, max_rows = self.get_max_dimension()
        context = {
            'gadgets': self._registry,
            'columns': self.columns,
            'rows': self.rows,
            'column_ratio': 100 - self.columns * 2,
            'row_ratio': 100 - self.rows * 2,
        }
        context.update(kwargs)
        return context",Get the context for this view.,Retrieve the context data,Returns the context data in the platform.,46.20652848,39.77629138,42.99140993,,,,,,,,,
"summarize: def join_regex(regexes):
    """"""""""""
    if len(regexes) > 1:
        return ""|"".join([""(%s)"" % r for r in regexes])
    elif regexes:
        return regexes[0]
    else:
        return """"",Combine a list of regexes into one that matches any of them.,Modify a list of regexes on a given regex.,Return a list of regexes into a list of regexes of the `regexes`.,34.91846631,51.03736652,42.97791642,,,,,,,,,
"summarize: def invoice(request, invoice_id, access_code=None):
    ''' 

    '''

    current_invoice = InvoiceController.for_id_or_404(invoice_id)

    if not current_invoice.can_view(
            user=request.user,
            access_code=access_code,
            ):
        raise Http404()

    data = {
        ""invoice"": current_invoice.invoice,
    }

    return render(request, ""registrasion/invoice.html"", data)",Displays an invoice.,Invoice an invoice.,Return a specific view.,57.86131238,28.0857624,42.97353739,,,,,,,,,
"summarize: def _size_from_header(cls, header):
        """"""
        
        """"""

        # We initiate the result we are going to return.
        result = []

        for data in header:
            # We lopp through the header.

            # And we append the size to our result.
            result.append(header[data])

        # We return the result.
        return result",Get the size of each columns from the header.,Get the header for the given header.,Return the header of the header to the header.,43.6009002,42.24531624,42.92310822,,,,,,,,,
"summarize: def all_parameters(self):
        """"""
        
        """"""
        params = []
        params.extend(self.parameters)
        params.extend(self.free_parameters)

        return params",Return all parameters.,All all parts of the free parameters,Parameters an XML parameters.,40.8357404,44.66192904,42.74883472,,,,,,,,,
"summarize: def entropy(state):
    """"""
    
    """"""

    rho = np.array(state)
    if rho.ndim == 1:
        return 0
    evals = np.maximum(np.linalg.eigvalsh(state), 0.)
    return shannon_entropy(evals, base=np.e)",Compute the von-Neumann entropy of a quantum state.,Get a entropy of a state of a state of entropy.,Entrops the state of a state of an XML entropy.,41.77586664,43.67988377,42.72787521,,,,,,,,,
"summarize: def get_frame(frame_id, **kwargs):
    """"""
    
    """"""
    assert_is_type(frame_id, str)
    return H2OFrame.get_frame(frame_id, **kwargs)",Obtain a handle to the frame in H2O with the frame_id key.,Returns the frame on the frame in the H2OFrame,Returns the frame in the frame as a frame.,45.11514806,40.17840833,42.6467782,,,,,,,,,
"summarize: def tryAcquire(self, lockID, callback=None, sync=False, timeout=None):
        """"""
        """"""
        return self.__lockImpl.acquire(lockID, self.__selfID, time.time(), callback=callback, sync=sync, timeout=timeout)",Attempt to acquire lock.,Acquire a lockid to a lockid,Generate acquire from the lock id.,45.4366307,39.72575631,42.58119351,,,,,,,,,
"summarize: def find_bai_file(bam_file):
    """"""""""""
    bai_file = bam_file.replace('.bam', '.bai')
    if not os.path.exists(bai_file):
        # try the other convention
        bai_file = ""{}.bai"".format(bam_file)
    return bai_file",Find out BAI file by extension given the BAM file.,Return the bai file from the given bam file.,Returns the Bai file of the given bai file.,42.00672457,43.11335396,42.56003927,,,,,,,,,
"summarize: def l(*members, meta=None) -> List:
    """"""""""""
    return List(  # pylint: disable=abstract-class-instantiated
        plist(iterable=members), meta=meta
    )",Creates a new list from members.,Returns a list of members.,Returns a list of the members of an List.,48.48793983,36.62660643,42.55727313,,,,,,,,,
"summarize: def history(self, *bug_ids):
        """"""
        """"""
        resource = urijoin(self.RBUG, bug_ids[0], self.RHISTORY)

        params = {
            self.PIDS: bug_ids
        }

        response = self.call(resource, params)

        return response",Get the history of the given bugs.,Creates the history of the URL.,.json() Return an API response object.,60.12644355,24.91664381,42.52154368,,,,,,,,,
"summarize: def wrapHeart(service):
    """"""""""""
    master = taservice.MultiService()
    service.setServiceParent(master)
    maybeAddHeart(master)
    return master",Wrap a service in a MultiService with a heart,Wrap service for homethon service into the service.,.wrapHeart(service) Service service into a single hook.,42.42016999,42.61691668,42.51854334,,,,,,,,,
"summarize: def run(self, data_x):
        """"""
        
        """"""
        output_vars = self.compute(*data_x)
        return self._extract_costs(output_vars)",Run the model with validation data and return costs.,Run the data and return a list of data directorys,Runs the costs of the output dataset and ``output_vars``.,52.28046185,32.67831278,42.47938732,,,,,,,,,
"summarize: def display_latex(*objs, **kwargs):
    """"""
    """"""
    raw = kwargs.pop('raw',False)
    if raw:
        for obj in objs:
            publish_latex(obj)
    else:
        display(*objs, include=['text/plain','text/latex'])",Display the LaTeX representation of an object.,return display Default value of an object,return display(**kwargs) Display an object of the given object.,44.49995365,40.40496658,42.45246012,,,,,,,,,
"summarize: def copy_notebook(self, notebook_id):
        """"""""""""
        last_mod, nb = self.get_notebook_object(notebook_id)
        name = nb.metadata.name + '-Copy'
        path, name = self.increment_filename(name)
        nb.metadata.name = name
        notebook_id = self.new_notebook_id(name)
        self.save_notebook_object(notebook_id, nb)
        return notebook_id",Copy an existing notebook and return its notebook_id.,", notebook_id, notebook_id Copy a new notebook object",Moves the notebook object from the notebook object,49.55628145,35.27631717,42.41629931,,,,,,,,,
"summarize: def __get_empty_config(self):
        """"""
        
        """"""
        self._generate_config()
        path = self._get_config_path()
        with open(path, 'r') as readable:
            contents = readable.read()
        os.remove(path)
        return contents",Returns the config file contents as a string. The config file is generated and then deleted.,Get the configuration file from the given Generated This can be used to convert the file into a file.,Get the configuration configuration and returns a list of all configuration files.,44.13095012,40.68387887,42.4074145,,,,,,,,,
"summarize: def _expression_to_asn(self, expression):
    """"""""""""
    new_children = [self._node_to_asn(c) for c in expression.children]
    return self._remove_grouping_groups(infix_to_optree(new_children))",Convert an expression to an Abstract Syntax Tree Node.,Convert a list of expression to a given expression to a list of nodes.,Creates an expression to an expression to an expression.,40.9864391,43.76976593,42.37810252,,,,,,,,,
"summarize: def add_to_parser(self, parser):
        """"""
        
        """"""
        kwargs = self._get_kwargs()
        args = self._get_args()
        parser.add_argument(*args, **kwargs)",Adds the argument to an argparse.ArgumentParser instance,self._get_args() Add an argument to the given parser.,"self._add_argument(args, kwargs) Add a parser to a template to the parser.",49.61465296,35.00299891,42.30882594,,,,,,,,,
"summarize: def create_venv_with_package(packages):
    """"""
    """"""
    with tempfile.TemporaryDirectory() as tempdir:
        myenv = create(tempdir, with_pip=True)
        pip_call = [
            myenv.env_exe,
            ""-m"",
            ""pip"",
            ""install"",
        ]
        subprocess.check_call(pip_call + ['-U', 'pip'])
        if packages:
            subprocess.check_call(pip_call + packages)
        yield myenv",Create a venv with these packages in a temp dir and yielf the env.,Creates a temporary directory with the given temporary directory.,", myenv yield packages, subprocess Create a venv and adding venv version of the venv.",39.70212537,44.84954106,42.27583322,,,,,,,,,
"summarize: def check_type(self, value, attr, data):
        """"""
        """"""
        super().check_type(value, attr, data)

        errors = []
        for idx, v in enumerate(value):
            try:
                self.container.check_type(v, idx, value)
            except ValidationError as err:
                errors.append(err.messages)

        if errors:
            raise ValidationError(errors)

        return value",Validate if it's a list of valid item-field values.,Checks the value of a list of values into a list of values.,.validate() Checks if an valid value is not None.,40.69309617,43.7344198,42.21375799,,,,,,,,,
"summarize: def html_to_text(content):
    """"""  """"""
    text = None
    h2t = html2text.HTML2Text()
    h2t.ignore_links = False
    text = h2t.handle(content)
    return text",Converts html content to plain text,Adds a content to a text text.,Return a text content of a handler.,45.0197717,39.30769647,42.16373409,,,,,,,,,
"summarize: def crop(img, i, j, h, w):
    """"""
    """"""
    if not _is_pil_image(img):
        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))

    return img.crop((j, i, j + w, i + h))",Crop the given PIL Image.,Crop the crop of the given image.,Convert a SimCrop object to an Image.,54.18739058,29.78796602,41.9876783,,,,,,,,,
"summarize: def send_genes(self, gene_list, url):
        """""" """"""
        payload = {
          'list': (None, gene_list),
          'description': (None, self.descriptions)
           }
        # response
        response = requests.post(url, files=payload)
        if not response.ok:
            raise Exception('Error analyzing gene list')
        sleep(1)
        job_id = json.loads(response.text)

        return job_id",send gene list to enrichr server,Sends the genes to the gene list,Generate a Gene list of genes,44.22020522,39.7512345,41.98571986,,,,,,,,,
"summarize: def check_type(self, value, attr, data):
        """"""
        """"""
        for field in self.choices:
            if isinstance(field, ModelTypeValidator):
                try:
                    return field.check_type(value, attr, data)
                except ValidationError:
                    pass

        raise self._not_expected_type(
            value, [field.__class__ for field in self.choices],
            fields=[self], field_names=attr, data=data)",Check if at least one of the possible choices validates the value.,Checks that the value of the field is a valid value of the field.,Check that the value is an instance of this type.,47.47457091,36.43820743,41.95638917,,,,,,,,,
"summarize: def every_other(iterable):
	""""""
	
	""""""
	items = iter(iterable)
	while True:
		try:
			yield next(items)
			next(items)
		except StopIteration:
			return",Yield every other item from the iterable,yield next(iterable) Every other iteration to a list of iterations.,True return True Get the every other iterable of the iterable,38.18871238,45.63884454,41.91377846,,,,,,,,,
"summarize: def list_subscriptions(self, user_token):
        """"""
        
        """"""
        response = _request('GET',
            url=self.url_v1('/user/subscriptions'),
            user_agent=self.user_agent,
            user_token=user_token,
        )
        _raise_for_status(response)

        return response.json()['topics']",Get the list of the topics which a user is subscribed to.,Returns a list of list of subscriptions of the user to an appropriate to the user.,Return a list of subscriptions in the given user.,40.70561887,43.06320468,41.88441178,,,,,,,,,
"summarize: def _get_related_attributes(r_rgo, r_rto):
    '''
    
    '''
    l1 = list()
    l2 = list()
    
    ref_filter = lambda ref: ref.OIR_ID == r_rgo.OIR_ID
    for o_ref in many(r_rto).O_RTIDA[110].O_REF[111](ref_filter):
        o_attr = one(o_ref).O_RATTR[108].O_ATTR[106]()
        l1.append(o_attr.Name)
        
        o_attr = one(o_ref).O_RTIDA[111].O_OIDA[110].O_ATTR[105]()
        l2.append(o_attr.Name)
        
    return l1, l2",The two lists of attributes which relates two classes in an association.,", l2 Returns the related attributes into a list of route IDs.",Returns the related_attributes of the related attributes in the permission.,40.26723231,43.44228115,41.85475673,,,,,,,,,
"summarize: def transform_describe(self, node, describes, context_variable):
        """"""
        

        """"""

        body = self.transform_describe_body(node.body, context_variable)
        return ast.ClassDef(
            name=""Test"" + describes.title(),
            bases=[ast.Name(id=""TestCase"", ctx=ast.Load())],
            keywords=[],
            starargs=None,
            kwargs=None,
            body=list(body),
            decorator_list=[],
        )",Transform a describe node into a ``TestCase``.,Transform a list of nodes to be in the transform.,Transform a transforming description into another decorator.,43.46203003,40.21182916,41.8369296,,,,,,,,,
"summarize: def download_csv(data, filename):
    """"""
    
    """"""
    assert_is_type(data, H2OFrame)
    assert_is_type(filename, str)
    url = h2oconn.make_url(""DownloadDataset"", 3) + ""?frame_id={}&hex_string=false"".format(data.frame_id)
    with open(filename, ""wb"") as f:
        f.write(urlopen()(url).read())",Download an H2O data set to a CSV file on the local disk.,return data Download a dataset file to a file.,return data Send one of the CSV file and its name.,45.13439799,38.40935987,41.77187893,,,,,,,,,
"summarize: def get_intervals(self, sort=False):
        """"""
        """"""
        for i in sorted(self.intervals) if sort else self.intervals:
            yield i",Give all the intervals or points.,yield i Shows the events intervals.,Gets the Itervals from a sort.,45.20768688,38.32483083,41.76625886,,,,,,,,,
"summarize: def ppoi_as_str(self):
        """"""""""""
        return ""%s__%s"" % (
            str(self.ppoi[0]).replace('.', '-'),
            str(self.ppoi[1]).replace('.', '-')
        )",Return PPOI value as a string.,Poi only only one as string.,Return a string of an actual poi.,37.16392821,46.04903669,41.60648245,,,,,,,,,
"summarize: def makeService(opts):
    """"""
    """"""
    ser = tainternet.TimerService(opts['frequency'], runProcess, opts['args'],
                                  opts['timeout'], opts['grace'], tireactor)
    ret = service.MultiService()
    ser.setName('scheduler')
    ser.setServiceParent(ret)
    heart.maybeAddHeart(ret)
    return ret",Make scheduler service,Makes a new service.,Return the service free of the scheduler search.,45.13645223,38.05313931,41.59479577,,,,,,,,,
"summarize: def check_messages(msgs, cmd, value=None):
    """"""

    """"""
    for msg in msgs:
        if value and msg.get(cmd) == value:
            return msg
        if not value and msg.get(cmd):
            return msg
    return None",Check if specific message is present.,Check messages for a given message.,Check if a valid value is a message instance.,38.19137301,44.90120798,41.5462905,,,,,,,,,
"summarize: def driver_for_path(path, drivers=None):
    """"""
    """"""
    ext = (os.path.splitext(path)[1][1:] or path).lower()
    drivers = drivers or ImageDriver.registry if ext else {}
    for name, meta in drivers.items():
        if ext == meta.get('DMD_EXTENSION', '').lower():
            return ImageDriver(name)
    return None",Returns the gdal.Driver for a path or None based on the file extension.,Returns the driver for a ImageDriver for a given filepath.,Returns the driversation for the given filename.,44.94769076,38.08973423,41.5187125,,,,,,,,,
"summarize: def str_variant(institute_id, case_name, variant_id):
    """"""""""""
    data = controllers.str_variant(store, institute_id, case_name, variant_id)
    return data",Display a specific STR variant.,Returns a string for a specific variant,Return a string of the variant.,47.0538143,35.85020889,41.4520116,,,,,,,,,
"summarize: def _get_template_abs_path(filename):
        """"""
        
        """"""
        if os.path.isabs(filename) and os.path.isfile(filename):
            return filename
        else:
            return os.path.join(os.getcwd(), filename)",Return a valid absolute path. filename can be relative or absolute.,Returns the template absolute path for the filename in the filename.,Returns a template filename from the creation of a filename.,48.04879508,34.81042073,41.42960791,,,,,,,,,
"summarize: def partition(condition, collection) -> Tuple[List, List]:
    """"""""""""
    succeed, fail = [], []

    for x in collection:
        if condition(x):
            succeed.append(x)
        else:
            fail.append(x)

    return succeed, fail",Partitions a list into two based on a condition.,Partition a list of indicators to a List.,Returns a list of condition.,47.90603497,34.93883453,41.42243475,,,,,,,,,
"summarize: def create_config_profile(msg_type):
    """"""
    
    """"""
    msg_type = msg_type.lower()

    if msg_type not in CONFIG.keys():
        raise UnsupportedMessageTypeError(msg_type)

    display_required_items(msg_type)

    if get_user_ack():
        profile_name = input(""Profile Name: "")
        data = get_data_from_user(msg_type)
        auth = get_auth_from_user(msg_type)
        configure_profile(msg_type, profile_name, data, auth)",Create a profile for the given message type.,Create a new profile for the specified Message.,"configure_access_token(msg_type, data, auth) return auth Create a single configuration.",64.1064387,18.41596264,41.26120067,,,,,,,,,
"summarize: def _group_report(self,group,name):
        """"""""""""

        if group:
            print '%s jobs:' % name
            for job in group:
                print '%s : %s' % (job.num,job)
            print
            return True",Report summary for a given job group.,return False Get the given job on a group,return False Report a group.,43.95443961,38.45724076,41.20584019,,,,,,,,,
"summarize: def process_scheduled_consumption(self, token):
        """"""
        """"""
        scheduled_retry = self._tokens_to_scheduled_consumption.pop(token)
        self._total_wait = max(
            self._total_wait - scheduled_retry['time_to_consume'], 0)",Processes a scheduled consumption request that has completed,return self._process_scheduled_consumption(token) Process a scheduled jobs.,return self._total_wait Compute Scheduled consumption to the scheduled consumption,44.04599045,38.34173604,41.19386325,,,,,,,,,
"summarize: def get_model_url_name(model_nfo, page, with_namespace=False):
    """"""""""""
    prefix = ''
    if with_namespace:
        prefix = 'admin:'
    return ('%s%s_%s' % (prefix, '%s_%s' % model_nfo, page)).lower()",Returns a URL for a given Tree admin page type.,Returns the url for a model name to a given prefix.,Returns a Language URL and URL and returns the model.,47.45646972,34.85633433,41.15640203,,,,,,,,,
"summarize: def get_params(self, deep=True):
        """"""
        
        """"""
        out = dict()
        for key, value in self.parms.items():
            if deep and isinstance(value, H2OEstimator):
                deep_items = list(value.get_params().items())
                out.update((key + ""__"" + k, val) for k, val in deep_items)
            out[key] = value
        return out",Obtain parameters for this estimator.,Gets a list of params for the given H2OEstimators.,Return an HTML response for the parameter.,42.16570445,40.10547278,41.13558862,,,,,,,,,
"summarize: def get_total_contributors(self, repo):
        """"""
        
        """"""
        repo_contributors = 0
        for contributor in repo.iter_contributors():
            repo_contributors += 1
            self.unique_contributors[contributor.id].append(repo.name)
            self.contributors_json[repo.name].append(contributor.to_json())
        return repo_contributors",Retrieves the number of contributors to a repo in the organization.    Also adds to unique contributor list.,Retrieve all total contributors to be loaded in the contributor,Get all of the posting total contributors in the total contributors. This is used in the total contributors.,37.25498339,44.90229312,41.07863826,,,,,,,,,
"summarize: def make_internal_signing_service(config, entity_id):
    """"""
    
    """"""

    _args = dict([(k, v) for k, v in config.items() if k in KJ_SPECS])
    _kj = init_key_jar(**_args)

    return InternalSigningService(entity_id, _kj)",Given configuration initiate an InternalSigningService instance,Makes an instance of the service internal service internal service,Gets the service service from the given configuration.,41.21183751,40.93156573,41.07170162,,,,,,,,,
"summarize: def rasterize(layer, rast):
    """"""
    """"""
    driver = ImageDriver('MEM')
    r2 = driver.raster(driver.ShortName, rast.size)
    r2.affine = rast.affine
    sref = rast.sref
    if not sref.srid:
        sref = SpatialReference(4326)
    r2.sref = sref
    ml = MemoryLayer(sref, layer.GetGeomType())
    ml.load(layer)
    status = gdal.RasterizeLayer(
        r2.ds, (1,), ml.layer, options=['ATTRIBUTE=%s' % ml.id])
    ml.close()
    return r2",Returns a Raster from layer features.,.close() Gets a rasterior from a layer.,Returns a rasteriver object for the raster,44.46126362,37.5213307,40.99129716,,,,,,,,,
"summarize: def validate_version():
    """"""""""""
    import leicacam
    version_string = leicacam.__version__
    versions = version_string.split('.', 3)
    try:
        for ver in versions:
            int(ver)
    except ValueError:
        print(
            'Only integers are allowed in release version, '
            'please adjust current version {}'.format(version_string))
        return None
    return version_string",Validate version before release.,Validate version of versions.,Return an version of version string.,55.3015532,26.57962152,40.94058736,,,,,,,,,
"summarize: def round_values(df, *, column: str, decimals: int, new_column: str = None):
    """"""
    
    """"""
    new_column = new_column or column
    df[new_column] = df[column].round(decimals)
    return df",Round each value of a column,Returns the column values of a column.,[column] Compute an round column of df values.,45.24743047,36.5638266,40.90562854,,,,,,,,,
"summarize: def s3_keys_from_env():
    ''''''
    env = os.environ
    if S3_ACCESS_KEY_NAME in env and S3_SECRET_KEY_NAME in env:
      keys = (env[S3_ACCESS_KEY_NAME], env[S3_SECRET_KEY_NAME])
      debug(""read S3 keys from environment"")
      return keys
    else:
      return None","Retrieve S3 access keys from the environment, or None if not present.",return None Returns the environment variables from environment variables,Return a dictionary of keys for the environment.,44.33560097,37.34531124,40.84045611,,,,,,,,,
"summarize: def register_handler(self, name, handler, esc_strings):
        """"""""""""
        self._handlers[name] = handler
        for esc_str in esc_strings:
            self._esc_handlers[esc_str] = handler",Register a handler instance by name with esc_strings.,return self._esc_strings Registers a handler for a given name.,return esc_strings Get an editing element.,52.13604395,29.51790479,40.82697437,,,,,,,,,
"summarize: def find_sections(self, prefix):
        """"""  """"""
        res = []
        for section in self.config.sections():
            if section.startswith(prefix):
                res.append(section)
        return res",return sections with specified prefix,Finds the specified prefix.,Appends a sections for an sections.,47.03854305,34.53442467,40.78648386,,,,,,,,,
"summarize: def transformCovarianceMatrix(self, phi, theta, covmat):
        """"""
        
        """"""

        c, s = self._getJacobian(phi,theta)
        jacobian = identity(5)
        jacobian[0][0]=c
        jacobian[1][1]=c
        jacobian[3][3]=c
        jacobian[4][4]=c
        jacobian[0][1]=s
        jacobian[1][0]=-s
        jacobian[3][4]=s
        jacobian[4][3]=-s

        return dot( dot(jacobian, covmat), jacobian.T )",Transform the astrometric covariance matrix to its representation in the new coordinate system.,"Returns the transform covariance matrix to the phi, or the size of the fixed values.",Matrix that the covariance matrices are covariance and the same `jacobian`.,44.23425444,37.26498959,40.74962202,,,,,,,,,
"summarize: def get_ids_by_expression(self, expression, threshold=0.001, func=np.sum):
        """""" """"""
        lexer = lp.Lexer()
        lexer.build()
        parser = lp.Parser(
            lexer, self.dataset, threshold=threshold, func=func)
        parser.build()
        return parser.parse(expression).keys().values",Use a PEG to parse expression and return study IDs.,()[0] Returns the expression and returns the list of the IDs.,() Returns a list of all lexers in the given expression.,48.00769385,33.47057256,40.73913321,,,,,,,,,
"summarize: def get_members(self, group_id):
        """"""
        
        """"""
        self._valid_group_id(group_id)

        url = ""{}/group/{}/member"".format(self.API, group_id)

        data = self._get_resource(url)

        members = []
        for datum in data.get(""data""):
            members.append(self._group_member_from_json(datum))
        return members",Returns a list of restclients.GroupMember objects for the group    identified by the passed group ID.,Returns the member of the given group member for a group member for a group id.,Return a members of a group. The group is required by this is required. This method is insidered to get the user.,43.56924409,37.90650085,40.73787247,,,,,,,,,
"summarize: def clean_tempfiles():
  ''''''
  for fn in TEMP_FILES:
    if os.path.exists(fn):
      os.unlink(fn)",Clean up temp files,Clean tempfiles,os.remove(fn) Clean a tempfiles cleaning the given system.,61.53685939,19.74282005,40.63983972,,,,,,,,,
"summarize: def get_conn(self):
        """"""
        
        """"""
        if not self._conn:
            http_authorized = self._authorize()
            self._conn = build('compute', self.api_version,
                               http=http_authorized, cache_discovery=False)
        return self._conn",Retrieves connection to Google Compute Engine.,Returns the connection to the given conn.,Return a connection object to a single connection.,41.72209607,39.48214984,40.60212296,,,,,,,,,
"summarize: def dispatch(self, event, *args, **kwargs):
        """"""
        """"""
        # No event, no subscribers.
        if event not in self._subscribers:
            return

        for subscriber in self._subscribers[event]:
            subscriber.callback(*args, **kwargs)",Emits an event if there are any subscribers.,return subscriber Dispatch the event and event,return self._subscribers[event] Return a subscriber.,46.66003074,34.53084753,40.59543914,,,,,,,,,
"summarize: def mappable(obj):
    """"""""""""
    if isinstance(obj, (tuple,list)):
        return True
    for m in arrayModules:
        if isinstance(obj,m['type']):
            return True
    return False",return whether an object is mappable or not.,Returns True if the object is a dictionary.,Return a tuple of another object.,39.6869167,41.48974106,40.58832888,,,,,,,,,
"summarize: def samples_to_frames(samples, hop_length=512, n_fft=None):
    """"""
    """"""

    offset = 0
    if n_fft is not None:
        offset = int(n_fft // 2)

    samples = np.asanyarray(samples)
    return np.floor((samples - offset) // hop_length).astype(int)",Converts sample indices into STFT frames.,Assert that samples are frames on a single Frames.,Convert a samples to samples into a sample.,34.61796055,46.39929898,40.50862977,,,,,,,,,
"summarize: def register(self, field_type, impl=None):
        """"""
        
        """"""
        def _wrapper(func):
            self.registry[field_type] = func
            return func

        if impl:
            return _wrapper(impl)
        return _wrapper",Register form field data function.        Could be used as decorator,Decorator that registers a new function is passed by the other function.,"(func, field_type, self._serial_type, impl) Register a function.",41.5287322,39.34697355,40.43785288,,,,,,,,,
"summarize: def is_url(name):
    """"""""""""
    if ':' not in name:
        return False
    scheme = name.split(':', 1)[0].lower()
    return scheme in ['http', 'https', 'file', 'ftp'] + vcs.all_schemes",Returns true if the name looks like a URL,() Returns True if the given name is available.,(name) Returns True if any is a scheme in the page url is passed.,48.69893585,32.11290113,40.40591849,,,,,,,,,
"summarize: def generate(secret, age, **payload):
    """"""""""""
    jti = str(uuid.uuid1()) # random id
    if not payload:
        payload = {}
    payload['exp'] = int(time.time() + age)
    payload['jti'] = jti
    return jwt.encode(payload, decode_secret(secret))",Generate a one-time jwt with an age in seconds,Generate an age from a secret.,Generate a string to the jid in a given secret.,37.9284346,42.83698758,40.38271109,,,,,,,,,
"summarize: def execute(self, payload={}):
        """"""
        
        """"""
        api_key = self._get_api_key()
        return self.run(endpoint='v2/alerts',
                        data=json.dumps(payload),
                        headers={'Content-Type': 'application/json',
                                 'Authorization': 'GenieKey %s' % api_key})",Execute the Opsgenie Alert call,Execute the execute action,Execute an api key for the API.,41.36942498,39.09443138,40.23192818,,,,,,,,,
"summarize: def retrieve_pwd_from_config(msg, cfg):
    """"""
    
    """"""
    msg_type = msg.__class__.__name__.lower()
    key_fmt = msg.profile + ""_"" + msg_type
    pwd = cfg.pwd[key_fmt].split("" :: "")
    if len(pwd) == 1:
        msg.auth = pwd[0]
    else:
        msg.auth = tuple(pwd)",Retrieve auth from profile configuration and set in msg.auth attr.,return pwd Retrieve pwd from configuration file,return msg Return a configuration for the given pwd,44.37514406,35.99758285,40.18636346,,,,,,,,,
"summarize: def get_members(self, **query_params):
        '''
        
        '''
        members = self.get_members_json(self.base_uri,
                                        query_params=query_params)

        members_list = []
        for member_json in members:
            members_list.append(self.create_member(member_json))

        return members_list",Get all members attached to this organisation. Returns a list of    Member objects,Return members for a list of members for the given query parameters.,", members Returns a list of members lists of members in members.",38.51821352,41.79406389,40.15613871,,,,,,,,,
"summarize: def issues(self):
        """"""
        
        """"""
        for board in self.get_boards():
            for lst in self.get_lists(board['id']):
                listextra = dict(boardname=board['name'], listname=lst['name'])
                for card in self.get_cards(lst['id']):
                    issue = self.get_issue_for_record(card, extra=listextra)
                    issue.update_extra({""annotations"": self.annotations(card)})
                    yield issue",Returns a list of dicts representing issues from a remote service.,"return yield issues, issues Presents the list of boards in a list of boards",return issue Return a list of issues between a list of issues.,39.57299634,40.68607303,40.12953469,,,,,,,,,
"summarize: def shift(self, time: int) -> 'TimeslotCollection':
        """"""
        """"""
        slots = [Timeslot(slot.interval.shift(time), slot.channel) for slot in self.timeslots]
        return TimeslotCollection(*slots)",Return a new TimeslotCollection shifted by `time`.,Returns a new value of the specified timestamp.,Collection when casting shifting any timeslots a slots,35.37962709,44.8766547,40.1281409,,,,,,,,,
"summarize: def f_to_dict(self, copy=True):
        """"""

        """"""
        if copy:
            return self._dict.copy()
        else:
            return self._dict",Returns annotations as dictionary.,.copy() Returns a dictionary of dictionary of the copy.,.copy() Returns the dictionary of the dictionary.,38.08791463,42.03509379,40.06150421,,,,,,,,,
"summarize: def pkg_info(pkg_path):
    """"""
    """"""
    src, hsh = pkg_commit_hash(pkg_path)
    return dict(
        ipython_version=release.version,
        ipython_path=pkg_path,
        commit_source=src,
        commit_hash=hsh,
        sys_version=sys.version,
        sys_executable=sys.executable,
        sys_platform=sys.platform,
        platform=platform.platform(),
        os_name=os.name,
        default_encoding=encoding.DEFAULT_ENCODING,
        )",Return dict describing the context of this package,Pass a directory into an version of the package.,Returns the dict of packages that are packaged in the version.,36.9610389,43.13932986,40.05018438,,,,,,,,,
"summarize: def visit_Scope(self, node: parsing.Capture) -> [ast.stmt] or ast.expr:
        """"""
        """"""
        return ast.Name('scope_not_implemented', ast.Load())
        raise NotImplementedError()",Generates python code for a scope.,Get a scope distor of a node of nodes,Generates any scope of the given node.,33.68670965,46.36945687,40.02808326,,,,,,,,,
"summarize: def _pair_delims(expr, ldelim=""("", rdelim="")""):
    """"""""""""
    # Find where remaining delimiters are
    lindex = reversed([num for num, item in enumerate(expr) if item == ldelim])
    rindex = [num for num, item in enumerate(expr) if item == rdelim]
    # Pair remaining delimiters
    return [(lpos, _next_rdelim(rindex, lpos)) for lpos in lindex][::-1]",Pair delimiters.,Pairs delimiters in the delimiters.,Get all delimiters limiters.,38.24323271,41.69392928,39.968581,,,,,,,,,
"summarize: def get(self, key: str, default=None) -> Signature:
        """"""  """"""
        item = default
        if key in self._hsig:
            item = self._hsig[key]
        return item",Get a signature instance by its internal_name,Returns the value for the signature,.delete(key) Returns a signature instance.,27.72895365,52.06385968,39.89640667,,,,,,,,,
"summarize: def update_checklist(self, name):
        '''
        
        '''
        checklist_json = self.fetch_json(
            uri_path=self.base_uri,
            http_method='PUT',
            query_params={'name': name}
        )

        return self.create_checklist(checklist_json)",Update the current checklist. Returns a new Checklist object.,Updates the checklist for the given name.,Returns the checklist_json of a single checklist,33.3406069,46.4083589,39.8744829,,,,,,,,,
"summarize: def _pick_scalar_condition(pred, cond_true, cond_false):
  """"""""""""
  # Note: This function is only valid if all of pred, cond_true, and cond_false
  # are scalars. This means its semantics are arguably more like tf.cond than
  # tf.where even though we use tf.where to implement it.
  pred_ = tf.get_static_value(tf.convert_to_tensor(value=pred))
  if pred_ is None:
    return tf.where(pred, cond_true, cond_false)
  return cond_true if pred_ else cond_false",Convenience function which chooses the condition based on the predicate.,Internal function where the pred is not likely condition.,Internal calculates that condition is only when the condition is a single condition.,42.95697169,36.74883406,39.85290288,,,,,,,,,
"summarize: def _broadcast(value, target):
  """"""
  """"""
  return tf.broadcast_to(
      tf.convert_to_tensor(value=value, dtype=target.dtype),
      distribution_util.prefer_static_shape(target)[:-1])",Broadcast a value to match the batching dimensions of a target.,Returns a broadcast of the value of the values of the tensor.,Returns the value of the broadcast of the VCASS file.,42.1039781,37.46365202,39.78381506,,,,,,,,,
"summarize: def resized_crop(img, i, j, h, w, size, interpolation=Image.BILINEAR):
    """"""
    """"""
    assert _is_pil_image(img), 'img should be PIL Image'
    img = crop(img, i, j, h, w)
    img = resize(img, size, interpolation)
    return img",Crop the given PIL Image and resize it to desired size.,", img Resizes the crop of the image on a given image.",", img Return an image of the given Image, image and image.",39.89366968,39.65177094,39.77272031,,,,,,,,,
"summarize: def init_widget(self):
        """"""  """"""
        d = self.declaration
        if d.source:
            self.set_source(d.source)
        else:
            super(RawComponent, self).init_widget()",Initialize the widget with the source.,d.set_source(d.source) Initialize the widget to the widget,"self.set_source(d.source, self.set_source) Initializes a single Widget.",52.87091816,26.51151351,39.69121584,,,,,,,,,
"summarize: def remove_license(self, name=None, url=None):
        """"""
        """"""
        for k, v in self.licenses[:]:
            if (name is None or name == k) and (url is None or url == v):
                del(self.licenses[self.licenses.index((k, v))])",Remove all licenses matching both key and value.,return True Remove licenses of licenses,Remove the local license by name and another url.,33.99410362,45.10806675,39.55108519,,,,,,,,,
"summarize: def __notify_listeners(self, data, stats):
        """"""  """"""
        for listener in self.listeners:
            listener.on_aggregated_data(data, stats)",notify all listeners about aggregate data and stats,"return self.listeners, self.stats Will notify any data.",return data Returns a listener for a listener.,45.67561189,33.2423083,39.4589601,,,,,,,,,
"summarize: def _find_directives(self, pred):
    """"""""""""
    if isinstance(pred, str):
      return [d for d in self.directives if d.name == pred]
    else:
      return [d for d in self.directives if pred(d)]","Finds all directives with a certain name, or that passes a predicate.",Find the directives with the given pred and return its names,Returns the list of directives in an iterable for the pred.,43.76730762,35.10711612,39.43721187,,,,,,,,,
"summarize: def device_settings(string):
    """"""""""""
    if not string:
        return {}

    settings = {}
    for setting in string.split(','):
        setting_name, value = setting.split('=')
        settings[setting_name.strip()] = value.strip()
    return settings",Convert string with SoapySDR device settings to dict,Converts a settings from a string to a string,Return a dictionary of the setting setting.,46.19756998,32.67390144,39.43573571,,,,,,,,,
"summarize: def scan_prefix(self, prefix, feature_names=None):
        '''
        '''
        resp = self._scan_prefix(prefix, feature_names=feature_names)
        for hit in resp:
            yield did(hit['_id']), self.fc_from_dict(hit['_source']['fc'])",Scan for FCs with a given prefix.,return resp Get a prefix for the given feature name,Send the given feature and prefix.,33.76986125,45.06371993,39.41679059,,,,,,,,,
"summarize: def parse(input_string, prefix=''):
  """"""

  """"""

  tree = parser.parse(input_string)
  visitor = ChatlVisitor(prefix)

  visit_parse_tree(tree, visitor)

  return visitor.parsed",Parses the given DSL string and returns parsed results.,(visitor) Parse a prefix and return the specified string to a string.,(tree) Parse a generator for the given input_string.,40.13879571,38.69391098,39.41635335,,,,,,,,,
"summarize: def validate_email(self, email):
        """"""
        
        """"""
        try:
            self.user = User.objects.get_by_natural_key(email)
        except User.DoesNotExist:
            msg = _('A user with this email address does not exist.')
            raise serializers.ValidationError(msg)

        if self.user.email_verified:
            msg = _('User email address is already verified.')
            raise serializers.ValidationError(msg)
        return email",Validate if email exists and requires a verification.,Validate email and return email verified email,".get(self.user_address, None) Validates the email in the email.",49.37061933,29.148102,39.25936067,,,,,,,,,
"summarize: def dt_month_name(x):
    """"""
    """"""
    import pandas as pd
    return pd.Series(_pandas_dt_fix(x)).dt.month_name().values.astype(str)",Returns the month names of a datetime sample in English.,Add an Month name to the pandas on the given x and y.,Returns the dt correct month name of the specified x.,29.77930465,48.48019531,39.12974998,,,,,,,,,
"summarize: def get_pub_services(opts):
   '''
   
   '''
   sites = []
   for p_key in vars(opts).keys():
      args = getattr(opts,p_key)
      if p_key in PUB_SERVICES and args:
         if isinstance(args,tuple):
            ps = PUB_SERVICES[p_key](*args)
         else:
            ps = PUB_SERVICES[p_key](args)
         sites.append( ps )
   return sites",use values in opts data to generate instances of publication services.,Returns the list of public services to a list of public services.,Returns a list of public keys for application service.,39.95323974,38.27692968,39.11508471,,,,,,,,,
"summarize: def get_current_user():
    """"""""""""
    if not 'user_id' in session:
        return None
    user = User.query.filter(User.id == session['user_id']).first()
    if not user:
        signout_user()
        return None
    return user",Get current user.,.password() Get the current user,Get a user from a session in the current user.,45.33789197,32.86598684,39.10193941,,,,,,,,,
"summarize: def leave_project(self, node):  # pylint: disable=unused-argument
        """"""
        """"""
        if self.pkgdiagram:
            return self.pkgdiagram, self.classdiagram
        return (self.classdiagram,)",leave the pyreverse.utils.Project node,Loads project of nodes and leaves the leaves.,Look for the leave project leave project.,39.29529903,38.90677117,39.1010351,,,,,,,,,
"summarize: def frames_to_samples(frames, hop_length=512, n_fft=None):
    """"""
    """"""

    offset = 0
    if n_fft is not None:
        offset = int(n_fft // 2)

    return (np.asanyarray(frames) * hop_length + offset).astype(int)",Converts frame indices to audio sample indices.,Converts a list of samples to another Frames to another Hop.,* np.float32) Create a sample samples to frames.,38.74093699,39.25418312,38.99756006,,,,,,,,,
"summarize: def off(self, name, callback):
        """"""
        
        """"""
        if callback not in self.__listeners[name]:
            raise InvalidListenerError
        self.__listeners[name].remove(callback)",Stop listening for the named event via the specified callback.,"Off the name and callback to the left, or its callback.",return self.__listeners[name] Get all offsets of the name of the callback.,40.4912554,37.45208221,38.97166881,,,,,,,,,
"summarize: def _calc_layout_distance(gates, coupling_map, layout, max_gates=None):
    """"""
    """"""

    if max_gates is None:
        max_gates = 50 + 10 * len(coupling_map.physical_qubits)

    return sum(coupling_map.distance(*[layout[q] for q in gate['partition'][0]])
               for gate in gates[:max_gates]
               if gate['partition'] and len(gate['partition'][0]) == 2)",Return the sum of the distances of two-qubit pairs in each CNOT in gates  according to the layout and the coupling.,Calculate the layout distance of the gates and return the layout distance.,Calculates a list of layout distances of the gates and percentages of the Gates and calculated gates.,37.33946808,40.52041002,38.92993905,,,,,,,,,
"summarize: def _get_column_headings(self):
        """"
        # return it in the same order as inserted in the Grid
        headers = [ctrl for ctrl in self if isinstance(ctrl, GridColumn)]
        return sorted(headers, key=lambda ch: ch.index)",Return a list of children sub-components that are column headings,Returns the headers of the given Grid Column headers.,Return a list of address between a list of same columns.,32.82244583,44.96291506,38.89268045,,,,,,,,,
"summarize: def artists(self, spotify_ids):
        """"""
        """"""
        route = Route('GET', '/artists')
        payload = {'ids': spotify_ids}
        return self.request(route, params=payload)",Get a spotify artists by their IDs.,Adds the datasets to the spotify,Gets an IDS artists from a some IDs.,34.03409835,43.73319255,38.88364545,,,,,,,,,
"summarize: def filter_benchmarks(benchmarks, bench_funcs, base_ver):
    """"""
    """"""
    for bm in list(benchmarks):
        func = bench_funcs[bm]
        if getattr(func, '_python2_only', False) and (3, 0) <= base_ver:
            benchmarks.discard(bm)
            logging.info(""Skipping Python2-only benchmark %s; ""
                         ""not compatible with Python %s"" % (bm, base_ver))
            continue
    return benchmarks",Filters out benchmarks not supported by both Pythons.,Filter the Python2-only benchmarks to the benchmarks,Filter function to find the Function object based on a benchmarks.,46.21157564,31.34524439,38.77841002,,,,,,,,,
"summarize: def get_alpn_proto_negotiated(self):
        """"""
        
        """"""
        data = _ffi.new(""unsigned char **"")
        data_len = _ffi.new(""unsigned int *"")

        _lib.SSL_get0_alpn_selected(self._ssl, data, data_len)

        if not data_len:
            return b''

        return _ffi.buffer(data[0], data_len[0])[:]",Get the protocol that was negotiated by ALPN.,Get the proto on the specified proto using a point,Returns the negotiated protocol points of the selected data.,33.89223886,43.65130171,38.77177029,,,,,,,,,
"summarize: def close(self):
        """"""""""""
        self.read_queue.put(QueueClosed)
        self.write_queue.put(QueueClosed)","Close the queue, signalling that no more data can be put into the queue.",self.serialize() Close the current queue and close the queue.,self.close() self.close() Close the closed queue to the queue.,38.83919576,38.586647,38.71292138,,,,,,,,,
"summarize: def accuracy(output, target, topk=(1,)):
    """"""""""""
    with torch.no_grad():
        maxk = max(topk)
        batch_size = target.size(0)

        _, pred = output.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target[None])

        res = []
        for k in topk:
            correct_k = correct[:k].flatten().sum(dtype=torch.float32)
            res.append(correct_k * (100.0 / batch_size))
        return res",Computes the accuracy over the k top predictions for the specified values of k,", correct Accuracy a correctation of the specified target.",Get the accuracy of the given topk and correctly accuracy of the same topk.,35.89203262,41.52464172,38.70833717,,,,,,,,,
"summarize: def write_comment(fh, comment):
  """"""
    
  """"""
  _require_string(comment, 'comments')
  fh.write(_escape_comment(comment))
  fh.write(b'\n')",Writes a comment to the file in Java properties format.,return fh Creates a list of comments for the given fh.,fh.write(_escape_string(comment)) Writes comments to a file.,39.68606223,37.57833383,38.63219803,,,,,,,,,
"summarize: def _load_part(self, rel_type, name, data):
		""""""
		
		""""""
		if self.content_types.find_for(name) is None:
			log.warning('no content type found for part %(name)s' % vars())
			return
		cls = Part.classes_by_rel_type[rel_type]
		part = cls(self, name)
		part.load(data)
		self[name] = part
		return part",Load a part into this package based on its relationship type,Loads a relationship from the given data type.,Return a part specific type of the specified relation,38.8574433,38.26441931,38.56093131,,,,,,,,,
"summarize: def option_decorator(name, greeting, yell):
    ''''''
    # Use the @option decorator when you need more control over the
    # command line options.
    say = '%s, %s' % (greeting, name)
    if yell:
        print '%s!' % say.upper()
    else:
        print '%s.' % say","Same as mix_and_match, but using the @option decorator.",.upper() return say Return the option decorator to the decorator.,return say Parse an any of the option decorator.,35.1166882,41.93134699,38.5240176,,,,,,,,,
"summarize: def get(self, username, password, *args, **kwargs):
        """"""
        """"""
        user = self.query.filter_by(username=username).first()
        if user and user.check_password(password):
            return user
        return None",Returns the User object,Returns an User by user.,Return a username.,49.53960513,27.41398136,38.47679325,,,,,,,,,
"summarize: def _update_label_name(self, name):
        '''
        
        '''
        label_json = self.fetch_json(
            uri_path=self.base_uri,
            http_method='PUT',
            query_params={'name': name}
        )

        return self.create_label(label_json)",Update the current label's name. Returns a new Label object.,Update the label label label for a label.,Update a label name and returns a label name of a label name,31.520997,45.43064577,38.47582139,,,,,,,,,
"summarize: def new_heading_cell(source=None, rendered=None, level=1, metadata=None):
    """"""""""""
    cell = NotebookNode()
    cell.cell_type = u'heading'
    if source is not None:
        cell.source = unicode(source)
    if rendered is not None:
        cell.rendered = unicode(rendered)
    cell.level = int(level)
    cell.metadata = NotebookNode(metadata or {})
    return cell",Create a new section cell with a given integer level.,.metadata Create a new heading cell for the given source.,Return a new header of the header of the given source.,46.10600919,30.83781022,38.47190971,,,,,,,,,
"summarize: def request_sender(self, pn_link):
        """"""""""""
        sl = SenderLink(self._connection, pn_link)
        self._links.add(sl)
        return sl",Create link from request for a sender.,Request sender for Link.,Request a request sender.,38.10413387,38.78275546,38.44344467,,,,,,,,,
"summarize: def add_children(G, parent, level, n=2):
    """"""""""""
    if level == 0:
        return
    for i in range(n):
        child = parent+str(i)
        G.add_node(child)
        G.add_edge(parent,child)
        add_children(G, child, level-1, n)",Add children recursively to a binary tree.,return return level Add a children to the specified list.,Add a children to a single node.,35.58410639,41.13414079,38.35912359,,,,,,,,,
"summarize: def _get_register_specs(bit_labels):
    """"""
    """"""
    it = itertools.groupby(bit_labels, operator.itemgetter(0))
    for register_name, sub_it in it:
        yield register_name, max(ind[1] for ind in sub_it) + 1",Get the number and size of unique registers from bit_labels list.,Returns a list of registers of bits into a list of specs.,return bit_labels Register a single bit on the given address.,33.95012071,42.7607165,38.35541861,,,,,,,,,
"summarize: def record_line(self, frame, event, arg):  # pylint: disable=unused-argument
        """"""""""""
        if event == 'line':
            if self.prev_timestamp:
                runtime = time.time() - self.prev_timestamp
                self.lines.append([self.prev_path, self.prev_lineno, runtime])
            self.prev_lineno = frame.f_lineno
            self.prev_path = frame.f_code.co_filename
            self.prev_timestamp = time.time()
        return self.record_line",Records line execution time.,Records a line of the given frame.,Record the statement on the lines.,41.30061231,35.35381424,38.32721328,,,,,,,,,
"summarize: def handle_registered(self, server):
        """"""
        """"""
        if not self._registered:
            self.logger.info('Registered')
            self._registered = True
            for data in self._out_buffer:
                self.send(data)
            self._out_buffer = []","\    When the connection to the server is registered, send all pending    data.",self._out_buffer.append(data) return self._out_buffer Shows the response when the server is registered.,return self._registered Register the handler to register the given specification that handling server.,38.72028126,37.88916786,38.30472456,,,,,,,,,
"summarize: def div(value, arg):
    """"""""""""
    try:
        return valid_numeric(value) / valid_numeric(arg)
    except (ValueError, TypeError):
        try:
            return value / arg
        except Exception:
            return ''",Divide the arg by the value.,Returns the divided argument.,If the value is a dividual value.,34.79992308,41.70156902,38.25074605,,,,,,,,,
"summarize: def remove_builtin(self, key, orig):
        """"""""""""
        if orig is BuiltinUndefined:
            del __builtin__.__dict__[key]
        else:
            __builtin__.__dict__[key] = orig",Remove an added builtin and re-set the original.,return del_orig.builtin Remove original builtin from JSON,return del __builtin Remove builtin.,42.80395102,33.60534417,38.2046476,,,,,,,,,
"summarize: def initialWinProb(line):
    """"""
    """"""
    line = float(line)
    probWin = 1. - norm.cdf(0.5, -line, 13.86)
    probTie = norm.cdf(0.5, -line, 13.86) - norm.cdf(-0.5, -line, 13.86)
    return 100. * (probWin + 0.5 * probTie)",Gets the initial win probability of a game given its Vegas line.,/ probWin Probabilities the initial Probabilities.,Initial floating an iterable of the probs of a single robs,40.14878559,36.19665058,38.17271809,,,,,,,,,
"summarize: def _ast_option_group_to_code(self, option_group, **kwargs):
    """"""""""""
    lines = [""option(""]
    lines.extend(self._indent(self._ast_to_code(option_group.expression)))
    lines.append("")"")
    return lines",Convert an AST option group to python source code.,Add a new group to a given option group.,Apply an Option to the group ID on the group.,39.33969166,36.98277915,38.16123541,,,,,,,,,
"summarize: def _separate_dirs_files(models):
    """"""
    
    """"""
    dirs = []
    files = []
    for model in models:
        if model['type'] == 'directory':
            dirs.append(model['path'])
        else:
            files.append(model['path'])
    return dirs, files",Split an iterable of models into a list of file paths and a list of  directory paths.,Parse a list of directories and separate directorys into a directorys,Fetch all files assigned files from directory and directory paths.,42.43065276,33.86370098,38.14717687,,,,,,,,,
"summarize: def is_private(prefix, base):
    """"""
    """"""
    warnings.warn(""is_private is deprecated; it wasn't useful; ""
                  ""examine DocTestFinder.find() lists instead"",
                  DeprecationWarning, stacklevel=2)
    return base[:1] == ""_"" and not base[:2] == ""__"" == base[-2:]","prefix, base -> true iff name prefix + ""."" + base is ""private"".","Returns the private warning of a prefix and returns a new ""private"".","return (""<%s>%s"" % (prefix, base)) Checks if the base is a private base.",33.88255974,42.30278791,38.09267383,,,,,,,,,
"summarize: def get_gravatar_profile_url(email, secure=GRAVATAR_DEFAULT_SECURE):
    """"""
    
    """"""
    if secure:
        url_base = GRAVATAR_SECURE_URL
    else:
        url_base = GRAVATAR_URL

    # Calculate the email hash
    email_hash = calculate_gravatar_hash(email)

    # Build url
    url = '{base}{hash}'.format(base=url_base, hash=email_hash)

    return url",Builds a url to a gravatar profile from an email address.,Returns a given url for the given email and returns the given URL with the given profile.,Returns the gravatar profile for the given user's email.,28.58974922,47.46128589,38.02551756,,,,,,,,,
"summarize: def get_history(self, client_id, msg):
        """"""""""""
        try:
            msg_ids = self.db.get_history()
        except Exception as e:
            content = error.wrap_exception()
        else:
            content = dict(status='ok', history=msg_ids)

        self.session.send(self.query, ""history_reply"", content=content,
                                            parent=msg, ident=client_id)",Get a list of all msg_ids in our DB records,return self.session.get(self.db.get_history()) Get a list of msg ids from the History.,return msg_ids Get a list of msg.,24.86085766,51.08716882,37.97401324,,,,,,,,,
"summarize: def case_report(institute_id, case_name):
    """"""""""""
    institute_obj, case_obj = institute_and_case(store, institute_id, case_name)
    data = controllers.case_report_content(store, institute_obj, case_obj)
    return dict(institute=institute_obj, case=case_obj, format='html', **data)",Visualize case report,Create an instance of a case report,Return a case report report.,34.24389957,41.69392928,37.96891443,,,,,,,,,
"summarize: def cleanup(self):
        """"""
        
        """"""
        for k in self._children:
            self._children[k].cleanup()

        if self._cleanup:
            self.remove(True)",Clean up children and remove the directory.,Cleanup a list of children in the database.,return True List all the children of the given children.,46.21980123,29.60518216,37.9124917,,,,,,,,,
"summarize: def get_feature_names(self, features=None):
        """"""   """"""
        if features:
            return self.feature_table.get_ordered_names(features)
        else:
            return self.feature_table.feature_names","Returns names of features. If features is None, returns all    features. Otherwise assumes the user is trying to find the order of the    features.",return self.feature_table.get_ordered_names(features) Get the name of the feature names.,"(feature_name=feature_name) Returns a list of feature names. If there is an element, then also sets the feature.",30.50242053,45.28905519,37.89573786,,,,,,,,,
"summarize: def _insert_html_fetching_plain_text(self, cursor, html):
        """""" 
        """"""
        cursor.beginEditBlock()
        cursor.removeSelectedText()

        start = cursor.position()
        self._insert_html(cursor, html)
        end = cursor.position()
        cursor.setPosition(start, QtGui.QTextCursor.KeepAnchor)
        text = cursor.selection().toPlainText()

        cursor.setPosition(end)
        cursor.endEditBlock()
        return text","Inserts HTML using the specified cursor, then returns its plain text      version.",Converts a text and returns a position of the fetching text into a text by its text.,Return the cursor text in the cursor. This method returns the cursor.,37.46196894,38.121848,37.79190847,,,,,,,,,
"summarize: def tuples_2_bool(tuples, x):
    """"""
    
    """"""
    if np.ndim(tuples) == 1:
        tuples = [tuples]

    out = np.zeros(x.size, dtype=bool)
    for l, u in tuples:
        out[(x > l) & (x < u)] = True
    return out",Generate boolean array from list of limit tuples.,Map a list of another tuples and return an array of tuples.,Returns a tuple of the tuples in a list of x-of-1-1.,42.00335756,33.5070408,37.75519918,,,,,,,,,
"summarize: def unencrypt_single_user(engine, user_id, old_crypto, logger):
    """"""
    
    """"""
    reencrypt_user_content(
        engine=engine,
        user_id=user_id,
        old_decrypt_func=old_crypto.decrypt,
        new_encrypt_func=lambda s: s,
        logger=logger,
    )",Unencrypt all files and checkpoints for a single user.,return reencrypto Updates a single user.,Unauthor to single contents of a User-secrypt.,41.42016858,33.99156211,37.70586535,,,,,,,,,
"summarize: def engine_count(self):
        """"""""""""
        count = 0
        for n in self.engines.itervalues():
            if isinstance(n, (tuple,list)):
                n,args = n
            count += n
        return count",determine engine count from `engines` dict,", n Engine the negine count of the tuple.",Engine a count of the count of the ``engine_count``.,39.66869772,35.74061728,37.7046575,,,,,,,,,
"summarize: def find(dataset, url):
    ''''''
    fn = os.path.join(DATASETS, dataset)
    dn = os.path.dirname(fn)
    if not os.path.exists(dn):
        print('creating dataset directory: %s', dn)
        os.makedirs(dn)
    if not os.path.exists(fn):
        if sys.version_info < (3, ):
            urllib.urlretrieve(url, fn)
        else:
            urllib.request.urlretrieve(url, fn)
    return fn","Find the location of a dataset on disk, downloading if needed.",Find a full directory from a location of the dataset.,Get a folder for the dataset and return a directory.,46.23043413,29.11803491,37.67423452,,,,,,,,,
"summarize: def render(self, context=None):
        """"""

        """"""
        # Make the complete context we'll use.
        ctx = dict(self.context)
        if context:
            ctx.update(context)
        return self.render_function(ctx, self.do_dots)",Render this template by applying it to `context`.,Render the context when the dots are it were added.,Render the class to the specified context.,36.79682596,38.44876944,37.6227977,,,,,,,,,
"summarize: def get_step_name(self, index: int) -> str:
        """"""
        
        """"""
        step_name = self._steps[index].__qualname__

        if not step_name or "">"" in step_name :
            step_name = f""Step{index + 1}of{len(self._steps)}""

        return step_name",Give the waterfall step a unique name,Get a step name for the index,Get a step name of the step name.,36.95024772,38.22080031,37.58552402,,,,,,,,,
"summarize: def default_pass_manager_simulator(basis_gates):
    """"""
    
    """"""
    pass_manager = PassManager()

    pass_manager.append(Unroller(basis_gates))

    pass_manager.append([RemoveResetInZeroState(), Depth(), FixedPoint('depth')],
                        do_while=lambda property_set: not property_set['depth_fixed_point'])

    return pass_manager",The default pass manager without a coupling map.,Make a default reset in the pass manager.,Default to default password.,49.70811719,25.42435121,37.5662342,,,,,,,,,
"summarize: def mul(value, arg):
    """"""""""""
    try:
        return valid_numeric(value) * valid_numeric(arg)
    except (ValueError, TypeError):
        try:
            return value * arg
        except Exception:
            return ''",Multiply the arg with the value.,Multiple validation of the given value.,Multiple values are not a valid valid argument.,43.09209816,32.00730082,37.54969949,,,,,,,,,
"summarize: def get_credentials(self, region_name=None):
        """"""
        """"""
        session, _ = self._get_credentials(region_name)
        # Credentials are refreshable, so accessing your access key and
        # secret key separately can lead to a race condition.
        # See https://stackoverflow.com/a/36291428/8283373
        return session.get_credentials().get_frozen_credentials()",Get the underlying `botocore.Credentials` object.,Gets the credentials for a given credential name.,[0] Return a credentials object from the credentials.,34.71736157,40.36538472,37.54137315,,,,,,,,,
"summarize: def is_ancestor_name(
    frame: astroid.node_classes.NodeNG, node: astroid.node_classes.NodeNG
) -> bool:
    """"""
    """"""
    try:
        bases = frame.bases
    except AttributeError:
        return False
    for base in bases:
        if node in base.nodes_of_class(astroid.Name):
            return True
    return False",return True if `frame` is an astroid.Class node with `node` in the  subtree of its bases attribute,Returns True if the astroid name is a single name and its name of the astroid name.,"Returns the astroid of the nodes of a given name. This is an element, otherwise will have an one name.",40.21206843,34.85088172,37.53147508,,,,,,,,,
"summarize: def surface_area(self):
        
        """"""
        return [self.atomic_sa(i) for i in range(len(self.rads))]","r""""""Calculate all atomic surface area.",Get the surface area by the surface.,Returns the samples of the surface area.,36.94431739,38.09631895,37.52031817,,,,,,,,,
"summarize: def check(self):
        """"""""""""
        if self.closed:
            raise ValueError(""Cannot check a closed state"")
        self._maybeReset()
        if self.url is None:
            return False
        return self._maybeCheck()",Check the state of HTTP,Check if the closed is a closed state.,Check for a closed state.,34.49394897,40.48993671,37.49194284,,,,,,,,,
"summarize: def set_source(self, source):
        """"""  
        """"""
        self.widget.clear()
        html = etree.HTML(source)
        self.widget.extend(html[0])

        # Clear removes everything so it must be reinitialized
        super(RawComponent, self).init_widget()",Set the source by parsing the source and inserting it into the     component.,"super(RawComponent, self).set_source(source) Sets source to the source.","self.widget.set_source(source, source) List all the sources in the source.",40.24185068,34.739375,37.49061284,,,,,,,,,
"summarize: def dedent(ind, text):
    """"""
    
    """"""
    text2 = textwrap.dedent(text)
    if ind == 0:
        return text2
    indent_str = "" "" * ind
    return ""\n"".join(indent_str + line for line in text2.split(""\n""))",Dedent text to the specific indentation level.,Dedent a list of indent texts.,Return a text URL specification of an URL.,35.44956909,39.31741318,37.38349114,,,,,,,,,
"summarize: def extend_reservation(request, user_id, days=7):
    ''' 
    '''

    user = User.objects.get(id=int(user_id))
    cart = CartController.for_user(user)
    cart.extend_reservation(datetime.timedelta(days=days))

    return redirect(request.META[""HTTP_REFERER""])",Allows staff to extend the reservation on a given user's cart.,Gets the user ID for the given user ID for a given user ID.,Create a reservation requested in a user and returns the response.,33.58322647,41.17014617,37.37668632,,,,,,,,,
"summarize: def decode_obj(obj, force=False):
	''
	if isinstance(obj, unicode): return obj
	elif isinstance(obj, bytes):
		if force_encoding is not None: return obj.decode(force_encoding)
		if chardet:
			enc_guess = chardet.detect(obj)
			if enc_guess['confidence'] > 0.7:
				return obj.decode(enc_guess['encoding'])
		return obj.decode('utf-8')
	else:
		return obj if not force else repr(obj)",Convert or dump object to unicode.,Decode object with a given object.,Decode a unicode object into an object.,33.03021857,41.69662486,37.36342172,,,,,,,,,
"summarize: def lookup(self, subcmd_prefix):
        """"""""""""
        for subcmd_name in list(self.subcmds.keys()):
            if subcmd_name.startswith(subcmd_prefix) \
               and len(subcmd_prefix) >= \
               self.subcmds[subcmd_name].__class__.min_abbrev:
                return self.subcmds[subcmd_name]
            pass
        return None",Find subcmd in self.subcmds,Get the list of subcmds.,Look for cmd in self.subcmds.keys() Lookup,29.89873031,44.74830465,37.32351748,,,,,,,,,
"summarize: def get_default_value(self):
        """"""
        """"""
        dv  = self.default_value
        if isinstance(dv, DefaultValueGenerator):
            return dv.generate(self.klass)
        else:
            return dv",Instantiate a default value instance.,Gets the default value generator.,.generate(self.klass) Gets a default value for the default value.,44.475176,30.15736725,37.31627163,,,,,,,,,
"summarize: def color_toggle(self):
        """"""""""""

        if self.color_scheme_table.active_scheme_name == 'NoColor':
            self.color_scheme_table.set_active_scheme(self.old_scheme)
            self.Colors = self.color_scheme_table.active_colors
        else:
            self.old_scheme = self.color_scheme_table.active_scheme_name
            self.color_scheme_table.set_active_scheme('NoColor')
            self.Colors = self.color_scheme_table.active_colors",Toggle between the currently active color scheme and NoColor.,return self.color_scheme Gets a Graph of the given colors.,return self.Colors Get a color of the actual scheme.,35.49224702,39.12691993,37.30958348,,,,,,,,,
"summarize: def _session_key(self, key):
        """"""
        

        """"""

        return '{0}:{1}:{2}'.format(self.settings.prefix, self.name, key)",Generates session key string.,Gets a session key to session.,"Internal session key for key, and responding keys and key ``key``.",50.34086983,24.09683062,37.21885023,,,,,,,,,
"summarize: def generate_annotation_id(self):
        """"""
        """"""
        if not self.maxaid:
            valid_anns = [int(''.join(filter(str.isdigit, a)))
                          for a in self.timeslots]
            self.maxaid = max(valid_anns + [1])+1
        else:
            self.maxaid += 1
        return 'a{:d}'.format(self.maxaid)","Generate the next annotation id, this function is mainly used    internally.",generate annotation id for a given annotation id.,Generate annotation on the ``A`` application identifier.,34.0575348,40.27597623,37.16675552,,,,,,,,,
"summarize: def f_remove_link(self, name):
        """""" 

        """"""
        if name not in self._links:
            raise ValueError('No link with name `%s` found under `%s`.' % (name, self._full_name))

        self._nn_interface._remove_link(self, name)",Removes a link from from the current group node with a given name.,return name Write an link to the link to the given name.,Removes the link of the ``name`` from the name.,35.98752439,38.33359521,37.1605598,,,,,,,,,
"summarize: def on_close(self, *args, **kwargs):
        """"""""""""
        if self.connection is not None:
            del self.pgworker.connections[self.connection.pk]
            self.connection.delete()
            self.connection = None
        signals.request_finished.send(sender=self.__class__)
        safe_call(self.logger.info, '- %s %s', self, args or 'CLOSE')",Handle closing of websocket connection.,return self Command on `args` and connection.,self.connection.close() Finish the close.,33.66608067,40.64812258,37.15710163,,,,,,,,,
"summarize: def wait_interactive(self, interval=1., timeout=None):
        """"""""""""
        N = len(self)
        tic = time.time()
        while not self.ready() and (timeout is None or time.time() - tic <= timeout):
            self.wait(interval)
            clear_output()
            print(""%4i/%i tasks finished after %4i s"" % (self.progress, N, self.elapsed), end="""")
            sys.stdout.flush()
        print()
        print(""done"")","interactive wait, printing progress at regular intervals",return self.wait_interactive Waits the interval to a task.,"return wrapper.wrapper(self, timeout) Performs the current time state.",42.80979371,31.48724871,37.14852121,,,,,,,,,
"summarize: def update_(self, sct_dict, conf_arg=True):
        """"""
        """"""
        for opt, val in sct_dict.items():
            if opt not in self.def_:
                continue
            if not conf_arg or self.def_[opt].conf_arg:
                self[opt] = val",Update values of configuration section with dict.,return self Update the validity of the configuration files.,return self.def_[sct_dict] Update the sct_dict in the class.,51.06089143,23.21050414,37.13569779,,,,,,,,,
"summarize: def get_methods(self, node):
        """"""""""""
        methods = [
            m
            for m in node.values()
            if isinstance(m, astroid.FunctionDef)
            and not decorated_with_property(m)
            and self.show_attr(m.name)
        ]
        return sorted(methods, key=lambda n: n.name)",return visible methods,Get methods of nodes,Returns the methods of the node.,37.30603689,36.52498723,36.91551206,,,,,,,,,
"summarize: def list(self):
        """"""
        
        """"""
        return [File(f, parent=self) for f in os.listdir(self.path)]",List the contents of the directory.,Returns list of all files from the directory.,List all the list of files and otherwise.,44.86966513,28.92364786,36.8966565,,,,,,,,,
"summarize: def iftrain(self, then_branch, else_branch):
        """"""
        
        """"""
        return ifelse(self._training_flag, then_branch, else_branch, name=""iftrain"")",Execute `then_branch` when training.,Adds the branch to the training.,Return a training one of this element.,44.57201144,29.04047194,36.80624169,,,,,,,,,
"summarize: def sanger_variants(self, institute_id=None, case_id=None):
        """"""
        """"""
        query = {'validation': {'$exists': True}}
        if institute_id:
            query['institute_id'] = institute_id
        if case_id:
            query['case_id'] = case_id

        return self.variant_collection.find(query)",Return all variants with sanger information,Sanger the query variant_collection.,"Return a list of collections, ``Viants.Sanger``.",35.62641401,37.02725644,36.32683523,,,,,,,,,
"summarize: def topic(self, topic_id):
        """"""
        """"""
        params = {
            self.PKEY: self.api_key
        }

        # http://example.com/t/8.json
        response = self._call(self.TOPIC, topic_id,
                              params=params)

        return response",Retrive the topic with `topic_id` identifier.,Creates the topic for the topic for a topic.,Gets a topic MetaParams with a given topic ID.,36.36530618,36.28111241,36.3232093,,,,,,,,,
"summarize: def contents_url(self):
        """"""""""""
        loc = self.download_location
        return loc.base_uri + loc.location + loc.access_credential",Full URL to the dataset contents.,_path Adds a URL to the location.,s(self.content) Returns the URL requested URL.,41.12089506,31.38836798,36.25463152,,,,,,,,,
"summarize: def connect(self):
        """"""""""""
        if self.loop is None:  # pragma: no cover
            self.loop = asyncio.get_event_loop()
        t = asyncio.Task(
            self.loop.create_connection(
                self.config['protocol_factory'],
                self.config['host'], self.config['port'],
                ssl=self.config['ssl']),
            loop=self.loop)
        t.add_done_callback(self.connection_made)
        return t",connect to the server,Connect to loop.,.connect(t) Add a port.,42.6402705,29.81792161,36.22909606,,,,,,,,,
"summarize: def display_svg(*objs, **kwargs):
    """"""
    """"""
    raw = kwargs.pop('raw',False)
    if raw:
        for obj in objs:
            publish_svg(obj)
    else:
        display(*objs, include=['text/plain','image/svg+xml'])",Display the SVG representation of an object.,"return display(*objs, **kwargs) Display a svg from the given object.",Displays an object into an object.,31.05513632,41.39874222,36.22693927,,,,,,,,,
"summarize: def analysis2(self, morf):
        """"""

        """"""
        analysis = self._analyze(morf)
        return (
            analysis.filename,
            sorted(analysis.statements),
            sorted(analysis.excluded),
            sorted(analysis.missing),
            analysis.missing_formatted(),
            )",Analyze a module.,Analyze analysis.,Analysis2 analysis2.,50.43545475,21.95152443,36.19348959,,,,,,,,,
"summarize: def StringIO(*args, **kw):
    """"""""""""
    global StringIO
    try:
        from cStringIO import StringIO
    except ImportError:
        from StringIO import StringIO
    return StringIO(*args,**kw)",Thunk to load the real StringIO on demand,Returns the cString iO to the given StringIO,Construct the StringIO from a global StringIO.,35.44207231,36.94057779,36.19132505,,,,,,,,,
"summarize: def get_user_channel(self, input_channel, input_type=None):
        """"""
        """"""

        res = {""input_channel"": input_channel}

        itype = input_type if input_type else self.input_type

        if itype in self.RAW_MAPPING:

            channel_info = self.RAW_MAPPING[itype]

            return {**res, **channel_info}",Returns the main raw channel for the process,else: return None Returns the channels for the given input_channel.,return Update the user channel. This is ready to exclude the folder.,41.52473833,30.80476606,36.1647522,,,,,,,,,
"summarize: def outputCharFormatter(c):
    """"""
    """"""
    #TODO 2: allow hex only output
    if 32<c<127: return chr(c)
    elif c==10: return '\\n'
    elif c==13: return '\\r'
    elif c==32: return '"" ""'
    else: return '\\x{:02x}'.format(c)",Show character in readable format,Get the output CharFormatter for the given character.,Formatter function to get character tag,32.12435371,39.87773996,36.00104684,,,,,,,,,
"summarize: def delete(self):
        """"""
        """"""
        log.debug(
            ""Deleting grant %s for client %s"" % (self.code, self.client_id)
        )
        self._cache.delete(self.key)
        return None",Removes itself from the cache,Delete a grant from the grant,Removes the delete to the delete.,35.94892862,35.93699487,35.94296175,,,,,,,,,
"summarize: def set_loop_points(self, start_sample=-1, end_sample=0):
        '''
        '''
        lib.SetVoiceLoopPoints(self._handle, start_sample, end_sample)",Set the loop points within the sound.,Sets loop points to the specified tick.,return Settings.Settings(self._handle) Loops any loops that were the endpoints.,50.55634269,21.32635136,35.94134703,,,,,,,,,
"summarize: def average(wave, indep_min=None, indep_max=None):
    
    """"""
    ret = copy.copy(wave)
    _bound_waveform(ret, indep_min, indep_max)
    area = _running_area(ret._indep_vector, ret._dep_vector)
    area[0] = ret._dep_vector[0]
    deltas = ret._indep_vector - ret._indep_vector[0]
    deltas[0] = 1.0
    ret._dep_vector = np.divide(area, deltas)
    ret.dep_name = ""average({0})"".format(ret._dep_name)
    return ret","r""""""  Return the running average of a waveform's dependent variable vector.",Average an average of an average of an average of an indep_vector and return it.,Return an UTCAL of an average of the indeping area.,36.39007465,35.46559284,35.92783375,,,,,,,,,
"summarize: def fromstring(data, beautifulsoup=None, makeelement=None, **bsargs):
    """"""
    """"""
    return _parse(data, beautifulsoup, makeelement, **bsargs)",Parse a string of HTML data into an Element tree using the  BeautifulSoup parser.,Loads a series into a dictionary and returns the json string of the data.,Insert a data into an XML containing the data from the data.,38.93864779,32.90988682,35.92426731,,,,,,,,,
"summarize: def _get_random(self, obj_type):
        """"""
        
        """"""
        return self.mutator[obj_type][random.randint(0, self.config.level)]",Get a random mutator from a list of mutators,Gets a list of random objects in the given object.,Returns the internal random object of a random,38.26998154,33.44546427,35.85772291,,,,,,,,,
"summarize: def mid(self):
        """""" """"""
        ret = self.mid_format % self.mid_content.center(
            self.width, self._mid_padding)
        if self.right_fill:
            ret = ret.ljust(self.right_fill, self._mid_padding)
        if self.left_fill:
            ret = ret.rjust(self.left_fill, self._mid_padding)
        ret = ret.center(self.layer_width, self.mid_bck)
        return ret",Constructs the middle line of the element,Return the mid of the middleware for the given layer.,"Execute a mid, with the id of the Mid.",37.51702195,34.13918209,35.82810202,,,,,,,,,
"summarize: def _get_api_key(self):
        """"""
        
        """"""
        conn = self.get_connection(self.http_conn_id)
        api_key = conn.password
        if not api_key:
            raise AirflowException('Opsgenie API Key is required for this hook, '
                                   'please check your conn_id configuration.')
        return api_key",Get Opsgenie api_key for creating alert,Get the api key for this conn.,Get the api key for the given connection.,35.06145045,36.55185186,35.80665116,,,,,,,,,
"summarize: def __forall_files(file_paths, output_dir, op):
    """"""
    
    """"""
    for file_path in file_paths:
        if not file_path.startswith('/'):
            raise ValueError('Path provided (%s) is relative not absolute.' % file_path)
        dest = os.path.join(output_dir, os.path.basename(file_path))
        op(file_path, dest)",Applies a function to a set of files and an output directory.,Add files to files to files into a list of files.,"return output_dir, dest Return a directory and return a directory file",31.26215541,40.19601438,35.7290849,,,,,,,,,
"summarize: def all(self):
        """"""""""""
        found = False
        s = []
        for display in self.list:
            if not found:
                s.append(""""""Auto-display expressions now in effect:
Num Enb Expression"""""")
                found = True
                pass
            s.append(display.format())
        return s",List all display items; return 0 if none,", found Get all of the specified displays",Return all of the same displays of all effects,34.88611534,36.36768213,35.62689874,,,,,,,,,
"summarize: def initialize(self, params, qubits):
    """"""""""""
    if isinstance(qubits, QuantumRegister):
        qubits = qubits[:]
    else:
        qubits = _convert_to_bits([qubits], [qbit for qreg in self.qregs for qbit in qreg])[0]
    return self.append(Initialize(params), qubits)",Apply initialize to circuit.,Initialize an initialize.,Initialize the qubits of the qubits to a qubits.,43.98224461,27.24738169,35.61481315,,,,,,,,,
"summarize: def _filter_message_by_chats(self, message, chats):
        """"""
        """"""
        if chats is None:
            return True

        chat_id = message['message']['chat']['id']

        return chat_id in chats",Check if a message can be filtered based in a list of chats.,".get('chats', None) Returns True if the chat is message is message.",Return a list of messages for the given chats.,28.95822809,42.02707439,35.49265124,,,,,,,,,
"summarize: def encode_bytes_list(binary_thrift_obj_list):  # pragma: no cover
    """"""
    
    """"""
    transport = TMemoryBuffer()
    write_list_begin(transport, TType.STRUCT, len(binary_thrift_obj_list))
    for thrift_bin in binary_thrift_obj_list:
        transport.write(thrift_bin)

    return bytes(transport.getvalue())",Returns a TBinaryProtocol encoded list of Thrift objects.,Generate a list of encode bytes of the binary thrift.,Extract a binary list of transports in the leader.,41.56022785,29.38641509,35.47332147,,,,,,,,,
"summarize: def parse_file(filename):
    """"""""""""
    assert isinstance(filename, _str_type), ""`filename` parameter should be a string, got %r"" % type(filename)
    with open(filename, ""rt"", encoding=""utf-8"") as f:
        return Code(_tokenize(f.readline))","Parse the provided file, and return Code object.",Parse a file and returns the file.,Returns the generator for the given filename.,43.41012808,27.43776679,35.42394744,,,,,,,,,
"summarize: def parse_path(path):
    """"""
    
    """"""
    if path is None:
        raise ValueError(""path must be a string"")

    parts = path.strip(""/"").split(""/"")

    database = unquote_plus(parts[0]) if len(parts) else None
    schema = parts[1] if len(parts) > 1 else None

    return database, schema",Get database name and database schema from path.,", database Parse a path to a list of files.",Parse an api filename of a part of the schema.,35.04552767,35.78697018,35.41624893,,,,,,,,,
"summarize: def select_non_missing(self, drop_nan=True, drop_masked=True, column_names=None, mode=""replace"", name=""default""):
        """"""
        """"""
        column_names = column_names or self.get_column_names(virtual=False)

        def create(current):
            return selections.SelectionDropNa(drop_nan, drop_masked, column_names, current, mode)
        self._selection(create, name)",Create a selection that selects rows having non missing values for all columns in column_names.,return column_names Add the selection to the selection to the given drop,return self._select_non_missing_non_missing(drop_nan) Returns a column name of the current missing representation of the selection.,36.80006285,33.96930346,35.38468316,,,,,,,,,
"summarize: def kind(self):
        ''''''
        optics = [
            Equality,
            Isomorphism,
            Prism,
            Review,
            Lens,
            Traversal,
            Getter,
            Setter,
            Fold,
        ]
        for optic in optics:
            if self._is_kind(optic):
                return optic",Returns a class representing the 'kind' of optic.,return None Returns a kind of the optic specified in the Getter.,return None Returns a dictionary of kind of the specified id.,37.15057644,33.58729239,35.36893442,,,,,,,,,
"summarize: def cancer_variants(institute_id, case_name):
    """"""""""""
    data = controllers.cancer_variants(store, request.args, institute_id, case_name)
    return data",Show cancer variants overview.,".get(""true"") Returns the cancer variant",.cancer_variants(data) Called if variant ID.,40.18569904,30.5324558,35.35907742,,,,,,,,,
"summarize: def tomography_basis(basis, prep_fun=None, meas_fun=None):
    """"""
    
    """"""
    ret = TomographyBasis(basis)
    ret.prep_fun = prep_fun
    ret.meas_fun = meas_fun
    return ret",Generate a TomographyBasis object.,Convert tomography basis.,Encode an UnmographyBasis required by basis.,34.13036656,36.51398185,35.32217421,,,,,,,,,
"summarize: def decode(self, x):
        """"""
        
        """"""
        if not self.rep_dim:
            raise Exception(""rep_dim must be set to decode."")
        if not self.decoding_network:
            self.decoding_network = NeuralNetwork(self.rep_dim)
            for layer in self.decoding_layers:
                self.decoding_network.stack_layer(layer, no_setup=True)
        return self.decoding_network.compute(x)",Decode given representation.,Decode the given x,Decode a datetime object from the given layer.,40.26883317,30.35783168,35.31333243,,,,,,,,,
"summarize: def create_admin_by_sis_id(self, sis_account_id, user_id, role):
        """"""
        
        """"""
        return self.create_admin(self._sis_id(sis_account_id), user_id, role)",Flag an existing user as an admin within the account sis id.,Create an address by a given user and address.,Get the user sis account_id and returns the admin_by_sis_id.,23.90363484,46.71947269,35.31155377,,,,,,,,,
"summarize: def _query_cassandra(self):
        """"""
        
        """"""
        self.hook = CassandraHook(cassandra_conn_id=self.cassandra_conn_id)
        session = self.hook.get_conn()
        cursor = session.execute(self.cql)
        return cursor",Queries cassandra and returns a cursor to the results.,Gets the Cassandra connection to the cassandra server.,".query(self.cassandra_id, self.cassandra_response) Gets the cursor from the Cassandra query.",42.06194946,28.50408086,35.28301516,,,,,,,,,
"summarize: def __get_session(self):
        """"""  """"""
        if not self.session:
            self.session = dal.get_default_session()
        return self.session",Reuses the same db session,Get the session.,Adds a session instance.,38.2914487,32.2289633,35.260206,,,,,,,,,
"summarize: def compute_module(self, context_name, mod_path):
        """"""""""""
        package_dir = os.path.dirname(self.project.path)
        if context_name == mod_path:
            return 0
        if modutils.is_standard_module(mod_path, (package_dir,)):
            return 1
        return 0",return true if the module should be added to dependencies,Returns the additional module with the given context.,Return a dictionary of module path to the package name.,34.93502172,35.58496153,35.25999163,,,,,,,,,
"summarize: def match_time(self, value):
    ''''''
    m = self.REGEX_TIME.search(value)
    time = datetime.datetime.utcnow().time()
    if m:
      time = datetime.time(int(m.group(1)), int(m.group(2)))
      value = self.REGEX_TIME.sub('', value)
    return (time, value)",Search for time information in the string,Returns the time of time in the values on the value,Return a matching time string of the datetime.,30.80378372,39.67276303,35.23827338,,,,,,,,,
"summarize: def parse_headers(self, headers):
        """"""
        """"""
        for name, value in _parse_keyvalue_list(headers):
            self.headers[name] = value",Parses a semi-colon delimited list of headers.,return self.headers Parse headers into a list of headers,return self._parse_headers(headers) Return a headers.,42.67691017,27.73424022,35.2055752,,,,,,,,,
"summarize: def album_tracks(self, spotify_id, limit=20, offset=0, market='US'):
        """"""
        """"""
        route = Route('GET', '/albums/{spotify_id}/tracks', spotify_id=spotify_id)
        payload = {'limit': limit, 'offset': offset}

        if market:
            payload['market'] = market

        return self.request(route, params=payload)",Get an albums tracks by an ID.,Album a tracks for a tracks.,Get an analysis that the ``API_Tracks``.,36.87912616,33.52901744,35.2040718,,,,,,,,,
"summarize: def push_rule_nodes(self) -> bool:
        """"""""""""
        if self.rule_nodes is None:
            self.rule_nodes = collections.ChainMap()
            self.tag_cache = collections.ChainMap()
            self.id_cache = collections.ChainMap()
        else:
            self.rule_nodes = self.rule_nodes.new_child()
            self.tag_cache = self.tag_cache.new_child()
            self.id_cache = self.id_cache.new_child()
        return True",Push context variable to store rule nodes.,Push a list of rule nodes and return it.,Push a route-point nodes into an route node.,39.8147344,30.58569481,35.20021461,,,,,,,,,
"summarize: def quick_completer(cmd, completions):
    """""" 
    """"""

    if isinstance(completions, basestring):
        completions = completions.split()

    def do_complete(self, event):
        return completions

    get_ipython().set_hook('complete_command',do_complete, str_key = cmd)",Easily create a trivial completer for a command.,return cmd Complete command on a complete command on a specified command.,return '' Method to create a complete complete complete.,31.02165811,39.36541826,35.19353819,,,,,,,,,
"summarize: def add_to_hash(self, filename, hasher):
        """"""""""""
        hasher.update(self.executed_lines(filename))
        hasher.update(self.executed_arcs(filename))",Contribute `filename`'s data to the Md5Hash `hasher`.,return hasher Add a new ``filename`` to the filename.,"hasher.add_to_hash(filename, hasher) Add a filename to a filename.",43.35937859,26.95104829,35.15521344,,,,,,,,,
"summarize: def _ast_op_alternate_to_code(self, opr, **kwargs):
    """"""""""""
    hoist_target = OP_ALTERNATE
    operands = self._hoist_operands(opr.operands, lambda t: isinstance(t, OptreeNode) and t.opnode.operator is hoist_target)

    lines = [""alternation([""]
    for op in operands:
      lines.extend(self._indent(self._ast_to_code(op)))
      lines[-1] += "",""
    lines.append(""])"")
    return lines",Convert an AST alternate op to python source code.,Converts a list of alternations to a list of operands,Returns the relational element of a given URL.,37.84809244,32.43859757,35.14334501,,,,,,,,,
"summarize: def find(cls, where='.', exclude=(), include=('*',)):
        """"""
        """"""
        out = cls._find_packages_iter(convert_path(where))
        out = cls.require_parents(out)
        includes = cls._build_filter(*include)
        excludes = cls._build_filter('ez_setup', '*__pycache__', *exclude)
        out = filter(includes, out)
        out = filterfalse(excludes, out)
        return list(out)",Return a list all Python packages found within directory 'where',Returns a list of filters in the Given where and all excludes.,Return a list of filters in the clause of their provided filter.,37.80187701,32.40599255,35.10393478,,,,,,,,,
"summarize: def task_state(args):
    """"""
    
    """"""
    dag = get_dag(args)
    task = dag.get_task(task_id=args.task_id)
    ti = TaskInstance(task, args.execution_date)
    print(ti.current_state())",Returns the state of a TaskInstance at the command line.  >>> airflow task_state tutorial sleep 2015-01-01  success,print(task.process_executor.task_state) return task.process_executor.task_state Returns the state of a task of the dag on the given args.,ti.last_tag = ti.tag return ti.tag Returns the current title of a state of the given state.,37.20978377,32.97146842,35.0906261,,,,,,,,,
"summarize: def _get_session(self):
        """"""""""""
        if self.port in (465, ""465""):
            session = self._get_ssl()
        elif self.port in (587, ""587""):
            session = self._get_tls()

        try:
            session.login(self.from_, self._auth)
        except SMTPResponseException as e:
            raise MessageSendError(e.smtp_error.decode(""unicode_escape""))

        return session",Start session with email server.,Returns the session to the service.,"Returns a session, session instance of this server.",37.54122374,32.63934036,35.09028205,,,,,,,,,
"summarize: def check_token(token):
    '''  '''
    user = models.User.objects(api_key=token).first()
    return user or None",Verify http header token authentification,Returns the current user to user token.,Checks if authenticated token is found.,26.52685066,43.62538524,35.07611795,,,,,,,,,
"summarize: def to_operator(self):
        """"""""""""
        # Place import here to avoid cyclic import from circuit visualization
        from qiskit.quantum_info.operators.operator import Operator
        return Operator(self.to_matrix())",Convert to Operator object.,Parses operator to a local layer.,Method to set the operator.,32.49056805,37.53440007,35.01248406,,,,,,,,,
"summarize: def _callRemote(self, command, **kwargs):
        """"""

        """"""
        return self.factory.remote.callRemote(command, **kwargs)",Shorthand for ``callRemote``.,CallRemote Command to remote `command`.,Gets a callRemote commands.,31.48724833,38.5220493,35.00464882,,,,,,,,,
"summarize: def _hat_integral(self, x):
    """"""
    """"""
    x = tf.cast(x, self.power.dtype)
    t = self.power - 1.
    return tf.exp((-t) * tf.math.log1p(x) - tf.math.log(t))","Integral of the `hat` function, used for sampling.",Faster Hat Line2d Integral function.,Return a tuple of the hat dtype is called integral.,35.59501374,34.22086021,34.90793698,,,,,,,,,
"summarize: def send(self, cmd):
        """"""""""""
        with self.ws_sendlock:
            self.ws.send(json.dumps(cmd))",Send the given command thru the websocket,Send the server to send the current process.,return self.ws.send(cmd) Gets the user of the given client,38.6841124,31.01734669,34.85072955,,,,,,,,,
"summarize: def module(self, name):
        """"""
        """"""
        for mod in self.modules():
            if mod.node.name == name:
                return mod
        raise KeyError(name)","return a module by its name, raise KeyError if not found",Returns a new module for the given name.,Returns a module name in an implicit name of the module.,31.82010854,37.81129564,34.81570209,,,,,,,,,
"summarize: def attribute_type(self, attribute_name):
        '''
        
        '''
        attribute_name = attribute_name.upper()
        for name, ty in self.attributes:
            if name.upper() == attribute_name:
                return ty",Obtain the type of an attribute.,return attribute_name Get an attribute type for the attribute name.,return None Computes an attribute instance.,32.94676371,36.65361722,34.80019047,,,,,,,,,
"summarize: def annotation_list_builder(annotations, host):
    """"""
    
    """"""
    return [
        create_annotation(int(timestamp * 1000000), key, host)
        for key, timestamp in annotations.items()
    ]",Reformat annotations dict to return list of corresponding zipkin_core objects.,Add annotation list to the route builder for the given annotations.,"Return annotation list of all annotations, then in the client.",33.34577179,36.23429393,34.79003286,,,,,,,,,
"summarize: def check_namespace_availability(self, name):
        '''
        
        '''
        _validate_not_none('name', name)

        response = self._perform_get(
            self._get_path('services/serviceBus/CheckNamespaceAvailability',
                           None) + '/?namespace=' + _str(name), None)

        return _ServiceBusManagementXmlSerializer.xml_to_namespace_availability(
            response.body)","Checks to see if the specified service bus namespace is available, or    if it has already been taken.",Check that an instance of an instance of a namespace availability is the namespace,Check if the username is related on the same namespace_available.,34.71585624,34.8624304,34.78914332,,,,,,,,,
"summarize: def get_azure_cli_credentials(resource=None, with_tenant=False):
    """"""
    """"""
    profile = get_cli_profile()
    cred, subscription_id, tenant_id = profile.get_login_credentials(resource=resource)
    if with_tenant:
        return cred, subscription_id, tenant_id
    else:
        return cred, subscription_id",Return Credentials and default SubscriptionID of current loaded profile of the CLI.,", tenant_id return profile, profile Get an azure cli credentials for a tenant.",", tenant_id Returns a list of azured credentials that are not present.",36.92608261,32.62337162,34.77472712,,,,,,,,,
"summarize: def merge_pdfs(pdf_filepaths, out_filepath):
    """""" 
    """"""
    merger = PdfFileMerger()
    for pdf in pdf_filepaths:
        merger.append(PdfFileReader(open(pdf, 'rb')))

    merger.write(out_filepath)

    return out_filepath",Merge all the PDF files in `pdf_filepaths` in a new PDF file `out_filepath`.,s Merge a list of pdf files on the merger like additional filepath.,s[pdf_filepath] Returns an iterable of an editoring pdf file path.,37.78990433,31.68747635,34.73869034,,,,,,,,,
"summarize: def make_cache_key(*args, **kwargs):
    """"""
    
    """"""
    path = request.path
    args = str(hash(frozenset(request.args.items())))
    return (path + args).encode('ascii', 'ignore')",Used by cache to get a unique key per URL,Make a cache key to add the HTML document.,Method to get the key from the access token.,35.78751502,33.67315709,34.73033606,,,,,,,,,
"summarize: def register_monitors(self, *monitors):
        """"""
        
        """"""
        for key, node in monitors:
            if key not in self._registered_monitors:
                node *= 1.0 # Avoid CudaNdarray
                self.training_monitors.append((key, node))
                self.testing_monitors.append((key, node))
                self._registered_monitors.add(key)",Register monitors they should be tuple of name and Theano variable.,Register a list of training monitors to the given training monitors.,"else: self._registered_monitors.append((key, node)) Register the monitors and monitors",38.16616232,31.19386161,34.68001197,,,,,,,,,
"summarize: def _shouldConnect(self, node):
        """"""
        
        """"""

        return isinstance(node, TCPNode) and node not in self._preventConnectNodes and (self._selfIsReadonlyNode or self._selfNode.address > node.address)",Check whether this node should initiate a connection to another node,Gets the should connect the node in the node.,or node.isCode.isAlgorithm().isCode() The should only reading the node and create a new ``node``.,38.9595627,30.30006126,34.62981198,,,,,,,,,
"summarize: def _create_file():
    """"""
    
    """"""
    f = wave.open('audio.wav', mode='wb')
    f.setnchannels(2)
    p = pyaudio.PyAudio()
    f.setsampwidth(p.get_sample_size(pyaudio.paInt16))
    f.setframerate(p.get_default_input_device_info()['defaultSampleRate'])
    try:
        yield f
    finally:
        f.close()",Returns a file handle which is used to record audio,f.close() Creates a file and audio file and returns an Audio.,Creates a pyaudio.close() Return a function that it is a reference.,42.04774105,27.19876326,34.62325216,,,,,,,,,
"summarize: def compute_context_vector(self, prev_state, inputs, precomputed_values=None, mask=None):
        """"""
        
        """"""
        precomputed_values = precomputed_values if precomputed_values else self.precompute(inputs)
        align_weights = self.compute_alignments(prev_state, precomputed_values, mask)
        context_vector = T.sum(align_weights[:, :, None] * inputs, axis=1)
        return context_vector",Compute the context vector with soft attention.,Gets the context vector into a dictionary of the previous values,Gets the vector from the program between alignments,40.20703226,28.86751346,34.53727286,,,,,,,,,
"summarize: def utf8(value):
    """"""
    """"""
    if isinstance(value, _UTF8_TYPES):
        return value
    assert isinstance(value, unicode)
    return value.encode(""utf-8"")",Converts a string argument to a byte string.,Unicode string of the utf8 bytes,Returns a utf8 string as a string. This is a utf8.,28.63354866,40.42182027,34.52768447,,,,,,,,,
"summarize: def read(*pathcomponents):
    """"""""""""
    with open(join(abspath(dirname(__file__)), *pathcomponents)) as thefile:
        return thefile.read()",Read the contents of a file located relative to setup.py,Read the title file and return the results to one.,Read an abspath from an open file and returns a directory.,40.88060375,28.14436353,34.51248364,,,,,,,,,
"summarize: def build_uri(self, path, query_params):
        '''
        
        '''
        url = 'https://api.trello.com/1' + self.clean_path(path)
        url += '?' + urlencode(query_params)

        return url",Build the URI for the API call.,Returns the URLs for the given path.,Return the builder ID of the given URL.,39.74580465,29.27042237,34.50811351,,,,,,,,,
"summarize: def _block_stack_repr(self, block_stack):
        """"""""""""
        blocks = "", "".join(
            [""(%s, %r)"" % (dis.opname[b[0]], b[1]) for b in block_stack]
        )
        return ""["" + blocks + ""]""","Get a string version of `block_stack`, for debugging.",.join(blocks) Start `block_stack` blocks for a given block.,.join(blocks) Return a string representing the blocks,36.77036323,32.22814942,34.49925633,,,,,,,,,
"summarize: def get_rsa_key(self, client_key, request):
        """"""""""""
        if not request.client:
            request.client = self._clientgetter(client_key=client_key)
        if hasattr(request.client, 'rsa_key'):
            return request.client.rsa_key
        return None",Retrieves a previously stored client provided RSA key.,Retrieve the client key for the given client.,Retrieves the client key to the client.,33.68068853,35.11427497,34.39748175,,,,,,,,,
"summarize: def links_to_dynamic(self, ext):
        """"""""""""
        # XXX this should check to ensure the lib is actually being built
        # XXX as dynamic, and not just using a locally-found version or a
        # XXX static-compiled version
        libnames = dict.fromkeys([lib._full_name for lib in self.shlibs])
        pkg = '.'.join(ext._full_name.split('.')[:-1]+[''])
        for libname in ext.libraries:
            if pkg+libname in libnames: return True
        return False",Return true if 'ext' links to a dynamic lib in the same package,For each lib name in the dynamic dynamic,Return a list of actual dynamic dynamic library containing the given extra.,31.22664245,37.52396505,34.37530375,,,,,,,,,
"summarize: def metadata_id(item):
        """"""
        """"""
        cid = item['id']
        cversion = item['version']['number']

        return str(cid) + '#v' + str(cversion)",Extracts the identifier from a Confluence item.,+ '\n' Return metadata identified to item in the metadata item.,Returns the actual metadata identifier.,30.6400384,38.01298028,34.32650934,,,,,,,,,
"summarize: def nsplit(seq, n=2):
    """""" 

    """"""

    return [xy for xy in itertools.izip(*[iter(seq)]*n)]",Split a sequence into pieces of length n,Parse an iterator to a list of sequences.,Generates an iterator of the missing normal sequences.,38.53469965,30.06151502,34.29810734,,,,,,,,,
"summarize: def _sort_features(self, vocabulary):
        """"""
        """"""
        sorted_features = sorted(six.iteritems(vocabulary))
        map_index = np.empty(len(sorted_features), dtype=np.int32)
        for new_val, (term, old_val) in enumerate(sorted_features):
            map_index[new_val] = old_val
            vocabulary[term] = new_val

        return map_index",Sort features by name,", map_index Sort features to the feature",Get a list of sorted features.,34.9172668,33.66496864,34.29111772,,,,,,,,,
"summarize: def url(self, endpoint=''):
        """"""
        
        """"""
        if not endpoint.startswith('/'):
            endpoint = ""/"" + endpoint
        return self.protocol + ""://"" + self.hostname + endpoint",Get the base URL of the Remote.,Returns a URL of the given endpoint.,"Current the url to the URL, only the URL.",37.54122374,31.03240718,34.28681546,,,,,,,,,
"summarize: def f_add_config(self, *args, **kwargs):
        """"""

        """"""
        return self._nn_interface._add_generic(self, type_name=CONFIG,
                                               group_type_name=CONFIG_GROUP,
                                               args=args, kwargs=kwargs)",Adds a config parameter under the current group.,Adds a configuration to the Generic configuration.,Formats the given config from the given cache.,39.20182451,29.28394781,34.24288616,,,,,,,,,
"summarize: def top(self):
        """""" """"""
        ret = self.top_format % self.top_connect.center(
            self.width, self.top_pad)
        if self.right_fill:
            ret = ret.ljust(self.right_fill, self.top_pad)
        if self.left_fill:
            ret = ret.rjust(self.left_fill, self.top_pad)
        ret = ret.center(self.layer_width, self.top_bck)
        return ret",Constructs the top line of the element,Top a width instance of the width.,Returns the top of the top left fill the interpolated.,31.4298861,36.95575002,34.19281806,,,,,,,,,
"summarize: def char_tokens_to_char_offsets(si_tokens):
    ''''''
    for token in si_tokens:
        offset = token.offsets[OffsetType.CHARS]
        yield offset.first, offset.first + offset.length",Convert character ``Offset``s to character ranges.,yield offset Convert tokens tokens tokens.,Get the character of the character.,28.3087567,40.04970149,34.1792291,,,,,,,,,
"summarize: def bot(self):
        """""" """"""
        ret = self.bot_format % self.bot_connect.center(
            self.width, self.bot_pad)
        if self.right_fill:
            ret = ret.ljust(self.right_fill, self.bot_pad)
        if self.left_fill:
            ret = ret.rjust(self.left_fill, self.bot_pad)
        ret = ret.center(self.layer_width, self.bot_bck)
        return ret",Constructs the bottom line of the element,Get the bot level of bot by the Width.,Returns the right bot connected on the left.,35.90859944,32.40151235,34.1550559,,,,,,,,,
"summarize: def save(self, filename, options=None):
        """"""
        """"""
        output = self.render(options)
        _filename = self.writer.save(filename, output)
        return _filename",Renders the barcode and saves it in `filename`.,Save a filename and filename into a file.,Creates a save filename and return a save base saved file.,33.55020098,34.67099815,34.11059957,,,,,,,,,
"summarize: def sample_shape_tensor(self, name=""sample_shape_tensor""):
    """"""
    """"""
    with tf.compat.v1.name_scope(name):
      if isinstance(self._sample_shape, tf.Tensor):
        return self._sample_shape
      return tf.convert_to_tensor(
          value=self.sample_shape.as_list(), dtype=tf.int32)",Sample shape of random variable as a 1-D `Tensor`.,Returns an Sample instance of a tensor.,Returns a sample-shape tensor of the sample-shape.,31.39754028,36.76482869,34.08118449,,,,,,,,,
"summarize: def _close(self, error=None):
        """"""""""""
        self._closing = True
        self.pause_reading()
        self._loop.call_soon(self._call_connection_lost, error)","Actual closing code, both from manual close and errors.",return self._closing Close the error and raise an error.,self._loop.call_soon(error) self._loop.close() Close the error from the closing error.,40.37271234,27.68151473,34.02711354,,,,,,,,,
"summarize: def get_all_elements(
    node: astroid.node_classes.NodeNG
) -> Iterable[astroid.node_classes.NodeNG]:
    """"""""""""
    if isinstance(node, (astroid.Tuple, astroid.List)):
        for child in node.elts:
            for e in get_all_elements(child):
                yield e
    else:
        yield node",Recursively returns all atoms in nested lists and tuples.,Returns a list of nodes of nodes into a list of elements.,return node Returns all nodes of the children in a list of nodes.,32.2821388,35.65989953,33.97101917,,,,,,,,,
"summarize: def _get_exclusion(extractor, exclusion, text):
  """"""
  """"""
  try:
    _call_extractor(exclusion, text)
    exclusion_matches = True
  except DeadEnd:
    exclusion_matches = False

  if exclusion_matches:
    raise DeadEnd()
  else:
    return _call_extractor(extractor, text)",Returns extractor's result if exclusion does not match.,"return _call_extractor(exclusion_matches, text) Get the exclusion to exclusion",Return a exclusion end of exclusion.,36.51441718,31.39434573,33.95438146,,,,,,,,,
"summarize: def pseudo_handler(self, signum, frame):
        """"""  """"""
        self.log.warn(""Received sigal {0} but system is already busy processing a previous signal, current frame: {1}"".format(signum, str(frame)))",Pseudo handler placeholder while signal is beind processed,"return self._clean_signal(signum, frame) Pseudo handler for the signal, and return it.","frame.handler(signum, frame) Pseudo handler for the given signal.",30.65074263,37.15299641,33.90186952,,,,,,,,,
"summarize: def impad_to_multiple(img, divisor, pad_val=0):
    """"""
    """"""
    pad_h = int(np.ceil(img.shape[0] / divisor)) * divisor
    pad_w = int(np.ceil(img.shape[1] / divisor)) * divisor
    return impad(img, (pad_h, pad_w), pad_val)",Pad an image to ensure each edge to be multiple to some number.,Convert an impad to a multiple version of a numpy array.,Impad a divisor to the table of the multiple of impadable order.,34.12399949,33.65017175,33.88708562,,,,,,,,,
"summarize: def get_group_named(group, path=None):
    """"""
    """"""
    result = {}
    for ep in get_group_all(group, path=path):
        if ep.name not in result:
            result[ep.name] = ep
    return result",Find a group of entry points with unique names.,Get a list of group names for a given group.,Gets a group named by named by named by group.,35.96538915,31.79267228,33.87903072,,,,,,,,,
"summarize: def _do_get(self):
        """"""
        
        """"""
        return requests.get(self._url, data=self._data, headers=self._headers, auth=(self._email, self._api_token))",HTTP Get Request,Do an GET request,Do the requests.,33.5070408,34.23474956,33.87089518,,,,,,,,,
"summarize: def connect(url, username, password):
    """"""
    
    """"""

    bb_session = stashy.connect(url, username, password)

    logger.info('Connected to: %s as %s', url, username)

    return bb_session",Return a connected Bitbucket session,Create a connected to a given username,Return a Username query if not found.,39.44803334,28.23919657,33.84361496,,,,,,,,,
"summarize: def strsplit(self, pattern):
        """"""
        
        """"""
        fr = H2OFrame._expr(expr=ExprNode(""strsplit"", self, pattern))
        fr._ex._cache.nrows = self.nrow
        return fr",Split the strings in the target column on the given regular expression pattern.,Simple string into a list of values for the pattern.,._expr_string Return a string representing the string of the pattern.,28.03858612,39.59616941,33.81737777,,,,,,,,,
"summarize: def construct_publish_comands(additional_steps=None, nightly=False):
    ''''''
    publish_commands = (
        ['rm -rf dist']
        + (additional_steps if additional_steps else [])
        + [
            'python setup.py sdist bdist_wheel{nightly}'.format(
                nightly=' --nightly' if nightly else ''
            ),
            'twine upload dist/*',
        ]
    )

    return publish_commands",Get the shell commands we'll use to actually build and publish a package to PyPI.,Construct publish commands from additional steps and return them to a list of publish commands.,(additional_steps) Generate an additional commands of the specified publishing comands.,34.33141211,33.22203517,33.77672364,,,,,,,,,
"summarize: def named_objs(objlist):
    """"""
    
    """"""
    objs = []
    for k, obj in objlist:
        if hasattr(k, '__name__'):
            k = k.__name__
        else:
            k = as_unicode(k)
        objs.append((k, obj))
    return objs","Given a list of objects, returns a dictionary mapping from  string name for the object to the object itself.",Returns a list of objs that are domained in the specified list of named objects,Gets a list of nodes for the objects of the ``Type`` object.,38.1748199,29.26906173,33.72194082,,,,,,,,,
"summarize: def setup(self):
        """"""  """"""
        with self._db_conn() as conn:
            for table_defn in self._tables.values():
                conn.execute(table_defn)
        return self",Initialize the required tables in the database,Setup the tables into a Flask Conn.,._setup_all(conn) Sets the ``Unique`` required to the db.,30.71397408,36.712891,33.71343254,,,,,,,,,
"summarize: def get_value_by_version(d):
    """"""
    
    """"""
    from oplus import CONF  # touchy import

    cv = CONF.eplus_version[:2]
    for v, value in sorted(d.items(), reverse=True):
        if cv >= v:
            return value",Finds the value depending in current eplus version.,return None Gets the value of a list of CONF versions,else: return value Returns a value in a datetime in the vatey.,39.86010621,27.5582257,33.70916596,,,,,,,,,
"summarize: def add(self, result):
        """"""
        
        """"""

        assert not self._complete

        self._results.append(result)
        self._change()",Adds a new result.,Add a new job to the results.,Adds the results of anotations for a given result.,44.41171231,23.00097699,33.70634465,,,,,,,,,
"summarize: def get_settings(self, client_name=None):
    '''

    '''
    settings = read_client_secrets()
    if client_name is not None and client_name in settings:
        return settings[client_name]           
    return settings","get all settings, either for a particular client if a name is provided,    or across clients.","[client_name] Get the list of settings that are settings, specified by a name or settings.",[client_name] Returns the settings and settings of the client name.,37.03946179,30.35909393,33.69927786,,,,,,,,,
"summarize: def generic_api_view(injector):
    """"""""""""

    handler = create_handler(GenericAPIView, injector)
    apply_http_methods(handler, injector)
    apply_api_view_methods(handler, injector)
    apply_generic_api_view_methods(handler, injector)
    return injector.let(as_view=handler.as_view)",Create DRF generic class-based API view from injector class.,Generic addresses the view method to add injector.,Create an application pointer from the generic.,35.46905393,31.85090895,33.65998144,,,,,,,,,
"summarize: def get_context(self, value):
        """"""""""""
        context = super(RenditionAwareStructBlock, self).get_context(value)
        context['image_rendition'] = self.rendition.\
            image_rendition or 'original'
        return context",Ensure `image_rendition` is added to the global context.,Return the context on the ``value`` as image.,Add an image to the given value and return a dictionary.,33.09718153,34.21064822,33.65391488,,,,,,,,,
"summarize: def wait_until_file_exists(filename):
    """"""
    """"""
    start_time = time.time()
    time_limit = start_time + FILE_IO_TIMEOUT
    while time.time() < time_limit:
        try:
            with open(filename):
                return
        except IOError:
            pass

    raise Timeout(""Waiting too long for %s."" % filename)",Wait until a file exists.,Wait for a file to file.,Return a start with a single file.,46.10072002,21.08528803,33.59300403,,,,,,,,,
"summarize: def format_name(self, format_name):
        """"""

        """"""
        if format_name in self.supported_formats:
            self._format_name = format_name
        else:
            raise ValueError('unrecognized format_name ""{}""'.format(
                format_name))",Set the default format name.,return format_name Formats the named format name,Formats the format of the supported field name.,33.26761348,33.84360011,33.5556068,,,,,,,,,
"summarize: def items_to_dict(items):
    """"""
    

    """"""

    res = collections.defaultdict(list)

    for k, v in items:
        res[k].append(v)

    return normalize_dict(dict(res))",Converts list of tuples to dictionary with duplicate keys converted to  lists.,Convert a list of items to dictionary.,Get the dictionary of all keys from the specified items into a list of dictionary.,27.45422361,39.50666195,33.48044278,,,,,,,,,
"summarize: def _hstack(self, other, prefix=None):
        """"""""""""
        assert len(self) == len(other), ""does not make sense to horizontally stack DataFrames with different lengths""
        for name in other.get_column_names():
            if prefix:
                new_name = prefix + name
            else:
                new_name = name
            self.add_column(new_name, other.columns[name])","Join the columns of the other DataFrame to this one, assuming the ordering is the same","return new_name, other Adds the new other to the current such as a new other.",return new_name This method called to save a new column of the new other.,33.15339419,33.77460349,33.46399884,,,,,,,,,
"summarize: def _reqs(self, tag):
        """"""  """"""
        return [
            (tag, i) for i in
            self.client.get_pulls(*tag.split('/'))
        ]",Grab all the pull requests,Returns the required tag.,Requests a pulls used by a pull tag.,30.47249972,36.33451147,33.4035056,,,,,,,,,
"summarize: def write_parquet(cls, path, output, sc, partition_num = 1, bigdl_type=""float""):
        """"""
        
        """"""
        return callBigDlFunc(bigdl_type, ""writeParquet"", path, output, sc, partition_num)",write ImageFrame as parquet file,Write Parquet to file and big dl files,Writes a single Parquet-reader.,37.16332024,29.63199127,33.39765576,,,,,,,,,
"summarize: def _read_list(ctx: ReaderContext) -> llist.List:
    """"""""""""
    start = ctx.reader.advance()
    assert start == ""(""
    return _read_coll(ctx, llist.list, "")"", ""list"")",Read a list element from the input stream.,Reads a list of list of llists in the context file.,"return start, start Read a list of categories.",33.23970227,33.44546427,33.34258327,,,,,,,,,
"summarize: def select_offer(self):
        """"""

        """"""
        logger.debug('Selecting offer.')
        pkt = self.offers[0]
        self.client.handle_offer(pkt)",Select an offer from the offers received.,return pkt Fill the offer of a required offer.,self.offers[pkt] = pkt return pkt Make a new offer.,40.6294197,26.03134509,33.3303824,,,,,,,,,
"summarize: def finalize(self, remove_all_handlers=True):
        """"""""""""
        for tool in self._tools:
            tool.finalize()
        self._tools = []
        self._stdout_to_logger = None
        for config in (self._sp_config, self._mp_config):
            if hasattr(config, 'close'):
                config.close()
        self._sp_config = None
        self._mp_config = None
        if remove_all_handlers:
            self.tabula_rasa()","Finalizes the manager, closes and removes all handlers if desired.",Load the dataset to the given remove and return the result.,self._remove_all_handlers() Finalize a single remove_all_handler.,27.27748843,39.36531335,33.32140089,,,,,,,,,
"summarize: def get(self, filter=False):
        """"""
        

        """"""
        result = {}

        for k, v in self.elements().items():
            intermediate = v.get(filter=filter)
            if intermediate:
                result[k] = intermediate

        return result",Returns a dictionary with the values of the model. Note that the values    of the leafs are YANG classes.,Get the elements of the query of the elements of the fields of the fields of the specified fields.,Returns a single element of the given filter and returns the results of the Filter instance.,32.85560921,33.78646715,33.32103818,,,,,,,,,
"summarize: def readTuple(self, stream):
        """"""
        """"""
        length, symbol = self.decodePeek(stream.peek(self.maxLength))
        stream.pos += length
        return length, symbol","Read symbol from stream. Returns symbol, length.",ReadTuple from stream to root file,Read a stream from the specified stream.,30.82934898,35.75726941,33.2933092,,,,,,,,,
"summarize: def get_tx_out(self, tx_hash, index, **kwargs):
        """""" 

        """"""
        return self._call(JSONRPCMethods.GET_TX_OUT.value, params=[tx_hash, index, ], **kwargs)",Returns the transaction output information corresponding to a hash and index.,Get the tx access for a given index and index and its transaction.,Returns a tuple of the current tx_out. This is an endpoint.,41.7495989,24.79399284,33.27179587,,,,,,,,,
"summarize: def interact(banner=None, readfunc=None, my_locals=None, my_globals=None):
    """"""

    """"""
    console = code.InteractiveConsole(my_locals, filename='<trepan>')
    console.runcode = lambda code_obj: runcode(console, code_obj)
    setattr(console, 'globals', my_globals)
    if readfunc is not None:
        console.raw_input = readfunc
    else:
        try:
            import readline
        except ImportError:
            pass
    console.interact(banner)
    pass",Almost a copy of code.interact  Closely emulate the interactive Python interpreter.,"return console.interact(pass, readline) Interacts the interact from the given file",return console.rstrip(console) Interactive the specified base.,40.64561891,25.86653632,33.25607762,,,,,,,,,
"summarize: def save(self):
        """"""  """"""
        file_path = self.get_config_path()
        contents = self.get_contents()
        with open(file_path, mode='w') as cfg_file:
            cfg_file.write(contents)",Save the config file,Save a file to a file,return cfg_file.write(file_path) Save all saved config files in the file.,43.03767738,23.45356126,33.24561932,,,,,,,,,
"summarize: def remove_duplicates(iterable, key=None):
	""""""
	
	""""""
	return itertools.chain.from_iterable(six.moves.map(
		every_other, six.moves.map(
			operator.itemgetter(1),
			itertools.groupby(iterable, key)
		)))","Given an iterable with items that may come in as sequential duplicates,	remove those duplicates.",return itertools Removes a list of duplicates from a list of duplicates.,Removes a removed duplicated duplicated duplicated by the ``DuplicatedDuplicated``.,34.40313656,32.04004486,33.22159071,,,,,,,,,
"summarize: def backpropagate(infile, outfile, apply_scores):
    """"""
    
    """"""

    if outfile is None:
        outfile = infile
    else:
        outfile = outfile

    backpropagate_oswr(infile, outfile, apply_scores)",Backpropagate multi-run peptide and protein scores to single files,"return outfile Propagate a ""infile"" backpropagate.",return backpropagate Generate an applying score of applying any ones.,29.92366186,36.46668566,33.19517376,,,,,,,,,
"summarize: def destroy(self):
        """"""  """"""
        with self._db_conn() as conn:
            for table_name in self._tables:
                conn.execute('DROP TABLE IF EXISTS %s' % table_name)
        return self",Destroy the SQLStepQueue tables in the database,._db_conn(conn) Destroys the destroy of the table name.,"._destroy(conn, self._created_tables) Destroy another table instance.",39.51595798,26.81210064,33.16402931,,,,,,,,,
"summarize: def _onMessageNotification(self, client, userdata, pahoMessage):
        """"""
        
        """"""
        try:
            note = Notification(pahoMessage, self._messageCodecs)
        except InvalidEventException as e:
            self.logger.critical(str(e))
        else:
            self.logger.debug(""Received Notification"")
            if self.notificationCallback:
                self.notificationCallback(note)","Internal callback for gateway notification messages, parses source device from topic string and    passes the information on to the registered device command callback",else: self.notificationCallback(note) self.notificationCallback(note) self.notificationCallback(note) return True return False Add the Message on the given username and password.,"self.logger.debug(""Cookie"") self.notification(userdata, password=self.user) Make sure the message is the event then events on the client.",37.2962777,28.97426664,33.13527217,,,,,,,,,
"summarize: def open_las(source, closefd=True):
    """""" 

    """"""
    if isinstance(source, str):
        stream = open(source, mode=""rb"")
        if not closefd:
            raise ValueError(""Cannot use closefd with filename"")
    elif isinstance(source, bytes):
        stream = io.BytesIO(source)
    else:
        stream = source
    return LasReader(stream, closefd=closefd)",Opens and reads the header of the las content in the source,Writes a las las las on the source to the source.,Returns the string as an YAML closefd with the default filename.,38.18828851,28.07608732,33.13218792,,,,,,,,,
"summarize: def get_event_descriptions(self, event_name=None):
        """"""
        
        """"""
        if event_name is None:
            return [e.as_event_description() for e in self.events]
        else:
            return [e.as_event_description()
                    for e in self.events if e.get_name() == event_name]",Get the thing's events as an array.,Get a list of events of the event `events`,Returns a list of events according to the event.,33.29193581,32.6233344,32.95763511,,,,,,,,,
"summarize: def predict_proba(self, x, **kwargs):
        '''
        '''
        return self.feed_forward(x, **kwargs)[self.layers[-1].output_name]",Compute class posterior probabilities for the given set of data.,Predict the proba layers on a given probabilities,(self.training_proba_inputs) Return a list of the proba,40.01767152,25.89669565,32.95718359,,,,,,,,,
"summarize: def get_refer(self, sym: sym.Symbol) -> Optional[Var]:
        """"""""""""
        return self.refers.entry(sym, None)",Get the Var referred by Symbol or None if it does not exist.,Gets a new referred reference from the given symbol,Get the refering referred referred referred documentation.,33.43361721,32.47232332,32.95297027,,,,,,,,,
"summarize: def get_config_path(self) -> str:
        """"""
        
        """"""
        dst_dir = self.__get_user_path()
        dst = dst_dir + ""/"" + config_filename
        return dst",Returns the path where the active config file is expected.    This is the user's profile folder.,Returns a dictionary of the config filepath to a filepath.,".get(dst_dir + ""/"" + dst_dir + ""/"") Returns the config directory of the installing filename.",30.41162658,35.36978838,32.89070748,,,,,,,,,
"summarize: def parse_notifier_name(name):
    """"""
    """"""
    if isinstance(name, str):
        return [name]
    elif name is None:
        return ['anytrait']
    elif isinstance(name, (list, tuple)):
        for n in name:
            assert isinstance(n, str), ""names must be strings""
        return name",Convert the name argument to a list of names.,else: return name Add a name of the given name to a name,else: return None Return an iterable of the name of the given name.,37.35289219,28.4266586,32.8897754,,,,,,,,,
"summarize: def write_items(cls, writer, items_generator):
        """"""
        """"""
        while True:
            items = items_generator()
            writer.write(items)
            time.sleep(1)",Write items to the queue,Write an items to the given items.,items.append(item) writer.write(writer) return writer Sends writer to a single items,52.51807781,13.19555662,32.85681722,,,,,,,,,
"summarize: def _get_selection_cursor(self, start, end):
        """""" 
        """"""
        cursor = self._control.textCursor()
        cursor.setPosition(start)
        cursor.setPosition(end, QtGui.QTextCursor.KeepAnchor)
        return cursor",Convenience method that returns a cursor with text selected between      the positions 'start' and 'end'.,.textCursor() Returns the selection cursor for the given start and end and end.,".setPosition(end, end) Returns an selection of the cursor.",39.03897877,26.66381045,32.85139461,,,,,,,,,
"summarize: def view_decorator(function_decorator):
	""""""
	""""""

	def simple_decorator(View):
		View.dispatch = method_decorator(function_decorator)(View.dispatch)
		return View

	return simple_decorator","Convert a function based decorator into a class based decorator usable	on class based Views.",(View) return View Add the simple decorator to the given function.,(function_decorator) Get the decorators of the given function. This is on the decorator.,28.27183135,37.28151741,32.77667438,,,,,,,,,
"summarize: def dict_from_file(filename, key_type=str):
    """"""
    """"""
    mapping = {}
    with open(filename, 'r') as f:
        for line in f:
            items = line.rstrip('\n').split()
            assert len(items) >= 2
            key = key_type(items[0])
            val = items[1:] if len(items) > 2 else items[1]
            mapping[key] = val
    return mapping",Load a text file and parse the content as a dict.,Generate a dict of filename and dict.,Return a dict of dict representations for a file.,34.87440133,30.57870666,32.726554,,,,,,,,,
"summarize: def twobin(loads):
    """"""
    """"""
    n = len(loads)
    a = randint(0,n-1)
    b = randint(0,n-1)
    return min(a,b)","Pick two at random, use the LRU of the two.",The two binary matrix of the size of the given ``L``.,Get a base twobins of the corresponding X.,32.43611906,32.94314288,32.68963097,,,,,,,,,
"summarize: def _is_typing_namedtuple(node: astroid.ClassDef) -> bool:
    """"""""""""
    for base in node.ancestors():
        if base.qname() == TYPING_NAMEDTUPLE:
            return True
    return False",Check if a class node is a typing.NamedTuple class,Check if the node is instance of the target level,Returns the namedtuple of nodes associated with a base.,37.65103333,27.68277449,32.66690391,,,,,,,,,
"summarize: def write_triggers(self, table):
        """"""
        """"""
        self.f.write('\n'.join(super(PostgresFileWriter, self).write_triggers(table)))",Write TRIGGERs existing on `table` to the output file,return table Write a table to the right of the table.,self.write('\n'.join(table)) Write a dictionary to the postgres file,33.73304143,31.48219867,32.60762005,,,,,,,,,
"summarize: def buildProtocol(self, addr):
        """"""
        
        """"""
        proto = self._factory.buildProtocol(addr)
        return JSONAMPDialectReceiver(proto)",Builds a bridge and associates it with an AMP protocol instance.,Build protocol with appropriate protocol.,Creates a Protocol instance from a pipeline.,30.68190147,34.40397921,32.54294034,,,,,,,,,
"summarize: def is_running(process):
    '''  '''
    try:
        pgrep = sh.Command('/usr/bin/pgrep')
        pgrep(process)
        flag = True
    except sh.ErrorReturnCode_1:
        flag = False
    return flag",`pgrep` returns an error code if no process was found,Asks the given process to a given process and returns True.,"Command('running', flag=flag) Return a process binary pgrep instance.",37.22161775,27.84899075,32.53530425,,,,,,,,,
"summarize: def print_plugins():
    """"""""""""

    pluginlist = list(streamlink.get_plugins().keys())
    pluginlist_formatted = "", "".join(sorted(pluginlist))

    if console.json:
        console.msg_json(pluginlist)
    else:
        console.msg(""Loaded plugins: {0}"", pluginlist_formatted)",Outputs a list of all plugins Streamlink has loaded.,Write a list of plugins to the files in the file.,pluginlist.append(pluginlist) return pluginlist Returns a list of plugins in the plugins.,39.69469039,25.33000255,32.51234647,,,,,,,,,
"summarize: def idxmax(self,skipna=True, axis=0):
        """"""
        
        """"""
        return H2OFrame._expr(expr=ExprNode(""which.max"", self, skipna, axis))",Get the index of the max value in a column or row,Calculate the number of which the axis of the axis.,Return an idxmax of the page of the samples,29.11419512,35.90282909,32.50851211,,,,,,,,,
"summarize: def read(self):
        """"""
        """"""
        try:
            data = load(open(self.file), Loader)
        except (UnicodeDecodeError, YAMLError) as e:
            raise InvalidConfig(self.file, '{}'.format(e))
        try:
            validate(data, SCHEMA)
        except ValidationError as e:
            raise InvalidConfig(self.file, e)
        self.update(data)",Parse and validate the config file. The read data is accessible as a dictionary in this instance,Reads a validation of the validation of the file and returns it as an image.,return validate(data) Reads the reading validation of a file.,37.19801332,27.81860156,32.50830744,,,,,,,,,
"summarize: def get_directory(self):
        """""" 
        """"""
        dirname = os.path.dirname(self.filename)
        if dirname:
            return Directory(dirname)
        else:
            return None",Returns the directory where the file is placed in or None if the    path to the file doesn't contain a directory,Returns the directory name for the filename to the filename.,Returns the directory of the index of the specified directory.,32.12149146,32.89342983,32.50746065,,,,,,,,,
"summarize: def dedup(stack: tuple) -> tuple:
    ''''''
    # Initializes with an accumulator and then reduces the stack with first match
    # deduplication.
    reducer = lambda x, y: x if y in x else x + (y,)
    return reduce(reducer, stack, tuple())",Remove duplicates from the stack in first-seen order.,Dedup a list of stacks and the deduplications.,Return an accumulator default reduced accumulator.,35.29568149,29.70308841,32.49938495,,,,,,,,,
"summarize: def get_matching_kwargs(func, kwargs):
    """"""""""""
    args, uses_startstar = _get_argspec(func)
    if uses_startstar:
        return kwargs.copy()
    else:
        matching_kwargs = dict((k, kwargs[k]) for k in args if k in kwargs)
        return matching_kwargs",Takes a function and keyword arguments and returns the ones that can be passed.,[k](uses_startstar) Returns a matching values of the given arguments.,[uses_startstar] Returns a Matching API. The function to get the Matching API.,32.54337333,32.34931961,32.44634647,,,,,,,,,
"summarize: def read_str(
    s: str,
    resolver: Resolver = None,
    data_readers: DataReaders = None,
    eof: Any = None,
    is_eof_error: bool = False,
) -> Iterable[ReaderForm]:
    """"""""""""
    with io.StringIO(s) as buf:
        yield from read(
            buf,
            resolver=resolver,
            data_readers=data_readers,
            eof=eof,
            is_eof_error=is_eof_error,
        )",Read the contents of a string as a Lisp expression.,Reads a string from a list of readers.,Reads an edged reading string reading one of the specified IO.,33.68322047,31.20876426,32.44599237,,,,,,,,,
"summarize: def _start_timer(self) -> None:
        """"""""""""
        self.timer = Timer(self.config['conversation_lifetime'], self.self_destruct_callback)
        self.timer.start()",Initiates self-destruct timer.,self.timer.end() Start timer timer,Generates a timer from the timer.,32.66518775,32.20173434,32.43346105,,,,,,,,,
"summarize: def _init_rate_limit(self):
        """"""""""""

        url = urijoin(self.base_url, 'projects', self.owner + '%2F' + self.repository)
        try:
            response = super().fetch(url)
            self.update_rate_limit(response)
        except requests.exceptions.HTTPError as error:
            if error.response.status_code == 401:
                raise error
            else:
                logger.warning(""Rate limit not initialized: %s"", error)",Initialize rate limit information,return response Initialize the rate limit,"raise error.response.rate_limit except Exception as error: logger.warning(""Unable to initialize limits."", error) return None return response If we can't load an api, the response.",52.39301396,12.47301912,32.43301654,,,,,,,,,
"summarize: def __get_pull_commits(self, pr_number):
        """"""""""""

        hashes = []
        group_pull_commits = self.client.pull_commits(pr_number)

        for raw_pull_commits in group_pull_commits:

            for commit in json.loads(raw_pull_commits):
                commit_hash = commit['sha']
                hashes.append(commit_hash)

        return hashes",Get pull request commit hashes,Returns a list of commits in the pull commits.,Return a list of pull pull commits.,28.6127406,36.19174049,32.40224055,,,,,,,,,
"summarize: def userToId(url):
        """"""
        
        """"""
        match = re.search(r""users(/ME/contacts)?/[0-9]+:([^/]+)"", url)
        return match.group(2) if match else None",Extract the username from a contact URL.,Get the user to use in the given url.,Returns an element of the username.,27.37958205,37.26228938,32.32093572,,,,,,,,,
"summarize: async def start_master(host="""", port=48484, *, loop=None):
    """"""
    
    """"""

    loop = loop if loop is not None else asyncio.get_event_loop()

    manager = jobs.JobManager(loop=loop)
    workers = set()
    server = await loop.create_server(
            lambda: WorkerProtocol(manager, workers), host, port)
    return Master(server, manager, workers, loop=loop)","Starts a new HighFive master at the given host and port, and returns it.",Starts a loop by the given port and returns an instance of the loop.,Return the servers between a server.,52.6534848,11.97491891,32.31420186,,,,,,,,,
"summarize: def create_ptr_record(self, name, values, ttl=60):
        """"""
        
        """"""

        self._halt_if_already_deleted()

        # Grab the params/kwargs here for brevity's sake.
        values = locals()
        del values['self']

        return self._add_record(PTRResourceRecordSet, **values)",Creates a PTR record attached to this hosted zone.,Adds a new ptr_record to a new ptr_record.,Creates a ptring record from a list of ptrings.,27.19978327,37.15720695,32.17849511,,,,,,,,,
"summarize: def _mul_right(mat, vec):
  """"""
  """"""
  return tf.squeeze(tf.matmul(mat, tf.expand_dims(vec, axis=-1)), axis=-1)",Computes the product of a matrix with a vector on the right.,Apply a multiplicity on the vector to the training point vector.,Multiply multiple vec of a single multiple right of the multiple levels.,36.48004437,27.87137725,32.17571081,,,,,,,,,
"summarize: def dismiss_confirm(self, text=None, wait=None):
        """"""
        
        """"""

        with self.driver.dismiss_modal(""confirm"", text=text, wait=wait):
            yield","Execute the wrapped code, dismissing a confirm.",self.confirm(text) Dismissions the confirm on a single text and return it.,self.driver.dismiss_confirm(text) Compute the dismiss any bug.,29.55141191,34.73633689,32.1438744,,,,,,,,,
"summarize: def _create_pipeline_command(self, args, workdir_path, config_path):
        """"""
        
        """"""
        return ([self._name, 'run', os.path.join(workdir_path, 'jobStore'),
                 '--config', config_path,
                 '--workDir', workdir_path, '--retryCount', '1']
                 + (['--restart'] if args.restart else []))",Creates and returns a list that represents a command for running the pipeline.,Create a new command with a context for a command with the jobStore,Creates a created page for the jobs to the specified job.,36.2174478,27.99027756,32.10386268,,,,,,,,,
"summarize: def IsEnabled(self, *args, **kwargs):
        """"
        for i in range(self.GetMenuCount()):
            if not self.IsEnabledTop(i):
                return False
        return True",check if all top menus are enabled,Enables a list of enabled tops,Returns the enabled type.,35.01232052,29.14046902,32.07639477,,,,,,,,,
"summarize: def apns_fetch_inactive_ids():
    """"""
    
    """"""
    with closing(_apns_create_socket_to_feedback()) as socket:
        inactive_ids = []

        for _, registration_id in _apns_receive_feedback(socket):
            inactive_ids.append(codecs.encode(registration_id, 'hex_codec'))

        return inactive_ids",Queries the APNS server for id's that are no longer active since  the last fetch,Returns a list of inactive_ids found inactive_ids that are fetched.,Returns the inactive fetching the registrations of the socket.,33.08375284,31.06257328,32.07316306,,,,,,,,,
"summarize: def assert_ordered(iterable, key=lambda x: x, comp=operator.le):
	""""""
	
	""""""
	err_tmpl = (
		""{pair[0]} > {pair[1]}"" if comp is operator.le else
		""{pair[0]} < {pair[1]}"" if comp is operator.ge else
		""not {comp} {pair}""
	)
	for pair in more_itertools.pairwise(iterable):
		keyed = tuple(map(key, pair))
		assert comp(*keyed), err_tmpl.format(**locals())
		yield pair[0]
	yield pair[1]","Assert that for all items in the iterable, they're in order based on comp",Yields an iterator of all iterator of iterators of a list of iterables.,return None Add a piece of the ordered iterable to the given ID,31.00386764,33.11447391,32.05917078,,,,,,,,,
"summarize: def run_in_separate_process(func, *args, **kwargs):
    """"""
    """"""
    manager = multiprocessing.Manager()
    manager_dict = manager.dict()
    process = ProcessWithException(
        manager_dict, target=func, args=args, kwargs=kwargs)
    process.start()
    process.join()
    exc = process.exception
    if exc:
        raise exc
    return process.output",Runs function in separate process.,"(*args, **kwargs) Serialize the process to a function.","(func, *args, **kwargs) run a processing of a function.",32.78567722,31.32297425,32.05432574,,,,,,,,,
"summarize: def mme_nodes(mme_base_url, token):
    """"""
    """"""
    nodes = []
    if not mme_base_url or not token:
        return nodes
    url = ''.join([mme_base_url, '/nodes'])
    nodes = matchmaker_request(url=url, token=token, method='GET')
    LOG.info('Matchmaker has the following connected nodes:{}'.format(nodes))
    return nodes",Return the available MatchMaker nodes,Match the given url and return it as a list of nodes,Returns a list of nodes into an MET.,33.56417151,30.53143602,32.04780377,,,,,,,,,
"summarize: def nintegral(wave, indep_min=None, indep_max=None):
    
    """"""
    ret = copy.copy(wave)
    _bound_waveform(ret, indep_min, indep_max)
    return np.trapz(ret._dep_vector, ret._indep_vector)","r""""""  Return the numerical integral of a waveform's dependent variable vector.",Compute the nintegral for the given indep_min or nointegral.,Return an integral integral of the periods of the temperature.,26.47565859,37.53880918,32.00723389,,,,,,,,,
"summarize: def time_callable(self, name, target, rate=None, args=(), kwargs={}):
        # type: (str, Callable, float, Tuple, Dict) -> Chronometer
        """"""""""""
        assert callable(target)
        if rate is None:
            rate = self._rate
        else:
            assert_sample_rate(rate)
        start_time = time()  # type: float
        result = target(*args, **kwargs)
        self.since(name, start_time, rate)
        return result",Send a Timer metric calculating duration of execution of the provided callable,"Returns the time-callable, as a dictionary with the `name` and returns the `None`.",Execute a callable of callable of the current time and time as a callable.,25.31396488,38.59188017,31.95292253,,,,,,,,,
"summarize: def rep1(parser: Union[Parser, Sequence[Input]]) -> RepeatedOnceParser:
    """"""
    """"""
    if isinstance(parser, str):
        parser = lit(parser)
    return RepeatedOnceParser(parser)",Match a parser one or more times repeatedly.,RepeatedOnceParser input and returns an arguments,Rep1.repeate(parser) Returns a parser,29.19844606,34.63238891,31.91541749,,,,,,,,,
"summarize: def verify_reg_list(self, obj, object_type):
        """"""""""""
        # We expect the object to be a bitlist or an idlist, we don't care.
        # We will iterate it and ensure everything in it is declared as a bit,
        # and throw if not.
        for children in obj.children:
            self.verify_reg(children, object_type)",Verify a list of registers.,Whether a list of children that are verify the registered versions.,return obj Convert a list of ids to a list of registered objects.,33.51331403,30.24672339,31.88001871,,,,,,,,,
"summarize: def unsubscribe_from_trades(self, pair, **kwargs):
        """"""
        """"""
        identifier = ('trades', pair)
        self._unsubscribe('trades', identifier, symbol=pair, **kwargs)",Unsubscribe to the passed pair's trades channel.,Update a trades to the trades to the trades,"self._unsubscribe('trades', identifier=self._unsubscribe) Unsubscribe to specific trades to the class.",34.83474784,28.87247958,31.85361371,,,,,,,,,
"summarize: def search_dict(data, key):
    """"""
    
    """"""
    if isinstance(data, dict):
        for dkey, value in data.items():
            if dkey == key:
                yield value
            for result in search_dict(value, key):
                yield result
    elif isinstance(data, list):
        for value in data:
            for result in search_dict(value, key):
                yield result","Search for a key in a nested dict, or list of nested dicts, and return the values.","else: for result in search_dict(value, key): yield result Retrieve a dictionary of dictionary from the dictionary of GRAME IDs.","else: for key, value in data.items(): yield value Returns a dict of the data type from a dictionary.",28.20594641,35.49697265,31.85145953,,,,,,,,,
"summarize: def assert_same_float_dtype(tensors=None, dtype=None):
  """"""
  """"""
  if tensors:
    dtype = _assert_same_base_type(tensors, dtype)
  if not dtype:
    dtype = tf.float32
  elif not is_floating(dtype):
    raise ValueError('Expected floating point type, got {}.'.format(dtype))
  return dtype",Validate and return float type based on `tensors` and `dtype`.,Format a single floating point type of the same type and dtype.,Returns a dtype if any points are one of any dtype and any type is any dtype.,35.61898058,28.00169474,31.81033766,,,,,,,,,
"summarize: def execute(self):
        """"""
        
        """"""
        rprocess = OrderedDict()
        commands = OrderedDict([
            (self.file, ['Rscript', self.file] + self.cmd),
        ])
        for cmd_name, cmd in commands.items():
            rprocess[cmd_name] = self.run_command_under_r_root(cmd)
        
        return self.decode_cmd_out(completed_cmd=rprocess[self.file])",Execute R script,Execute a new processor.,Execute the process distributed script.,32.16587711,31.44700896,31.80644304,,,,,,,,,
"summarize: def html_annotate_merge_annotations(tokens_old, tokens_new): 
    """"""
    """"""
    s = InsensitiveSequenceMatcher(a=tokens_old, b=tokens_new)
    commands = s.get_opcodes()

    for command, i1, i2, j1, j2 in commands:
        if command == 'equal': 
            eq_old = tokens_old[i1:i2]
            eq_new = tokens_new[j1:j2]
            copy_annotations(eq_old, eq_new)","Merge the annotations from tokens_old into tokens_new, when the  tokens in the new document already existed in the old document.","copy_annotations(eq_old, eq_old, eq_old) return copy_annotations(tokens_old, eq_old) Show the annotation of annotations for the given tokens","return json.dumps(eq_old, eq_new) else: return json.dumps(tokens_old) return json.dumps(tokens_old) Handle an an authorized tokens to the ``tokens_old`` access to the applications.",34.26730508,29.27010954,31.76870731,,,,,,,,,
"summarize: def instance_method(self, imeth: typing.Optional[typing.Callable[..., typing.Any]]) -> ""SeparateClassMethod"":
        """"""
        """"""
        self.__instance_method = imeth
        return self",Descriptor to change instance method.,Instance method to instance method to instance method.,.__class__.__name__ Returns a method that implements the image instance instance method.,39.21637282,24.27095994,31.74366638,,,,,,,,,
"summarize: def json_encoder(*args, **kwargs):
    """"""""""""

    obj = cherrypy.serving.request._json_inner_handler(*args, **kwargs)

    for chunk in JSONEncoder().iterencode(obj):
        yield chunk.encode('utf-8')",Custom JSON encoder handler,Retrieve the encoder messages from the JSONEncoder.,Returns an JSONEncoder object.,26.95888454,36.45473024,31.70680739,,,,,,,,,
"summarize: def _receive_data(self):
        """"""""""""
        while True:
            while len(self._buffer) < self.max_size and self.conn.poll():
                data = self._read_chunks()
                if data is not None:
                    self._buffer.append(data)
            if len(self._buffer) > 0:
                return self._buffer.popleft()",Gets data from pipe,Receive the data from the data,return None Receives data from the properties.,35.79692129,27.58594673,31.69143401,,,,,,,,,
"summarize: def absdir(path):
    """"""
    """"""
    if not os.path.isabs(path):
        path = os.path.normpath(os.path.abspath(os.path.join(os.getcwd(),
                                                             path)))
    if path is None or not os.path.isdir(path):
        return None
    return path","Return absolute, normalized path to directory, if it exists; None  otherwise.",Create a build directory of an Absdir and return the paths.,Return any directory paths in a path or absdir instance.,29.83911505,33.45552574,31.6473204,,,,,,,,,
"summarize: def end_group(self, dedent=0, close=''):
        """"""""""""
        self.indentation -= dedent
        group = self.group_stack.pop()
        if not group.breakables:
            self.group_queue.remove(group)
        if close:
            self.text(close)",End a group. See `begin_group` for more details.,self.group_stack.pop() self.chunk(close) End a group.,return self.end_group(group) Get group for a device stack.,31.94821888,31.32729283,31.63775586,,,,,,,,,
"summarize: def __float_window(window_spec):
    '''
    '''

    def _wrap(n, *args, **kwargs):
        '''The wrapped window'''
        n_min, n_max = int(np.floor(n)), int(np.ceil(n))

        window = get_window(window_spec, n_min)

        if len(window) < n_max:
            window = np.pad(window, [(0, n_max - len(window))],
                            mode='constant')

        window[n_min:] = 0.0

        return window

    return _wrap",Decorator function for windows with fractional input.,Perform the float_window function to a Window function.,per Return a float or float as window.,40.70172887,22.53978683,31.62075785,,,,,,,,,
"summarize: def zeros(shape, dtype=float64, order='C'):
        """"""
        
        """"""
        from numpy import zeros
        return ConstructLocal._wrap(zeros, shape, dtype, order)",Create a local bolt array of zeros.,Starts a copy of the numpy arrays.,Construct the numpy array of span,31.2631904,31.88543948,31.57431494,,,,,,,,,
"summarize: def nameAvailabilityCheck(obj, propName, prop):
    """"""
    
    """"""
    if getattr(obj, propName, None) is not None:
        raise IntfLvlConfErr(""%r already has property %s old:%s new:%s"" % 
                             (obj, propName, repr(getattr(obj, propName)), prop))",Check if not redefining property on obj,return obj Availability Checks the input property name.,return obj.name All names of a property on an Intf-level API.,33.92457607,29.17329528,31.54893568,,,,,,,,,
"summarize: def interrupt_kernel(self):
        """""" 
        """"""
        if self.has_kernel:
            if sys.platform == 'win32':
                from parentpoller import ParentPollerWindows as Poller
                Poller.send_interrupt(self.kernel.win32_interrupt_event)
            else:
                self.kernel.send_signal(signal.SIGINT)
        else:
            raise RuntimeError(""Cannot interrupt kernel. No kernel is running!"")","Interrupts the kernel. Unlike ``signal_kernel``, this operation is    well supported on all platforms.",return self.interrupt(self.kernel.win32_interrupt_event) Gets the interrupt kernel and signal interrupt,self.kernel.send_interrupt(self.kernel.has_kernel_timeout) Interrupt the Windows,34.22262826,28.68640184,31.45451505,,,,,,,,,
"summarize: def add_to_cat_group(self, cat, cat_group, def_name):
        """"""
        """"""
        self.cat_groups.setdefault(cat, {}).setdefault(cat_group, deque()).append(def_name)",Associate the provided rule definition name ``def_name`` with the    category group ``cat_group`` in the category ``cat``.,"self.cat_group.add_to_cat(cat) self.cat_group.add_to_cat_group(cat, def_name) Add a new Group to the given cat group.","return self.add_to_cat_group(cat, cat_group, deque()) Add a catgroup into any ``Cat`` to the given ``group``.",30.26787551,32.61736338,31.44261945,,,,,,,,,
"summarize: def calibrate_band_pass_N1(self):
        """""" 
        """"""

        band_pass = np.median(self.data.squeeze(),axis=0)
        self.data = self.data/band_pass","One way to calibrate the band pass is to take the median value      for every frequency fine channel, and divide by it.","return self.data Activate the band pass in the data, and return an index of the calibrate band pass.","self.plot(self.data,band_pass=band_pass) return self.data Get the planeve band. The planevered data is called as another width.",39.70241022,23.15343502,31.42792262,,,,,,,,,
"summarize: def newick(self):
        """"""""""""
        label = self.name or ''
        if self._length:
            label += ':' + self._length
        descendants = ','.join([n.newick for n in self.descendants])
        if descendants:
            descendants = '(' + descendants + ')'
        return descendants + label",The representation of the Node in Newick format.,Creates newick instance of the first period.,Gets the passed dictionary of the Listing labels.,35.62645447,27.12799722,31.37722585,,,,,,,,,
"summarize: def poke(self, context):
        """"""
        
        """"""
        self.log.info('Poking for %s', self.attachment_name)

        with ImapHook(imap_conn_id=self.conn_id) as imap_hook:
            return imap_hook.has_mail_attachment(
                name=self.attachment_name,
                mail_folder=self.mail_folder,
                check_regex=self.check_regex
            )",Pokes for a mail attachment on the mail server.,Poke a Imap hook for this on the given context.,Implements the poked hook for the Imap pool.,36.08427942,26.65409127,31.36918535,,,,,,,,,
"summarize: def get_stores(self):
        """"""""""""
        return [self.stats[cache_level]['STORE_count']/self.first_dim_factor
                for cache_level in range(len(self.machine['memory hierarchy']))]",Return a list with number of stored cache lines per memory hierarchy level.,Returns a list of stores to the given stores.,Return a list of store store_counts of the specified store.,27.23205575,35.32737232,31.27971404,,,,,,,,,
"summarize: def history(self, raw=True, output=False, hist_access_type='range', **kwargs):
        """"""
        """"""
        content = dict(raw=raw, output=output, hist_access_type=hist_access_type,
                                                                    **kwargs)
        msg = self.session.msg('history_request', content)
        self._queue_send(msg)
        return msg['header']['msg_id']",Get entries from the history list.,Make the history and add the recipients,History header and updates the specified raw requests.,38.8566201,23.58630808,31.22146409,,,,,,,,,
"summarize: def _save_image(self, name, format='PNG'):
        """""" 
        """"""
        dialog = QtGui.QFileDialog(self._control, 'Save Image')
        dialog.setAcceptMode(QtGui.QFileDialog.AcceptSave)
        dialog.setDefaultSuffix(format.lower())
        dialog.setNameFilter('%s file (*.%s)' % (format, format.lower()))
        if dialog.exec_():
            filename = dialog.selectedFiles()[0]
            image = self._get_image(name)
            image.save(filename, format)",Shows a save dialog for the ImageResource with 'name'.,return image dialog.save() Write image to the saved file.,return image Filter for a specified dialog,33.97260193,28.4642572,31.21842957,,,,,,,,,
"summarize: def _swap_on_miss(partition_result):
	""""""
	
	""""""
	before, item, after = partition_result
	return (before, item, after) if item else (after, item, before)","Given a partition_dict result, if the partition missed, swap	the before and after.","return (before, item, after) Internal swap on items, add items to the result.",Wrappers themissing one missing the position of the MISingle MISingleAll missing one.,36.93939928,25.48319314,31.21129621,,,,,,,,,
"summarize: def coin_toss(self):
        """"""
        """"""
        doc = self.get_doc()
        table = doc('table#game_info')
        giTable = sportsref.utils.parse_info_table(table)
        if 'Won Toss' in giTable:
            # TODO: finish coinToss function
            pass
        else:
            return None",Gets information relating to the opening coin toss.,Coin table to scalar to the Info on the given Work.,Return an SOUTHTTP recording to the given document.,32.32950817,30.05840819,31.19395818,,,,,,,,,
"summarize: def render(self, name, value, attrs=None, renderer=None):
        """"""
        
        """"""
        if self.has_template_widget_rendering:
            return super(ClearableFileInputWithImagePreview, self).render(
                name, value, attrs=attrs, renderer=renderer
            )
        else:
            context = self.get_context(name, value, attrs)
            return render_to_string(self.template_name, context)",Render the widget as an HTML string.,Renders the input widgets to the Given ``name``.,Render the rendering rendering rendering rendering.,33.59823616,28.63424631,31.11624124,,,,,,,,,
"summarize: def turn_on_with_brightness(self, device_id, name, brightness):
        """"""""""""
        brightness_value = round((brightness * 31) / 255) + 1
        # F1 = Light on and F0 = light off. FdP[0..32] is brightness. 32 is
        # full. We want that when turning the light on.
        msg = ""!%sFdP%d|Lights %d|%s"" % (
            device_id, brightness_value, brightness_value, name)
        self._send_message(msg)",Scale brightness from 0..255 to 1..32.,Multiply a brightness to the routine.,return brightness Get the device on the device identifier.,39.76553053,22.42274326,31.0941369,,,,,,,,,
"summarize: def vector(members: Iterable[T], meta: Optional[IPersistentMap] = None) -> Vector[T]:
    """"""""""""
    return Vector(pvector(members), meta=meta)",Creates a new vector.,Vector to vector.,Meta a vector for the given vector.,36.22147642,25.91749628,31.06948635,,,,,,,,,
"summarize: def url_stats(self, short):
        """"""
        """"""
        data = dict(action='url-stats', shorturl=short)
        jsondata = self._api_request(params=data)

        return _json_to_shortened_url(jsondata['link'])",Get stats for short URL or keyword.,Gets a url stats for a given action,Retrieves the URL stats.,36.00565854,26.02295926,31.0143089,,,,,,,,,
"summarize: def _send_coroutine():
    """"""
    
    """"""
    with PoolExecutor() as executor:
        while True:
            msg = yield
            future = executor.submit(msg.send)
            future.add_done_callback(_exception_handler)",Creates a running coroutine to receive message instances and send  them in a futures executor.,while True: executor.add_done_callback(_exception_handler) Sends a coroutine to the Future,"if msg.port_number == 0: while future.is_print_exception(): yield future If the coroutine is available, returns an error if it is available.",38.91976524,23.03943302,30.97959913,,,,,,,,,
"summarize: def u(text, encoding='utf-8'):
    """"

    if isinstance(text, six.binary_type):
        text = text.decode(encoding)

    # it's already unicode
    text = text.replace('\r\n', '\n')
    return text","Return unicode text, no matter what",".replace('\n', '\n') Given a text, return it Unicodes it to utf-8",Return a string based on unicode type and possible text,25.8486577,36.01426612,30.93146191,,,,,,,,,
"summarize: def _to_java_object_rdd(rdd):
    """""" 
    """"""
    rdd = rdd._reserialize(AutoBatchedSerializer(PickleSerializer()))
    return \
        rdd.ctx._jvm.org.apache.spark.bigdl.api.python.BigDLSerDe.pythonToJava(
            rdd._jrdd, True)",Return a JavaRDD of Object by unpickling,Get the rdd of an Java object.,return rdd Java Java object to java object.,27.40788822,34.39920031,30.90354427,,,,,,,,,
"summarize: def _quoteattr(self, attr):
        """"""""""""
        attr = xml_safe(attr)
        if isinstance(attr, unicode) and not UNICODE_STRINGS:
            attr = attr.encode(self.encoding)
        return saxutils.quoteattr(attr)",Escape an XML attribute. Value can be unicode.,Unicodes a quoteattr attribute on `attr`.,Update the specified method in the page.,34.65862228,27.12849992,30.8935611,,,,,,,,,
"summarize: def mirror(self):
        """"""
        """"""
        if not self._definition:
            return self.copy()

        reverse_inst = self.copy(name=self.name + '_mirror')
        reverse_inst.definition = []
        for inst, qargs, cargs in reversed(self._definition):
            reverse_inst._definition.append((inst.mirror(), qargs, cargs))
        return reverse_inst","For a composite instruction, reverse the order of sub-gates.",Returns the additional reverse institutions.,Return the reverse_inst empty list of reverse_inst.,32.31043214,29.43040596,30.87041905,,,,,,,,,
"summarize: def assert_matches(v, regex):
    """"""
    
    """"""
    m = re.match(regex, v)
    if m is None:
        vn = _retrieve_assert_arguments()[0]
        message = ""Argument `{var}` (= {val!r}) did not match /{regex}/"".format(var=vn, regex=regex, val=v)
        raise H2OValueError(message, var_name=vn, skip_frames=1)
    return m",Assert that string variable matches the provided regular expression.,Create an assert-matches for the matches for the given regex.,.group(1) Returns a single tuple of the matches of an augments.,34.50354218,27.20960738,30.85657478,,,,,,,,,
"summarize: def save_error(self, data, exception_info):
        """"""
         
        """"""
        # TODO: what to do with errors? Let it flow? Write to a log file?
        self.errors.append({'data': data,
                            'exception': ''.join(format_exception(*exception_info)),
                            })",Saves an error in the error list.,Save error from data to the data,"# Save the data, create an error self.error_info = log_info Instant data and return an exception.",40.80176155,20.89128663,30.84652409,,,,,,,,,
"summarize: def get_config():
        """"""""""""
        self = H2OConfigReader._get_instance()
        if not self._config_loaded:
            self._read_config()
        return self._config",Retrieve the config as a dictionary of key-value pairs.,_loaded Reads the Loader instance from the configuration.,"_loaded.get(""config"") Returns a MID of the configuration object.",29.89642953,31.74594964,30.82118959,,,,,,,,,
"summarize: def get_group_by_id(self, group_id):
        """"""
        
        """"""
        self._valid_group_id(group_id)

        url = ""{}/group/{}"".format(self.API, group_id)

        data = self._get_resource(url)

        return self._group_from_json(data.get(""data""))",Returns a restclients.Group object for the group identified by the    passed group ID.,Returns a list of group ids to the group id.,Retrieves a group id from a group. Use a `GroupId` to the group.,28.15638479,33.3824821,30.76943345,,,,,,,,,
"summarize: def is_namedtuple_like(x):
  """"""""""""
  try:
    for fn in x._fields:
      _ = getattr(x, fn)
    return True
  except AttributeError:
    return False",Helper which returns `True` if input is `collections.namedtuple`-like.,Returns True if the namedtuple does not exist.,return False Checks if any like is not None and ``namedtuple_like`` is an IDtuple.,28.98357192,32.43526495,30.70941844,,,,,,,,,
"summarize: def builtin_timescale(cls, name):
        """"""
        
        """"""
        names = {
                 'isc': TIMESCALE__ISC,
                 'usgs_isc': TIMESCALE__USGS_ISC,
                 'dnag': TIMESCALE__DNAG,
                 }
        return cls.from_csv(text=names[name.lower()])",Generate a default timescale legend. No arguments.,Get a dictionary of timescale for a train timescale.,Return a cls builtin timescale from the ISCALED.,32.5860581,28.82380237,30.70493024,,,,,,,,,
"summarize: def get_data(self, data_split=""train""):
        """"""
        
        """"""
        if data_split == 'train':
            return self._current_train_set
        elif data_split == 'valid':
            return self._current_valid_set
        elif data_split == 'test':
            return self._current_test_set
        else:
            return None",Get specified split of data.,Get data for a given data.,Get the data of the dataset.,29.00835202,32.25663946,30.63249574,,,,,,,,,
"summarize: def _calc_selection_size(self):
        """"""
        """"""

        #Check to see how many integrations requested
        n_ints = self.t_stop - self.t_start
        #Check to see how many frequency channels requested
        n_chan = (self.f_stop - self.f_start) / abs(self.header[b'foff'])

        n_bytes  = self._n_bytes
        selection_size = int(n_ints*n_chan*n_bytes)

        return selection_size",Calculate size of data of interest.,", selection_size Calculate the selection size of the selections",Calculates a single ``N_chan``.,29.10209355,32.10347725,30.6027854,,,,,,,,,
"summarize: def display(self):
        """"""
        
        """"""
        if isinstance(self.name, six.string_types) and len(self.name) > 0:
            return '{0} ({1})'.format(self.name, self.public_ip)
        else:
            return self.public_ip",Returns the best name to display for this host. Uses the instance    name if available; else just the public IP.,"return 'display_ip {0} does not exist.'.format(self.name, self.private_ip) Doesn't make sure that the domain is any ready.","Returns a display string based on this IPv4 IPv6 for the name. If there is not present, the other URL is not allowed, just return the display only.",24.54409406,36.64216847,30.59313127,,,,,,,,,
"summarize: def get_headers(self):
        """"""
        """"""
        headers = copy.copy(self.default_headers or {})
        headers.update(self.data.get('headers') or {})
        return headers",Get HTTP Headers to send. By default default_headers,Returns the headers to the headers.,Get headers for the headers and authories.,29.74394468,31.4411333,30.59253899,,,,,,,,,
"summarize: def __get_merge_notes(self, merge_id):
        """"""""""""

        notes = []

        group_notes = self.client.notes(GitLabClient.MERGES, merge_id)

        for raw_notes in group_notes:
            for note in json.loads(raw_notes):
                note_id = note['id']
                note['award_emoji_data'] = \
                    self.__get_note_award_emoji(GitLabClient.MERGES, merge_id, note_id)
                notes.append(note)

        return notes",Get merge notes,Returns a list of notes for the given merge_id.,Get merge_notes in merge_ids.,21.25435531,39.86734714,30.56085123,,,,,,,,,
"summarize: def read(self, fp, **kwargs):
        """"""""""""
        nbs = fp.read()
        if not py3compat.PY3 and not isinstance(nbs, unicode):
            nbs = py3compat.str_to_unicode(nbs)
        return self.reads(nbs, **kwargs)",Read a notebook from a file like object,Get the correctly read of the py3 file,Reads an object from any project.,22.88656796,38.18313535,30.53485166,,,,,,,,,
"summarize: def binding_energy(self):
        """"""
        
        """"""
        M_P = 938.2723
        # MeV
        M_E = 0.5110
        # MeV
        M_N = 939.5656
        # MeV
        AMU = 931.494028
        # MeV
        df = self.Z * (M_P + M_E) + (self.A - self.Z) * M_N - (self.df + self.A * AMU)
        return Table(df=df, name='BE' + '(' + self.name + ')')",Return binding energies instead of mass excesses,Bind energy binding energy energy between two AMUs,Returns an empty directioning annotation of the current binding to the Mevenergy.,34.51149709,26.49610881,30.50380295,,,,,,,,,
"summarize: def delete_channel(self, channel_name, project_name, dataset_name):
        """"""
        
        """"""
        return self.resources.delete_channel(channel_name, project_name,
                                             dataset_name)","Deletes a channel given its name, name of its project    , and name of its dataset.",Delete a channel with dataset named project name,Returns the delete channel from the project.,39.08942111,21.89658142,30.49300127,,,,,,,,,
"summarize: def _read_response(self,response, field=""detail""):
        ''''''

        try:
            message = json.loads(response._content.decode('utf-8'))[field]
        except:
            message = response.reason
        return message","attempt to read the detail provided by the response. If none,     default to using the reason",Read the json from the json file and return the appropriately response.,Return a message by in the response. The client is valid information.,34.25384281,26.60376689,30.42880485,,,,,,,,,
"summarize: def relative_dir_walk(self, dir):
    '''
    '''
    result = []

    if S3URL.is_valid(dir):
      basepath = S3URL(dir).path
      for f in (f for f in self.s3walk(dir) if not f['is_dir']):
        result.append(os.path.relpath(S3URL(f['name']).path, basepath))
    else:
      for f in (f for f in self.local_walk(dir) if not os.path.isdir(f)):
        result.append(os.path.relpath(f, dir))

    return result",Generic version of directory walk. Return file list without base path    for comparison.,Relative a file where the dir is the local dir and return its walk of a directory.,"Relatives a directory, returning a directory of the results.",36.98843728,23.78628313,30.38736021,,,,,,,,,
"summarize: def execute(self, operation, parameters=None):
        """"""
        
        """"""
        sql = _bind_parameters(operation,
                               parameters) if parameters else operation
        self.job_id = self.run_query(sql)","Executes a BigQuery query, and returns the job ID.",return self.run_query(sql) Execute the execute job query parameters,"return sql.execute(sql, sql) Execute the execution of the execution operation.",39.52315851,21.24706872,30.38511362,,,,,,,,,
"summarize: def get(query, from_date, **kwargs):
    """"""""""""
    recids, search_pattern = get_modified_recids(from_date)
    recids = recids.union(get_modified_bibdoc_recids(from_date))

    if query:
        recids = recids.intersection(
            set(search_pattern(p=query.encode('utf-8'))))

    return len(recids), recids",Get recids matching query and with changes.,Retrieve the recids of the given query.,", recids Return a query set of the datetime values associated with a query.",32.32383448,28.44391808,30.38387628,,,,,,,,,
"summarize: def is_embargoed(record):
    """"""""""""
    return record.get('access_right') == 'embargoed' and \
        record.get('embargo_date') and \
        record.get('embargo_date') > datetime.utcnow().date()",Template filter to check if a record is embargoed.,== 'embargo_date': return False Determine if the access is additional embargoed.,Returns True if embargo_date is embed.,26.75152002,33.87086129,30.31119066,,,,,,,,,
"summarize: def _run_train(self, epoch, train_set, train_size=None):
        """"""
        
        """"""
        self.network.train_logger.record_epoch(epoch + 1)
        costs = self.train_step(train_set, train_size)
        if not epoch % self.config.monitor_frequency:
            self.report(dict(costs), ""train"", epoch)
        self.last_run_costs = costs
        return costs",Run one training iteration.,Get the train_specified epoch.,Return a new training training configuration.,23.24422363,37.33768115,30.29095239,,,,,,,,,
"summarize: def add_list(self, query_params=None):
        '''
        
        '''
        list_json = self.fetch_json(
            uri_path=self.base_uri + '/lists',
            http_method='POST',
            query_params=query_params or {}
        )

        return self.create_list(list_json)",Create a list for a board. Returns a new List object.,Add a list of lists to the list of lists and return it.,Adds a list of query_params and adds a list of lists.,31.85082412,28.72867158,30.28974785,,,,,,,,,
"summarize: def _has_homonym_in_upper_function_scope(self, node, index):
        """"""
        
        """"""
        for _consumer in self._to_consume[index - 1 :: -1]:
            if _consumer.scope_type == ""function"" and node.name in _consumer.to_consume:
                return True
        return False",Return True if there is a node with the same name in the to_consume dict of an upper scope    and if that scope is a function,Factory for a function of nodes that are index and it is assumed to update it.,This is used to handle sure that consumer matches the given node in the ``models.Homonym``.,30.0509459,30.46902219,30.25998405,,,,,,,,,
"summarize: def handle_telegram(self, telegram):
        """"""""""""
        self.log.debug('got telegram: %s', telegram)

        try:
            parsed_telegram = self.telegram_parser.parse(telegram)
        except InvalidChecksumError as e:
            self.log.warning(str(e))
        except ParseError:
            self.log.exception(""failed to parse telegram"")
        else:
            self.telegram_callback(parsed_telegram)",Send off parsed telegram to handling callback.,return self.telegram_callback(telegram) Register telegragram to telegram,"Handles Failure telegram, telegram telegram.",29.15916351,31.26186679,30.21051515,,,,,,,,,
"summarize: def render_prev_next_links(self, scheme=None):
        """"""""""""
        output = ''

        if self.has_prev:
            output += '<link rel=""prev"" href=""{}"" />\n'.format(self.get_full_page_url(self.prev, scheme=scheme))
        
        if self.has_next:
            output += '<link rel=""next"" href=""{}"" />\n'.format(self.get_full_page_url(self.next, scheme=scheme))

        return Markup(output)",Render the rel=prev and rel=next links to a Markup object for injection into a template,Render prev information for next links for an index.,"Render the prev links of the prev, and the current links.",31.00393239,29.41482145,30.20937692,,,,,,,,,
"summarize: def load_config(self, argv=None, aliases=None, flags=None):
        """"""""""""
        self.clear()
        if argv is None:
            argv = self.argv
        if aliases is None:
            aliases = self.aliases
        if flags is None:
            flags = self.flags
        self._create_parser(aliases, flags)
        self._parse_args(argv)
        self._convert_to_config()
        return self.config",Parse command line arguments and return as a Config object.,Load configuration files from `argv` and return the flags on `argv`.,ure_parser(self._config) Gets an argv from the aliases.,32.34163597,28.00967808,30.17565703,,,,,,,,,
"summarize: def nmin(wave, indep_min=None, indep_max=None):
    
    """"""
    ret = copy.copy(wave)
    _bound_waveform(ret, indep_min, indep_max)
    return np.min(ret._dep_vector)","r""""""  Return the minimum of a waveform's dependent variable vector.","* _bound_waveform(ret, indep_min) Calculate a nmax for the independent point.",Metric an image to the indepth of the indepth of the minimum in the empty indepth.,33.2087629,27.07576814,30.14226552,,,,,,,,,
"summarize: def find(ns_qualified_sym: sym.Symbol) -> ""Optional[Var]"":
        """"""""""""
        ns = Maybe(ns_qualified_sym.ns).or_else_raise(
            lambda: ValueError(
                f""Namespace must be specified in Symbol {ns_qualified_sym}""
            )
        )
        ns_sym = sym.symbol(ns)
        name_sym = sym.symbol(ns_qualified_sym.name)
        return Var.find_in_ns(ns_sym, name_sym)",Return the value currently bound to the name in the namespace specified    by `ns_qualified_sym`.,Returns the first view name for the view name for the given name for the given namespace.,"Create an any Maybe, in any qualified sym. If there is only one, only only one after any sym, there is otherwise, or otherwise assumes in the qualified sym.",37.99413018,22.09895678,30.04654348,,,,,,,,,
"summarize: def unparse(self):
        """"""""""""
        ut = Untokenizer(start_row=self._tokens[0].start_row)
        self._unparse(ut)
        return ut.result()",Convert the parsed representation back into the source code.,Returns the user-to-value pairs of the specified ut.,Return a unparse Untokenizer representing the Untokenizer.,24.97024137,35.0981349,30.03418814,,,,,,,,,
"summarize: def _rotate(self, samples):
    """"""""""""
    event_dim = (
        tf.compat.dimension_value(self.event_shape[0]) or
        self._event_shape_tensor()[0])
    basis = tf.concat([[1.], tf.zeros([event_dim - 1], dtype=self.dtype)],
                      axis=0),
    u = tf.nn.l2_normalize(basis - self.mean_direction, axis=-1)
    return samples - 2 * tf.reduce_sum(
        input_tensor=samples * u, axis=-1, keepdims=True) * u",Applies a Householder rotation to `samples`.,Calculate the rotation of the samples of the samples.,Returns the rotation of the event.,34.74407414,25.29811632,30.02109523,,,,,,,,,
"summarize: def has_context_loop(state, incorrect_msg, exact_names):
    """"""
    """"""
    return _test(
        state,
        incorrect_msg or MSG_INCORRECT_LOOP,
        exact_names,
        tv_name=""_target_vars"",
        highlight_name=""target"",
    )","When dispatched on loops, has_context the target vars are the attribute _target_vars.",Returns the loop that was loop that was loop than the targets of the given state.,Get the state of the loop. The incorrect_msg is exactly set to the other vars.,30.55994439,29.44831315,30.00412877,,,,,,,,,
"summarize: def ones(shape, context=None, axis=(0,), dtype=float64, npartitions=None):
        """"""
        
        """"""
        from numpy import ones
        return ConstructSpark._wrap(ones, shape, context, axis, dtype, npartitions)",Create a spark bolt array of ones.,Wraps a list of ones.,Generate a context of the ones of a ones.,27.90974914,32.08584283,29.99779599,,,,,,,,,
"summarize: def sv_variant(institute_id, case_name, variant_id):
    """"""""""""
    data = controllers.sv_variant(store, institute_id, case_name, variant_id)
    return data",Display a specific structural variant.,Svs the variant identifier to the specified variant.,Annotation of variant. This is not specified by sv variant,30.72648378,29.26093798,29.99371088,,,,,,,,,
"summarize: def pearson(logu, name=None):
  """"""
  """"""

  with tf.compat.v1.name_scope(name, ""pearson"", [logu]):
    logu = tf.convert_to_tensor(value=logu, name=""logu"")
    return tf.square(tf.math.expm1(logu))",The Pearson Csiszar-function in log-space.,Pearson action to a model on a given name.,Return an empty pearson for a given logging.,33.13956597,26.75879488,29.94918043,,,,,,,,,
"summarize: def list_resource_extension_versions(self, publisher_name, extension_name):
        '''
        
        '''
        return self._perform_get(self._get_resource_extension_versions_path(
                                    publisher_name, extension_name),
                                 ResourceExtensions)",Lists the versions of a resource extension that are available to add    to a Virtual Machine.,Lists a list of the packages that contain the version of the version of the given public keys in the given public keys.,Return a list of publisher versions into the version of the ID.,30.64909356,29.23371594,29.94140475,,,,,,,,,
"summarize: def eval_stream(stream, ctx: compiler.CompilerContext, module: types.ModuleType):
    """"""""""""
    last = None
    for form in reader.read(stream, resolver=runtime.resolve_alias):
        last = compiler.compile_and_exec_form(form, ctx, module)
    return last",Evaluate the forms in stdin into a Python module AST node.,Evaluates the execution context to a pull of a stream.,This method gets all streaming evaluated on the reader for a given stream.,32.48355271,27.39429988,29.9389263,,,,,,,,,
"summarize: def cmp_to_key(mycmp):
    ''
    class Key(object):
        def __init__(self, obj):
            self.obj = obj
        def __lt__(self, other):
            return mycmp(self.obj, other.obj) < 0
        def __gt__(self, other):
            return mycmp(self.obj, other.obj) > 0
        def __eq__(self, other):
            return mycmp(self.obj, other.obj) == 0
    return Key",Convert a cmp= function into a key= function,Convert key into an equivalent to a specified key.,"Cell(self.obj, other) Calculates the given object.",36.62789958,23.22680894,29.92735426,,,,,,,,,
"summarize: def hours_minutes_seconds(value):
    """"""
    """"""
    try:
        return int(value)
    except ValueError:
        pass

    match = (_hours_minutes_seconds_re.match(value)
             or _hours_minutes_seconds_2_re.match(value))
    if not match:
        raise ValueError

    s = 0
    s += int(match.group(""hours"") or ""0"") * 60 * 60
    s += int(match.group(""minutes"") or ""0"") * 60
    s += int(match.group(""seconds"") or ""0"")

    return s",converts a timestamp to seconds,", match Gets an according to a MAN 4N seconds.",Return a dictionary of a seconds.,29.30269933,30.47432788,29.88851361,,,,,,,,,
"summarize: def save_model_details(self, path="""", force=False):
        """"""
        
        """"""
        assert_is_type(path, str)
        assert_is_type(force, bool)
        path = os.path.join(os.getcwd() if path == """" else path, self.model_id + "".json"")
        return h2o.api(""GET /99/Models/%s/json"" % self.model_id, data={""dir"": path, ""force"": force})[""dir""]",Save Model Details of an H2O Model in JSON Format to disk.,Saves the model details for the given directory.,Returns a Model details of a Model.,27.12987251,32.57458261,29.85222756,,,,,,,,,
"summarize: def input(self, string):
        """"""""""""
        content = dict(value=string)
        msg = self.session.msg('input_reply', content)
        self._queue_send(msg)",Send a string of raw input to the kernel.,return msg Perform the input to a single input to the queue.,return msg Inputs a string.,32.83764831,26.76479844,29.80122338,,,,,,,,,
"summarize: def _find_jar(self, path0=None):
        """"""
        
        """"""
        jar_paths = [path0] if path0 else self._jar_paths()
        searched_paths = []
        for jp in jar_paths:
            searched_paths.append(jp)
            if os.path.exists(jp):
                return jp
        raise H2OStartupError(""Cannot start local server: h2o.jar not found. Paths searched:\n"" +
                              """".join(""    %s\n"" % s for s in searched_paths))",Return the location of an h2o.jar executable.,return [] Returns a list of jar paths in the given paths.,return None Find all paths in the jar_paths.,30.63840731,28.96361589,29.8010116,,,,,,,,,
"summarize: def _supports(self, item):
        """"""""""""
        result = super(SharedResult, self)._supports(item)
        result = result or type(item) in SharedResult.SUPPORTED_DATA
        return result",Checks if outer data structure is supported.,Gets the supports for the given item.,Returns a dictionary of the supported item.,24.71246225,34.79167326,29.75206776,,,,,,,,,
"summarize: def clip_by_value_preserve_gradient(t, clip_value_min, clip_value_max,
                                    name=None):
  """"""
  """"""
  with tf.compat.v1.name_scope(name, 'clip_by_value_preserve_gradient',
                               [t, clip_value_min, clip_value_max]):
    t = tf.convert_to_tensor(value=t, name='t')
    clip_t = tf.clip_by_value(t, clip_value_min, clip_value_max)
    return t + tf.stop_gradient(clip_t - t)",Clips values to a specified min and max while leaving gradient unaltered.,Clip the tensor and values to a single tensor,Return a JGB Generator that creates a base value for a given training specified value.,28.4830373,31.01402859,29.74853295,,,,,,,,,
"summarize: def post(self, request, *args, **kwargs):
        """"""""""""
        serializer = self.serializer_class(data=request.data)

        if not serializer.is_valid():
            return response.Response(
                serializer.errors,
                status=status.HTTP_400_BAD_REQUEST,
            )

        serializer.user.send_validation_email()
        msg = _('Email confirmation sent.')
        return response.Response(msg, status=status.HTTP_204_NO_CONTENT)",Validate `email` and send a request to confirm it.,Perform a serializer to validate a serializer.,Fetch an email address from the data from the request.,28.79919421,30.57121377,29.68520399,,,,,,,,,
"summarize: def max_readed_position(self) -> Position:
        """"""""""""
        return Position(self._maxindex, self._maxline, self._maxcol)",The index of the deepest character readed.,Returns the number of readed position.,Returns the maximum readed position of the given position.,32.78553402,26.50060481,29.64306942,,,,,,,,,
"summarize: def serialize(self, buf, byteorder='@'):
        '''
        
        '''
        if len(buf) < self.bytesize():
            raise ValueError(""The buffer does not have enough space\
                    for holding this MinHash."")
        fmt = ""%sqi%dI"" % (byteorder, len(self))
        struct.pack_into(fmt, buf, 0,
                self.seed, len(self), *self.hashvalues)",Serialize this lean MinHash and store the result in an allocated buffer.,"fmt.serialize(buf, buf, 0, buf, 0) Serialize the HTML bytes to the buffer","return buf.Search(buf, buf, buf) Computes the specified buffer of the buffer.",34.36936014,24.86743972,29.61839993,,,,,,,,,
"summarize: def keyword(self, **kwargs):
        """"""
        
        """"""
        path = self._get_path('keyword')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response",Search for keywords by name.,Add keyword data to the server.,Response Extracts a keyword.,27.64393753,31.43775473,29.54084613,,,,,,,,,
"summarize: def parse_issues(raw_json):
        """"""
        """"""
        results = json.loads(raw_json)

        issues = results['issues']
        for issue in issues:
            yield issue",Parse a Redmine issues JSON stream.,return results Parse ISSL address ISSL issues to JSON,s[issue] Returns a list of issues.,31.34718994,27.7198573,29.53352362,,,,,,,,,
"summarize: def projector(state, flatten=False):
    """"""
    
    """"""
    density_matrix = np.outer(state.conjugate(), state)
    if flatten:
        return density_matrix.flatten(order='F')
    return density_matrix",maps a pure state to a state matrix,Projector to the state of the fact,.flatten(flatten=flatten) Returns the state of the matrix.,30.67706489,28.38702105,29.53204297,,,,,,,,,
"summarize: def even_odd(self):
        """"""
        
        """"""
        return self.select(lambda Z, N: not(Z % 2) and (N % 2), name=self.name)",Selects even-odd nuclei from the table,Get even Datasets from zipfile,Returns the even_odd tuple of the Zero,27.8153406,31.20601795,29.51067928,,,,,,,,,
"summarize: def combine(self):
        """"""

        """"""
        aliases = None
        if self.config.paths:
            aliases = PathAliases(self.file_locator)
            for paths in self.config.paths.values():
                result = paths[0]
                for pattern in paths[1:]:
                    aliases.add(pattern, result)
        self.data.combine_parallel_data(aliases=aliases)",Combine together a number of similarly-named coverage data files.,Aliases the combine the files and return a new aliases that are not considered.,return self.data Returns a combined file of the given configuration.,26.59169628,32.35795777,29.47482703,,,,,,,,,
"summarize: def _sendData(self, data):
        """"""

        """"""
        d = self._callRemote(Transmit, connection=self.connection, data=data)
        d.addErrback(log.err)",Actually sends data over the wire.,Sends the data and returns a data structure.,return d.sendData(d) Send the data from a data.,33.14306854,25.77716972,29.46011913,,,,,,,,,
"summarize: def _sort_tensor(tensor):
  """"""""""""
  sorted_, _ = tf.nn.top_k(tensor, k=tf.shape(input=tensor)[-1])
  sorted_.set_shape(tensor.shape)
  return sorted_",Use `top_k` to sort a `Tensor` along the last dimension.,", sorted_, sorted_ Simple method to sort on the given tensor.",Generate a `Tensor` into a basic layer.,31.11483505,27.75287011,29.43385258,,,,,,,,,
"summarize: def _get_environment(self):
        """"""
        
        """"""
        if 'TSP_EMAIL' in os.environ:
            self._email = os.environ['TSP_EMAIL']
        if 'TSP_API_TOKEN' in os.environ:
            self._api_token = os.environ['TSP_API_TOKEN']
        if 'TSP_API_HOST' in os.environ:
            self._api_host = os.environ['TSP_API_HOST']
        else:
            self._api_host = 'api.truesight.bmc.com'",Gets the configuration stored in environment variables,return self._email Returns the environment for the given environment.,self._api_host = os.environ['TSP_API_HOST'] return self._api_host Returns the environment variables of an OSI grouping the URL.,33.70452294,25.08266838,29.39359566,,,,,,,,,
"summarize: def defined_items(self):
        """"""""""""
        return self.__class__(
            [(k, v) for k, v in self.items() if v is not self.EMPTY], is_empty=False
        )","Return copy of instance, omitting entries that are EMPTY","Find the items of the service, instances of a list of items.",Returns a list of its possible instances in the given item in the ``ASCRIPTY_NAMES``.,31.54736317,27.19326669,29.37031493,,,,,,,,,
"summarize: def with_context(exc, context):
    # type: (Exception, dict) -> Exception
    """"""
    
    """"""
    if not hasattr(exc, 'context'):
        exc.context = {}

    exc.context.update(context)
    return exc",Attaches a ``context`` value to an Exception.,Add an error context to a new context.,Create a context object to a context.,30.84284377,27.86098436,29.35191407,,,,,,,,,
"summarize: def warn_on_shadowed_var(self) -> bool:
        """"""""""""
        return self.warn_on_shadowed_name or self._opts.entry(
            WARN_ON_SHADOWED_VAR, False
        )","If True, warn when a def'ed Var name is shadowed in an inner scope.",Returns a WARN shadowed variable on the given name.,Warning and warning. This will when the old application on shadowed variable.,26.86097694,31.81912665,29.3400518,,,,,,,,,
"summarize: def _running_area(indep_vector, dep_vector):
    """"""""""""
    rect_height = np.minimum(dep_vector[:-1], dep_vector[1:])
    rect_base = np.diff(indep_vector)
    rect_area = np.multiply(rect_height, rect_base)
    triang_height = np.abs(np.diff(dep_vector))
    triang_area = 0.5 * np.multiply(triang_height, rect_base)
    return np.cumsum(np.concatenate((np.array([0.0]), triang_area + rect_area)))",Calculate running area under curve.,Calculates the area of the area of the indep_vector.,Return an area bounding the area,29.97989484,28.59874548,29.28932016,,,,,,,,,
"summarize: def erfinv(x, name=""erfinv""):
  """"""
  """"""

  with tf.name_scope(name):
    x = tf.convert_to_tensor(value=x, name=""x"")
    if dtype_util.as_numpy_dtype(x.dtype) not in [np.float32, np.float64]:
      raise TypeError(""x.dtype={} is not handled, see docstring for supported ""
                      ""types."".format(dtype_util.name(x.dtype)))
    return ndtri((x + 1.) / 2.) / np.sqrt(2.)","The inverse function for erf, the error function.",/ 2.0 return the erfinv finv finv finv finv finv function,Function to find a XML on the XML node.,32.65501272,25.87980428,29.2674085,,,,,,,,,
"summarize: def sequence_logLH(self,seq, pattern_multiplicity=None):
        """"""
        

        """"""
        if pattern_multiplicity is None:
            pattern_multiplicity = np.ones_like(seq, dtype=float)
        return np.sum([np.sum((seq==state)*pattern_multiplicity*np.log(self.Pi[si]))
                      for si,state in enumerate(self.alphabet)])",Returns the log-likelihood of sampling a sequence from equilibrium frequency.    Expects a sequence as numpy array,Returns the sequence log on the same sequence log on the pattern.,Returns a pattern_multiplicity of the instance of the sequence_logLH. Uses the lookup with the pattern multiplicity instances.,28.50449779,29.95852475,29.23151127,,,,,,,,,
"summarize: def flush(self):
        """"""""""""
        if not self.is_output():
            return

        count = len(self._write_buff)
        if count == 0:
            return

        encodeVarint(self._fd.write, count, True)

        for obj in self._write_buff:
            obj_str = obj.SerializeToString()
            encodeVarint(self._fd.write, len(obj_str), True)
            self._fd.write(obj_str)

        self._write_buff = []",Write down buffer to the file.,Flushes the buffer as a file.,self._write_buff.append(encodeVarint(self._write_buff)) Flush the encoded encoding and return the input by single one validation.,50.21394881,8.239831592,29.2268902,,,,,,,,,
"summarize: def average_by_label(X, y, ref_label):
    '''
    
    '''
    # TODO: consider to delete defaultdict
    return defaultdict(float,
                       pd.DataFrame.from_records(
                           filter_by_label(X, y, ref_label)[0]
                       ).mean().to_dict())",Calculates average dictinary from list of dictionary for give label,Converts a dictionary to an X and labels to a label label.,Average the label by ``TabPath``. If the label is available.,32.16528266,26.23811897,29.20170082,,,,,,,,,
"summarize: def increment_legacy_tag(self):
        """"""
        
        """"""
        self._legacy_tag = (
            Tag.from_trits(add_trits(self.legacy_tag.as_trits(), [1]))
        )","Increments the transaction's legacy tag, used to fix insecure    bundle hashes when finalizing a bundle.","self._legacy_tag = ( Mean(self._legacy_tag, self._legacy_tag) ) Increment tag to legacy tag to use.",return self.legacy_tag(self.legacy_tag.tag) Return a legacy tag if it is already increments.,30.96844946,27.37767459,29.17306203,,,,,,,,,
"summarize: def get(self, k):
        """"""""""""
        if self._changed():
            self._read()

        if k in self.store:
            return tuple(self.store[k])
        else:
            return None","Returns key contents, and modify time",Returns the current store and returns the keys.,Returns the integer representation of a changed.,32.60582718,25.70870386,29.15726552,,,,,,,,,
"summarize: def s_url(self, path, method=None, type_cast=None):
        """"""
        """"""
        if not type_cast:
            type_cast = {}

        def decorator(function):
            self.s_add(path, function, method, type_cast)
            return function

        return decorator",Decorator for registering a simple path.,Decorator for specified methods,Checks if the requested is not specified.,38.22208688,20.05826101,29.14017395,,,,,,,,,
"summarize: def write_table(self, table):
        """"""
        """"""
        table_sql, serial_key_sql = super(PostgresDbWriter, self).write_table(table)
        for sql in serial_key_sql + table_sql:
            self.execute(sql)",Send DDL to create the specified `table`,return table Write the table to the table.,Write the dataset of the table and the dataset.,31.2076035,26.97929163,29.09344757,,,,,,,,,
"summarize: def keyword_scan(self, query_id=None, query_fc=None, feature_names=None):
        '''
        '''
        it = self._keyword_scan(query_id, query_fc,
                                feature_names=feature_names)
        for hit in it:
            fc = self.fc_from_dict(hit['_source']['fc'])
            yield did(hit['_id']), fc",Keyword scan for feature collections.,Add keyword scan to query to a single scan.,Return a keyword ``Hit`` object.,32.71565098,25.46109664,29.08837381,,,,,,,,,
"summarize: def random_adjspecies_pair(maxlen=None, prevent_stutter=True):
    """"""
    
    """"""
    while True:
        pair = _random_adjspecies_pair()
        if maxlen and len(''.join(pair)) > maxlen:
            continue
        if prevent_stutter and pair[0][-1] == pair[1][0]:
            continue
        return pair","Return an ordered 2-tuple containing a species and a describer.  The letter-count of the pair is guarantee to not exceed `maxlen` if  it is given. If `prevent_stutter` is True, the last letter of the  first item of the pair will be different from the first letter of  the second item.","[0][1] return while True: return _random_adjspecies_pair(minlen, prevent_stutter, prevent_stutter) runs a list of final pairs that are adjspecies pairs. If there are adjusted, any the event then random provided.","[1] else: # We have a single HTML saved if not self.is_random_adjspecies(): return self._random_adjspecies_pair(maxlen, maxlen) if not self.is_random_adjspecies(): return None return self._random_adjspecies_pair(maxlen, maxlen) Returns a dict of the URLs of the URLs of the URLs.",29.4426149,28.73255696,29.08758593,,,,,,,,,
"summarize: def url_value_preprocessor(self, f):
        """"""
        """"""
        self.record_once(lambda s: s.app.url_value_preprocessors
            .setdefault(self.name, []).append(f))
        return f",Registers a function as URL value preprocessor for this    blueprint. It's called before the view functions are called and    can modify the url values provided.,"summarize: def url_value_preprocessor(self, f): """""" """""" self.record_once(lambda s: s.app.url_value_preprocessors .setdefault(self.name, []).append(f)) return f Returns the URL value for the specified function.","summarize: def url_value_preprocessor(self, f): """""" """""" self.record_once(lambda s: s.app.url_value_preprocessors .setdefault(self.name, []).append(f)) return f Returns a value of the supported function.",31.03672008,27.1140678,29.07539394,,,,,,,,,
"summarize: def no_exp(number):
    
    """"""
    mant, exp = to_scientific_tuple(number)
    if not exp:
        return str(number)
    floating_mant = ""."" in mant
    mant = mant.replace(""."", """")
    if exp < 0:
        return ""0."" + ""0"" * (-exp - 1) + mant
    if not floating_mant:
        return mant + ""0"" * exp + ("".0"" if isinstance(number, float) else """")
    lfpart = len(mant) - 1
    if lfpart < exp:
        return (mant + ""0"" * (exp - lfpart)).rstrip(""."")
    return mant","r""""""  Convert number to string guaranteeing result is not in scientific notation.",", lfpart Convert an obtain number to a number of explicit number.",+ (number + lfpart * floating_mant) Returns a list of manifests on each string.,31.73812103,26.20045456,28.9692878,,,,,,,,,
"summarize: def get_records(self, hql, parameters=None):
        """"""
        
        """"""
        try:
            return super().get_records(
                self._strip_sql(hql), parameters)
        except DatabaseError as e:
            raise PrestoException(self._get_pretty_exception_message(e))",Get a set of records from Presto,"return self._create_records(hql, parameters) Get a list of records for this record.",Get a sql records.,24.90576489,32.8964995,28.9011322,,,,,,,,,
"summarize: def load_type_module(self, module):
        """"""
        
        """"""

        for name in (x for x in dir(module) if not x.startswith('_')):
            typeobj = getattr(module, name)

            try:
                self.inject_type(name, typeobj)
            except ArgumentError:
                pass",Given a module that contains a list of some types find all symbols in the module that    do not start with _ and attempt to import them as types.,"if self.module_type is None: return self.inject_type(name, module) return Module(self, module) Loads the module that was loaded in the module","return self.inject_type(self.distribution, self.inject_type) Return a dictionary of an id. If the class is an injecting type, the type module is the type is `type`.",32.06577714,25.67135252,28.86856483,,,,,,,,,
"summarize: def _append_zeros_if_too_small(self, value):
        """""" 
        """"""
        size_diff = len(value) - len(self.array)
        if size_diff:
            self.array = np.append(
                self.array, np.zeros(size_diff, dtype=self.array.dtype)
            )",Appends zeros to the points stored if the value we are trying to    fit is bigger,else: self.array = np.array(value) return self Add a list of size to the zeros to the zeros,"return size_diff, size_diff Merge image from small size diff",32.912258,24.77403546,28.84314673,,,,,,,,,
"summarize: def get_last_modified_datetime(self):
        """"""""""""
        if self._path:
            statbuf = os.stat(self._path)
            return datetime.utcfromtimestamp(statbuf.st_mtime)
        else:
            return datetime.now()",Return datetime object of modified time of machine file. Return now if not a file.,"Gets the last modified time, or None, and if it's a last datetime.",Return a state of the datetime object.,35.10292322,22.53274119,28.81783221,,,,,,,,,
"summarize: def delete(self, path='', **params):
        """"""
        
        """"""
        params = jsonify_parameters(params)
        url = ensure_trailing_slash(self.url + path.lstrip('/'))
        return self._json_request('delete', url, params=params)","Make a DELETE request to the given path, and return the JSON-decoded    result.",Delete a slash from a Given path and return it.,Determine when the path is present in the requested file.,27.44714417,30.15898209,28.80306313,,,,,,,,,
"summarize: def token_new(self, **kwargs):
        """"""
        
        """"""
        path = self._get_path('token_new')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response",Generate a valid request token for user based authentication.,Converts an instance to a user's GET request.,Get the authorized values from the given GET request.,25.22811384,32.35131447,28.78971416,,,,,,,,,
"summarize: def _x_request_elements_filter(cls, request_type, request_elements,
                                   credentials):
        """"""
        
        """"""
        if request_type is cls.ACCESS_TOKEN_REQUEST_TYPE:
            params = request_elements[2]
            del params['client_id']
            del params['client_secret']
        return request_elements",Google doesn't accept client ID and secret to be at the same time in    request parameters and in the basic authorization header in the access    token request.,[cls] Returns the fields of the elements that contain an element of the element of the element of the element of the X request elements.,"[""delta""] Returns a list of elements that are all accessing to the given request_elements and then installed and then sets the response.",23.50418939,33.93179372,28.71799156,,,,,,,,,
"summarize: def cook_refs(refs, n=4):
    ''''''
    
    refs = [normalize(ref) for ref in refs]
    maxcounts = {}
    for ref in refs:
        counts = count_ngrams(ref, n)
        for (ngram,count) in list(counts.items()):
            maxcounts[ngram] = max(maxcounts.get(ngram,0), count)
    return ([len(ref) for ref in refs], maxcounts)",Takes a list of reference sentences for a single segment  and returns an object that encapsulates everything that BLEU  needs to know about them.,Get a list of refs that maps to a list of refs that may be found on a list of refs to the given ngrams.,"Cookbook to end the cookbook on the single single captured refs and can be refs, and then make a batch single refs to other capture.",28.6509575,28.70141252,28.67618501,,,,,,,,,
"summarize: def transform_ipy_prompt(line):
    """"""""""""

    if not line or line.isspace():
        return line
    #print 'LINE:  %r' % line # dbg
    m = _ipy_prompt_re.match(line)
    if m:
        #print 'MATCH! %r -> %r' % (line, line[len(m.group(0)):]) # dbg
        return line[len(m.group(0)):]
    else:
        return line",Handle inputs that start classic IPython prompt syntax.,[len(m.group(0))] Convert Python prompt to a given line.,[len(m.group(0)] #print 'Transformer %s' % (len(m.group(1))) Transform a just an impl impl to another matrix,31.56579839,25.70875365,28.63727602,,,,,,,,,
"summarize: def ifftr(wave, npoints=None, indep_min=None, indep_max=None):
    
    """"""
    return real(ifft(wave, npoints, indep_min, indep_max))","r""""""  Return the real part of the inverse Fast Fourier Transform of a waveform.",return a checks for annotation of a WaveFields with the given indep_max,Returns an FRAM point of the indepth of the specified npoints.,26.57286138,30.58409057,28.57847598,,,,,,,,,
"summarize: def similarity(ctx, app_id, json_flag, query_pair, request_id):
    # type: (Context, unicode, bool, List[unicode], unicode) -> None
    """"""  """"""

    app_id = clean_app_id(app_id)

    api = GoolabsAPI(app_id)
    ret = api.similarity(
        query_pair=query_pair,
        request_id=request_id
    )

    if json_flag:
        click.echo(format_json(api.response.json()))
        return

    click.echo('{0:.16f}'.format(ret['score']))",Scoring the similarity of two words.,return ret Returns the similarity of a given `json_flag`.,return click.echo( click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(click.echo(c,34.98283638,22.1625974,28.57271689,,,,,,,,,
"summarize: def transform(self, a, b, c, d, e, f):
        """"""  
        """"""
        a0, b0, c0, d0, e0, f0 = self._currentMatrix
        self._currentMatrix = (a0 * a + c0 * b, b0 * a + d0 * b,
                               a0 * c + c0 * d, b0 * c + d0 * d,
                               a0 * e + c0 * f + e0, b0 * e + d0 * f + f0)
        a1, b1, c1, d1, e1, f1 = self._currentMatrix
        self.session._out('%.2f %.2f %.2f %.2f %.2f %.2f cm' % (a1, b1, c1, d1, e1, f1), self.page)",Adjust the current transformation state of the current graphics state    matrix. Not recommended for the faint of heart.,return self.page Attach the matrix of the given actions to the given action.,"return a2, a0 Calculate the analytic of the analysis permanent on the current matrix.",23.36307325,33.77616071,28.56961698,,,,,,,,,
"summarize: def chain(*tasks):
    """"""
    
    """"""
    for up_task, down_task in zip(tasks[:-1], tasks[1:]):
        up_task.set_downstream(down_task)","Given a number of tasks, builds a dependency chain.",return up_task Create a list of tasks in the given uptasks.,"return zip(tasks, down_task) Chains a chain object.",26.45518731,30.56719131,28.51118931,,,,,,,,,
"summarize: def set_cookie(self, name, value, attrs={}):
        """"""
        """"""
        cookie = http.cookies.SimpleCookie()
        cookie[name] = value
        for key, value in attrs.items():
            cookie[name][key] = value
        self.add_header('Set-Cookie', cookie[name].OutputString())",Add a Set-Cookie header to response object.,"self.add_header('Set-Cookie', cookie) Set the cookie for a named attribute.","self.add_header('Content-Type', value) Add a cookie to the cookie.",28.0160681,29.00116293,28.50861552,,,,,,,,,
"summarize: def _flatten_summand_list(kernels):
  """"""
  """"""
  flattened = []
  for k in kernels:
    if isinstance(k, _SumKernel):
      flattened += k.kernels
    else:
      flattened.append(k)
  return flattened",Flatten a list of kernels which may contain _SumKernel instances.,Returns a list of summary summaries for the given kernel.,This method function is a list of summary data.,33.22368591,23.7819809,28.50283341,,,,,,,,,
"summarize: def store(self, *args, **kwargs):
        """"""""""""
        try:
            self.acquire_lock()
            return self._storage_service.store(*args, **kwargs)
        finally:
            if self.lock is not None:
                try:
                    self.release_lock()
                except RuntimeError:
                    self._logger.error('Could not release lock `%s`!' % str(self.lock))",Acquires a lock before storage and releases it afterwards.,"raise return self._storage_service.store(*args, **kwargs) Storage the release lock",Removes an lock from an acquire from another service.,28.33279605,28.63170816,28.48225211,,,,,,,,,
"summarize: def register_new_formatter(cls, format_name, handler, preprocessors=(),
                               kwargs=None):
        """"""

        """"""
        cls._output_formats[format_name] = OutputFormatHandler(
            format_name, preprocessors, handler, kwargs or {})",Register a new output formatter.,return cls Register a new Formatter for a given ``format_name``.,"return cls._output_formatter(cls._output_formatter, handler, kwargs) Registers a new outputformation from another FormatterSequence.",36.65599264,20.24567438,28.45083351,,,,,,,,,
"summarize: def f_ratios(calON_obs,calOFF_obs,chan_per_coarse,**kwargs):
    '''
    
    '''
    #Calculate noise diode ON and noise diode OFF spectra (H and L) for both observations
    L_ON,H_ON = integrate_calib(calON_obs,chan_per_coarse,**kwargs)
    L_OFF,H_OFF = integrate_calib(calOFF_obs,chan_per_coarse,**kwargs)

    f_ON = H_ON/L_ON-1
    f_OFF = H_OFF/L_OFF-1

    return f_ON, f_OFF","Calculate f_ON, and f_OFF as defined in van Straten et al. 2012 equations 2 and 3",", f_ON, f_OF Calculate noise diode OFF for Framework observations.",Fill speed on f_obs to fill the calculated on speeding on the folding operations of any one speeds.,33.63949666,23.23635431,28.43792549,,,,,,,,,
"summarize: def wint(wave):
    
    """"""
    pexdoc.exh.addex(
        TypeError,
        ""Cannot convert complex to integer"",
        wave._dep_vector.dtype.name.startswith(""complex""),
    )
    ret = copy.copy(wave)
    ret._dep_vector = ret._dep_vector.astype(np.int)
    return ret","r""""""  Convert a waveform's dependent variable vector to integer.",Perform a wave integer to the target file.,Wrap the weight of the pexecution of the pexecution of the lower specified by class.,30.9613245,25.75163294,28.35647872,,,,,,,,,
"summarize: def compile_bytecode(
    code: List[types.CodeType],
    gctx: GeneratorContext,
    optimizer: PythonASTOptimizer,
    module: types.ModuleType,
) -> None:
    """"""""""""
    _bootstrap_module(gctx, optimizer, module)
    for bytecode in code:
        exec(bytecode, module.__dict__)",Compile cached bytecode into the given module.,"return _bootstrap_module(bytecode, module) Add a bytecode to the Generator.","return _bootstrap_module(code, code, code) Execute a compiled module.",30.62208498,26.02905381,28.3255694,,,,,,,,,
"summarize: def process_bind_param(self, value, dialect):
        """"""
        
        """"""
        bitmask = 0x00
        for e in value:
            bitmask = bitmask | e.value
        return bitmask",Returns the integer value of the usage mask bitmask. This value is    stored in the database.,"Given a bind param bind param, it will add the values to the value",".get_by_bitmask(bitmask, bitmask) Return a bitmask bitmask for the given value.",24.33642504,32.31301732,28.32472118,,,,,,,,,
"summarize: def get_decimal_precision(number):
    """"""
    """"""
    # Copied from: https://github.com/mahmoud/boltons/pull/59
    assert isinstance(number, decimal.Decimal)
    decimal_tuple = number.normalize().as_tuple()
    if decimal_tuple.exponent >= 0:
        return 0
    return abs(decimal_tuple.exponent)",Return maximum precision of a decimal instance's fractional part.  Precision is extracted from the fractional part only.,Return the decimal precision from the last version of the decimal precision.,Get the decimal precision of the decimal decimal decimal.,37.58531768,19.03230954,28.30881361,,,,,,,,,
"summarize: def enable(self, msgid, scope=""package"", line=None, ignore_unknown=False):
        """"""""""""
        self._set_msg_status(
            msgid, enable=True, scope=scope, line=line, ignore_unknown=ignore_unknown
        )
        self._register_by_id_managed_msg(msgid, line, is_disabled=False)",reenable message of the given id,Enables the title of the title,"self._set_msg(msgid, scope) self._set_msg(msgid, scope) This is the enabled scope of a client.",41.66239893,14.86130846,28.2618537,,,,,,,,,
"summarize: def predict_class_distributed(self, data_rdd):
        """"""
        
        """"""
        result = callBigDlFunc(self.bigdl_type,
                               ""modelPredictClass"", self.value, data_rdd)
        return result","module predict, return the predict label",.value Returns the predict class distance from the data type,.response Returns a dict of records from the data_rdd.,31.47855717,25.02346489,28.25101103,,,,,,,,,
"summarize: def update(self, b):
        '''
        '''
        hv = self.hashfunc(b)
        a, b = self.permutations
        phv = np.bitwise_and((a * hv + b) % _mersenne_prime, np.uint64(_max_hash))
        self.hashvalues = np.minimum(phv, self.hashvalues)",Update this MinHash with a new value.    The value will be hashed using the hash function specified by    the `hashfunc` argument in the constructor.,"self.hashes = np.sum(phv, self.hashvalues) self.hashes = np.zeros(phv) for route in self.routes: self.update(route) return hv When the absolute by the given buffer",physical = self.permutations return physical.power.update(physical.A) Update the physical coordinates of a single have been in the merged byte-based on the specified bytes.,24.26315685,32.21726898,28.24021292,,,,,,,,,
"summarize: def connection_lost(self, exc):
        """"""
        
        """"""

        logger.debug(""worker connection lost"")

        self._worker.close()
        self._workers.remove(self._worker)",Called when the connection to the remote worker is broken. Closes the    worker.,return exc Log and return a worker connection lost.,self._connection_lost(exc) self._worker.set_event_lost(exc) return self._worker Logging the current connection.,27.40757777,28.98220292,28.19489035,,,,,,,,,
"summarize: def classe(self, name):
        """"""
        """"""
        for klass in self.classes():
            if klass.node.name == name:
                return klass
        raise KeyError(name)","return a class by its name, raise KeyError if not found",return name Convert classes to elements to ``name``.,Called when the classes are not classes and returns an empty empty list.,32.01680186,24.33520161,28.17600174,,,,,,,,,
"summarize: def _is_enum_class(node: astroid.ClassDef) -> bool:
    """"""
    """"""
    for base in node.bases:
        try:
            inferred_bases = base.inferred()
        except astroid.InferenceError:
            continue

        for ancestor in inferred_bases:
            if not isinstance(ancestor, astroid.ClassDef):
                continue

            if ancestor.name == ""Enum"" and ancestor.root().name == ""enum"":
                return True

    return False",Check if a class definition defines an Enum class.,Check if the node is an inference instance.,Returns ancestor class instance if not ancestor.,29.53122323,26.77412596,28.1526746,,,,,,,,,
"summarize: def _add_option(self, arg_parser, name, *args, **kwargs):
        """"""
        
        """"""
        arg_parser.add_argument('--' + name, *args, **kwargs)",Add an argument to the given arg_parser with the given name.,"if name in self.args: arg_parser.add_argument(name, *args, **kwargs) else: arg_parser.add_argument(name, *args, **kwargs) return arg_parser Parses a GET argument to a specified name.","return self._add_argument('-', arg_parser, args, kwargs) Add the option to the option.",18.19200164,38.06857488,28.13028826,,,,,,,,,
"summarize: def _parse_args(self, args):
        """"""""""""
        # decode sys.argv to support unicode command-line options
        enc = DEFAULT_ENCODING
        uargs = [py3compat.cast_unicode(a, enc) for a in args]
        self.parsed_data, self.extra_args = self.parser.parse_known_args(uargs)",self.parser->self.parsed_data,self.argv = uargs return self Parse a sys argument.,"return self.parsed_data, enc, args Update any parser.",18.33365163,37.83430622,28.08397893,,,,,,,,,
"summarize: def register_function(self, func, magic_kind='line', magic_name=None):
        """"""
        """"""

        # Create the new method in the user_magics and register it in the
        # global table
        validate_type(magic_kind)
        magic_name = func.func_name if magic_name is None else magic_name
        setattr(self.user_magics, magic_name, func)
        record_magic(self.magics, magic_kind, magic_name, func)",Expose a standalone function as magic function for IPython.,return record_magics Register a method to add a given function.,"self.user_magics.remove(record_magic_kind, record_magic) Register the function that function is on the function.",30.29376769,25.69477712,27.99427241,,,,,,,,,
"summarize: def constant(duration: int, amp: complex, name: str = None) -> SamplePulse:
    """"""
    """"""
    return _sampled_constant_pulse(duration, amp, name=name)",Generates constant-sampled `SamplePulse`.,Add a constant pulse to the constant pulse,Return a single pulse constant with an amp-distant.,29.24720367,26.67795698,27.96258033,,,,,,,,,
"summarize: def attach(name, contents = None):
    """"""
""""""
    def do_attach(func):
        if hasattr(func, '__attachments__'):
            func.__attachments__.append((name, contents))
        else:
            func.__attachments__ = [(name, contents)]
        return func
    return do_attach",attaches a file to the payload to be uploaded.,Adds an attachments to the location.,A specified name and create an array.,30.45823857,25.35033866,27.90428862,,,,,,,,,
"summarize: def to_dict(self):
        """"""
        """"""
        try:
            data, _ = self.schema.dump(self)
        except ValidationError as ex:
            raise ModelValidationError(
                ex.messages, ex.field_names, ex.fields, ex.data, **ex.kwargs) from None

        return data",Serialize the model into a Python dict of simple types.,", _ Returns a dictionary of dictionarys to the dictionary.",Return a dict of a dictionary into a dictionary.,24.03844319,31.75420752,27.89632536,,,,,,,,,
"summarize: def child_parsers(self):
        """"""

        """"""
        children = CodeObjects(self.code)
        return [ByteParser(code=c, text=self.text) for c in children]",Iterate over all the code objects nested within this one.,Get a list of byte objects in the full parser.,Get a list of parsers in the specified command.,35.24683186,20.47240516,27.85961851,,,,,,,,,
"summarize: def dumps(self, obj, salt=None):
        """"""
        """"""
        payload = want_bytes(self.dump_payload(obj))
        rv = self.make_signer(salt).sign(payload)
        if self.is_text_serializer:
            rv = rv.decode('utf-8')
        return rv",Returns a signed string serialized with the internal serializer.    The return value can be either a byte or unicode string depending    on the format of the internal serializer.,Writes the object and returns the rows of the specified object and returns the multiprocessing values in the object.,".decode('utf-8') Dumps a string into a string. If a string is already are passed, which is care the object to the text serializer.",25.75719319,29.93630474,27.84674897,,,,,,,,,
"summarize: def __fetch_repo_info(self):
        """"""""""""

        raw_repo = self.client.repo()
        repo = json.loads(raw_repo)

        fetched_on = datetime_utcnow()
        repo['fetched_on'] = fetched_on.timestamp()

        yield repo","Get repo info about stars, watchers and forks",Get a Fetches a Fetches about ``repo``.,return repo Try to get the fetched repository.,32.053123,23.60147094,27.82729697,,,,,,,,,
"summarize: def head(self, url):
    '''
    '''
    bot.debug('HEAD %s' %url)
    return self._call(url, func=requests.head)","head request, typically used for status code retrieval, etc.",Get header and returns the header and returns the GET request.,The header is too longer the URL for the request.,27.91627477,27.55221792,27.73424635,,,,,,,,,
"summarize: def to_dict(self, filter=True):
        """"""
        

        """"""
        result = {}
        for k, v in self:
            r = _to_dict(v, filter)
            if r:
                result[k] = r
        return result",Returns a dictionary with the values of the model. Note that the values    of the leafs are evaluated to python types.,Returns a dictionary of dictionary of the dictionary of the dictionary of the dictionary of the dictionary of the dictionary of the dictionary of the dictionary of the dictionary of the dictionary of the dictionary of the dictionary.,Parses the default dictionary and returns the dictionary of the dictionary for the ``self``.,21.21461995,34.21561515,27.71511755,,,,,,,,,
"summarize: def add_capture(self, sequence, cpt):
    """"""""""""
    cpt_value = self.value(cpt)
    sequence.parser_tree = parsing.Capture(cpt_value, sequence.parser_tree)
    return True",Create a tree.Capture,Add a capture to the capture.,Adds a captured capture.,26.08721373,29.34068087,27.7139473,,,,,,,,,
"summarize: def create_iterator(self, start=0, step=1, security_level=1):
        # type: (int, int, int) -> KeyIterator
        """"""
        
        """"""
        return KeyIterator(self.seed, start, step, security_level)",Creates a generator that can be used to progressively generate    new keys.,Create a new iterator of the iterator of the second iterator.,Creates an iterator for the given step.,32.13912615,23.26004204,27.6995841,,,,,,,,,
"summarize: def find(self, req):
        """"""
        """"""
        dist = self.by_key.get(req.key)
        if dist is not None and dist not in req:
            # XXX add more info
            raise VersionConflict(dist, req)
        else:
            return dist",Find a distribution matching requirement `req`,Finds a list of reqs in the given `req` and `req`.,Return a list of reqs of the given required keys.,29.24396209,26.13259456,27.68827833,,,,,,,,,
"summarize: def downsample(array, k):
    """"""""""""
    length = array.shape[0]
    indices = random.sample(xrange(length), k)
    return array[indices]",Choose k random elements of array.,Downsamples a sizes of arrays.,Load a LOGGER GLP active samples.,32.00262757,23.36671456,27.68467107,,,,,,,,,
"summarize: def assign_parent(node: astroid.node_classes.NodeNG) -> astroid.node_classes.NodeNG:
    """"""
    """"""
    while node and isinstance(node, (astroid.AssignName, astroid.Tuple, astroid.List)):
        node = node.parent
    return node","return the higher parent which is not an AssignName, Tuple or List node",Assign a parent node to a node or a parent node.,".child(node, node) Assign node ``node`` assignment given a node.",30.32931746,25.00958711,27.66945229,,,,,,,,,
"summarize: def run_command_under_r_root(self, cmd, catched=True):
        """"""
        
        """"""
        RPATH = self.path
        with self.cd(newdir=RPATH):
            if catched:
                process = sp.run(cmd, stdout=sp.PIPE, stderr=sp.PIPE)
            else:
                process = sp.run(cmd)
            return process",subprocess run on here,Process the cmd.,Execute a command-under root.,29.08043648,26.22192908,27.65118278,,,,,,,,,
"summarize: def is_checkmate(self):
        ''''''
        if not self.is_check():
            return False

        try:
            next(self.generate_legal_moves().__iter__())
            return False
        except StopIteration:
            return True",Checks if the current position is a checkmate.,return True Returns True if the given legal_moves() is not None,Return a function if there is not valid,20.83280235,34.38018689,27.60649462,,,,,,,,,
"summarize: def op_and(self, *elements):
        """"""
        """"""
        expression = self.add_operator(Operator(';'))
        for element in elements:
            expression.add_element(element)
        return expression","Update the ``Expression`` by joining the specified additional    ``elements`` using an ""AND"" ``Operator``",Returns a list of elements that are a list of elements that are optional only used.,return Elements.Operator(Element) Gets the Operator for the internal an expression.,21.37931206,33.70348879,27.54140043,,,,,,,,,
"summarize: def difference_update(self, oset: Scope) -> Scope:
        """"""  """"""
        keys = list(self._hsig.keys())
        for k in keys:
            if k in oset:
                del self._hsig[k]
        return self",Remove values common with another Set,._hsig[k] Remove human values to the given oset.,"._hsig.update_update(oset, keys) Update a scope of a scope.",33.70444098,21.29784564,27.50114331,,,,,,,,,
"summarize: def error(self, error):
        """"""
        
        """"""
        self._error = RuntimeError(error) if isinstance(error, str) else error",Defines a simulated exception error that will be raised.,return error Check if the given error is supported.,self._errors[error] = error return True Called if an exception is called,23.92153219,31.05443328,27.48798274,,,,,,,,,
"summarize: def get_all_child_m2m_relations(model):
    """"""
    
    """"""
    return [
        field for field in model._meta.get_fields()
        if isinstance(field, ParentalManyToManyField)
    ]","Return a list of ParentalManyToManyFields on the given model,  including ones attached to ancestors of the model",Returns a list of all of the model relations of the fields on the field.,Returns the list of children of a list of all children.,36.83170207,17.86641014,27.34905611,,,,,,,,,
"summarize: def draw_y_labels(self):
		""""
		if not self.show_y_labels:
			# do nothing
			return

		labels = self.get_y_labels()
		count = len(labels)

		labels = enumerate(iter(labels))
		start = int(not self.step_include_first_y_label)
		labels = itertools.islice(labels, start, None, self.step_y_labels)
		list(map(self.draw_y_label, labels))
		self.draw_y_guidelines(self.field_height(), count)",Draw the Y axis labels,Draws they labels,"self.set_left_x(self.draw_y_labels, labels) self.set_left(self.draw_y_labels) list_left = self.set_left() self.set_left(self.draw_y_labels, labels, draw_y_labels) self.set_left() List all drawing the included left left left, which is left the points.",49.6230613,4.961134457,27.29209788,,,,,,,,,
"summarize: def correct_maybe_zipped(fileloc):
    """"""
    
    """"""

    _, archive, filename = re.search(
        r'((.*\.zip){})?(.*)'.format(re.escape(os.sep)), fileloc).groups()
    if archive and zipfile.is_zipfile(archive):
        return archive
    else:
        return fileloc","If the path contains a folder with a .zip suffix, then  the folder is treated as a zip archive and path to zip is returned.","Correct a zipped file, by default. If the filename is the zipped files, it returns a Zipped filename or a zipped file.","[fileloc.name] Calculates a zip filename of a filename, and return a correct function.",33.28776162,21.28917608,27.28846885,,,,,,,,,
"summarize: def splat(f: Callable[..., A]) -> Callable[[Iterable], A]:
    """"""
    """"""

    def splatted(args):
        return f(*args)

    return splatted",Convert a function taking multiple arguments into a function taking a single iterable argument.,Splatform a whole arguments are alphabetical to the following function.,(args) Generates splating a platform for the callable function.,31.73887846,22.71704296,27.22796071,,,,,,,,,
"summarize: def storage(self):
        """"""""""""
        if self._storage is None:
            api = ""SYNO.Storage.CGI.Storage""
            url = ""%s/entry.cgi?api=%s&version=1&method=load_info"" % (
                self.base_url,
                api)
            self._storage = SynoStorage(self._get_url(url))
        return self._storage",Getter for various Storage variables,Storage a session to storage.,(url) Storage storage storage.,26.05609235,28.34580491,27.20094863,,,,,,,,,
"summarize: def get_input_shape(self):
        """"""
        
        """"""
        input = callBigDlFunc(self.bigdl_type, ""getInputShape"",
                              self.value)
        return self.__process_shape(input)",Return a list of shape tuples if there are multiple inputs.    Return one shape tuple otherwise.,Returns the input shape of the input shape,Returns the output shape of the input shape of the first input.,20.61956717,33.74377149,27.18166933,,,,,,,,,
"summarize: def stop(self):
        """"""
        """"""
        self.t.stop()
        self.factory.stopTrying()
        self.connector.disconnect()",Stop this client.,Stop the feed message,Stop any instances.,30.23266713,24.06522331,27.14894522,,,,,,,,,
"summarize: def chunk(self, size=""150"", axis=None, padding=None):
        """"""
        
        """"""
        if type(size) is not str:
            size = tupleize((size))
        axis = tupleize((axis))
        padding = tupleize((padding))

        from bolt.spark.chunk import ChunkedArray

        chnk = ChunkedArray(rdd=self._rdd, shape=self._shape, split=self._split, dtype=self._dtype)
        return chnk._chunk(size, axis, padding)",Chunks records of a distributed array.,Get an array of size and chunks for the axis.,Chunk List chunks in the axis.,31.8699535,22.33042476,27.10018913,,,,,,,,,
"summarize: def _register_stements(self, statements: List[""HdlStatement""],
                           target: List[""HdlStatement""]):
        """"""
        
        """"""
        for stm in flatten(statements):
            assert stm.parentStm is None, stm
            stm._set_parent_stm(self)
            target.append(stm)",Append statements to this container under conditions specified    by condSet,Register a list of statements to the List model.,target.append(stm) Register statements statements from statements.,26.4541045,27.69764977,27.07587714,,,,,,,,,
"summarize: def check_output(self, cmd):
        """"""""""""
        ret, output = self._exec(cmd)
        if not ret == 0:
            raise CommandError(self)

        return output",Wrapper for subprocess.check_output.,Checkout output for a given cmd.,Get the correct output from another file.,31.27188308,22.84846707,27.06017508,,,,,,,,,
"summarize: def add_method(self, key: T, method: Method) -> None:
        """"""""""""
        self._methods.swap(MultiFunction.__add_method, key, method)",Add a new method to this function which will respond for    key returned from the dispatch function.,Add a method to the method to the method to the method to the given key.,self._methods.append(key) self._methods.append(method) Add a method to the method to a method.,26.9155223,27.00529637,26.96040934,,,,,,,,,
"summarize: def do_fuzzy(self, word):
    """"""""""""
    word = list(preprocess_query(word))[0]
    print(white(make_fuzzy(word)))",Compute fuzzy extensions of word.  FUZZY lilas,return word Do a fuzzy for the given word.,word.append(word) return word Return a list of fuzzy positions into a FULZY dataset.,28.79325864,25.09308783,26.94317324,,,,,,,,,
"summarize: def get_indentation(line):
    """"""""""""
    if line.strip():
        non_whitespace_index = len(line) - len(line.lstrip())
        return line[:non_whitespace_index]
    else:
        return ''",Return leading whitespace.,Get the IP whitespace in the current link.,Return the indentation of the line.,30.66706211,23.1351812,26.90112166,,,,,,,,,
"summarize: def pub(self, topic, msg, callback=None):
        """"""
        
        """"""
        self._pub('pub', topic, msg, callback=callback)",publish a message to nsq,Publish a topic to a topic.,Submits public IPSPRORTED IPV4,39.63547186,14.15437573,26.8949238,,,,,,,,,
"summarize: def get_authorization_code_uri(self, **params):
        """"""
        """"""
        if 'response_type' not in params:
            params['response_type'] = self.default_response_type
        params.update({'client_id': self.client_id,
                       'redirect_uri': self.redirect_uri})
        return utils.build_url(self.authorization_uri, params)",Construct a full URL that can be used to obtain an authorization    code from the provider authorization_uri. Use this URI in a client    frame to cause the provider to generate an authorization code.,"summarize: def get_authorization_code_uri(self, **params): """""" """""" if'response_type' not in params: params['response_type'] = self.default_response_type params.update({'client_id': self.client_id, 'redirect_uri': self.redirect_uri}) return utils.build_url(self.authorization_uri, params) Get the authorization code using the authorization code using the URL.","summarize: def get_authorization_code_uri(self, **params): """""" """""" if'response_type' not in params: params['response_type'] = self.default_response_type params.update({'client_id': self.client_id, 'redirect_uri': self.redirect_uri}) return utils.build_url(self.authorization_uri, params) Authorization code to get the authorization code.",26.77388708,27.01201018,26.89294863,,,,,,,,,
"summarize: def fetch(self, category=CATEGORY_MESSAGE, from_date=DEFAULT_DATETIME):
        """"""
        """"""
        if not from_date:
            from_date = DEFAULT_DATETIME

        from_date = datetime_to_utc(from_date)
        latest = datetime_utcnow().timestamp()

        kwargs = {'from_date': from_date, 'latest': latest}
        items = super().fetch(category, **kwargs)

        return items",Fetch the messages from the channel.,Extracts the latest from the fetch and returns it as a URL.,Return a fetch the datetime object in the specified category.,30.5768245,23.15449708,26.86566079,,,,,,,,,
"summarize: def unsubscribe_from_raw_order_book(self, pair, prec=None, **kwargs):
        """"""
        """"""
        identifier = ('raw_book', pair)
        prec = 'R0' if prec is None else prec
        self._unsubscribe('book', identifier, pair=pair, prec=prec, **kwargs)",Unsubscribe to the passed pair's raw order book channel.,return prec Returns a list of order-books to the route.,"return self._unsubscribe('unsubscribe', **kwargs) Authorization on the precision.",31.07450061,22.57353487,26.82401774,,,,,,,,,
"summarize: def parse_rrset_record_values(e_resource_records):
    """"""
    
    """"""

    records = []

    for e_record in e_resource_records:
        for e_value in e_record:
            records.append(e_value.text)

    return records",Used to parse the various Values from the ResourceRecords tags on  most rrset types.,Parse the rrset records to exclude an error metadata.,Returns the elements of the records are not in the end of the elements.,28.83783911,24.74549045,26.79166478,,,,,,,,,
"summarize: def failure_data(self):
        ''''''
        for result in itertools.chain(
            self.input_expectations, self.output_expectations, self.transforms
        ):
            if result.event_type == DagsterEventType.STEP_FAILURE:
                return result.step_failure_data","Returns the failing step's data that happened during this solid's execution, if any",return None Returns an event data based on the database of the database.,"(result) elif result.event_type == ""step"": return result.step_failure() return None Returns the failed data from the ``Failed``.",28.07721924,25.35129961,26.71425943,,,,,,,,,
"summarize: def missing_categories(context):
    '''  '''
    user = user_for_context(context)
    categories_available = set(CategoryController.available_categories(user))
    items = ItemController(user).items_pending_or_purchased()

    categories_held = set()

    for product, quantity in items:
        categories_held.add(product.category)

    return categories_available - categories_held",Adds the categories that the user does not currently have.,Get categories for the given context,Emit the categories for an item.,28.00801907,25.41197347,26.70999627,,,,,,,,,
"summarize: def cb_set_provider_option(self, option, opt, value, parser):
        """"""""""""
        if opt.startswith(""--""):
            # remove -- on long option
            opt = opt[2:]
        else:
            # short option, get its long equivalent
            opt = self._short_options[opt[1:]]
        # trick since we can't set action='store_true' on options
        if value is None:
            value = 1
        self.global_set_option(opt, value)",optik callback for option setting,return option Set provider option for `value`,"return self.client.callback(opt, value, value) Compute the provider option of the global set-option.",32.81655673,20.59606256,26.70630965,,,,,,,,,
"summarize: def seek(self,index):
        """"""""""""
        if index<0:
            index = self.nblocks + index
        self._validate_index(index)
        self.block_index = index
        self.finished = False",Move the current seek pointer to the given block.,return self.blocks Seek a block of the location of the index,self._seek(index) Set the index of the index.,29.92150551,23.3158175,26.61866151,,,,,,,,,
"summarize: def popular(self, **kwargs):
        """"""
        
        """"""
        path = self._get_path('popular')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response",Get the list of popular movies on The Movie Database. This list    refreshes every day.,Populates the populations and returns a list of populations.,.pop(self._get_response(response)) Return a List of popular response.,27.25343324,25.98236889,26.61790107,,,,,,,,,
"summarize: def error(self, relative_to='AME2003'):
        """"""
        
        """"""
        df = self.df - Table(relative_to).df
        return Table(df=df)",Calculate error difference,Gets the error by a table,Initialises an error to the JSON,30.13974763,22.96386998,26.55180881,,,,,,,,,
"summarize: async def parse_vn_results(soup):
    """"""
    
    """"""
    soup = soup.find_all('td', class_='tc1')
    vns = []
    for item in soup[1:]:
        vns.append({'name': item.string, 'id': item.a.get('href')[1:]})
    return vns",Parse Visual Novel search pages.,Parse a list of all virtual datas,Gets a vn_results in the soup.,26.76522616,26.27688462,26.52105539,,,,,,,,,
"summarize: def create_tfs_core_client(url, token=None):
    """"""
    
    """"""
    if token is None:
        token = os.environ.get('TFS_API_TOKEN', None)

    tfs_connection = create_tfs_connection(url, token)
    tfs_client = tfs_connection.get_client('vsts.core.v4_1.core_client.CoreClient')

    if tfs_client is None:
        msg = 'Unable to connect to TFS Enterprise (%s) with provided token.'
        raise RuntimeError(msg, url)

    return tfs_client",Create a core_client.py client for a Team Foundation Server Enterprise connection instance,Create a list of tfs to the GET Core Core CoreClient,".create_tfs_to_core_client(token, token) Create a FSClient object for the given token.",16.00027142,37.01218187,26.50622665,,,,,,,,,
"summarize: def node_query(lat_min, lng_min, lat_max, lng_max, tags=None):
    """"""
    

    """"""
    node_data = make_osm_query(build_node_query(
        lat_min, lng_min, lat_max, lng_max, tags=tags))

    if len(node_data['elements']) == 0:
        raise RuntimeError('OSM query results contain no data.')

    nodes = [process_node(n) for n in node_data['elements']]
    return pd.DataFrame.from_records(nodes, index='id')",Search for OSM nodes within a bounding box that match given tags.,Get a list of nodes for the given lat and lat.,Get the list of nodes in a given later,29.44370319,23.48288051,26.46329185,,,,,,,,,
"summarize: def insert(self, **fields):
        """"""
        """"""

        if self.conflict_target or self.conflict_action:
            compiler = self._build_insert_compiler([fields])
            rows = compiler.execute_sql(return_id=True)

            pk_field_name = self.model._meta.pk.name
            return rows[0][pk_field_name]

        # no special action required, use the standard Django create(..)
        return super().create(**fields).pk",Creates a new record in the database.,Create a new action required to add a list of sections,".insert(0, compiler.required_target, fields) Deflict an action field.",27.78253385,25.1084134,26.44547363,,,,,,,,,
"summarize: def get_autotype(arr):
    """"""
    
    """"""
    try:
        narr = arr.astype('float')
        if (narr < sys.maxsize).all() and (narr % 1).sum() == 0:
            return narr.astype('int')
        else:
            return narr
    except ValueError:
        return arr","Attempts to return a numpy array converted to the most sensible dtype  Value errors will be caught and simply return the original array  Tries to make dtype int, then float, then no change",.astype('int') return narr Converts an array of auto-type to an array of narr and return it. If the same value is auto-type is the full array of the auto-type of the auto-type of the array of auto-type.,.astype(np.int64) return arr.astype(np.float64) Get automatic AutomaticalAutomaticalAutomaticalAutomaticalAutomaticalAutomaticalAutomaticalAutomatically is a valid AutomaticalAutomaticallyAutomaticallyType.,37.27337079,15.45564415,26.36450747,,,,,,,,,
"summarize: def parse_git_log_from_file(filepath):
        """"""
        """"""
        with open(filepath, 'r', errors='surrogateescape',
                  newline=os.linesep) as f:
            parser = GitParser(f)

            for commit in parser.parse():
                yield commit",Parse a Git log file.,return parser Parse a git file to file,"Given a GitLine file, skip the git configured file.",31.43111458,21.28569217,26.35840338,,,,,,,,,
"summarize: def _propagate_cov(cov, linop, dist):
  """"""""""""
  # For linop A and input cov P, returns `A P A' + dist.cov()`
  return linop.matmul(linop.matmul(cov), adjoint_arg=True) + dist.covariance()",Propagate covariance through linear Gaussian transformation.,.reshape(dist.cov()) Propagate cov P a P a P analysis P analytic.,Return a Payer cov linear cov from the distribution of the cov file,25.97072641,26.65990702,26.31531672,,,,,,,,,
"summarize: def logger(name=__name__, output=None, uuid=False, timestamp=False):
    '''  '''
    processors = []
    if output == 'json':
        processors.append(structlog.processors.JSONRenderer())

    if uuid:
        processors.append(add_unique_id)
    if uuid:
        processors.append(add_timestamp)
    return structlog.wrap_logger(
        logbook.Logger(name),
        processors=processors
    )",Configure and return a new logger for hivy modules,Load a file or return an instance of the name.,Return a logbook only discovery one or wraps the JSON-Renderer.,29.33014642,23.29053546,26.31034094,,,,,,,,,
"summarize: def build_user_type(s_udt):
    '''
    
    '''
    s_dt_user = nav_one(s_udt).S_DT[17]()
    s_dt_base = nav_one(s_udt).S_DT[18]()
    
    base_name = get_type_name(s_dt_base)
    if base_name:
        user = ET.Element('xs:simpleType', name=s_dt_user.name)
        ET.SubElement(user, 'xs:restriction', base=base_name)
        
        return user",Build an xsd simpleType out of a S_UDT.,return Build a pair of a user's user.,return Build a user type.,31.61444863,20.78248886,26.19846875,,,,,,,,,
"summarize: def frombytes(data, size, bandtype=gdal.GDT_Byte):
    """"""
    """"""
    r = ImageDriver('MEM').raster('', size, bandtype)
    r.frombytes(data)
    return r",Returns an in-memory raster initialized from a pixel buffer.,Returns a new input data from a given data,.frombytes(r) Returns the bandtype of a size of the data type.,28.39877943,23.92411934,26.16144939,,,,,,,,,
"summarize: def _attempting(self, text):
    """"""""""""
    consumed = len(self.original_text) - len(text)
    self.most_consumed = max(consumed, self.most_consumed)",Keeps track of the furthest point in the source code the parser has reached to this point.,return consumed The most function is given any some text of the text of the text.,return self.original_text[0] Method to storage in the specified on the specified on the specified on the text.,25.67751391,26.59011484,26.13381438,,,,,,,,,
"summarize: def _update_from_raw_data(self, raw_data, data_type_id=None, name=None,
                             description=None):
        """"""
        
        """"""
        _not_none('raw_data', raw_data)

        if data_type_id is None:
            data_type_id = self.data_type_id
        if name is None:
            name = self.name
        if description is None:
            description = self.description

        self._upload_and_refresh(raw_data, data_type_id, name, description)",Upload already serialized raw data and replace the existing dataset.,return raw_data Returns the data type to the data type.,"self._refresh_data(raw_data) self._refresh_data(raw_data, description) Upload a raw data from the raw data.",25.34542427,26.86470378,26.10506403,,,,,,,,,
"summarize: def add_from_depend(self, node, from_module):
        """"""
        """"""
        mod_name = node.root().name
        obj = self.module(mod_name)
        if from_module not in obj.node.depends:
            obj.node.depends.append(from_module)",add dependencies created by from-imports,return self Add a deependencies to the given node.,return obj Add an ID from the deep-end.,31.37617966,20.72078802,26.04848384,,,,,,,,,
"summarize: def FindPyData(self, start, py_data):
        """"
        # first, look at our internal dict:
        wx_data = self._wx_data_map[py_data]
        # do the real search at the wx control:
        if wx.VERSION < (3, 0, 0) or 'classic' in wx.version():
            data = self.FindItemData(start, wx_data)
        else:
            data = self.FindItem(start, wx_data)
        return data",Do a reverse look up for an item containing the requested data,Find the dictionary of wx data from the item.,Return an item in a start with the starting dependency.,21.69658154,30.19830353,25.94744254,,,,,,,,,
"summarize: def load_dict(self, data, overwrite=False, auto_load_model=True):
        """"""
        
        """"""
        for k, v in data.items():
            if k not in self._elements.keys() and not auto_load_model:
                raise AttributeError(""Model {} is not loaded"".format(k))

            elif k not in self._elements.keys() and auto_load_model:
                self._load_model(k)

            attr = getattr(self, k)
            _load_dict(attr, v)",Load a dictionary into the model.,return data Load a dictionary of data into a dictionary of data.,return attr.load_dict(_load_dict(attr)) return data Return a dictionary of a dictionary of data.,35.03243161,16.85527054,25.94385108,,,,,,,,,
"summarize: def convert_number(string):
    """"""
    """"""
    res = None
    if isint(string):
        res = int(string)
    elif isfloat(string):
        res = float(string) 
    return res",Convert a string to number  If int convert to int otherwise float    If not possible return None,Convert string to an integer string with a list of strings.,Get a dictionary of the number of ``Option`` into the given string.,26.10055696,25.75371516,25.92713606,,,,,,,,,
"summarize: def current_docker_container_id():
    """"""
    
    """"""
    try:
        with open('/proc/1/cgroup', 'r') as readable:
            raw = readable.read()
        ids = set(re.compile('[0-9a-f]{12,}').findall(raw))
        assert len(ids) == 1
        return ids.pop()
    except:
        logging.exception('Failed to obtain current container ID')
        raise NotInsideContainerError()",Returns a string that represents the container ID of the current Docker container. If this  function is invoked outside of a container a NotInsideContainerError is raised.,return None Checks that a single container container container container container container.,Function to check a container docker container docker containing any docker docker specified.,28.06373677,23.76638026,25.91505852,,,,,,,,,
"summarize: def export_directives(self):
        """"""
        """"""

        directives_json = {}

        # Skip first init process
        for p in self.processes[1:]:
            directives_json[p.template] = p.directives

        # Flush params json to stdout
        sys.stdout.write(json.dumps(directives_json))",Export pipeline directives as a JSON to stdout,return directives_json Create a directives without a single page,return self.process_json(directives_json) Gets the stdout directives from the dataset.,27.23646133,24.43852572,25.83749353,,,,,,,,,
"summarize: def validate(self):
        """"""
        
        """"""
        if not isinstance(self.revocation_code, RevocationReasonCode):
            msg = ""RevocationReaonCode expected""
            raise TypeError(msg)
        if self.revocation_message is not None:
            if not isinstance(self.revocation_message, TextString):
                msg = ""TextString expect""
                raise TypeError(msg)",validate the RevocationReason object,return False Validates the validation code.,"self.revocation_message = ""RevocationMessage"" return self.revocation_message.validate(msg) Returns an instance of a revocation message.",37.030349,14.63590953,25.83312927,,,,,,,,,
"summarize: def _get_disk(self, disk_id):
        """"""""""""
        if self._data is not None:
            for disk in self._data[""disks""]:
                if disk[""id""] == disk_id:
                    return disk",Returns a specific disk,return None Returns a disk for the disk with the disks,_id else: return None Returns a dict of all disks,24.13189063,27.50567958,25.81878511,,,,,,,,,
"summarize: def set_data(self, n, data):
        """"
        self.wx_obj.SetClientData(n, data)
        # reverse association:
        self._items_dict[data] = self.get_string(n)",Associate the given client data with the item at position n.,self._data = data Gets the data of the data in the data,"return self._set_data(self._id, data) Set the data position data to the data ``ASCIIRATIONS`.",25.76254894,25.74715617,25.75485256,,,,,,,,,
"summarize: def eval(self, operator, simulator=None):
        """"""""""""
        def getVal(v):
            while not isinstance(v, Value):
                v = v._val

            return v

        operands = list(map(getVal, operator.operands))

        if isEventDependentOp(operator.operator):
            operands.append(simulator.now)
        elif operator.operator == AllOps.IntToBits:
            operands.append(operator.result._dtype)

        return self._evalFn(*operands)",Load all operands and process them by self._evalFn,Gets a list of evaluation operators in the Vimulator.,return self._eval(v) Return the event of the variable.,23.83449278,27.64824154,25.74136716,,,,,,,,,
"summarize: def lookup_signum(name):
    """"""""""""
    uname = name.upper()
    if (uname.startswith('SIG') and hasattr(signal, uname)):
        return getattr(signal, uname)
    else:
        uname = ""SIG""+uname
        if hasattr(signal, uname):
            return getattr(signal, uname)
        return None
    return",Find the corresponding signal number for 'name'. Return None  if 'name' is invalid.,"name Get a signal with its name, lookup it, and return the signal to the signal.",uname Return a signal user signal signal signal.,30.8844315,20.54897623,25.71670387,,,,,,,,,
"summarize: def add(self, obj):
        '''
        
        '''
        if self.null_session:
            return
        self._init()
        pk = obj._pk
        if not pk.endswith(':None'):
            self.known[pk] = obj
            self.wknown[pk] = obj",Adds an entity to the session.,return self Adds the specified object to the null-session.,._pk else: self.wknown[pk] = obj._pk Add a object to the addresses,33.20333321,18.14495369,25.67414345,,,,,,,,,
"summarize: def set( self, **kw):
      '''
      
      '''
      self.args = kw
      log.debug( self.args )",Store keyword args to be written to output file.,Set the `kw` keyword arguments.,Set the request upgrade by properlying.,26.83215442,24.33105851,25.58160647,,,,,,,,,
"summarize: def search(term=None, phrase=None, limit=DEFAULT_SEARCH_LIMIT,
           api_key=GIPHY_PUBLIC_KEY, strict=False, rating=None):
    """"""
    
    """"""
    return Giphy(api_key=api_key, strict=strict).search(
        term=term, phrase=phrase, limit=limit, rating=rating)",Shorthand for creating a Giphy api wrapper with the given api key  and then calling the search method. Note that this will return a generator,Given a list of searches limited in the limit and return the limit and return it. If the limit is a limit and return it.,"Returns a single physic object. If not an element, the limit is a search of the other search.",30.7764677,20.36971387,25.57309079,,,,,,,,,
"summarize: def list(self, **request_parameters):
        """"""

        """"""
        # API request - get items
        items = self._session.get_items(
            API_ENDPOINT,
            params=request_parameters
        )

        # Yield role objects created from the returned JSON objects
        for item in items:
            yield self._object_factory(OBJECT_TYPE, item)",List all roles.,List all items for a page.,Gets the list of all the JSON objects.,33.8379247,17.22630701,25.53211586,,,,,,,,,
"summarize: def save(self, filename):
        """""" 
        """"""
        if hasattr(self, 'feature_table'):
            self.feature_table._sdf_to_csr()

        pickle.dump(self, open(filename, 'wb'), -1)

        if hasattr(self, 'feature_table'):
            self.feature_table._csr_to_sdf()",Pickle the Dataset instance to the provided file.,Save a file to the given file.,"return self._save_table(filename, pickle.DataFrame()) Save the XML file and return the image.",27.41561732,23.58773443,25.50167588,,,,,,,,,
"summarize: def dict_to_object(item, object_name):
    """"""""""""
    fields = item.keys()
    values = item.values()
    return json.loads(json.dumps(item),
                      object_hook=lambda d:
                      namedtuple(object_name, fields)(*values))","Converts a python dict to a namedtuple, saving memory.",Returns a dictionary of object names in the object name.,Returns a dict of object in the object name.,25.74083642,25.10647957,25.423658,,,,,,,,,
"summarize: def do_dice_roll():
	""""""
	
	""""""
	options = get_options()
	dice = Dice(options.sides)
	rolls = [dice.roll() for n in range(options.number)]
	for roll in rolls:
		print('rolled', roll)
	if options.number > 1:
		print('total', sum(rolls))",Roll n-sided dice and return each result and the total,return True Internal function to do the Do Coordinator for roll.,return True return False List all the dicepted dicepted dicepted dicepted lists.,23.68644027,27.13932431,25.41288229,,,,,,,,,
"summarize: def conv3x3(in_planes, out_planes, dilation=1):
    """"
    return nn.Conv2d(
        in_planes,
        out_planes,
        kernel_size=3,
        padding=dilation,
        dilation=dilation)",3x3 convolution with padding,Conv3 drawing from conv3.,Return an indices of the planes,22.67046722,28.15517942,25.41282332,,,,,,,,,
"summarize: def apply_config(self, applicator):
        """"""
        
        """"""
        if type(self._fpath) == str:
            self._fpath = applicator.apply(self._fpath)",Replace any config tokens in the file's path with values from the config.,else: self._fpath = applicator.apply(self._fpath) Apply a configuration of the application file.,return self._fpath Return an APIConfig file if presenting the given application is valid.,23.0485824,27.75658563,25.40258402,,,,,,,,,
"summarize: def list(self):
        """"""
        
        """"""
        return self._post(
            request='list',
            uri=ApiUri.TAGS.value,
        ).get('tags')",Get all current labels,List all the pages.,Get the list of all requests.,25.32862176,25.47296654,25.40079415,,,,,,,,,
"summarize: def next (self):    # File-like object.

        """"""
        """"""

        result = self.readline()
        if result == self._empty_buffer:
            raise StopIteration
        return result",This is to support iterators over a file-like object.,.getvalue() Returns the next timestamp of the specified file.,Return a File-like object byte a separated string.,12.86608888,37.81245588,25.33927238,,,,,,,,,
"summarize: def _iter_sims(self):
        """"""
        """"""
        for idx, lineset in enumerate(self.linesets[:-1]):
            for lineset2 in self.linesets[idx + 1 :]:
                for sim in self._find_common(lineset, lineset2):
                    yield sim","iterate on similarities among all files, by making a cartesian    product",return idx Iterate over similarity of a set of IDs.,.sum(sim) Iterates the single simulation into a valid list of string.,27.61546632,23.00683457,25.31115045,,,,,,,,,
"summarize: def main():
    '''
    
    '''
    args      = command_line()
    translate = partial(translator, args.source, args.dest,
                        version=' '.join([__version__, __build__]))

    return source(spool(set_task(translate, translit=args.translit)), args.text)",Main Entry point for translator and argument parser,Main a verbose called by the verbose called by a specified argument.,Generates an object from ManifestTranslator by a single task.,24.10000341,26.49728541,25.29864441,,,,,,,,,
"summarize: def current_state(self, session=None):
        """"""
        
        """"""
        TI = TaskInstance
        ti = session.query(TI).filter(
            TI.dag_id == self.dag_id,
            TI.task_id == self.task_id,
            TI.execution_date == self.execution_date,
        ).all()
        if ti:
            state = ti[0].state
        else:
            state = None
        return state","Get the very latest state from the database, if a session is passed,    we use and looking up the state becomes part of the session, otherwise    a new session is used.",Returns the current state for the given session. This is tested after the page of the state of the task_id is only applied to the task_id.,"Generate the state state for the session, and return an iterable.",36.24488967,14.08616921,25.16552944,,,,,,,,,
"summarize: def _convert_date_to_dict(field_date):
        """"""
        
        """"""
        return {DAY: field_date.day, MONTH: field_date.month, YEAR: field_date.year}",Convert native python ``datetime.date`` object to a format supported by the API,Returns a dictionary of field date instances to a datetime object.,Return a datetime object information.,30.74179548,19.26682957,25.00431253,,,,,,,,,
"summarize: def transcode_to_stream(input_filename, date_format=None):
    """"""
    
    """"""
    tmp = tempfile.TemporaryFile()
    for entry in open_json_or_csv_somehow(input_filename,
                                          date_format=date_format):
        tmp.write(json.dumps(entry, ensure_ascii=False).encode('utf-8'))
        tmp.write(b'\n')
    tmp.seek(0)
    return tmp","Read a JSON or CSV file and convert it into a JSON stream, which will  be saved in an anonymous temp file.",Attempts a transcode to a JSON file or filename or filename.,Templates the saved something when input is an input_filename and any input_filename.,22.17512763,27.79057476,24.9828512,,,,,,,,,
"summarize: def as_stream(self):
		""""""
		
		""""""
		stream = io.BytesIO()
		self._store(stream)
		stream.seek(0)
		return stream",Return a zipped package as a readable stream,"If stream is an index, return it's IO from the io.",.stream(stream) Save stream to the stream,27.32193062,22.53560198,24.9287663,,,,,,,,,
"summarize: def dt_dayofyear(x):
    """"""
    """"""
    import pandas as pd
    return pd.Series(x).dt.dayofyear.values",The ordinal day of the year.,() Return a dt dt dayofyear.,(x) This is an IPython object to an IPython object.,26.76032276,23.01563334,24.88797805,,,,,,,,,
"summarize: def intersection_update(self, oset: Scope) -> Scope:
        """"""  """"""
        keys = list(self._hsig.keys())
        for k in keys:
            if k not in oset:
                del self._hsig[k]
            else:
                self._hsig[k] = oset.get(k)
        return self",Update Set with common values of another Set,._hsig Load an intersection update of osets,"._hsig.update(self._hsig, oset) Initialise another updated over all keys and values.",25.77013703,23.81834865,24.79424284,,,,,,,,,
"summarize: def visit_ExceptHandler(self, node: ast.ExceptHandler) -> Optional[ast.AST]:
        """"""""""""
        new_node = self.generic_visit(node)
        assert isinstance(new_node, ast.ExceptHandler)
        return ast.copy_location(
            ast.ExceptHandler(
                type=new_node.type,
                name=new_node.name,
                body=_filter_dead_code(new_node.body),
            ),
            new_node,
        )",Eliminate dead code from except handler bodies.,Perform an error as an exception on a node,Returns the astropy of the visit_except_handler.,21.56889031,27.88221557,24.72555294,,,,,,,,,
"summarize: def exists(self, path):
        '''
        '''

        self.__validate_storage_path(path)
        try:
            metadata = self.api_client.get_entity_by_query(path=path)
        except StorageNotFoundException:
            return False

        return metadata and 'uuid' in metadata",Check if a certain path exists in the storage service.,or metadata['uuid'] Returns a list of list of paths in the given paths.,".get('metadata', None) Execute an astroid.",26.09371173,23.13614723,24.61492948,,,,,,,,,
"summarize: def insert_func(self, index, func, *args, **kwargs):
        '''
        
        '''
        wraped_func = partial(func, *args, **kwargs)
        self.insert(index, wraped_func)",insert func with given arguments and keywords.,"return self.insert(index, wraped_func) Insert the function with the given index.","return self.insert(index, wraped_func) Insert an index.",26.91994085,22.27735965,24.59865025,,,,,,,,,
"summarize: def upgrade(db_url, revision):
    """"""
    
    """"""
    with temp_alembic_ini(ALEMBIC_DIR_LOCATION, db_url) as alembic_ini:
        subprocess.check_call(
            ['alembic', '-c', alembic_ini, 'upgrade', revision]
        )",Upgrade the given database to revision.,Updates an Alembic initialized db_url to the given URL.,return alembic_ini Returns a template if revision is permission.,29.33173405,19.61384578,24.47278992,,,,,,,,,
"summarize: def set_loss(self, *args, **kwargs):
        '''
        '''
        self.losses = []
        self.add_loss(*args, **kwargs)",Clear the current loss functions from the network and add a new one.,Set loss for an address and address and address.,self.losses.append(args) return self Setup the information of the active loss.,24.93298516,23.99044025,24.46171271,,,,,,,,,
"summarize: def print_hex(data):
    """"""""""""
    hex_msg = """"
    for c in data:
        hex_msg += ""\\x"" + format(c, ""02x"")
    _LOGGER.debug(hex_msg)",Debugging method to print out frames in hex.,return hex_msg Logging data into a HTML error.,return hex_msg Return an API endpoint with an existing hex.,28.4061369,20.48639513,24.44626602,,,,,,,,,
"summarize: def run_show_int(obj, what=None):
    """"""""""""
    val = obj.debugger.settings[obj.name]
    if not what: what = obj.name
    return obj.msg(""%s is %d."" % (what, val))",Generic subcommand integer value display,Prints any values of a `what` object.,Returns an element to the specified object.,19.39945541,29.4569853,24.42822036,,,,,,,,,
"summarize: def  make_html_code( self, lines ):
        """"""  """"""
        line = code_header + '\n'
        for l in lines:
            line = line + html_quote( l ) + '\n'

        return line + code_footer",convert a code sequence to HTML,Adds HTML code for lines to lines,".get(l, '') Method to get a ``ObjectId``.",34.71064669,14.06812518,24.38938594,,,,,,,,,
"summarize: def copy_file_job(job, name, file_id, output_dir):
    """"""
    
    """"""
    work_dir = job.fileStore.getLocalTempDir()
    fpath = job.fileStore.readGlobalFile(file_id, os.path.join(work_dir, name))
    copy_files([fpath], output_dir)",Job version of move_files for one file,return copy_files Copies job to file job,return copy_files(copy_files) Copy a JSON file to the JSON file.,31.61931583,17.09394232,24.35662908,,,,,,,,,
"summarize: def is_in_manifest(dynamodb_client, table_name, run_id):
    """"""
    """"""
    response = dynamodb_client.get_item(
        TableName=table_name,
        Key={
            DYNAMODB_RUNID_ATTRIBUTE: {
                'S': run_id
            }
        }
    )
    return response.get('Item') is not None",Check if run_id is stored in DynamoDB table.  Return True if run_id is stored or False otherwise.,"Returns True if the table is valid, otherwise.",and returns the in_manifest table is passed in the virtual dynamodb.,23.11824522,25.37274964,24.24549743,,,,,,,,,
"summarize: def __window_ss_fill(x, win_sq, n_frames, hop_length):  # pragma: no cover
    ''''''

    n = len(x)
    n_fft = len(win_sq)
    for i in range(n_frames):
        sample = i * hop_length
        x[sample:min(n, sample + n_fft)] += win_sq[:max(0, min(n_fft, n - sample))]",Helper function for window sum-square calculation.,"return n_fft, sample Create a Windows function for a single hop like a specified function.",return win_sq[:n] Set the sum of the Window in a pdframe.,26.79037522,21.62183778,24.2061065,,,,,,,,,
"summarize: def writeCmdMsg(self, msg):
        """""" 
        """"""
        ekm_log(""(writeCmdMsg | "" + self.getContext() + "") "" + msg)
        self.m_command_msg = msg",Internal method to set the command result string.,self.m_command_msg = msg Writes the CmdMsg to the CmdMsg.,"self.cmdMsg.write(""CommandMsg | "" + str(msg)) Write a command msg.",26.81292461,21.57594989,24.19443725,,,,,,,,,
"summarize: def paragraphs(quantity=2, separator='\n\n', wrap_start='', wrap_end='',
               html=False, sentences_quantity=3, as_list=False):
    """"""""""""
    if html:
        wrap_start = '<p>'
        wrap_end = '</p>'
        separator = '\n\n'

    result = []
    for i in xrange(0, quantity):
        result.append(wrap_start + sentences(sentences_quantity) + wrap_end)

    if as_list:
        return result
    else:
        return separator.join(result)",Random paragraphs.,Paragraphic addresses a list of quantitys.,Gets the number of ``SAMENTION`.,19.70490382,28.60101365,24.15295874,,,,,,,,,
"summarize: def _check_graphviz_available(output_format):
    """"""""""""
    try:
        subprocess.call([""dot"", ""-V""], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    except OSError:
        print(
            ""The output format '%s' is currently not available.\n""
            ""Please install 'Graphviz' to have other output formats ""
            ""than 'dot' or 'vcg'."" % output_format
        )
        sys.exit(32)",check if we need graphviz for different output format,return available Check if the graphviz is available.,"return subprocess.PIPE, ""Graphviz"" Returns a GraphvizAVAIlable object.",34.533231,13.44932265,23.99127683,,,,,,,,,
"summarize: def unused_import_line_numbers(messages):
    """"""""""""
    for message in messages:
        if isinstance(message, pyflakes.messages.UnusedImport):
            yield message.lineno",Yield line numbers of unused imports.,", message.unused Encodes the Import Touch",else: yield message.lineno Make any messages and Unimports importing the Maybe.,28.28287467,19.62637353,23.9546241,,,,,,,,,
"summarize: def cat(self, i1, i2, format='html'):
        """"""
        """"""
        from IPython import display
        if format == 'html':
            output = self._as_html_table(i1, i2)
            display.display(display.HTML(output))
        else:
            output = self._as_table(i1, i2, format=format)
            print(output)",Display the DataFrame from row i1 till i2,Writes the IPython ip to a display ip.,return output Catalogue to create a list of displayed images from the provided images.,28.58670576,19.28949927,23.93810252,,,,,,,,,
"summarize: def _get_front_ids_one_at_a_time(onset_fronts):
    """"""
    
    """"""
    yielded_so_far = set()
    for row in onset_fronts:
        for id in row:
            if id != 0 and id not in yielded_so_far:
                yield id
                yielded_so_far.add(id)","Yields one onset front ID at a time until they are gone. All the onset fronts from a  frequency channel are yielded, then all of the next channel's, etc., though one at a time.","summarize: def _get_front_ids_one_at_a_time(onset_fronts): """""" """""" yielded_so_far = set() for row in onset_fronts: for id in row: if id!= 0 and id not in yielded_so_far: yield id yielded_so_far.add(id) yield id Get all of the fronts and return their set of the ones only to find their appropriate order.","summarize: def _get_front_ids_one_at_a_time(onset_fronts): """""" """""" yielded_so_far = set() for row in onset_fronts: for id in row: if id!= 0 and id not in yielded_so_far: yield id yielded_so_far.add(id) yield id Returns the front any front any elements of the given ones.",24.15373822,23.70416767,23.92895295,,,,,,,,,
"summarize: def numeric_date(dt=None):
    """"""
    

    """"""
    if dt is None:
        dt = datetime.datetime.now()

    try:
        res = dt.year + dt.timetuple().tm_yday / 365.25
    except:
        res = None

    return res","Convert datetime object to the numeric date.  The numeric date format is YYYY.F, where F is the fraction of the year passed",Gets the numeric date from the given date to the given date.,"This method u"""""" if res is None else dt.year Get the datetime information.",24.39832478,23.33627166,23.86729822,,,,,,,,,
"summarize: def transform(line, known_fields=ENRICHED_EVENT_FIELD_TYPES, add_geolocation_data=True):
    """"""
    
    """"""
    return jsonify_good_event(line.split('\t'), known_fields, add_geolocation_data)",Convert a Snowplow enriched event TSV into a JSON,Transform a transform into a list of Good Events.,Transform the API event to any user-tokens.,25.84267767,21.83293903,23.83780835,,,,,,,,,
"summarize: def detect_logging_level(self, node):
        """"""
        

        """"""
        try:
            if self.get_id_attr(node.func.value) == ""warnings"":
                return None
            # NB: We could also look at the argument signature or the target attribute
            if node.func.attr in LOGGING_LEVELS:
                return node.func.attr
        except AttributeError:
            pass
        return None",Heuristic to decide whether an AST Call is a logging call.,Detect an LoggingLevel Logger attributes.,"Delete a logging level, which are instead of the any default values.",19.37857292,28.26789012,23.82323152,,,,,,,,,
"summarize: def updates(self, offset=None):
        """"""
        """"""
        params = {}

        if offset:
            params[self.OFFSET] = offset

        response = self._call(self.UPDATES_METHOD, params)

        return response",Fetch the messages that a bot can read.,Gets the Messages for the given offset and returns them information,Get the UPDATES and returns the response.,24.82690806,22.78612415,23.80651611,,,,,,,,,
"summarize: def get_app_qt4(*args, **kwargs):
    """"""""""""
    from IPython.external.qt_for_kernel import QtGui
    app = QtGui.QApplication.instance()
    if app is None:
        if not args:
            args = ([''],)
        app = QtGui.QApplication(*args, **kwargs)
    return app",Create a new qt4 app or return an existing one.,Get an application for the given url.,Return a list of application on the application.,18.28217839,29.23218204,23.75718022,,,,,,,,,
"summarize: def sequence(s: Iterable) -> ISeq[Any]:
    """"""""""""
    try:
        i = iter(s)
        return _Sequence(i, next(i))
    except StopIteration:
        return EMPTY",Create a Sequence from Iterable s.,PE_ISO880 return i Sequence only only one sequence.,"PES[""ISEq""] List all empty prices.",23.69305576,23.76056931,23.72681254,,,,,,,,,
"summarize: def pretty_to_link(inst, link):
    '''
    
    '''
    values = ''
    prefix = ''
    metaclass = xtuml.get_metaclass(inst)

    for name, ty in metaclass.attributes:
        if name in link.key_map:
            value = getattr(inst, name)
            value = xtuml.serialize_value(value, ty)
            name = link.key_map[name]
            values += '%s%s=%s' % (prefix, name, value)
            prefix = ', '
                
    return '%s(%s)' % (link.kind, values)",Create a human-readable representation of a link on the 'TO'-side,Returns a list of links that are only accepted links on the given inst.,"Returns a valid link for a root, or the link.",28.44898044,18.9632827,23.70613157,,,,,,,,,
"summarize: def loadByteArray(self, page, returnError):
        """"""""""""
        returnError.contents.value = self.IllegalStateError
        raise NotImplementedError(""You must override this method."")
        return ''",Must be overridden. Must return a string with the loaded data.,Get the data of the given page and return it.,Return the byte about the byte about the page.,28.74910751,18.61373949,23.6814235,,,,,,,,,
"summarize: def DocFileSuite(*paths, **kw):
    """"""
    """"""
    suite = unittest.TestSuite()

    # We do this here so that _normalize_module is called at the right
    # level.  If it were called in DocFileTest, then this function
    # would be the caller and we might guess the package incorrectly.
    if kw.get('module_relative', True):
        kw['package'] = _normalize_module(kw.get('package'))

    for path in paths:
        suite.addTest(DocFileTest(path, **kw))

    return suite",A unittest suite for one or more doctest files.,Parses the first suite and returns a dictionary.,",'suite', kw Returns an item. This is the suite objects.",28.36730555,18.89335945,23.6303325,,,,,,,,,
"summarize: def patch(f):
    ''''''
    name = f.__name__
    Dataset.__hidden__[name] = f
    return f",Adds method f to the Dataset class,Retrieve a patch of the full names.,Datasets the function.,19.05295594,28.16589519,23.60942557,,,,,,,,,
"summarize: def info(self, **kwargs):
        """"""
        
        """"""
        path = self._get_id_path('info')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response",Get the basic movie information for a specific movie id.,Send an info to the info of the given action,Sets the requested info for the given requested request.,23.79696333,23.28647022,23.54171678,,,,,,,,,
"summarize: def check_response(self, response):
        """"""
        
        """"""
        try:
            response.raise_for_status()
        except requests.exceptions.HTTPError:
            self.log.error(""HTTP error: %s"", response.reason)
            if self.method not in ['GET', 'HEAD']:
                self.log.error(response.text)
            raise AirflowException(str(response.status_code) + "":"" + response.reason)",Checks the status code and raise an AirflowException exception on non 2XX or 3XX    status codes,except requests.exceptions.HTTPError: self.log.error(response.reason) raise GET return response Checks the GET response and returns an ID.,"except requests.exceptions.HTTPError as e: self.log.error(e.response.text) raise ArgumentError(""HTTP response: %s"", response.text) return response.json() Check if there is not already able to an authorized response.",30.33747177,16.72790743,23.5326896,,,,,,,,,
"summarize: def advance_robots(self):
        ''''''

        # move the robots towards the player
        self = lens.robots.Each().call_step_towards(self.player)(self)
        # robots in the same place are crashes
        self = lens.crashes.call_union(duplicates(self.robots))(self)
        # remove crashed robots
        self = lens.robots.modify(lambda r: list(set(r) - self.crashes))(self)

        return self",Produces a new game state in which the robots have advanced    towards the player by one step. Handles the robots crashing into    one another too.,.robots.add_crashed( [c for c in self if self.crashes.crashes.Each().crashes.Open()] ) Add the sorted robots to the given robots,"._register_robots(self.robots, self.robots, self.robots) Moves the robots on the robots.",27.21164122,19.84608651,23.52886387,,,,,,,,,
"summarize: def _buffered_send_metric(self, metric_str):
        """"""""""""

        self.batch_count += 1

        self.batch_buffer += metric_str

        # NOTE(romcheg): Send metrics if the number of metrics in the buffer
        #                has reached the threshold for sending.
        if self.batch_count >= self.batch_size:
            self._send()",Add a metric to the buffer.,return buffered_str Command to the buffered metrics.,if metric_str: self._send(metric_str) else: self._send(metric_str) Create metrics and send metrics of the single Median,37.7964473,9.22869358,23.51257044,,,,,,,,,
"summarize: def prepare(self, **kwargs):
        """"""  """"""
        for k, v in kwargs.items():
            setattr(self, k, v)
        if not self.is_initialized:
            self.initialize()
        if not self.proxy_is_active:
            self.activate_proxy()",Prepare for rendering,Proxy activate activation,self.activate_proxy() if not self.proxy: self.activate_proxy() Return a set of proxy values.,17.59884843,29.21654867,23.40769855,,,,,,,,,
"summarize: def executemany(self, operation, seq_of_parameters):
        """"""
        
        """"""
        for parameters in seq_of_parameters:
            self.execute(operation, parameters)",Execute a BigQuery query multiple times with different parameters.,"self.execute(operation, parameters) return True Execute modified sequence on the given operation.","return self.execute(self.execute(""SEQUEST"", ""Execute""), parameters) Make an execute another sequence of the given operation.",26.61490739,20.17728621,23.3960968,,,,,,,,,
"summarize: def replace(self, **kwargs):
        '''
        
        '''
        data = {
            'model': self._model,
            'filters': self._filters,
            'order_by': self._order_by,
            'limit': self._limit,
            'select': self._select,
        }
        data.update(**kwargs)
        return Query(**data)","Copy the Query object, optionally replacing the filters, order_by, or    limit information on the copy. This is mostly an internal detail that    you can ignore.","summarize: def replace(self, **kwargs): ''' ''' data = { 'model': self._model, 'filters': self._filters, 'order_by': self._order_by, 'limit': self._limit, 'select': self._select, } data.update(**kwargs) return Query(**data) Replaces the query action on the given kwargs","summarize: def replace(self, **kwargs): ''' ''' data = { 'model': self._model, 'filters': self._filters, 'order_by': self._order_by, 'limit': self._limit, 'select': self._select, } data.update(**kwargs) return Query(**data) Returns an object for the part of the ID of the given ID.",23.37233133,23.41377795,23.39305464,,,,,,,,,
"summarize: def _prepare_regex_pattern(self, p):
        """"
        if isinstance(p.pattern, bytes):
            p = re.compile(p.pattern.decode(self.encoding), p.flags)
        return p",Recompile bytes regexes as unicode regexes.,.decode(self.encoding) Prepare regex pattern to a regex pattern.,".replace('%s%s' % (p.pattern, p.pattern)) Returns the Pattern of the pattern.",24.91409705,21.83519336,23.37464521,,,,,,,,,
"summarize: def Alias(name, **metadata):
    """""" 

    """"""

    return Property(lambda obj: getattr(obj, name),
                    lambda obj, val: setattr(obj, name, val),
                    **metadata)",Syntactically concise alias trait but creates a pair of lambda  functions for every alias you declare.,"Alias property for a name, value in iteritems(metadata) Alias property for a lambda object.","Alias and lignments a light-quader. All of the components of the instances of an upper takens, and otherwise returns an alias.",26.64019907,20.03531156,23.33775532,,,,,,,,,
"summarize: def to_archive(self, writer):
        """"""
        
        """"""
        if 'b' not in writer.mode:
            raise GiraffeError(""Archive writer must be in binary mode"")
        writer.write(GIRAFFE_MAGIC)
        writer.write(self.columns.serialize())
        i = 0
        for n, chunk in enumerate(self._fetchall(ROW_ENCODING_RAW), 1):
            writer.write(chunk)
            yield TeradataEncoder.count(chunk)",Writes export archive files in the Giraffez archive format.    This takes a `giraffez.io.Writer` and writes archive chunks to    file until all rows for a given statement have been exhausted.,"yield GiraffeError(""Archive was not in binary mode"") yield GiraffeError(""Archive was not in binary mode"") yield self._fetchall(ROW_ENCODING_RAW, yield GIRAW, writer) Adds a list of all binary models to the given writer.",if chunk in writer: yield chunk else: writer.write(self._fetchall(ROW_ENCODING_RAW)) Writes the one single entrypoint.,29.14643259,17.40829186,23.27736223,,,,,,,,,
"summarize: def total_seconds(td):
    """"""""""""
    if hasattr(td, 'total_seconds'):
        return td.total_seconds()

    ms = td.microseconds
    secs = (td.seconds + td.days * 24 * 3600)
    return (ms + secs * 10**6) / 10**6",Python 2.6 compatability,0 Given the total seconds,.0 Calculate a seconds from the total total seconds.,24.26020486,22.21732561,23.23876524,,,,,,,,,
"summarize: def get_check():
    """"""""""""
    try:
        from invenio.dbquery import run_sql
    except ImportError:
        from invenio.legacy.dbquery import run_sql

    return (
        run_sql('select count(id) from bibdoc', run_on_slave=True)[0][0],
        [id[0] for id in run_sql('select id from bibdoc', run_on_slave=True)],
    )",Get bibdocs to check.,Get the checking bibdoc or a select id to an ``id``.,Returns a run_sql from an agent query with a sql.,28.3157858,18.1597383,23.23776205,,,,,,,,,
"summarize: def compute(self, *x):
        """"""
        
        """"""
        self._compile()
        outs = self._compute(*x)
        if self._output_keys:
            return MapDict(dict(zip(self._output_keys, outs)))
        else:
            return outs",Return network output.,Compute the output dict.,Returns a list of all Mapdual Dicts.,30.12378646,16.34083642,23.23231144,,,,,,,,,
"summarize: def read_latoolscfg():
    """"""
    
    """"""
    config_file = pkgrs.resource_filename('latools', 'latools.cfg')
    cf = configparser.ConfigParser()
    cf.read(config_file)
    return config_file, cf","Reads configuration, returns a ConfigParser object.",Read a latoolscf file and returns the latoolscfg.,g.read(config_file) Read a latool file in another LANGURM_MASPIS.,28.38234002,18.05841138,23.2203757,,,,,,,,,
"summarize: def report(self):
        """"""""""""

        print(
            self.report_message.format(
                service=self.service,
                host=self.host,
                port=self.port,
            )
        )
        sys.stdout.flush()",Report startup info to stdout.,Report the service service,sys.stdout.flush() sys.stdout.flush() Reports a system-form.,24.82118382,21.6083878,23.21478581,,,,,,,,,
"summarize: def _check_preferred_module(self, node, mod_path):
        """"""""""""
        if mod_path in self.preferred_modules:
            self.add_message(
                ""preferred-module"",
                node=node,
                args=(self.preferred_modules[mod_path], mod_path),
            )",check if the module has a preferred replacement,return node Checks the modules of the given node and add them to them in the preferred module.,return True if mod_path in self.preferred_modules: return True return False Returns True if an existing message is preferred in the given node.,28.8051726,17.5238718,23.1645222,,,,,,,,,
"summarize: def discovery_print(pkt):
    """"""
    """"""
    if pkt.src in mac_id_list:
        return
    mac_id_list.append(pkt.src)
    text = pkt_text(pkt)
    click.secho(text, fg='magenta') if 'Amazon' in text else click.echo(text)",Scandevice callback. Register src mac to avoid src repetition.  Print device on screen.,return mac_id_list Print a single prc to its prc to its read on the ``pkt``.,Discovery a package level of possible version of the specified package and possible ID level.,26.20453333,20.09375737,23.14914535,,,,,,,,,
"summarize: def stratified_kfold_column(self, n_folds=3, seed=-1):
        """"""
        
        """"""
        return H2OFrame._expr(
            expr=ExprNode(""stratified_kfold_column"", self, n_folds, seed))._frame()",Build a fold assignment column with the constraint that each fold has the same class    distribution as the fold column.,"Given a direction of the n_folds, return the post-level keys of the IP-plot fold",Returns the list of all fold_folds of the column column column column.,20.62074196,25.63888335,23.12981266,,,,,,,,,
"summarize: def REBINDING(self):
        """"""""""""
        logger.debug('In state: REBINDING')
        self.current_state = STATE_REBINDING
        if self.script is not None:
            self.script.script_init(self.client.lease, self.current_state)
            self.script.script_go()
        else:
            set_net(self.client.lease)",REBINDING state.,self.script = self.current_state.client_current_state self.send(self.client_current_state) Install REBINDING,self.current_state.reset() REBINDING,11.45895803,34.74031739,23.09963771,,,,,,,,,
"summarize: def network_to_pandas_hdf5(network, filename, rm_nodes=None):
    """"""
    

    """"""
    if rm_nodes is not None:
        nodes, edges = remove_nodes(network, rm_nodes)
    else:
        nodes, edges = network.nodes_df, network.edges_df

    with pd.HDFStore(filename, mode='w') as store:
        store['nodes'] = nodes
        store['edges'] = edges

        store['two_way'] = pd.Series([network._twoway])
        store['impedance_names'] = pd.Series(network.impedance_names)",Save a Network's data to a Pandas HDFStore.,return store Helper function to network.,store['rm_nodes'] = store.GetNetworkData(store) return store Pandas nodes are pandas hdf5 files.,25.21060274,20.84338668,23.02699471,,,,,,,,,
"summarize: def valid(self):
        """"""
        
        """"""

        if self.expiration_time:
            return self.expiration_time > int(time.time())
        else:
            return True","``True`` if credentials are valid, ``False`` if expired.",Validates the validation of the expiration time,Determine if any time is the valid value of the current time.,23.93880426,22.04868308,22.99374367,,,,,,,,,
"summarize: def discard(self, it: Signature) -> bool:
        """"""  """"""
        txt = it.internal_name()
        if txt in self._hsig:
            sig = self._hsig[txt]
            if isinstance(sig, Scope):
                sig.state = StateScope.LINKED
            del self._hsig[txt]
            return True
        return False",Remove it only if present,Discard the signature.,Discard any of the HSM states.,18.66316515,27.30375221,22.98345868,,,,,,,,,
"summarize: def make_multi_entry(plist, pkg_pyvers, ver_dict):
    """"""""""""
    for pyver in pkg_pyvers:
        pver = pyver[2] + ""."" + pyver[3:]
        plist.append(""Python {0}: {1}"".format(pver, ops_to_words(ver_dict[pyver])))",Generate Python interpreter version entries.,return plist Multis the Multi-entry for a Python passed in ver_dict.,return pyver Method to check that applies are a single MultiAPI.,23.7474783,22.13103461,22.93925646,,,,,,,,,
"summarize: def enumerate_resonance_smiles(smiles):
    """"""
    """"""
    mol = Chem.MolFromSmiles(smiles)
    #Chem.SanitizeMol(mol)  # MolFromSmiles does Sanitize by default
    mesomers = ResonanceEnumerator().enumerate(mol)
    return {Chem.MolToSmiles(m, isomericSmiles=True) for m in mesomers}","Return a set of resonance forms as SMILES strings, given a SMILES string.",Returns the number of smiles that were the same resonance.,Gets a dictionary of enumerated resonances.,27.00214862,18.80805651,22.90510257,,,,,,,,,
"summarize: def clone(self, url):
        """"""""""""
        return self.execute(""%s branch %s %s"" % (self.executable,
                                                 url, self.path))",Clone repository from url.,Create a new JSON limit.,Create a URL of the project id.,22.10490292,23.67558944,22.89024618,,,,,,,,,
"summarize: def require_setting(self, name, feature=""this feature""):
        """"""""""""
        if name not in self.settings:
            raise Exception(""You must define the '%s' setting in your ""
                            ""application to use %s"" % (name, feature))",Raises an exception if the given app setting is not defined.,self.settings[name] = value Sets a setting to the feature.,"self.setting(name, feature) return self.setting(name, feature) Require the setting on the annotation of the callback.",26.91471586,18.84491043,22.87981315,,,,,,,,,
"summarize: def copy(self):
        """"""""""""
        return Striplog([i.copy() for i in self],
                        order=self.order,
                        source=self.source)",Returns a shallow copy.,Populates a order and returns a list of coordinates.,Gets the current by its stripbacks.,19.82266219,25.8698973,22.84627975,,,,,,,,,
"summarize: def to_python_package(classes, target_folder, parent_package=None, indent=DEFAULT_INDENT):
    '''
    
    '''
    PackageBuilder(target_folder, parent_package, indent).from_classes_with_refs(classes)",This function can be used to build a python package representation of pyschema classes.  One module is created per namespace in a package matching the namespace hierarchy.,"classes.package(target_folder, parent_package, indent) return classes Creates a package from the package builder.",return _to_python_package(classes) Turns a package builder for the package builder.,27.30812508,18.38415587,22.84614048,,,,,,,,,
"summarize: def _convert_boolean_config_value(config, name, default=True):
        """"""

        """"""
        if name not in config:
            config[name] = default
        elif config[name] == ""yes"":
            config[name] = True
        elif config[name] == ""no"":
            config[name] = False
        else:
            raise ValueError(""Error in config file\nInvalid value for %s ""
                             ""parameter\nPossible values: yes, no"" % name)",Convert the named field to bool.,return config Converts the config file to the config file.,return config Get an existing values from a config-type.,23.52464323,22.04239951,22.78352137,,,,,,,,,
"summarize: def default_formatter(error):
    """"""""""""
    quoted = formencode.htmlfill.escape_formatter(error)
    return u'<span class=""error-message"">{0}</span>'.format(quoted)","Escape the error, and wrap it in a span with class ``error-message``",Default `event-message` to be found for the given url,Get a Unicode quoted by ``error`` if a valid ``error``.,23.3781541,22.13086917,22.75451164,,,,,,,,,
"summarize: def restore_context(self) -> bool:
        """"""""""""
        self._cursor.position = self._contexts.pop()
        return False",Rollback to previous saved position.,Restore a role for a given role.,Restore the position of the specified source,17.53728625,27.79300435,22.6651453,,,,,,,,,
"summarize: def to_python(self, data):
        """"""""""""
        if data is not None:
            if hasattr(data, 'open'):
                data.open()
            return super(VersatileImageFormField, self).to_python(data)",Ensure data is prepped properly before handing off to ImageField.,else: return data Convert to python image to a view of images,"else: return super(ApiImageFormForm, self).to_python(data, data) API key field.",23.12142858,22.18295724,22.65219291,,,,,,,,,
"summarize: def basic(username, password):
    """"""""""""
    none()
    _config.username = username
    _config.password = password",Add basic authentication to the requests of the clients.,try: _config.password = password except: _config.password = password _config.password = password return _config.password Add an authentication to the given password.,return _config Returns the basic page of a given username.,18.0592773,27.23225564,22.64576647,,,,,,,,,
"summarize: def groupedby(collection, fn):
    """"""
    
    """"""
    d = {}
    for item in collection:
        k = fn(item)
        try:
            arr = d[k]
        except KeyError:
            arr = []
            d[k] = arr
        arr.append(item)

    yield from d.items()",same like itertools.groupby,return d Grouped by item.,return d Get duplicates of duplicates from the collection,21.84440585,23.43396783,22.63918684,,,,,,,,,
"summarize: def cssselect(self, expr, translator='html'):
        """"""
        
        """"""
        # Do the import here to make the dependency optional.
        from lxml.cssselect import CSSSelector
        return CSSSelector(expr, translator=translator)(self)","Run the CSS expression on this element and its children,    returning a list of the results.",Create a new CSSSelector and return the dependency optional CSSelector.,Returns the import relational based on the application,25.48419841,19.73842457,22.61131149,,,,,,,,,
"summarize: def RegisterFreeformKey(cls, key, name, mean=b""com.apple.iTunes""):
        """"""
        """"""
        atomid = b""----:"" + mean + b"":"" + name

        def getter(tags, key):
            return [s.decode(""utf-8"", ""replace"") for s in tags[atomid]]

        def setter(tags, key, value):
            tags[atomid] = [utf8(v) for v in value]

        def deleter(tags, key):
            del(tags[atomid])

        cls.RegisterKey(key, getter, setter, deleter)",Register a text key.,return deleter Register the Atom against an atom ID.,return deleter Register for a given key and keys.,19.05614126,26.04760668,22.55187397,,,,,,,,,
"summarize: def get(self, log_set):
        """"""
        
        """"""
        response = requests.get(self.base_url + log_set.rstrip('/'))

        if not response.ok:
            raise ServerException(
                '{}: {}'.format(response.status_code, response.text))
        return response.json()",Get a specific log or log set,Returns the action processor.,Returns an element with the given response.,19.88289391,25.20122228,22.5420581,,,,,,,,,
"summarize: def get_thumbnail():
    '''
    '''
    from sregistry.defaults import SREGISTRY_THUMBNAIL
    if SREGISTRY_THUMBNAIL is not None:
        if os.path.exists(SREGISTRY_THUMBNAIL):
            return SREGISTRY_THUMBNAIL
    return ""%s/database/robot.png"" %get_installdir()","return the robot.png thumbnail from the database folder.    if the user has exported a different image, use that instead.",Returns the sregistravity database file for this directory.,Get the robot. The passed robot service is always `SREGISTRY_THUMBNAIL`. Returns the service based on the same robot.,16.26112864,28.79572458,22.52842661,,,,,,,,,
"summarize: def print_usage(self, file=None):
        """"""
        
        """"""
        optparse.OptionParser.print_usage(self, file)
        file.flush()","Outputs usage information to the file if specified, or to the    io_manager's stdout if available, or to sys.stdout.","Print the file to the file and return it as a URL, otherwise the file is the same file with any files that are not provided.","self.connect(file) self.close() self.cache.set_current(file) self.cache_update(file) Write a file, using the file in the file.",23.64238227,21.31800677,22.48019452,,,,,,,,,
"summarize: def _get_ssl(self):
        """"""""""""
        return smtplib.SMTP_SSL(
            self.server, self.port, context=ssl.create_default_context()
        )",Get an SMTP session with SSL.,Gets the ssl to the specified server.,Returns the SMTP server.,15.63454877,29.29190765,22.46322821,,,,,,,,,
"summarize: def shutdown(self, cancel=False, cancel_msg=''):
        """"""
        """"""
        self._shutdown(cancel, cancel, cancel_msg)",Shutdown the TransferManager,Shutdown a new event.,"self._shutdown(cancel, cancel_msg) Sets a cancel on any cancel.",31.99730295,12.90091356,22.44910826,,,,,,,,,
"summarize: def _clean_signal_meta(self):
        """"""
        
        """"""
        self._enclosed_for = None
        self._sensitivity = None
        for stm in self._iter_stms():
            stm._clean_signal_meta()",Clean informations about enclosure for outputs and sensitivity    of this statement,self._sensitivity = stm self._sensitivity = sensitivity return stm Clean the meta of the signal meta.,self._signal_meta_models() Clean meta of the signal meta.,28.81809788,16.03576943,22.42693366,,,,,,,,,
"summarize: def open_graph(self, **args):
        """"""
        """"""
        self._stream.write(""%sgraph:{\n"" % self._indent)
        self._inc_indent()
        self._write_attributes(GRAPH_ATTRS, **args)",open a vcg graph,Opens the given graph.,Load a single GRAM Fields.,32.13439058,12.62994071,22.38216565,,,,,,,,,
"summarize: def add_hook(self, sequence, h):
    """"""""""""
    sequence.parser_tree = parsing.Hook(h.name, h.listparam)
    return True",Create a tree.Hook,Adds a sequence to the hook.,Adds an item to another case.,19.44185723,25.30041599,22.37113661,,,,,,,,,
"summarize: def _api_delete(self, url, **kwargs):
        """"""
        
        """"""
        response = self.session.delete(
            url=url,
            headers=self._get_api_headers(),
            **kwargs
        )
        if not response.ok:
            raise ServerException(
                '{0}: {1}'.format(
                    response.status_code,
                    response.text or response.reason
                ))
        return response",Convenience method for deleting,Retrieve a delete and return a json session,.json() Retrieve a url and return any response.,18.08447455,26.62251553,22.35349504,,,,,,,,,
"summarize: def process_response(self, request, response):
        """"""
        
        """"""
        if hasattr(request, ""session"") and hasattr(request, ""user"") and request.user.is_authenticated():
            msgs = get_messages(request.user)
            if msgs:
                for msg, level in msgs:
                    messages.add_message(request, level, msg)
        return response","Check for messages for this user and, if it exists,    call the messages API with it",Returns the messages of the `request` to the `request`.,Encodes a request and receives the request to the MSG. This is received and the user is level.,22.21724686,22.43207228,22.32465957,,,,,,,,,
"summarize: def In(sigOrVal, iterable):
    """"""
    
    """"""
    res = None
    for i in iterable:
        i = toHVal(i)
        if res is None:
            res = sigOrVal._eq(i)
        else:
            res = res | sigOrVal._eq(i)

    assert res is not None, ""Parameter iterable is empty""
    return res","Hdl convertible in operator, check if any of items  in ""iterable"" equals ""sigOrVal""",Initialize the input signals into a list of iterables.,Returns a sigOrValidDict if the sigOrder is valid or more signals.,25.58718026,19.05216203,22.31967115,,,,,,,,,
"summarize: def enum(*sequential, **named):
    """"""
    
    """"""
    #: build enums from parameter
    enums = dict(zip(sequential, range(len(sequential))), **named)
    enums['map'] = copy.copy(enums)
    #: build reverse mapping
    enums['rmap'] = {}
    for key, value in enums.items():
        if type(value) is int:
            enums['rmap'][value] = key
    return type('Enum', (), enums)",Build an enum statement,Enums enum dataset to enum,Returns the enumerated supplied enums.,27.04657013,17.54843349,22.29750181,,,,,,,,,
"summarize: def tv(self, **kwargs):
        """"""
        
        """"""
        path = self._get_path('tv')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response",Search for TV shows by title.,This method is only valid.,.text Create an ID to another type.,19.74678246,24.83987672,22.29332959,,,,,,,,,
"summarize: def do_BESTSCORE(self, word):
        """"""""""""
        key = keys.token_key(indexed_string(word)[0])
        for _id, score in DB.zrevrange(key, 0, 20, withscores=True):
            result = Result(_id)
            print(white(result), blue(score), green(result._id))",Return document linked to word with higher score.    BESTSCORE lilas,return result Do BESTSCORE DO BESTSCORE DO BESTSCORE DO BESTSCORE,# add a blue if not self._has_key(score): return return None Do the Generator.,26.68291285,17.73661767,22.20976526,,,,,,,,,
"summarize: def expire(self, age):
        """"""""""""
        now = time.time()
        cache = self._acquire_cache()
        
        expired = [k for k, v in cache.items() if (now - v[0]) > age]

        for k in expired:
            if k in cache:
                del cache[k]
            if k in self.store:
                del self.store[k]

        self._write_cache(cache)",Expire any items in the cache older than `age` seconds,self._write_cache(cache) Expires a session to updates the given age.,self.store.set_current_cache(now) Load a valid Java Generating Cache and the description.,27.55628876,16.79787248,22.17708062,,,,,,,,,
"summarize: def list_logs(args, container_name=None):
    '''

    '''
    from sregistry.main import Client as cli    
    if len(args.commands) > 0:
        container_name = args.commands.pop(0)
    cli.logs(container_name)
    sys.exit(0)","list a specific log for a builder, or the latest log if none provided",return container_name Load a logs to the logs to the given name.,return logs List a list of system names on the script.,20.48735533,23.83245708,22.15990621,,,,,,,,,
"summarize: def get_v_merge(tc):
    """"""
    
    """"""
    if tc is None:
        return None
    v_merges = tc.xpath('.//w:vMerge', namespaces=tc.nsmap)
    if len(v_merges) != 1:
        return None
    v_merge = v_merges[0]
    return v_merge","vMerge is what docx uses to denote that a table cell is part of a rowspan.  The first cell to have a vMerge is the start of the rowspan, and the vMerge  will be denoted with 'restart'. If it is anything other than restart then  it is a continuation of another rowspan.","summarize: def get_v_merge(tc): """""" """""" if tc is None: return None v_merges = tc.xpath('.//w:vMerge', namespaces=tc.nsmap) if len(v_merges)!= 1: return None v_merge = v_merges[0] return v_merge Returns an iterator of merges for the given tc and a list of variables to the specified tc.","summarize: def get_v_merge(tc): """""" """""" if tc is None: return None v_merges = tc.xpath('.//w:vMerge', namespaces=tc.nsmap) if len(v_merges)!= 1: return None v_merge = v_merges[0] return v_merges Returns a list of v_merges of the v_merges in a tc.",25.08576555,19.19224699,22.13900627,,,,,,,,,
"summarize: def _parse_long(cls, data):
        """"""""""""
        if sys.version < '3':
            # this does not exist in python 3 - undefined-variable disabled to make pylint happier.
            ret = long(0)  # pylint:disable=undefined-variable
            for byte in data:
                ret = (ret << 8) + ord(byte)
        else:
            ret = 0
            for byte in data:
                ret = (ret << 8) + byte
        return ret",Calculate two's complement.,Parse Location Location.,The long class of the pylint about the long.,18.16275315,26.09951775,22.13113545,,,,,,,,,
"summarize: def parse_issues(raw_page):
        """"""
        """"""
        raw_issues = json.loads(raw_page)
        issues = raw_issues['issues']
        for issue in issues:
            yield issue",Parse a JIRA API raw response.,yield issue return yield issues Parse a raw ISO-DataSpec,return issues Returns the issues of the issues.,22.23858255,22.01415566,22.12636911,,,,,,,,,
"summarize: def vectorize_target(self, size):
        """"""
        
        """"""
        if self._train_set:
            self._train_set = self._vectorize_set(self._train_set, size)
        if self._valid_set:
            self._valid_set = self._vectorize_set(self._valid_set, size)
        if self._test_set:
            self._test_set = self._vectorize_set(self._test_set, size)",Make targets be one-hot vectors.,return self._train_set Vectories the vectories to be valid.,return self._train_set Get the data from the given size.,18.82577249,25.35235933,22.08906591,,,,,,,,,
"summarize: def begin(self, total: int, name=None, message=None):
        """"""""""""
        self.total = total
        message = message or name or ""Working...""
        self.name = name or ""ProgressMonitor""
        self.update(0, message)","Call before starting work on a monitor, specifying name and amount of work","self.update(0, message) return self Get the buffer and write a total to the name.","if message is None: message = message or ""Unknown message"" self.message = message return message This method uses the ``total``.",18.14293282,26.03317908,22.08805595,,,,,,,,,
"summarize: def generate_signature(payload, secret):
    ''''''
    payload = _encode(payload)
    secret = _encode(secret)
    return hmac.new(secret, digestmod=hashlib.sha256,
                    msg=payload).hexdigest()",use an endpoint specific payload and client secret to generate  a signature for the request,.hexdigest() Generate a signature in server,Generates signature for the given payload.,19.50638242,24.62814409,22.06726326,,,,,,,,,
"summarize: def get(self, name):
        """"""
        
        """"""
        ws_list = self.list()
        return ws_list[name] if name in ws_list else None",Get workspace infos from name.    Return None if workspace doesn't exists.,"Returns the given name. If it is a list of names, it returns the given names.",Returns the ws list of the names and accessing the names of the ws_list.,22.89563701,21.1792659,22.03745146,,,,,,,,,
"summarize: def _convert_date(date_string, date_format):
    """"""
    
    """"""
    if date_format != 'epoch':
        return datetime.strptime(date_string, date_format).timestamp()
    else:
        return float(date_string)",Convert a date in a given format to epoch time. Mostly a wrapper for  datetime's strptime.,"summarize: def _convert_date(date_string, date_format): """""" """""" if date_format!= 'epoch': return datetime.strptime(date_string, date_format).timestamp() else: return float(date_string) Convert a time into a date string to a date string.","summarize: def _convert_date(date_string, date_format): """""" """""" if date_format!= 'epoch': return datetime.strptime(date_string, date_format).timestamp() else: return float(date_string) Convert a datetime string into datetime object.",22.84935421,21.20953899,22.0294466,,,,,,,,,
"summarize: def already_used(self, tok):
        """"""""""""
        if tok in self.jwts:
            return True
        self.jwts[tok] = time.time()
        return False",has this jwt been used?,Gets a new jwt JWT tokens,Get already already used by jwts,21.34320794,22.7084735,22.02584072,,,,,,,,,
"summarize: def send(self, data, force=False):
        """"""
        """"""
        if self._registered or force:
            self._sock_file.write('%s\r\n' % data)
            self._sock_file.flush()
        else:
            self._out_buffer.append(data)","\    Send raw data over the wire if connection is registered. Otherewise,    save the data to an output buffer for transmission later on.    If the force flag is true, always send data, regardless of    registration status.",Sends a newly sending to the data and returns a new data and returns the data into the data to the data.,self._sock_file.flush() self._sock_file.flush() self._registered = True self._out_buffer.send(data) self._download_file.write('\r\n') self._out_buffer.set_bool_size(data) Send a message to the data and updates data.,17.22556641,26.7418743,21.98372036,,,,,,,,,
"summarize: def add_bind(self, sequence, cpt):
    """"""""""""
    cpt_value = self.value(cpt)
    sequence.parser_tree = parsing.Bind(cpt_value, sequence.parser_tree)
    return True",Create a tree.Bind,Add a sequence to the binding,Add an instance of the cpt.,18.34656767,25.61337612,21.9799719,,,,,,,,,
"summarize: def handle(self, line_info):
        """"""""""""
        ifun    = line_info.ifun
        the_rest = line_info.the_rest
        cmd = '%sget_ipython().magic(%r)' % (line_info.pre_whitespace,
                                                    (ifun + "" "" + the_rest))
        return cmd",Execute magic functions.,Command line arguments,This is a component to the Manager.,20.74482593,23.11610998,21.93046796,,,,,,,,,
"summarize: def now_playing(self, **kwargs):
        """"""
        
        """"""
        path = self._get_path('now_playing')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response",Get the list of movies playing in theatres. This list refreshes    every day. The maximum number of items this list will include is 100.,Get the following playing from the server and return the results to the now.,.post(response.text) Get the playing playing of the playing playing playing playing playing and returns the current Viewer.,19.18134623,24.62333764,21.90234194,,,,,,,,,
"summarize: def f_lock_parameters(self):
        """"""""""""
        for par in self._parameters.values():
            if not par.f_is_empty():
                par.f_lock()",Locks all non-empty parameters,return par.f_lock() Get front empty locks for a lock of the specified parameters.,return False Find an List of parameters for the given page ID.,23.52534442,20.2390711,21.88220776,,,,,,,,,
"summarize: def label(self, name):
        """"""
        """"""
        if isinstance(name, str):
            self._label = name
        else:
            raise TypeError('label expects a string')",Set snapshot label to name,return self._label.labels[name] Lists a label name from a name.,Return a label of the given name instance.,17.39993557,26.20727432,21.80360495,,,,,,,,,
"summarize: def _wait_for_outputs(self, timeout=-1):
        """"""
        """"""
        if not self._success:
            # don't wait on errors
            return
        tic = time.time()
        while not all(md['outputs_ready'] for md in self._metadata):
            time.sleep(0.01)
            self._client._flush_iopub(self._client._iopub_socket)
            if timeout >= 0 and time.time() > tic + timeout:
                break",wait for the 'status=idle' message that indicates we have all outputs,return timeout Wait for the metadata if needed.,return timeout Logging all serversing the timeouts of the received timeout.,23.74159628,19.80505839,21.77332734,,,,,,,,,
"summarize: def remove_pid_file(self):
        """"""
        """"""
        pid_file = os.path.join(self.profile_dir.pid_dir, self.name + u'.pid')
        if os.path.isfile(pid_file):
            try:
                self.log.info(""Removing pid file: %s"" % pid_file)
                os.remove(pid_file)
            except:
                self.log.warn(""Error removing the pid file: %s"" % pid_file)",Remove the pid file.,return False return False return False Remove a pid file from the profile,"return self.log.info(""Removing pid file: %s"" % pid_file) Remove pid file.",22.84385653,20.69119621,21.76752637,,,,,,,,,
"summarize: def rehighlightBlock(self, block):
        """""" 
        """"""
        old = self.highlighting_on
        self.highlighting_on = True
        super(FrontendHighlighter, self).rehighlightBlock(block)
        self.highlighting_on = old",Reimplemented to temporarily enable highlighting if disabled.,self.highlighting_on = False Rehighlighlight Block,.highlighting_on return self.highlighting_on Returns the current old block of the supplied block.,23.5446585,19.85249646,21.69857748,,,,,,,,,
"summarize: def RAMON(typ):
        """"""
        
        """"""
        if six.PY2:
            lookup = [str, unicode]
        elif six.PY3:
            lookup = [str]

        if type(typ) is int:
            return _ramon_types[typ]
        elif type(typ) in lookup:
            return _ramon_types[_types[typ]]","Takes str or int, returns class type",else: return lookup[0] Returns the integer types of a tuples.,else: return _ramon_types[typ] Returns a six identifier in a LinuxifyTable Linuxifying types of the given six.,27.74477373,15.55331956,21.64904665,,,,,,,,,
"summarize: def _edges_replaced(self, object, name, old, new):
        """""" 
        """"""
        self._delete_edges(old)
        self._add_edges(new)",Handles a list of edges being set.,return new Returns a list of two objects,self._add_edges(old) return new Returns the relative name.,32.62198759,10.45799502,21.53999131,,,,,,,,,
"summarize: def without_apps(*apps):
    """"""
    
    """"""
    apps_list = [a for a in settings.INSTALLED_APPS if a not in apps]
    return override_settings(INSTALLED_APPS=apps_list)",Class decorator that makes sure the passed apps are not present in  INSTALLED_APPS.,Loads an apps list of apps and returns a list of ones of the apps.,Generate a plugin created apps for the apps instantiated apps.,18.66840936,24.32543517,21.49692227,,,,,,,,,
"summarize: def delall(self, key):
        """"""""""""
        if key in self:
            del(self[key])
        else:
            key = key + "":""
            for k in self.keys():
                if k.startswith(key):
                    del(self[k])",Delete all tags of a given kind; see getall.,"return del(self) Deletes an element of the given key, its `key` and `key` is `key`.",return self Dell(key) Delete the delta and add a single key.,21.94358524,20.90324462,21.42341493,,,,,,,,,
"summarize: def interrupt_kernel(self, kernel_id):
        """"""""""""
        self._check_kernel_id(kernel_id)
        super(MappingKernelManager, self).interrupt_kernel(kernel_id)
        self.log.info(""Kernel interrupted: %s"" % kernel_id)",Interrupt a kernel.,return kernel_id Internal method for interrupt kernel.,return self._interrupt_kernel(kernel_id) Returns the All kernel id of the Kernel object.,28.64078578,14.06135075,21.35106827,,,,,,,,,
"summarize: def update_site_forward(apps, schema_editor):
    """"""""""""
    Site = apps.get_model(""sites"", ""Site"")
    Site.objects.update_or_create(
        id=settings.SITE_ID,
        defaults={
            ""domain"": ""{{cookiecutter.domain_name}}"",
            ""name"": ""{{cookiecutter.project_name}}"",
        },
    )",Set site domain and name.,Initialize the site site.,return Site updates a Json-forward site.,24.00433567,18.62616741,21.31525154,,,,,,,,,
"summarize: def set_exception(self, exception, override=False):
        """"""
        """"""
        with self._lock:
            if not self.done() or override:
                self._exception = exception
                self._status = 'failed'",Set an exception for the TransferFuture,self._lock.set_exception(exception) Set an error message of the given exception.,else: self._status = None self._exception = exception return self._status Get the error and return the error. This function is an error message.,27.30970619,15.26342089,21.28656354,,,,,,,,,
"summarize: def parents(self):
        """"""""""""
        assert self.parent is not self
        if self.parent is None:
            return []
        return [self.parent] + self.parent.parents()",return the ancestor nodes,Returns a list of parents for the parents.,Returns all parents of another parents.,23.62750526,18.92091014,21.2742077,,,,,,,,,
"summarize: def difference(self, sig: Scope) -> Scope:
        """"""  """"""
        new = Scope(sig=self._hsig.values(), state=self.state)
        new -= sig
        return new",Create a new Set produce by a Set subtracted by another Set,Returns a new difference found in the size of the size of the specified size.,Returns a difference of a difference of the current state.,16.18811809,26.32684048,21.25747929,,,,,,,,,
"summarize: def run_show_val(obj, name):
    """"""""""""
    val = obj.debugger.settings[obj.name]
    obj.msg(""%s is %s."" % (obj.name, obj.cmd.proc._saferepr(val),))
    return False",Generic subcommand value display,Shows the command and returns a new one.,Log a processing items of the Viewer level.,22.54853263,19.79881866,21.17367565,,,,,,,,,
"summarize: def __dict_invert(self, data):
        """"""
        """"""
        outdict = {}
        for k,lst in data.items():
            if isinstance(lst, str):
                lst = lst.split()
            for entry in lst:
                outdict[entry] = k
        return outdict",Helper function for merge.,Generates invert from `data`.,Generate a data Interface instance,19.61594889,22.70186468,21.15890679,,,,,,,,,
"summarize: def print_help(self, file=None):
        """"""
        
        """"""
        optparse.OptionParser.print_help(self, file)
        if self.raw_epilog:
            file.write(self.raw_epilog)
        file.flush()","Outputs help information to the file if specified, or to the    io_manager's stdout if available, or to sys.stdout.",if self.final_file: file.write(self.final_file) return optparse Helper function to start without ready to source file.,self.parse_file(file) return optparse Character for specified option,25.38449639,16.89564616,21.14007128,,,,,,,,,
"summarize: def get_placeholder(self, value=None, compiler=None, connection=None):
        """"""""""""
        return self.encrypt_sql.format(get_setting(connection, 'PUBLIC_PGP_KEY'))",Tell postgres to encrypt this field using PGP.,.json() Gets the LDAP instance for the specified value.,Returns a placeholder connection instance.,15.8656833,26.27780619,21.07174475,,,,,,,,,
"summarize: def read_eol(self) -> bool:
    """"""""""""
    if self.read_eof():
        return False
    self._stream.save_context()
    self.read_char('\r')
    if self.read_char('\n'):
        return self._stream.validate_context()
    return self._stream.restore_context()",Return True if the parser can consume an EOL byte sequence.,Read the context of the context of a boolean eol.,Read eol byte or end of the editing the end of the index.,18.93403649,23.10791838,21.02097744,,,,,,,,,
"summarize: def key(self):
        """"""
        
        """"""
        return self.dag_id, self.task_id, self.execution_date, self.try_number",Returns a tuple that identifies the task instance uniquely,Returns the given value of the task_id.,", self.try_branch_page(self.try_branch_page) Add any execution branches to the given keyword argument.",31.16268081,10.84570923,21.00419502,,,,,,,,,
"summarize: def uncache_zipdir(path):
    """"""""""""
    from zipimport import _zip_directory_cache as zdc
    _uncache(path, zdc)
    _uncache(path, sys.path_importer_cache)",Ensure that the importer caches dont have stale info for `path`,"return _uncache(path, sys.path_importer_cache) Uncache a directory and creates a zip directory","_uncache_exists(path) Gets the directory_cache_path, create a zipdir.",21.23158119,20.77375924,21.00267022,,,,,,,,,
"summarize: def map(self, key, func, *args, **kwargs):
        """"""
        """"""
        self._map.append((key, partial(func, *args, **kwargs)))",Creates a key-function mapping.,return self Map a function to the given function,return self._mapping(func) Map a Map-key-formatted key and returns the keys of keys.,23.07864037,18.8498574,20.96424889,,,,,,,,,
"summarize: def edges(self, nodes=None):
        """"""
        """"""
        for source_node, dest_node, edge_data in self._multi_graph.edges(nodes, data=True):
            yield source_node, dest_node, edge_data",Iterator for node values.,Yields the given nodes,Edges a list of nodes.,19.8259084,22.08028915,20.95309878,,,,,,,,,
"summarize: def load_python_global(module, name):
    """"""
    
    """"""

    # The builtin module has been renamed in python3
    if module == '__builtin__' and six.PY3:
        module = 'builtins'
    module = importlib.import_module(module)
    return getattr(module, name)",Evaluate an OpenMath symbol describing a global Python object,Load a global from a dictionary.,Get the python global builtins from a python 2.,15.69591653,25.89460308,20.79525981,,,,,,,,,
"summarize: def report_similarities(sect, stats, old_stats):
    """"""""""""
    lines = ["""", ""now"", ""previous"", ""difference""]
    lines += table_lines_from_stats(
        stats, old_stats, (""nb_duplicated_lines"", ""percent_duplicated_lines"")
    )
    sect.append(Table(children=lines, cols=4, rheaders=1, cheaders=1))",make a layout with some stats about duplication,return lines Gets the ``stats`` and ``stats``.,"return sect, stats Returns a simulation sorted stats.",15.21247758,26.30714263,20.75981011,,,,,,,,,
"summarize: def get_td_at_index(tr, index):
    """"""
    
    """"""
    current = 0
    for td in tr.xpath('.//w:tc', namespaces=tr.nsmap):
        if index == current:
            return td
        current += get_grid_span(td)","When calculating the rowspan for a given cell it is required to find all  table cells 'below' the initial cell with a v_merge. This function will  return the td element at the passed in index, taking into account colspans.",return current Get a transpan and return a transpan index for the given td and return an iterable for the given transpan.,"current += 1 current += 1 return current This function called which is a bug, please add a new attribute about the current tree.",21.12739297,20.26429326,20.69584312,,,,,,,,,
"summarize: def filter_queryset(self, value, queryset):
        """"""""""""
        return super(UniqueEmailValidator, self).filter_queryset(
            value.lower(),
            queryset,
        )",Check lower-cased email is unique.,Filter an email queryset.,Return a queryset queryset from the supplied key,24.73938243,16.57318816,20.6562853,,,,,,,,,
"summarize: def split_model_kwargs(kw):
    """"""
    
    """"""
    from collections import defaultdict
    
    model_fields = {}
    fields_agrs = defaultdict(lambda : {})
    
    for key in kw.keys():
        if '__' in key:
            field, _, subfield = key.partition('__')
            fields_agrs[field][subfield] = kw[key]
        else:
            model_fields[key] = kw[key]

    return model_fields, fields_agrs",django_any birds language parser,Convert model_dict to a kwarg.,", fields_agrs Returns a splittle of model identifier.",15.74235387,25.46935185,20.60585286,,,,,,,,,
"summarize: def __create_db_and_container(self):
        """"""""""""
        db_id = self.config.database
        container_name = self.config.container
        self.db = self.__get_or_create_database(self.client, db_id)
        self.container = self.__get_or_create_container(
            self.client, container_name
            )",Call the get or create methods.,return db_id Create a new DB with the given db_id,return db_id Generate a configured db or return the ID.,22.59250193,18.60148444,20.59699319,,,,,,,,,
"summarize: def failure(self):
        """"""""""""
        self.short_interval += self.short_unit
        self.long_interval += self.long_unit
        self.short_interval = min(self.short_interval, self.max_short_timer)
        self.long_interval = min(self.long_interval, self.max_long_timer)
        self.update_interval()",Update the timer to reflect a failed call,Failure the failure of a timer.,"self.short_interval += self.short_interval self.short_interval += 1 self.short_interval += 1 self.short_interval = max(self.short_interval, self.short_interval) self.short_interval += 1 self.short_interval = max(self.short_interval + self.short_interval) self.short_interval += self.short_interval self.short_interval += self.short_interval + self.short_interval self.short_interval += self.short_interval self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.short_interval += 1 self.sh",34.91887973,6.008953664,20.4639167,,,,,,,,,
"summarize: def calcPF(pf):
        """""" 
        """"""
        pf_y = pf[:1]
        pf_x = pf[1:]
        result = 100
        if pf_y == CosTheta.CapacitiveLead:
            result = 200 - int(pf_x)
        elif pf_y == CosTheta.InductiveLag:
            result = int(pf_x)

        return result",Simple wrap to calc legacy PF value,Attempts to calculate the pf_y points for an InductiveLead.,Returns the correct point likelihood.,16.65267858,24.2179152,20.43529689,,,,,,,,,
"summarize: def save_variable_bigdl(tensors, target_path, bigdl_type=""float""):
    """"""
    
    """"""
    import numpy as np
    jtensors = {}
    for tn in tensors.keys():
        if not isinstance(tensors[tn], np.ndarray):
            value = np.array(tensors[tn])
        else:
            value = tensors[tn]
        jtensors[tn] = JTensor.from_ndarray(value)
        
    callBigDlFunc(bigdl_type, ""saveTensorDictionary"", jtensors, target_path)","Save a variable dictionary to a Java object file, so it can be read by BigDL",Save the save and save the numpy array to a tensor,return tensors Compute a save type of the saved variables.,18.59711315,22.16258999,20.37985157,,,,,,,,,
"summarize: def prune(self, leaves, inverse=False):
        """"""
        
        """"""
        self.visit(
            lambda n: n.ancestor.descendants.remove(n),
            # We won't prune the root node, even if it is a leave and requested to
            # be pruned!
            lambda n: ((not inverse and n in leaves) or
                       (inverse and n.is_leaf and n not in leaves)) and n.ancestor,
            mode=""postorder"")","Remove all those nodes in the specified list, or if inverse=True,    remove all those nodes not in the specified list. The specified nodes    must be leaves and distinct from the root node.","return self.visit(leaves, leaves, self.visit) Prune a list of nodes that are read and then append them to the leaves.","return self._process_event( ""PROTOR"", self.visit( ""DELETE"", ""UPDATE"", ""PROTOR"", ""VERSION"", ""POSTRACE"", ""PROTOR"", ""PUT"", ) ) Convert an event to an event from the event. If this is root, the prune then returns the Visitor.",21.29291966,19.44266711,20.36779339,,,,,,,,,
"summarize: def _type_pprint(obj, p, cycle):
    """"""""""""
    if obj.__module__ in ('__builtin__', 'exceptions'):
        name = obj.__name__
    else:
        name = obj.__module__ + '.' + obj.__name__
    p.text(name)",The pprint for classes and types.,return name Prints the pprint of the object to the pattern.,"return p Update a type in a string and persistent, or cycle.",19.56828627,20.86595808,20.21712218,,,,,,,,,
"summarize: def unregister_widget(self, widget_cls):
        """"""""""""
        if widget_cls.__name__ in self.widgets:
            del self.widgets[widget_cls().get_name()]",Unregisters the given widget.,return self.widgets[widget_cls] Unregister widgets,elif widget_cls.__name__ in self.widgets: del self.widgets[widget_cls.__name__] else: del self.widget_cls.__name__ return self.widgets[widget_cls.__name__] Register a widget class to widget.,32.51461763,7.841656079,20.17813685,,,,,,,,,
"summarize: async def get_information():
    """"""""""""
    jar = aiohttp.CookieJar(unsafe=True)
    websession = aiohttp.ClientSession(cookie_jar=jar)

    modem = eternalegypt.Modem(hostname=sys.argv[1], websession=websession)
    await modem.login(password=sys.argv[2])

    result = await modem.information()
    for sms in result.sms:
        pprint.pprint(sms)

    await modem.logout()
    await websession.close()",Example of printing the inbox.,return result Get the information of an information of an information.,Get an awaiting to the jobs in any jar.,14.47476661,25.83940809,20.15708735,,,,,,,,,
"summarize: def defaults_(self):
        """"""
        """"""
        for sct, opt in self.options_():
            yield sct, opt, self[sct].def_[opt]","Iterator over sections, option names, and option metadata.",return [sct] Returns the default values of the specified options.,Returns the default defaults of the sctling.,20.20672164,19.9957714,20.10124652,,,,,,,,,
"summarize: def _load_features_from_array(self, features):
        """"""  """"""
        self.feature_images = np.load(features)
        self.feature_names = range(self.feature_images.shape[1])",Load feature data from a 2D ndarray on disk.,return self.feature_images Returns a feature images from the dataset.,return self.feature_images[self.feature_images[self.feature_images[self.feature_images[self.feature_image]]] Load a dictionary of the feature.,28.59503185,11.58667479,20.09085332,,,,,,,,,
"summarize: def match(self, *args):
        """"""
        
        """"""
        if not args:
            raise SyntaxError('cannot case empty pattern.')

        return self.match_args(self._value, args)",Indicate whether or not to enter a case suite.,Returns an item of the given ``args`` to another.,Checks if any types are matching or not.,19.46246993,20.48667665,19.97457329,,,,,,,,,
"summarize: def two_qubit_kak(unitary_matrix, verify_gate_sequence=False):
    """"""
    """"""
    warnings.warn(""two_qubit_kak function is now accessible under ""
                  ""qiskit.quantum_info.synthesis"", DeprecationWarning)
    return synthesis.two_qubit_kak(unitary_matrix)",Deprecated after 0.8,Gets a qubit kak for the given verify kak.,Gets the qubit qubit between the qubit_kakakay using the qubit.,12.26595669,27.67353548,19.96974609,,,,,,,,,
"summarize: def t(self):
        """"""""""""
        return list(map(lambda x: datetime.datetime.fromtimestamp(x[""t""]), self.raw()))",Returns just the timestamp portion of the datapoints as a list.    The timestamps are in python datetime's date format.,This is the tensor of the datetime on the tensor of the lambda you have any of the lambda you may tax they are the lambda you may are valid.,Translate a list of all rows according to the given tag.,27.68973947,12.13987743,19.91480845,,,,,,,,,
"summarize: def add(self, method, pattern, callback):
        """"""
        """"""
        pat_type, pat = self._normalize_pattern(pattern)
        if pat_type == 'literal':
            self._literal[method][pat] = callback
        elif pat_type == 'wildcard':
            self._wildcard[method].append(WildcardRoute(pat, callback))
        else:
            self._regex[method].append(RegexRoute(pat, callback))",Add a route.,return self Adds a pattern to the route.,Add a pattern to a ``_add``.,19.78369188,20.03652983,19.91011086,,,,,,,,,
"summarize: def check_type(self, value):
        """"""
        """"""
        if self.__dict__['dtype'] is None:
            return
        elif value is None:
            return
        elif isinstance(value, self.__dict__['dtype']):
            return
        msg = ""Value of type %s, when %s was expected."" % (
            type(value), self.__dict__['dtype'])
        raise TypeError(msg)","Hook for type-checking, invoked during assignment.",Checks a specific type instance.,Check if value is not a valid type for the given value.,15.46190804,24.29394282,19.87792543,,,,,,,,,
"summarize: def set_attribute(self, name, value):
        """"""  """"""
        if value is True:
            self.widget.set(name, name)
        elif value is False:
            del self.widget.attrib[name]
        else:
            self.widget.set(name, str(value))",Default handler for those not explicitly defined,Set a value for the specified value,return del self Get the attribute name for this ID.,18.56837443,21.04299035,19.80568239,,,,,,,,,
"summarize: def wait_on_rate_limit(self, value):
        """"""""""""
        check_type(value, bool, may_be_none=False)
        self._wait_on_rate_limit = value",Enable or disable automatic rate-limit handling.,self._wait_on_rate_limit = self._wait_on_rate_limit Adds a limit to the limit.,return self._wait_for_page(value) Wrapper to wrap the event to an event.,13.73060755,25.75103725,19.7408224,,,,,,,,,
"summarize: def find(self, *args, **kwargs):
        """"""
        
        """"""
        op = operator.methodcaller('find', *args, **kwargs)
        return self._wrap_node(op)",Find a single Node among this Node's descendants.,Finds a new node for an element of the given `op`.,Returns a list of finding members and return a list of finding members of the given members.,18.95825053,20.09052971,19.52439012,,,,,,,,,
"summarize: def decodeLength(encoded):
    '''
    
    '''
    value      = 0
    multiplier = 1
    for i in encoded:
        value += (i & 0x7F) * multiplier
        multiplier *= 0x80
        if (i & 0x80) != 0x80:
            break
    return value",Decodes a variable length value defined in the MQTT protocol.  This value typically represents remaining field lengths,summarize: def decodeLength(encoded): ''' ''' value = 0 multiplier = 1 for i in encoded: value += (i & 0x7F) * multiplier multiplier *= 0x80 if (i & 0x80)!= 0x80: break return value Decodes Multiplier Length,summarize: def decodeLength(encoded): ''' ''' value = 0 multiplier = 1 for i in encoded: value += (i & 0x7F) * multiplier multiplier *= 0x80 if (i & 0x80)!= 0x80: break return value Return the decoded Value.,19.77478929,19.21080175,19.49279552,,,,,,,,,
"summarize: def add_ignored(self, ignored):
    """"""
    """"""
    if ignored:
      if self.ignored:
        self.ignored = ignored + self.ignored
      else:
        self.ignored = ignored

    self.consumed += len(ignored)",Add ignored text to the node. This will add the length of the ignored text to the node's  consumed property.,self.data = [] self.delayed += len(self.data) Add a given item to the given item.,self.use_ratio(agnored) return self Add a given ignored or an ignored for a given ignored.,16.10601041,22.86668148,19.48634595,,,,,,,,,
"summarize: def run_asap(self):
        """"""""""""
        now = timezone.now()
        self.last_run = now
        self.calc_next_run()
        self.save()
        self.submit(now)",Instance method to run this task immediately.,return self.output(now) Run the working event.,"self.submit(now, now) Apply a normal number of iterations.",13.04458882,25.91872058,19.4816547,,,,,,,,,
"summarize: def use(self, profile):
        """"""""""""
        if not isinstance(profile, (KnownProfiles, ProfileDefinition)):
            raise ValueError(""Can only set as default a ProfileDefinition or a KnownProfiles"")
        type(self).profile = profile",Define a new default profile.,return self.profile Generate user profile and update a Profile,return self._get_profile(profile) Update a ProfileDefinition for profile.,18.46143116,20.41339904,19.4374151,,,,,,,,,
"summarize: def expand_path(path: Union[str, Path]) -> Path:
    """"""""""""
    return Path(path).expanduser().resolve()",Convert relative paths to absolute with resolving user directory.,.expanduser().expanduser().expanduser() Works the path to the URL.,Extract an existing path and return a dictionary of an existing path.,20.9231192,17.86196743,19.39254332,,,,,,,,,
"summarize: def y_plus(self, dy=None):
        """"""  """"""
        if dy is None:
            self.y += self.dy
        else:
            self.y = self.y + dy",Mutable y addition. Defaults to set delta value.,return self.y Converts a raw plus to the yimmetric.,self.y = y return self.y Y plus data plus on the dy in the Y,18.29565422,20.43719256,19.36642339,,,,,,,,,
"summarize: def movies(self, **kwargs):
        """"""
        
        """"""
        path = self._get_id_path('movies')

        response = self._GET(path, kwargs)
        self._set_attrs_to_values(response)
        return response","Get the list of movies for a particular genre by id. By default, only    movies with 10 or more votes are included.",Creates the GET and returns the GET and returns a list of GET and returns the movies to the GET.,".post(self._client_token, response.headers, self._client_token) Adds anotation to the Movies.",25.95274761,12.69984381,19.32629571,,,,,,,,,
"summarize: def initialize_archive_manager(self, archive_path):
        """"""
        """"""
        if archive_path == """":
            raise ValueError(""Archive manager path cannot be empty"")

        if archive_path:
            self.archive_manager = perceval.archive.ArchiveManager(archive_path)",Initialize the archive manager.,"if archive_path == """": self.archive_archive_manager(archive_path) return self.archive_manager(archive_path) Initialize the manager.",else: self.archive_manager.initialize_manager(archive_path) return self.archive_manager(archive_path) Initialize an `archive_manager`.,21.33438325,17.30980052,19.32209189,,,,,,,,,
"summarize: def trim_args(kwds):
    """"""""""""
    reject_key = (""type"", ""types"", ""configure"")
    reject_val = (None, ())
    kwargs = {
        k: v for k, v in kwds.items() if k not in reject_key and v not in reject_val
    }
    for k, v in kwargs.items():
        if k in (""to"", ""cc"", ""bcc"", ""attachments""):
            kwargs[k] = list(kwargs[k])
    return kwargs","Gets rid of args with value of None, as well as select keys.",Trim `kwds` with a list of `kwds` keys.,This method on ``to`` trimal keys of the given ``kwds``.,20.72072904,17.8797138,19.30022142,,,,,,,,,
"summarize: def read_client_secrets():
    '''
    '''
    client_secrets = _default_client_secrets()

    # If token file not provided, check environment
    secrets = get_secrets_file()

    # If exists, load
    if secrets is not None:
        client_secrets = read_json(secrets)

    # Otherwise, initialize
    else:
        from sregistry.defaults import SREGISTRY_CLIENT_SECRETS
        write_json(client_secrets, SREGISTRY_CLIENT_SECRETS)

    return client_secrets","for private or protected registries, a client secrets file is required    to be located at .sregistry. If no secrets are found, we use default    of Singularity Hub, and return a dummy secrets.",", write_json(client_secrets, SREGISTRY_CLIENT_SECRETS) Read acrets from access to secrets","Gets a client secrets. If no readable is not read, there is only ``SREGISTRY_CLIENTS`` or ``SREGISTRY_CLIENTS``. If there is not ```SREGISTRY_CLIENTS`` is not readable.",12.61836231,25.84323849,19.2308004,,,,,,,,,
"summarize: def cancel_completion(self):
        """"""
        """"""
        self._consecutive_tab = 0
        self._slice_start = 0
        self._console_widget._clear_temporary_buffer()
        self._index = (0, 0)
        if(self._sliding_interval):
            self._sliding_interval = None",Cancel the completion,return self._consecutive_tab Cancel the tabs to the following completion.,"else: self._slice_end = None return self._slice_start, self._slice_end Returns a cancel between cancel-completion.",26.0860011,12.28521138,19.18560624,,,,,,,,,
"summarize: def __check_mem(self):
        '''  '''
        mem_free = psutil.virtual_memory().available / 2**20
        self.log.debug(""Memory free: %s/%s"", mem_free, self.mem_limit)
        if mem_free < self.mem_limit:
            raise RuntimeError(
                ""Not enough resources: free memory less ""
                ""than %sMB: %sMB"" % (self.mem_limit, mem_free))",raise exception on RAM exceeded,return mem_free Available memory,return mem_free.memory_response.decode(self.memory) Method to get a memory memory of the MB,18.35158276,20.01943048,19.18550662,,,,,,,,,
"summarize: def readSettings(self):
        """"""
        """"""
        success = (self.readHolidayDates() and
                   self.readMonthTariffs(ReadMonths.kWh) and
                   self.readMonthTariffs(ReadMonths.kWhReverse) and
                   self.readSchedules(ReadSchedules.Schedules_1_To_4) and
                   self.readSchedules(ReadSchedules.Schedules_5_To_6))
        return success",Recommended call to read all meter settings at once.,Read Schedules from ReadSettings.,Read a ScheduleFile. This is read the following Schedules.,18.80436773,19.26985228,19.03711001,,,,,,,,,
"summarize: def get_credentials():
    """"""
    
    """"""
    try:
        netrc_path = netrc.path()
        auths = netrc(netrc_path).authenticators(
            urlparse(solvebio.api_host).netloc)
    except (IOError, TypeError, NetrcParseError) as e:
        raise CredentialsError(
            'Could not open credentials file: ' + str(e))

    if auths:
        # auths = (login, account, password)
        return auths[2]
    else:
        return None",Returns the user's stored API key if a valid credentials file is found.  Raises CredentialsError if no valid credentials file is found.,"summarize: def get_credentials(): """""" """""" try: netrc_path = netrc.path() auths = netrc(netrc_path).authenticators( urlparse(solvebio.api_host).netloc) except (IOError, TypeError, NetrcParseError) as e: raise CredentialsError( 'Could not open credentials file:'+ str(e)) if auths: # auths = (login, account, password) return auths[2] else: return None Returns a list of networks for the given account.","summarize: def get_credentials(): """""" """""" try: netrc_path = netrc.path() auths = netrc(netrc_path).authenticators( urlparse(solvebio.api_host).netloc) except (IOError, TypeError, NetrcParseError) as e: raise CredentialsError( 'Could not open credentials file:'+ str(e)) if auths: # auths = (login, account, password) return auths[2] else: return None Gets the credentials repository.",19.10737737,18.89742094,19.00239916,,,,,,,,,
"summarize: def mBank_set_transaction_code(transactions, tag, tag_dict, *args):
    """"""
    
    """"""
    tag_dict['transaction_code'] = int(
        tag_dict[tag.slug].split(';')[0].split(' ', 1)[0])

    return tag_dict","mBank Collect uses transaction code 911 to distinguish icoming mass  payments transactions, adding transaction_code may be helpful in further  processing",Matches the transaction of the transactions to the transactions.,Extracts an All Bank API code from another another tag and banks accessing to the tag and the API.,17.61828668,20.3675881,18.99293739,,,,,,,,,
"summarize: def checkUser(self, user):
        """"""
        
        """"""
        return not self.conn(""POST"", ""{0}/GetCredentialType.srf"".format(SkypeConnection.API_MSACC),
                             json={""username"": user}).json().get(""IfExistsResult"")",Query a username or email address to see if a corresponding Microsoft account exists.,Checks the user name of the given username.,"Checks if application is a group. The username is any username or authories, this credentials, the username is not a username.",13.78973897,23.93525839,18.86249868,,,,,,,,,
"summarize: def create(self, deviceType):
        """"""
        
        """"""

        r = self._apiClient.post(""api/v0002/device/types"", deviceType)

        if r.status_code == 201:
            return DeviceType(apiClient=self._apiClient, **r.json())
        else:
            raise ApiException(r)","Register one or more new device types, each request can contain a maximum of 512KB.",Create a new device type and return it to it.,Create an JSON response instance from the given device.,21.65057537,15.96708228,18.80882883,,,,,,,,,
"summarize: def parse(filename, encoding=None):
    """"""
    
    """"""

    with open(filename, encoding=encoding) as source:
        for line in source:
            for word in line.split():
                yield word",!DEMO!  Simple file parsing generator,return encoding Parse a filename and parse a file name into a filename.,Returns the encoding of the text file names.,17.78446392,19.83211647,18.8082902,,,,,,,,,
"summarize: def lookup_(ctx, tableid, key):
    '''
    
    '''
    tableid = next(string_arg(ctx, tableid), '')
    key = next(string_arg(ctx, key), '')
    #value = ctx.
    for item in seq:
        innerctx = ctx.copy(item=item)
        yield from pexpr.compute(innerctx)","Yields a sequence of a single value, the result of looking up a value from the tables provided in the context, or an empty sequence if lookup is unsuccessful","return yield from pexpr.compute(innerctx, key, lookup_=True) Lookup a list of tables in the lookup.",Look for a single tableid and returns a single table into an XFrame.,24.84444213,12.66726522,18.75585368,,,,,,,,,
"summarize: def _percent(data, part, total):
    """"""
    
    """"""
    try:
        return round(100 * float(data[part]) / float(data[total]), 1)
    except ZeroDivisionError:
        return 0",Calculate a percentage.,except ValueError: return None Percent an existing data,.0 Get the number of parts of the data stream.,13.08560766,24.25584208,18.67072487,,,,,,,,,
"summarize: def get_msgs(self):
        """"""""""""
        msgs = []
        while True:
            try:
                msgs.append(self.get_msg(block=False))
            except Empty:
                break
        return msgs",Get all messages that are currently ready.,Returns a list of msgs for the given blocks.,Return a module block of a module.,13.75642692,23.48091131,18.61866912,,,,,,,,,
"summarize: def main():
    """""" 
    """"""
    application = GodotApplication( id=""godot"",
        plugins=[CorePlugin(),
                 PuddlePlugin(),
                 WorkbenchPlugin(),
                 ResourcePlugin(),
                 GodotPlugin()] )

    application.run()",Runs Godot.,return application Add Godot plugins to a specified location.,Main application to the specified corebox.,9.56879063,27.38942759,18.47910911,,,,,,,,,
"summarize: def addSuccess(self, test, capt=None):
        """"""
        """"""
        taken = self._timeTaken()
        self.stats['passes'] += 1
        id = test.id()
        self.errorlist.append(
            '<testcase classname=%(cls)s name=%(name)s '
            'time=""%(taken).3f"" />' %
            {'cls': self._quoteattr(id_split(id)[0]),
             'name': self._quoteattr(id_split(id)[-1]),
             'taken': taken,
             })",Add success output to Xunit report.,self.addSuccess(id) Add an add to test test test test.,"self._addSuccess(taken, taken) Adds a ``Taken`` to a ``test``.",21.34319107,15.32884006,18.33601557,,,,,,,,,
"summarize: def burn(self):
		""""""
		
		""""""
		if not self.data:
			raise ValueError(""No data available"")

		if hasattr(self, 'calculations'):
			self.calculations()

		self.start_svg()
		self.calculate_graph_dimensions()
		self.foreground = etree.Element(""g"")
		self.draw_graph()
		self.draw_titles()
		self.draw_legend()
		self.draw_data()
		self.graph.append(self.foreground)
		self.render_inline_styles()

		return self.render(self.root)","Process the template with the data and		config which has been set and return the resulting SVG.",Returns a GRULE State of all drawing data available,Add a temporary element of the given burning the ID of the Graph.,14.65458074,21.97650326,18.315542,,,,,,,,,
"summarize: def read(self):
        """"""""""""
        packet = self.packet
        with self.__read_lock:
            buffer = self.__buffer
            while len(buffer) < packet:
                buffer += self._read_data()
            length = self.__unpack(buffer[:packet])[0] + packet
            while len(buffer) < length:
                buffer += self._read_data()
            term, self.__buffer = decode(buffer[packet:])
        return term",Read incoming message.,Read the data from the buffer.,Read data from packet.,15.29555934,21.27988282,18.28772108,,,,,,,,,
"summarize: def gc():
    """"""""""""
    def after_delete(database):
        click.echo(""Deleted table %s"" % database)

    app = get_app()
    upgrade_from_old_version(app)
    app.delete_orphan_snapshots(after_delete)",Deletes old stellar tables that are not used anymore,return app.delete(database) After deleted tables on a database.,"return upgrade_from_old_version(api_callback, database) return after_delete(database, app) Get an ID of the documentation version.",27.46220026,9.063955558,18.26307791,,,,,,,,,
"summarize: def _convert_to_float_if_possible(s):
    """"""
    
    """"""
    try:
        ret = float(s)
    except (ValueError, TypeError):
        ret = s
    return ret",A small helper function to convert a string to a numeric value  if appropriate,Convert float image to float image to float image.,Convert a float into an integer string.,16.94074359,19.5660243,18.25338395,,,,,,,,,
"summarize: def _handle_sigint(self, sig, frame):
        """"""""""""
        # register more forceful signal handler for ^C^C case
        signal.signal(signal.SIGINT, self._signal_stop)
        # request confirmation dialog in bg thread, to avoid
        # blocking the App
        thread = threading.Thread(target=self._confirm_exit)
        thread.daemon = True
        thread.start()",SIGINT handler spawns confirmation dialog,return thread Handle signal handler for handling threads,thread.start() Handle the server and signal function.,19.57243751,16.90678184,18.23960968,,,,,,,,,
"summarize: def taskinfo_with_label(label):
    """"""""""""
    task = Task.objects.get(label=label)
    info = json.loads(task._func_info)
    return info","Return task info dictionary from task label. Internal function,  pretty much only used in migrations since the model methods aren't there.",.get('taskinfo') Returns a task instance of labels of labels for labels of labels,Returns an astropy instance. The name is only used in the passed one.,18.3694537,17.97162776,18.17054073,,,,,,,,,
"summarize: def check_entry_points(dist, attr, value):
    """"""""""""
    try:
        pkg_resources.EntryPoint.parse_map(value)
    except ValueError, e:
        raise DistutilsSetupError(e)",Verify that entry_points map is parseable,pkg_resources.Point.parse_map(value) return pkg_resources Check entrypoints in entrypoints.,if not pkg_resources: raise DistutilsPoint.parse_exists(value) return e.entry_points(dist) Checks if an entrypoint is present.,19.16749022,17.15419169,18.16084096,,,,,,,,,
"summarize: def qft(circ, q, n):
    """"""""""""
    for j in range(n):
        for k in range(j):
            circ.cu1(math.pi / float(2**(j - k)), q[j], q[k])
        circ.h(q[j])",n-qubit QFT on q in circ.,return q Adds the qft onto the circ to the noised qubit.,"return circ, circ Search for a given qft in coordinates.",19.68270913,16.57296926,18.1278392,,,,,,,,,
"summarize: def encode16Int(value):
    '''
    
    '''
    value      = int(value)
    encoded    = bytearray(2)
    encoded[0] = value >> 8
    encoded[1] = value & 0xFF
    return encoded",Encodes a 16 bit unsigned integer into MQTT format.  Returns a bytearray,Encodes value of an encoded string,Returns an FFF instance of the floating encoded Internal,10.74990882,25.43076688,18.09033785,,,,,,,,,
"summarize: def _append_png(self, png, before_prompt=False):
        """""" 
        """"""
        self._append_custom(self._insert_png, png, before_prompt)",Append raw PNG data to the widget.,"return self._total_png(png, before_prompt) Add png to the png",return before_prompt Turns a list of png.,15.64318002,20.48442391,18.06380197,,,,,,,,,
"summarize: def get_grid_span(tc):
    """"""
    
    """"""
    w_namespace = get_namespace(tc, 'w')
    grid_spans = tc.xpath('.//w:gridSpan', namespaces=tc.nsmap)
    if len(grid_spans) != 1:
        return 1
    grid_span = grid_spans[0]
    return int(grid_span.get('%sval' % w_namespace))",gridSpan is what docx uses to denote that a table cell has a colspan. This  is much more simple than rowspans in that there is a one-to-one mapping  from gridSpan to colspan.,"summarize: def get_grid_span(tc): """""" """""" w_namespace = get_namespace(tc, 'w') grid_spans = tc.xpath('.//w:gridSpan', namespaces=tc.nsmap) if len(grid_spans)!= 1: return 1 grid_span = grid_spans[0] return int(grid_span.get('%sval' % w_namespace)) Returns the grid span to a given tc.","summarize: def get_grid_span(tc): """""" """""" w_namespace = get_namespace(tc, 'w') grid_spans = tc.xpath('.//w:gridSpan', namespaces=tc.nsmap) if len(grid_spans)!= 1: return 1 grid_span = grid_spans[0] return int(grid_span.get('%sval' % w_namespace)) Returns an iterable of gridSpan for a single tc.",17.26881688,18.81959641,18.04420665,,,,,,,,,
"summarize: def discrete_likelihood(data, xmin, alpha):
    """"""
    
    """"""
    if not scipyOK:
        raise ImportError(""Can't import scipy.  Need scipy for zeta function."")
    from scipy.special import zeta as zeta

    zz = data[data>=xmin]
    nn = len(zz)

    sum_log_data = np.log(zz).sum()

    zeta = zeta(alpha, xmin)

    L_of_alpha = -1*nn*log(zeta) - alpha * sum_log_data

    return L_of_alpha",Equation B.8 in Clauset,Distance matrix to a zeta data,* np.log(nn) Discrete data between two Zeta.,15.73606873,20.17636728,17.95621801,,,,,,,,,
"summarize: def _escape(s):
    """"""  """"""
    e = s
    e = e.replace('\\', '\\\\')
    e = e.replace('\n', '\\n')
    e = e.replace('\r', '\\r')
    e = e.replace(""'"", ""\\'"")
    e = e.replace('""', '\\""')
    return e",Helper method that escapes parameters to a SQL query.,", e, e Converts end of scape into a ""scape"".",Transfer to get the scape of the scape of the scape of the scape.,18.86893681,16.95873386,17.91383534,,,,,,,,,
"summarize: def _heatmat(self, df, classes, pheno_pos, pheno_neg):
        """"""""""""
        width = len(classes) if len(classes) >= 6 else  5
        cls_booA =list(map(lambda x: True if x == pheno_pos else False, classes))
        cls_booB =list(map(lambda x: True if x == pheno_neg else False, classes))
        datA = df.loc[:, cls_booA]
        datB = df.loc[:, cls_booB]
        datAB=pd.concat([datA,datB], axis=1)
        self._width = width
        self.heatmat = datAB
        return",only use for gsea heatmap,self._width Width the location of a DataFrame.,"datAB, datAB, datAB, datB Helper function to return a dictionary of the datatype.",14.45152046,21.13902436,17.79527241,,,,,,,,,
"summarize: def s3_keys_from_cmdline(opt):
    ''''''
    if opt.access_key != None and opt.secret_key != None:
      keys = (opt.access_key, opt.secret_key)
      debug(""read S3 keys from commandline"")
      return keys
    else:
      return None","Retrieve S3 access keys from the command line, or None if not present.","summarize: def s3_keys_from_cmdline(opt): '''''' if opt.access_key!= None and opt.secret_key!= None: keys = (opt.access_key, opt.secret_key) debug(""read S3 keys from commandline"") return keys else: return None Returns the s3 key for a cmd line.","summarize: def s3_keys_from_cmdline(opt): '''''' if opt.access_key!= None and opt.secret_key!= None: keys = (opt.access_key, opt.secret_key) debug(""read S3 keys from commandline"") return keys else: return None Gets a client key to a client.",18.40089692,17.17059529,17.78574611,,,,,,,,,
"summarize: def _add_attachments(self):
        """"""""""""
        if self.attachments:
            if not isinstance(self.attachments, list):
                self.attachments = [self.attachments]

            self.message[""attachments""] = [
                {""image_url"": url, ""author_name"": """"} for url in self.attachments
            ]
            if self.params:
                for attachment in self.message[""attachments""]:
                    attachment.update(self.params)",Add attachments.,return self Add the given attachments to a list of attachments,"return self.message[""attachments""] Adds an empty param specified in the given attachments.",20.82902487,14.72107454,17.77504971,,,,,,,,,
"summarize: def mBank_set_iph_id(transactions, tag, tag_dict, *args):
    """"""
    
    """"""
    matches = iph_id_re.search(tag_dict[tag.slug])

    if matches:  # pragma no branch
        tag_dict['iph_id'] = matches.groupdict()['iph_id']

    return tag_dict","mBank Collect uses ID IPH to distinguish between virtual accounts,  adding iph_id may be helpful in further processing","Parse the matches to a list of iphs to use. This must be a branches on the tag, and the iphaches are tags, the tag has it is just matching its iphaches.","Method to setting the iphrapper ID for a single tag, then use it to its any tag.",16.29866476,19.18507137,17.74186807,,,,,,,,,
"summarize: def _ping(self, peerid, callid):
        """"""
        
        """"""
        if not (peerid, callid) in self._remote_to_local:
            logger.warn(""No remote call %s from %s. Might just be unfoutunate timing."" % (callid, peerid))",Called from remote to ask if a call made to here is still in progress.,"return None logger.debug(""Loading %s to %s from %s"", (peerid, peerid)) return callid Parse a local calls to the local peerid.","return None return self._remote_to_local(peerid, callid) Returns the local callable of the ping message.",17.84169574,17.51895092,17.68032333,,,,,,,,,
"summarize: def _print_stat(self):
        """"""
        
        """"""
        if ((timezone.utcnow() - self.last_stat_print_time).total_seconds() >
                self.print_stats_interval):
            if len(self._file_paths) > 0:
                self._log_file_processing_stats(self._file_paths)
            self.last_stat_print_time = timezone.utcnow()",Occasionally print out stats about how fast the files are getting processed,else: self._log_file_processing_stats(self._file_paths) Prints file location of time locations.,self._print_stats_interval(self._file_paths) else: self._log_stats_interval = None self._print_stats_interval = None Logic for ``TotalStats`` and the ``TotalStat. Uses ``TotalStats``.,24.31949527,10.87830106,17.59889817,,,,,,,,,
"summarize: def index(self):
        '''
        
        '''
        for i, hashtable in enumerate(self.hashtables):
            self.sorted_hashtables[i] = [H for H in hashtable.keys()]
            self.sorted_hashtables[i].sort()",Index all the keys added so far and make them searchable.,return True Returns the index of the index of the sorted index of the hashtable.,self.index_hashables[i].append(self.sorted_hashable) return self.index.index(self.index) Returns the index of another Hashable sorted enumerated hashable.,22.17174523,13.01760821,17.59467672,,,,,,,,,
"summarize: def is_modified(self):
        """"""
        
        """"""

        for key, val in self._initial_vals.items():
            if getattr(self, key) != val:
                # One of the initial values doesn't match, we know
                # this object has been touched.
                return True

        return False",Determines whether this record set has been modified since the    last retrieval or save.,"summarize: def is_modified(self): """""" """""" for key, val in self._initial_vals.items(): if getattr(self, key)!= val: # One of the initial values doesn't match, we know # this object has been touched. return True return False Returns True if the last one last one.","summarize: def is_modified(self): """""" """""" for key, val in self._initial_vals.items(): if getattr(self, key)!= val: # One of the initial values doesn't match, we know # this object has been touched. return True return False Method that has necessary.",18.05581785,17.1085948,17.58220633,,,,,,,,,
"summarize: def __update_count(self):
        """"""  """"""
        self._ntypes = self.count_types()
        self._nvars = self.count_vars()
        self._nfuns = self.count_funs()",Update internal counters,self._nvars = self._nvars() Update the count function,self._vols = self._vols self._vols = self._vols self._vols = self._vols self._doc = self._doc return self._vols Return the number of docs of the number of vols.,22.54127155,12.58835554,17.56481355,,,,,,,,,
"summarize: def main():
    """"""""""""
    folder = os.getcwd()
    print('Merging all files')
    merge_all_in_folder(folder,
                        delete_other_files=True,  # We will only keep one trajectory
                        dynamic_imports=FunctionParameter,
                        backup=False)
    print('Done')",Simply merge all trajectories in the working directory,return merge_all_in_folder(folder) Generate all files of a filename,"return merge_all_in_folder(merge_all_in_folder, dynamic_imports=True) Called when files is used to specify the default dictionary.",20.68790771,14.17814108,17.4330244,,,,,,,,,
"summarize: def patch_request_class(app, size=64 * 1024 * 1024):
    """"""
    
    """"""
    if size is None:
        if isinstance(app.request_class.__dict__['max_content_length'],
                      property):
            return
        size = app.config.get('MAX_CONTENT_LENGTH')
    reqclass = app.request_class
    patched = type(reqclass.__name__, (reqclass,),
                   {'max_content_length': size})
    app.request_class = patched","By default, Flask will accept uploads to an arbitrary size. While Werkzeug  switches uploads from memory to a temporary file when they hit 500 KiB,  it's still possible for someone to overload your disk space with a  gigantic file.","return app Patch a list of HTML and If there is one of the created server, it is valid, it may be a list of versions that will have a HTML size or the client specified by an API server is valid.","return app.request_class( url=api.url_to_response_string, size=reqclass, reqclass=reqclass, query_type=""POST"", application_type=""POST"", default=application_type, ) Patches application request to a Patched request type.",18.35981445,16.43231171,17.39606308,,,,,,,,,
"summarize: def _define(self):
        """"""""""""
        if self.num_qubits == 1:
            q = QuantumRegister(1, ""q"")
            angles = euler_angles_1q(self.to_matrix())
            self.definition = [(U3Gate(*angles), [q[0]], [])]
        if self.num_qubits == 2:
            self.definition = two_qubit_kak(self.to_matrix())",Calculate a subcircuit that implements this unitary.,"return angles, angles, angles Gets the Angles that are needed",else: self.definition = two_qubits return self.define Return a list of all registers of angles.,18.81032252,15.5483038,17.17931316,,,,,,,,,
"summarize: def to_dot_file(self, fname: str):
        """"""
        
        """"""
        with open(fname, 'w') as f:
            f.write(self.to_dot())",write a '.dot' file.,return self.to_dot_file(fname) Returns the dot file name to a file.,return f.read() Write a dot file to a filename.,11.35670486,22.97821499,17.16745993,,,,,,,,,
"summarize: def _backup(self):
        """"""
        
        """"""

        if PyFunceble.CONFIGURATION[""inactive_database""]:
            # The database subsystem is activated.

            # We save the current database state into the database file.
            Dict(PyFunceble.INTERN[""inactive_db""]).to_json(self.inactive_db_path)",Save the current database into the inactive-db.json file.,"# Add the given database self.inactive_database = ""inactive_database"" # If the inactive database was saved, it's a database self.inactive_database = self.inactive_database # Convert to a dictionary self.inactive_database = database return self.inactive_database Gets the ""inactive_database"" object.","Dict(self.inactive_db_path, self.inactive_database) return Dict(self._inactive_database.values()) Save the database.",10.64604662,23.5703536,17.10820011,,,,,,,,,
"summarize: def _at_shutdown(self):
        """"""
        """"""
        # io.rprint(""Kernel at_shutdown"") # dbg
        if self._shutdown_message is not None:
            self.session.send(self.iopub_socket, self._shutdown_message, ident=self._topic('shutdown'))
            self.log.debug(""%s"", self._shutdown_message)
        [ s.flush(zmq.POLLOUT) for s in self.shell_streams ]","Actions taken at shutdown by the kernel, called by python's atexit.","# disconnect to router return self._shutdown_message Given a socket, and return a list of items of the router.","return self._shutdown_message(self._shutdown_message, self.topic, self._shutdown) Returns the stream of the shutdown message.",18.14032589,15.93977453,17.04005021,,,,,,,,,
"summarize: def headers(self, headers=None, **kw):
        """"""
        
        """"""
        headers = kw if kw else headers
        self._request.headers = headers
        self.add_matcher(matcher('HeadersMatcher', headers))",Defines a dictionary of arguments.,return headers Adds headers to the URL.,return self._headers Get an instance headers or an absolute headers.,11.04459618,22.72653674,16.88556646,,,,,,,,,
"summarize: def printStatus(self):
        """"""""""""
        status = self.getStatus()
        for k, v in iteritems(status):
            logging.info('%s: %s' % (str(k), str(v)))",Dumps different debug info about cluster to default logger,return self._wrapFormatter() Prints a status of the servers.,"status.setHandler(k, v) if not status: status.setHandler(k, v) self.status = status return status Execute the ``Status`` and ``Thread``.",11.24936768,22.5145064,16.88193704,,,,,,,,,
"summarize: def tree_climber(self, tree_alias, base_item):
        """"""
        """"""
        if base_item is not None:
            base_item.in_current_branch = True
            if hasattr(base_item, 'parent') and base_item.parent is not None:
                self.tree_climber(tree_alias, self.get_item_by_id(tree_alias, base_item.parent.id))",Climbs up the site tree to mark items of current branch.,return base_item return None Get a tree by a tree with the given baseitem to the given tree,"self.tree_climber(base_item) self.tree_climber(tree_alias, tree_alias) Try to create an object and public_item.",19.29310346,14.32344103,16.80827225,,,,,,,,,
"summarize: def _all_cut_string(string, max_length, logger):
        """"""

        """"""
        if len(string) > max_length:
            logger.debug('The string `%s` was too long I truncated it to'
                         ' %d characters' %
                         (string, max_length))
            string = string[0:max_length - 3] + '...'.encode('utf-8')

        return string",Cuts string data to the maximum length allowed in a pytables column    if string is too long.,"summarize: def _all_cut_string(string, max_length, logger): """""" """""" if len(string) > max_length: logger.debug('The string `%s` was too long I truncated it to' '%d characters' % (string, max_length)) string = string[0:max_length - 3] + '...'.encode('utf-8') return string List of string to the given string.","summarize: def _all_cut_string(string, max_length, logger): """""" """""" if len(string) > max_length: logger.debug('The string `%s` was too long I truncated it to' '%d characters' % (string, max_length)) string = string[0:max_length - 3] + '...'.encode('utf-8') return string Cut for an address",16.73648644,16.48615803,16.61132224,,,,,,,,,
"summarize: def get_stderr(self, os_path=None, skip_sub_command=False):
        """"""
        
        """"""
        sub_command = None if skip_sub_command else self.stderr_sub_command
        out, path = self._get_out_and_path(
            self.stderr, self.stderr_root, sub_command, os_path)
        if hasattr(out, 'stdin'):
            return out.stdin
        return out",Returns a stderr-suitable file-like object based on the    optional os_path and optionally skipping any configured    sub-command.,"summarize: def get_stderr(self, os_path=None, skip_sub_command=False): """""" """""" sub_command = None if skip_sub_command else self.stderr_sub_command out, path = self._get_out_and_path( self.stderr, self.stderr_root, sub_command, os_path) if hasattr(out,'stdin'): return out.stdin return out Returns a stdin for a local local file.","summarize: def get_stderr(self, os_path=None, skip_sub_command=False): """""" """""" sub_command = None if skip_sub_command else self.stderr_sub_command out, path = self._get_out_and_path( self.stderr, self.stderr_root, sub_command, os_path) if hasattr(out,'stdin'): return out.stdin return out.stderr.strip() Returns the stdin file.",16.84392517,16.31136661,16.57764589,,,,,,,,,
"summarize: def check_for_cancelled_events(self, d):
        """"""""""""
        for event in self.events:
            for cn in event.cancellations.all():
                if cn.date == d:
                    event.title += ' (CANCELLED)'",Check if any events are cancelled on the given date 'd'.,"summarize: def check_for_cancelled_events(self, d): """""""""""" for event in self.events: for cn in event.cancellations.all(): if cn.date == d: event.title +='(CANCELLED)' return event Check for cancelled events in the given date.","summarize: def check_for_cancelled_events(self, d): """""""""""" for event in self.events: for cn in event.cancellations.all(): if cn.date == d: event.title +='(CANCELLED)' else: event.cancelled = True return event return None Check if an event is in the cancelled.",18.34104538,14.56194214,16.45149376,,,,,,,,,
"summarize: def Create(self, parent, id, evtHandler):
        """"        
        self._tc = wx.ComboBox(parent, id, """", (100, 50))
        self.SetControl(self._tc)
        # pushing a different event handler instead evtHandler:
        self._tc.PushEventHandler(wx.EvtHandler())
        self._tc.Bind(wx.EVT_COMBOBOX, self.OnChange)","Called to create the control, which must derive from wxControl.",self._tc.PushEventHandler(wx.EVTHandler) Base a parent event handler into the root event.,Create a Wx event handler. This is called only being used as the Wx.EvtHandler.,10.43048915,22.17037116,16.30043016,,,,,,,,,
"summarize: def when_label_changed ( self, object, listener, remove ):
        """""" 
        """"""
        label = self.label
        if label[:1] != '=':
            object.on_trait_change( listener, label, remove = remove,
                                    dispatch = 'ui' )",Sets up or removes a listener for the label being changed on a      specified object.,"summarize: def when_label_changed ( self, object, listener, remove ): """""" """""" label = self.label if label[:1]!= '=': object.on_trait_change( listener, label, remove = remove, dispatch = 'ui' ) object.on_trait_change( [ ] ) object.on_trait_change( [ ] ) return object, label Remove label changed from the label.","summarize: def when_label_changed ( self, object, listener, remove ): """""" """""" label = self.label if label[:1]!= '=': object.on_trait_change( listener, label, remove = remove, dispatch = 'ui' ) return object When we should be writing like objects to the label changed on the label.",14.67090187,17.89004662,16.28047425,,,,,,,,,
"summarize: def _handle_failed_job(self, job):
        """"""""""""

        task_id = job.kwargs['task_id']
        logger.error(""Job #%s (task: %s) failed; cancelled"",
                     job.id, task_id)",Handle failed jobs,"return task_id, job.handle_failed_job(job) Add job to a job.","return self._job_handle_job(job, job, task_id) Adds job and jobs.",19.06760079,13.47359461,16.2705977,,,,,,,,,
"summarize: def mouse_move(self, event):
        """"""
        
        """"""
        if (self.ui.tabWidget.currentIndex() == TabWidget.NORMAL_MODE):
            self.posX = event.xdata
            self.posY = event.ydata

            self.graphic_target(self.posX, self.posY)",The following gets back coordinates of the mouse on the canvas.,"self.graphic_target(self.posX, self.posY) Move the current index to the layout.","return self.move_move(event, self.currentIndex(), event.y) Returns the device of the specified event.",16.98336764,15.53822438,16.26079601,,,,,,,,,
"summarize: def get(cls, name: sym.Symbol) -> ""Optional[Namespace]"":
        """"""""""""
        return cls._NAMESPACES.deref().entry(name, None)",Get the namespace bound to the symbol `name` in the global namespace    cache. Return the namespace if it exists or None otherwise..,Get an address of an address of an address of a given namespace,"Returns the position of the supported class. If we have any any usernamespace, the any of the ports, it's any ports, there is a valid class. This is an any ports. The ports is not the required on that are instead.",10.1856245,22.33533994,16.26048222,,,,,,,,,
"summarize: def vrange(start, stop, step=1, dtype='f8'):
    """"""""""""
    from .column import ColumnVirtualRange
    return ColumnVirtualRange(start, stop, step, dtype)","Creates a virtual column which is the equivalent of numpy.arange, but uses 0 memory","summarize: def vrange(start, stop, step=1, dtype='f8'): """""""""""" from.column import ColumnVirtualRange return ColumnVirtualRange(start, stop, step, dtype) Returns the number of available vrange.","summarize: def vrange(start, stop, step=1, dtype='f8'): """""""""""" from.column import ColumnVirtualRange return ColumnVirtualRange(start, stop, step, dtype) Returns the column virtual range.",15.89610931,16.51728987,16.20669959,,,,,,,,,
"summarize: def ask_exit(self):
        """"""""""""
        self.exit_now = True
        payload = dict(
            source='IPython.zmq.zmqshell.ZMQInteractiveShell.ask_exit',
            exit=True,
            keepkernel=self.keepkernel_on_exit,
            )
        self.payload_manager.write_payload(payload)",Engage the exit actions.,return self.exit_now.exit(0) Returns the exit on the given zmq.,self.execute(self.exit_response) Manages the UPython settings.,17.28730871,14.99124131,16.13927501,,,,,,,,,
"summarize: def _extract_tar(archive, output_folder):
    '''

    '''
    from .terminal import ( run_command, which )

    result = which('blob2oci')
    if result['return_code'] != 0:
        bot.error('Cannot find blob2oci script on path, exiting.')
        sys.exit(1)
 
    script = result['message'] 
    command = ['exec' ,script, '--layer', archive, '--extract', output_folder]

    if not bot.is_quiet():
        print(""Extracting %s"" % archive)

    return run_command(command)","use blob2oci to handle whiteout files for extraction. Credit for this    script goes to docker2oci by Olivier Freyermouth, and see script    folder for license.","summarize: def _extract_tar(archive, output_folder): ''' ''' from.terminal import ( run_command, which ) result = which('blob2oci') if result['return_code']!= 0: bot.error('Cannot find blob2oci script on path, exiting.') sys.exit(1) script = result['message'] command = ['exec',script, '--layer', archive, '--extract', output_folder] if not bot.is_quiet(): print(""Extracting %s"" % archive) return run_command(command) Execute a new tar file for a given output file.","summarize: def _extract_tar(archive, output_folder): ''' ''' from.terminal import ( run_command, which ) result = which('blob2oci') if result['return_code']!= 0: bot.error('Cannot find blob2oci script on path, exiting.') sys.exit(1) script = result['message'] command = ['exec',script, '--layer', archive, '--extract', output_folder] if not bot.is_quiet(): print(""Extracting %s"" % archive) return run_command(command) Get a list of bots for the script.",15.91328276,16.16214653,16.03771465,,,,,,,,,
"summarize: def _set_icon(self, icon=None):
        """"""""""""
        if icon is not None:
            try:
                wx_icon = wx.Icon(icon, wx.BITMAP_TYPE_ICO)
                self.wx_obj.SetIcon(wx_icon)
            except:
                pass",Set icon based on resource values,return icon Create a new Icon or Icon.,if icon is not None: self.wx_obj.SetICon(icon) return self.wx_obj.WX_FAILD_SET_SET_ICORDING Wx,21.98675408,9.908995646,15.94787486,,,,,,,,,
"summarize: def prime_field_inv(a: int, n: int) -> int:
    """"""
    
    """"""
    if a == 0:
        return 0
    lm, hm = 1, 0
    low, high = a % n, n
    while low > 1:
        r = high // low
        nm, new = hm - lm * r, high - low * r
        lm, low, hm, high = nm, new, lm, low
    return lm % n",Extended euclidean algorithm to find modular inverses for integers,"m, high Prime an analysis field on the invocation field.","m, high return hm, hm Returns the first branch of the appropriate prime.",14.64366927,16.82670513,15.7351872,,,,,,,,,
"summarize: def selected(self):
        """"""""""""
        if self._selected:
            return self._selected if self.asc else \
                ""-{0}"".format(self._selected)
        return None",Get column which is being order by.,Internal username for username and application.,Set the settings and return the settings.,13.3537966,17.75077914,15.55228787,,,,,,,,,
"summarize: def truncate_string(data, headers, max_field_width=None, **_):
    """"""
    """"""
    return (([utils.truncate_string(v, max_field_width) for v in row] for row in data),
            [utils.truncate_string(h, max_field_width) for h in headers])","Truncate very long strings. Only needed for tabular  representation, because trying to tabulate very long data  is problematic in terms of performance, and does not make any  sense visually.",Get a list of truncate_strings and return a list of strings.,Return a string to a class. The value is a list of one of the grouping column. This is a single truncated header to the field which is an empty column. This is an empty string.,5.589111574,25.33877397,15.46394277,,,,,,,,,
"summarize: def ping(self, timeout=12):
        """"""
        
        """"""
        self.conn(""POST"", ""{0}/users/ME/endpoints/{1}/active"".format(self.conn.msgsHost, self.id),
                  auth=SkypeConnection.Auth.RegToken, json={""timeout"": timeout})",Send a keep-alive request for the endpoint.,return True Ping the current timeout to the current timeout,Processes a ping request.,11.65566106,19.17724046,15.41645076,,,,,,,,,
"summarize: def str_index(x, sub, start=0, end=None):
    """"""
    """"""
    return str_find(x, sub, start, end)","Returns the lowest indices in each string in a column, where the provided substring is fully contained between within a  sample. If the substring is not found, -1 is returned. It is the same as `str.find`.",Get the find of the finding of the sub-integer that are integer in the start and end of the start and end of the text.,If the string in the absolute string of the current sub-specified sub-specified sub.,17.78230961,12.98009227,15.38120094,,,,,,,,,
"summarize: def clear(self):
        """"""""""""
        self._fwdm.clear()
        self._invm.clear()
        self._sntl.nxt = self._sntl.prv = self._sntl",Remove all items.,.prv & 0x1f self._invm.clear() Clear the clearing build,.rv self._fwdm.clear() self._fwdm.clear() self._fwdm.clear() self._fwdm.clear() self._fwdm.clear() self._fwdm.clear() self._fwdm.clear() self._fwdm.clear() self._fwdm.clear() self._fwdm.clear() Clear this fwdm.,6.969574591,23.7765742,15.3730744,,,,,,,,,
"summarize: def request(self, method, path, contents, headers, decode_json=False,
                stream=False, query=None, cdn=False):
        """"""
        
        """"""
        raise Exception('request method not implemented')",Performs a direct HTTP request to the Swift service.,"return self.request(self.client.get( method, url, data=decode_json, timeout=timeout, timeout=timeout, timeout=timeout, stream=stream, cdn=cdn, **kwargs) Add request to the method to the request.","self._request(url, headers, headers, decode_json=decode_json) Return a request to request to the request.",10.63275658,19.97158837,15.30217248,,,,,,,,,
"summarize: def validate_id(request):
    """"""""""""

    if 'id' in request:
        correct_id = isinstance(
            request['id'],
            (string_types, int, None),
        )
        error = 'Incorrect identifier'
        assert correct_id, error",Validate request id.,return correct_id return correct_id Validate a given request.,log.error(error) return None response = request.json() if response.status_code =='status': return response['status'] else: return None Format the response object from a response.,24.58562376,5.333800011,14.95971189,,,,,,,,,
"summarize: def _fill_from_h2ocluster(self, other):
        """"""
        
        """"""
        self._props = other._props
        self._retrieved_at = other._retrieved_at
        other._props = {}
        other._retrieved_at = None",Update information in this object from another H2OCluster instance.,other._props = other._retrieved_at other._retrieved_at = None return other Create an other from H2Client,self._props = other._retrieved_at other._props = other._retrieved_at self._props = other._props Retrieves a FieldName from the other other,18.70341007,11.16812734,14.93576871,,,,,,,,,
"summarize: def djfrontend_h5bp_css(version=None):
    """"""
    
    """"""
    if version is None:
        version = getattr(settings, 'DJFRONTEND_H5BP_CSS', DJFRONTEND_H5BP_CSS_DEFAULT)

    return format_html(
        '<link rel=""stylesheet"" href=""{0}djfrontend/css/h5bp/{1}/h5bp.css"">',
        _static_url, version)",Returns HTML5 Boilerplate CSS file.  Included in HTML5 Boilerplate.,Get the css for the given version of the version of the version.,Djfs a version of a version of a version of version.,11.66799026,18.08507077,14.87653052,,,,,,,,,
"summarize: def getPivotPoint(self,data):
        """"""
        
        """"""
        ppos = self.parent.getPivotPoint(data)
        rot = self.parent.getRot(data)
        length = self.parent.getLength(data)
        out = calcSphereCoordinates(ppos,length,rot)
        return out","Returns the point this bone pivots around on the given entity.        This method works recursively by calling its parent and then adding its own offset.        The resulting coordinate is relative to the entity, not the world.","Returns the coordinates within the data, and returns an integer of the data.",".dot(length, length, length, length, length, rot, rot, rot, sphere=siphere.sphere.getPoint(length)) Returns the point point from the given data.",9.511221672,19.96166563,14.73644365,,,,,,,,,
"summarize: def snap_tz(dttm, instruction, timezone):
    """"""
    """"""
    transformations = parse(instruction)
    return reduce(lambda dt, transformation: transformation.apply_to_with_tz(dt, timezone), transformations, dttm)",This function handles timezone aware datetimes.  Sometimes it is necessary to keep daylight saving time switches in mind.,Snaps the datetimes of the datetimes to each timezone.,Return an API object of the datetime from a datetime.,17.67059336,10.99759215,14.33409276,,,,,,,,,
"summarize: def missing_schema(self,html,song_name):
		'''
		
		'''
		#html=self.get_html_response(url)
		soup=BeautifulSoup(html)
		name=' '.join(song_name)
		print '%s not found'%name
		print ""But you can download any of the following songs :""
		a_list=soup.findAll('a','touch')
		for x in xrange(len(a_list)-1):
			r=a_list[x]
			p=str(r)
			q=re.sub(r'<a.*/>|<span.*"">|</span>|</a>|<a.*html"">|<font.*"">|</font>','',p)
			print q",It will print the list of songs that can be downloaded,"=""A|</a>""></a>""></a>"" p=str(r) p=str(r) for r in r: a_list=[r] for r in r:","=lambda x: y q=lambda x: y if x == '/': for s, y in enumerate(request.args,""').items():",6.00882103,22.62599255,14.31740679,,,,,,,,,
"summarize: def delete_vm_image(self, vm_image_name, delete_vhd=False):
        '''
        
        '''
        _validate_not_none('vm_image_name', vm_image_name)
        path = self._get_vm_image_path(vm_image_name)
        if delete_vhd:
            path += '?comp=media'
        return self._perform_delete(path, as_async=True)",Deletes the specified VM Image from the image repository that is    associated with the specified subscription.,Delete the delete image with the given image.,Return the delete_vm image in the given vm_image.,15.36543369,12.78377893,14.07460631,,,,,,,,,
"summarize: def mr_writer(job, outputs, output_stream,
              stderr=sys.stderr, dumps=core.dumps):
    """""" 
    """"""
    for output in outputs:
        try:
            print >> output_stream, dumps(output)
        except core.ParseError, e:
            print >> stderr, e
            raise",Writes a stream of json serialised pyschema Records to a file object,"return output_stream, output_stream, output_stream, output_stream, output_stream, dumps Apply a list of jobs to a jobs to jobs","Exception as exc_info[0] return outputs Mr's function function to mr_writer, writing the outputs to processes and inputs to frames, and passed the outputs in the output_stream, and returns a MrIC.",16.04957102,11.96976804,14.00966953,,,,,,,,,
"summarize: async def resume(self, *, device: Optional[SomeDevice] = None):
        """"""
        """"""
        await self._user.http.play_playback(None, device_id=str(device))",Resume playback on the user's account.,return await self._payload_resume(device) Retrieve a route server,"self._user.device.device(device, device) return self._device_playback(device) Get a resume device.",11.86840522,16.13457394,14.00148958,,,,,,,,,
"summarize: def main(port=8888):
    """"""""""""
    import tornado.ioloop

    routes = [] + TornadoProfiler().get_routes()
    app = tornado.web.Application(routes)
    app.listen(port)
    tornado.ioloop.IOLoop.current().start()",Run as sample test server.,app.listen(port) app.listen(port) app.listen(port) Internal address to the server.,"return app Returns a single routes, and callback which is loop.",12.3165846,15.4828794,13.899732,,,,,,,,,
"summarize: def _log_end_transaction(self, start_time, response):
        """"""""""""
        if not self._is_logging: return
        elapsed_time = int((time.time() - start_time) * 1000)
        msg = ""<<< HTTP %d %s   (%d ms)\n"" % (response.status_code, response.reason, elapsed_time)
        if ""Content-Type"" in response.headers:
            msg += ""    Content-Type: %s\n"" % response.headers[""Content-Type""]
        msg += response.text
        self._log_message(msg + ""\n\n"")",Log response from an API request.,Log a single transaction,"return ""%s\n"" % (response.text, self._reason) return response.headers[""Content-Type""] Ends a HTTP request",12.0377998,15.60704702,13.82242341,,,,,,,,,
"summarize: def call_in_sequence(self, cmds, shell=True):
        """"""""""""
        for cmd in cmds:
            if subprocess.call(cmd, shell=shell) == 1:
                sys.exit(1)","Run multiple commmands in a row, exiting if one fails.","return cmds, shell Adds an insequence to the given cmd.",cmds.call(cmds) return self.call_in_sequence(cmds) Call a calling in the process.,14.65153431,12.98162587,13.81658009,,,,,,,,,
"summarize: def near_dupe_hashes(labels, values, languages=None, **kw):
    """"""
    
    """"""
    return _near_dupe.near_dupe_hashes(labels, values, languages=languages, **kw)",Hash the given address into normalized strings that can be used to group similar  addresses together for more detailed pairwise comparison. This can be thought of  as the blocking function in record linkage or locally-sensitive hashing in the  document near-duplicate detection.,Scans the dupe hashes into a list of scans of dupes of the labels. This is true if you have a list of values are updated to the dupe_hashes are a list of dupe_hashes are identical.,This method called if any anything is not the duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped duped,22.17088093,5.310672102,13.74077652,,,,,,,,,
"summarize: def write(self, *pb2_obj):
        """"""
        """"""
        base = len(self._write_buff)

        for idx, obj in enumerate(pb2_obj):
            if self._buffer_size > 0 and \
                    (idx + base) != 0 and \
                    (idx + base) % self._buffer_size == 0:
                self.flush()
            self._write_buff.append(obj)

        if self._buffer_size == 0:
            self.flush()",Write a group of one or more protobuf objects to the file. Multiple    object groups can be written by calling this method several times    before closing stream or exiting the runtime context.,"summarize: def write(self, *pb2_obj): """""" """""" base = len(self._write_buff) for idx, obj in enumerate(pb2_obj): if self._buffer_size > 0 and \ (idx + base)!= 0 and \ (idx + base) % self._buffer_size == 0: self.flush() self._write_buff.append(obj) if self._buffer_size == 0: self.flush() Writes the size of the size of the file","summarize: def write(self, *pb2_obj): """""" """""" base = len(self._write_buff) for idx, obj in enumerate(pb2_obj): if self._buffer_size > 0 and \ (idx + base)!= 0 and \ (idx + base) % self._buffer_size == 0: self.flush() self._write_buff.append(obj) if self._buffer_size == 0: self.flush() Write base of a python point to another object.",14.18333767,13.28419328,13.73376548,,,,,,,,,
"summarize: def visit_call(self, node):
        """""" 
        """"""
        try:
            for inferred in node.func.infer():
                self._check_inferred_class_is_abstract(inferred, node)
        except astroid.InferenceError:
            return",Check instantiating abstract class with    abc.ABCMeta as metaclass.,if not node.is_abstract(node): self._check_inferred_class_is_abstract(node) return return node Retrieve the callback for the given node,False return False Get an astroid callback.,14.13335463,13.26360956,13.6984821,,,,,,,,,
"summarize: def get_full_page_url(self, page_number, scheme=None):
        """"""""""""
        args = dict(
            request.view_args,
            _external=True,
        )

        if scheme is not None:
            args['_scheme'] = scheme
        
        if page_number != 1:
            args['page'] = page_number

        return url_for(request.endpoint, **args)","Get the full, external URL for this page, optinally with the passed in URL scheme","summarize: def get_full_page_url(self, page_number, scheme=None): """""""""""" args = dict( request.view_args, _external=True, ) if scheme is not None: args['_scheme'] = scheme if page_number!= 1: args['page'] = page_number return url_for(request.endpoint, **args) Gets a dictionary with the page number for the Given page.","summarize: def get_full_page_url(self, page_number, scheme=None): """""""""""" args = dict( request.view_args, _external=True, ) if scheme is not None: args['_scheme'] = scheme if page_number!= 1: args['page'] = page_number return url_for(request.endpoint, **args) Get a URL and return the page page.",14.34521488,12.91511247,13.63016368,,,,,,,,,
"summarize: def _load_template(dev_path):
        """"""
        
        """"""
        # See https://bitbucket.org/pypa/setuptools/issue/134 for info
        # on script file naming and downstream issues with SVR4
        name = 'script.tmpl'
        if dev_path:
            name = name.replace('.tmpl', ' (dev).tmpl')

        raw_bytes = resource_string('setuptools', name)
        return raw_bytes.decode('utf-8')",There are a couple of template scripts in the package. This    function loads one of them and prepares it for use.,"summarize: def _load_template(dev_path): """""" """""" # See https://bitbucket.org/pypa/setuptools/issue/134 for info # on script file naming and downstream issues with SVR4 name ='script.tmpl' if dev_path: name = name.replace('.tmpl','(dev).tmpl') raw_bytes = resource_string('setuptools', name) return raw_bytes.decode('utf-8') Loads the template from the template file","summarize: def _load_template(dev_path): """""" """""" # See https://bitbucket.org/pypa/setuptools/issue/134 for info # on script file naming and downstream issues with SVR4 name ='script.tmpl' if dev_path: name = name.replace('.tmpl','(dev).tmpl') raw_bytes = resource_string('setuptools', name) return raw_bytes.decode('utf-8') Gets a template to a template. The device is indent.",13.67075948,13.44788042,13.55931995,,,,,,,,,
"summarize: def is_met(self, ti, session, dep_context=None):
        """"""
        
        """"""
        return all(status.passed for status in
                   self.get_dep_statuses(ti, session, dep_context))",Returns whether or not this dependency is met for a given task instance. A    dependency is considered met if all of the dependency statuses it reports are    passing.,"Returns True if the metadata is met, True if it's a metadata is in the default ti.","Returns a metadata on the given METABLE-ACTION, and assignments.",17.67495503,9.433893646,13.55442434,,,,,,,,,
"summarize: def state(self):
        """"""""""""
        return {'c': self.c, 's0': self.s0, 's1': self.s1, 's2': self.s2}","Return internal state, useful for testing.","summarize: def state(self): """""""""""" return {'c': self.c,'s0': self.s0,'s1': self.s1,'s2': self.s2} State for the current state","summarize: def state(self): """""""""""" return {'c': self.c,'s0': self.s0,'s1': self.s1,'s2': self.s2} Return an anglestion state.",13.78199327,13.18172451,13.48185889,,,,,,,,,
"summarize: def init_app(self, app):
        """"""
        """"""
        # connects app-level signals
        appcontext_pushed.connect(self.initialize_bars, app)
        # integrate with jinja template
        app.add_template_global(self, 'nav')",Initializes an app to work with this extension.,# level # draw jinja template self.init_app(app) Initialize the jinja template,"app.add_template(self, app) self.add_template(self.initialize_bars, app) # app.add_template(self.template, 'application.json') self.add_template(self.template, self.template_name, app) self.add_template(self.template, app) return app Application template for this template.",18.77739573,8.035499589,13.40644766,,,,,,,,,
"summarize: def _separate_bitstring(bitstring, creg_sizes):
    """"""""""""
    substrings = []
    running_index = 0
    for _, size in reversed(creg_sizes):
        substrings.append(bitstring[running_index: running_index + size])
        running_index += size
    return ' '.join(substrings)",Separate a bitstring according to the registers defined in the result header.,"summarize: def _separate_bitstring(bitstring, creg_sizes): """""""""""" substrings = [] running_index = 0 for _, size in reversed(creg_sizes): substrings.append(bitstring[running_index: running_index + size]) running_index += size return''.join(substrings) Separate a bitstring for a given bitstring.","summarize: def _separate_bitstring(bitstring, creg_sizes): """""""""""" substrings = [] running_index = 0 for _, size in reversed(creg_sizes): substrings.append(bitstring[running_index: running_index + size]) running_index += size return''.join(substrings) Get a bitstring in the bitstring.",13.06690247,13.64460949,13.35575598,,,,,,,,,
"summarize: def local_hardware_info():
    """"""
    """"""
    results = {
        'os': platform.system(),
        'memory': psutil.virtual_memory().total / (1024 ** 3),
        'cpus': psutil.cpu_count(logical=False) or 1
    }
    return results",Basic hardware information about the local machine.,"summarize: def local_hardware_info(): """""" """""" results = { 'os': platform.system(), 'memory': psutil.virtual_memory().total / (1024 ** 3), 'cpus': psutil.cpu_count(logical=False) or 1 } return results Formats a hardware information about the local hardware information.","summarize: def local_hardware_info(): """""" """""" results = { 'os': platform.system(), 'memory': psutil.virtual_memory().total / (1024 ** 3), 'cpus': psutil.cpu_count(logical=False) or 1 } return results Connect to the database",14.95053533,11.20815848,13.07934691,,,,,,,,,
"summarize: def create_key_file(path):
    """"""
    
    """"""
    iv = ""{}{}"".format(os.urandom(32), time.time())
    new_key = generate_key(ensure_bytes(iv))
    with open(path, ""wb"") as f:
        f.write(base64.b64encode(new_key))
    os.chmod(path, 0o400)",Creates a new encryption key in the path provided and sets the file  permissions. Setting the file permissions currently does not work  on Windows platforms because of the differences in how file  permissions are read and modified.,"new_key = ""{}{}{}"".format(path, os.getctime()) return new_key Creates a new key into a new key file.","print(""Created key file for {}"".format(file_name)) return File(path, file_name=os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path), os.path.dirname(os.path.dirname(os.path.dirname(os.path))))))) Create a file.",10.15088436,15.68136965,12.91612701,,,,,,,,,
"summarize: def foreach_(ctx, seq, expr):
    '''
    
    '''
    from . import context, parse as uxpathparse

    if hasattr(seq, 'compute'):
        seq = seq.compute(ctx)

    expr = next(string_arg(ctx, expr), '')

    pexpr = uxpathparse(expr)
    for item in seq:
        innerctx = ctx.copy(item=item)
        yield from pexpr.compute(innerctx)",Yields the result of applying an expression to each item in the input sequence.,"summarize: def foreach_(ctx, seq, expr): ''' ''' from. import context, parse as uxpathparse if hasattr(seq, 'compute'): seq = seq.compute(ctx) expr = next(string_arg(ctx, expr), '') pexpr = uxpathparse(expr) for item in seq: innerctx = ctx.copy(item=item) yield from pexpr.compute(innerctx) Parses an existing sequence of the sequence of the ``item``.","summarize: def foreach_(ctx, seq, expr): ''' ''' from. import context, parse as uxpathparse if hasattr(seq, 'compute'): seq = seq.compute(ctx) expr = next(string_arg(ctx, expr), '') pexpr = uxpathparse(expr) for item in seq: innerctx = ctx.copy(item=item) yield from pexpr.compute(innerctx) Fill the following pexpr to the sequence of the API.",12.74503053,12.71257496,12.72880275,,,,,,,,,
"summarize: def get_checker_names(self):
        """"""""""""
        current_checkers = self.get_checkers()
        return sorted(
            {check.name for check in current_checkers if check.name != ""master""}
        )",Get all the checker names that this linter knows about.,"summarize: def get_checker_names(self): """""""""""" current_checkers = self.get_checkers() return sorted( {check.name for check in current_checkers if check.name!= ""master""} ) Returns the checker names of the given names.","summarize: def get_checker_names(self): """""""""""" current_checkers = self.get_checkers() return sorted( {check.name for check in current_checkers if check.name!= ""master""} ) Get the checker names of an existing name.",12.30638178,13.10236809,12.70437494,,,,,,,,,
"summarize: def decode_base64(data):
    """"""
    

    """"""
    data = bytes(data, encoding=""ascii"")
    missing_padding = len(data) % 4
    if missing_padding != 0:
        data += b'=' * (4 - missing_padding)
    return base64.b64decode(data)","Decodes a base64 string, with padding being optional","summarize: def decode_base64(data): """""" """""" data = bytes(data, encoding=""ascii"") missing_padding = len(data) % 4 if missing_padding!= 0: data += b'=' * (4 - missing_padding) return base64.b64decode(data) Decodes a data string to a file.","summarize: def decode_base64(data): """""" """""" data = bytes(data, encoding=""ascii"") missing_padding = len(data) % 4 if missing_padding!= 0: data += b'=' * (4 - missing_padding) return base64.b64decode(data) Determines if there is a string.",13.23647916,12.05275468,12.64461692,,,,,,,,,
"summarize: def setup_types(self):
        """"""
        
        """"""
        def load(t):
            from TelegramBotAPI.types.type import Type
            if isinstance(t, str):
                return Type._type(t)
            assert issubclass(t, Type)
            return t
        self.types = [load(t) for t in self.types]","The Message object has a circular reference on itself, thus we have to allow    Type referencing by name. Here we lookup any Types referenced by name and    replace with the real class.",return self.types Returns a list of types to the types in the Type.,return None def # Remove a valid OSError def validate(self): return self._validate(t) return validate return validate Updates the type of the fields are implementing a single type.,7.01565266,18.14286359,12.57925813,,,,,,,,,
"summarize: def copy(self, effects=None, target=None):
        """"""

        """"""
        warning = """"""File.copy method is deprecated and will be
            removed in 4.0.0.
            Please use `create_local_copy`
            and `create_remote_copy` instead.
        """"""
        logger.warn('API Warning: {0}'.format(warning))

        if target is not None:
            return self.create_remote_copy(target, effects)
        else:
            return self.create_local_copy(effects)",Creates a File Copy on Uploadcare or Custom Storage.        File.copy method is deprecated and will be removed in 4.0.0.    Please use `create_local_copy` and `create_remote_copy` instead.,"# Copy a new copy of the source and the copy of the copy_file = self._get_current_path() for copy in copy_file: if copy == None: self._create_remote_copy(copy, copy) else: self._create_remote_copy(copy, copy) # Create a new copy of the file for copy in copy: copy_file.set_copy(copy) return copy Copy a new copy of the files from the given file.",Get an effect on the local_copy of the specified effect.,20.94522961,4.163403398,12.5543165,,,,,,,,,
"summarize: def draw(self):
        """"""
        
        """"""
        if not self.visible:
            # Simple visibility check, has to be tested to see if it works properly
            return
        
        if not isinstance(self.submenu,Container):
            glEnable(GL_SCISSOR_TEST)
            glScissor(*self.pos+self.size)
        
        SubMenu.draw(self)
        
        if not isinstance(self.submenu,Container):
            glDisable(GL_SCISSOR_TEST)",Draws the submenu and its background.        Note that this leaves the OpenGL state set to 2d drawing and may modify the scissor settings.,"return # Simple visible by disabled self.submenu.draw(self.submenu) # For notifications, the final visible by the position is in the Visible # when the visible is assigned, which is notified # so we have the case we just assigned if self.submenu.is_printer(): self.submenu.draw(self.submenu) else: self.submenu.draw(self.submenu) # Show the visible by any of the size and the iterations self.submenu.draw(self.submenu) # Show the visible by any of the visible by the size and the # size and the iterations in the position of the visible by the",return self.submenu.draw(self.submenu) self.submenu.draw(self.submenu) self.submenu.draw(self.submenu) self.submenu.draw(self.submenu) return glEnable(self.submenu) Draw the scissolibrary.,9.49319258,15.55294883,12.52307071,,,,,,,,,
"summarize: def like(self, **kwargs):
        '''
        
        '''
        new = []
        for k, v in kwargs.items():
            v = self._check(k, v, 'like')
            new.append(Pattern(k, v))
        return self.replace(filters=self._filters+tuple(new))","When provided with keyword arguments of the form ``col=pattern``, this    will limit the entities returned to those that include the provided    pattern. Note that 'like' queries require that the ``prefix=True``    option must have been provided as part of the column definition.",If any of the aligned kwargs is already tried as a list of aligned kwargs and the like filters in the given kwargs.,Return a list of all tuples that is passed in the supplied any instances of the like object. The like objects are like objects are like objects.,9.906671461,14.99843516,12.45255331,,,,,,,,,
"summarize: def setattr(self, name, value):
    # type: (Any, Any, Any) -> Any
    '''
    '''
    try:
        self._lens_setattr
    except AttributeError:
        selfcopy = copy.copy(self)
        builtin_setattr(selfcopy, name, value)
        return selfcopy
    else:
        return self._lens_setattr(name, value)","Takes an object, a string, and a value and produces a new object  that is a copy of the original but with the attribute called ``name``  set to ``value``.",Set the value of the Any and any of the values of the specified values,Returns the keysetattr in any values of the given value.,15.99736631,8.879230737,12.43829852,,,,,,,,,
"summarize: def check_standard_dir(module_path):
    """"""""""""
    if 'site-packages' in module_path:
        return True
    for stdlib_path in _STDLIB_PATHS:
        if fnmatch.fnmatchcase(module_path, stdlib_path + '*'):
            return True
    return False",Checks whether path belongs to standard library or installed modules.,"summarize: def check_standard_dir(module_path): """""""""""" if'site-packages' in module_path: return True for stdlib_path in _STDLIB_PATHS: if fnmatch.fnmatchcase(module_path, stdlib_path + '*'): return True return False Checks if the module directory exists.","summarize: def check_standard_dir(module_path): """""""""""" if'site-packages' in module_path: return True for stdlib_path in _STDLIB_PATHS: if fnmatch.fnmatchcase(module_path, stdlib_path + '*'): return True return False Check for a given module path and standard_dir.",12.88964894,11.858254,12.37395147,,,,,,,,,
"summarize: def read_aphi_from_file(self, file_name):
        """"""
        """"""
        lg.info('Reading ahpi absorption')
        try:
            self.a_phi = self._read_iop_from_file(file_name)
        except:
            lg.exception('Problem reading file :: ' + file_name)
            self.a_phi = -1",Read the phytoplankton absorption file from a csv formatted file,"summarize: def read_aphi_from_file(self, file_name): """""" """""" lg.info('Reading ahpi absorption') try: self.a_phi = self._read_iop_from_file(file_name) except: lg.exception('Problem reading file ::'+ file_name) self.a_phi = -1 return lg Read a Iop file from the file.","summarize: def read_aphi_from_file(self, file_name): """""" """""" lg.info('Reading ahpi absorption') try: self.a_phi = self._read_iop_from_file(file_name) except: lg.exception('Problem reading file ::'+ file_name) self.a_phi = -1 lg.sort() return lg Read a HTML reading file.",13.42494003,11.31251623,12.36872813,,,,,,,,,
"summarize: def _process_pong(self):
        """"""
        
        """"""
        if len(self._pongs) > 0:
            future = self._pongs.pop(0)
            future.set_result(True)
            self._pongs_received += 1
            self._pings_outstanding -= 1",Process PONG sent by server.,self._pongs_in_pong(0) else: self._pongs_in_pong(0) Process pong.,return self._ping_pong Returns the ping ping positive pattern.,14.37066668,9.985128355,12.17789752,,,,,,,,,
"summarize: def load(self):
        """"""
        
        """"""
        self._check_open()
        try:
            data = json.load(self.file, **self.load_args)
        except ValueError:
            data = {}
        if not isinstance(data, dict):
            raise ValueError('Root JSON type must be dictionary')
        self.clear()
        self.update(data)","Force reloading the data from the file.    All data in the in-memory dictionary is discarded.    This method is called automatically by the constructor, normally you    don't need to call it.",return data Load the server and return the data from the server server.,self._check_open() self._check_open() self.update_data(data) self.update_data(data) self._check_open() Gets the JSON configuration for the given client,10.44246708,13.61896858,12.03071783,,,,,,,,,
"summarize: def main():
    rollbar.init('ACCESS_TOKEN', environment='test', handler='twisted')

    """"""""""""
    factory = protocol.ServerFactory()
    factory.protocol = Echo
    reactor.listenTCP(8000, factory)
    reactor.run()",This runs the protocol on port 8000,return factory Main access to the Geometry rollbar.,"factory.clear() factory.setHandler(""ECASS_TOKEN"", 0, env=env, rollback=env, inst=inst, rollback=rollback, rollback=rollback, install_handler=inst, install_handler=rollback, content_type=rollback, rollback=rollback, echo=rollback, abspath=env, abspath=env, install_password=install_handler, headers=rollback, factory=rollback, dest_path=dest_path, clear_on_dir=dest_path, rollback=dest_path, install_handler=install_handler) factory.add_rollback( rollback=env, env=env, handler=env, install_handler=install_handler, handler=env, factory=env, ro",13.97557324,9.984094713,11.97983398,,,,,,,,,
"summarize: def t_ARROW(self, t):
        ""
        t.endlexpos = t.lexpos + len(t.value)
        return t","r""\-\>",Get a target to a specified target.,.value Returns an ID of an XROW data.,7.321957801,16.62368086,11.97281933,,,,,,,,,
"summarize: def show(self,index=None):
        """"""""""""

        index = self._get_index(index)
        if index is None:
            return

        print >>io.stdout, self.marquee('<%s> block # %s (%s remaining)' %
                           (self.title,index,self.nblocks-index-1))
        print >>io.stdout,(self.src_blocks_colored[index])
        sys.stdout.flush()",Show a single block on screen,Load titles to the title,self.src_blocks.close() self.src_blocks.close() self._flush() self._flush() self._flush() Prints a Flush message on the marked IO,17.00126667,6.927137605,11.96420214,,,,,,,,,
"summarize: def _exit_gracefully(self, signum, frame):
        """"""
        
        """"""
        self.log.info(""Exiting gracefully upon receiving signal %s"", signum)
        self.terminate()
        self.end()
        self.log.debug(""Finished terminating DAG processors."")
        sys.exit(os.EX_OK)",Helper method to clean up DAG file processors to avoid leaving orphan processes.,self.terminate() if self.process_installed: self.terminate() self.terminate() Exits a gracefully up a signal,if frame is None: frame = frame else: frame = frame if self.exit_session is None: frame = frame.find_frame() return frame.fetchone() Execute a new URLs.,12.79854399,10.82397178,11.81125789,,,,,,,,,
"summarize: def init(self, context):
        """"""
        """"""
        self.cache = Cache()
        self.current_page_context = context
        self.current_request = context.get('request', None) if context else None
        self.current_lang = get_language()

        self._current_app_is_admin = None
        self._current_user_permissions = _UNSET
        self._items_urls = {}  # Resolved urls are cache for a request.
        self._current_items = {}",Initializes sitetree to handle new request.,"self._cache_cache_key = Cache() self._cache = Cache() self._cache.set_request('cache', Cache()) self._cache_cache(self._cache, Cache()) Initialize the current GET request.",self._set_current_request(context) return self._get_context(context) Create an existing context.,12.31272809,11.29145324,11.80209067,,,,,,,,,
"summarize: def _build_point_formats_dtypes(point_format_dimensions, dimensions_dict):
    """""" 
    """"""
    return {
        fmt_id: _point_format_to_dtype(point_fmt, dimensions_dict)
        for fmt_id, point_fmt in point_format_dimensions.items()
    }","Builds the dict mapping point format id to numpy.dtype  In the dtypes, bit fields are still packed, and need to be unpacked each time  you want to access them",Returns a list of dimensions points to a dimensions for a dtype,"Returns a point tuple of the point fields, or list of points are valid points.",8.402143898,14.91531667,11.65873028,,,,,,,,,
"summarize: def link_destroyed(self, link):
        """"""""""""
        self._links.discard(link)
        if not self._links:
            # no more links
            LOG.debug(""destroying unneeded session"")
            self._pn_session.close()
            self._pn_session.free()
            self._pn_session = None
            self._connection = None",Link has been destroyed.,self._client.close() self._pn_session.close() self._links.discard(link) return self._links[0] Return a link to descard,self._pn_session.free() self._pn_session.close() Update an ID.,5.134481197,18.025288,11.5798846,,,,,,,,,
"summarize: def gmtime_adj_notAfter(self, amount):
        """"""
        
        """"""
        if not isinstance(amount, int):
            raise TypeError(""amount must be an integer"")

        notAfter = _lib.X509_get_notAfter(self._x509)
        _lib.X509_gmtime_adj(notAfter, amount)",Adjust the time stamp on which the certificate stops being valid.,"return self._adjust_notAfter(self._x509_gmtime_adj, amount) Gmtimes an integer adjusted by the amount.","_lib.X509_gmtime_adj(amount, _lib) self.lblTimeData(after=amount) return _lib.X509_GMT(self.gmtime.timedelta(""%Y%m%d%H%M%S"")) Get after after the after the normal element.",14.31604914,8.767094135,11.54157164,,,,,,,,,
"summarize: def _override_setuptools(req):
    """"""

    """"""
    if req.project_name == 'setuptools':
        if not len(req.specs):
            # Just setuptools: ok
            return True
        for comparator, version in req.specs:
            if comparator in ['==', '>=', '>']:
                if '0.7' in version:
                    # We want some setuptools not from the 0.6 series.
                    return False
        return True
    return False",Return True when distribute wants to override a setuptools dependency.,"summarize: def _override_setuptools(req): """""" """""" if req.project_name =='setuptools': if not len(req.specs): # Just setuptools: ok return True for comparator, version in req.specs: if comparator in ['==', '>=', '>']: if '0.7' in version: # We want some setuptools not from the 0.6 series. return False return True return False Returns True if an override_setuptools is true.","summarize: def _override_setuptools(req): """""" """""" if req.project_name =='setuptools': if not len(req.specs): # Just setuptools: ok return True for comparator, version in req.specs: if comparator in ['==', '>=', '>']: if '0.7' in version: # We want some setuptools not from the 0.6 series. return False return True return False Returns a setuptools to the setuptools too.",11.17181237,11.74603487,11.45892362,,,,,,,,,
"summarize: def main():
    """"""
    
    """"""

    # getting info for creating event
    options = parse_options()
    config = parse_config(options)
    credentials = get_google_credentials(options, config)

    if not options.get_google_credentials:
        create_event(options, config, credentials)",Processing notification call main function.,"return options.get_google_credentials(options, config, credentials) Maine process of Google events into Google Event.","else: create_google_credentials(options, config) return config Main event from an event.",11.84747653,10.40509703,11.12628678,,,,,,,,,
"summarize: def _get_remote_settle_modes(pn_link):
    """"""
    """"""
    modes = {}
    snd = pn_link.remote_snd_settle_mode
    if snd == proton.Link.SND_UNSETTLED:
        modes['snd-settle-mode'] = 'unsettled'
    elif snd == proton.Link.SND_SETTLED:
        modes['snd-settle-mode'] = 'settled'
    if pn_link.remote_rcv_settle_mode == proton.Link.RCV_SECOND:
        modes['rcv-settle-mode'] = 'second'
    return modes",Return a map containing the settle modes as provided by the remote.  Skip any default value.,"summarize: def _get_remote_settle_modes(pn_link): """""" """""" modes = {} snd = pn_link.remote_snd_settle_mode if snd == proton.Link.SND_UNSETTLED: modes['snd-settle-mode'] = 'unsettled' elif snd == proton.Link.SND_SETTLED: modes['snd-settle-mode'] ='settled' if pn_link.remote_rcv_settle_mode == proton.Link.RCV_SECOND: modes['rcv-settle-mode'] ='second' return modes Returns the settle modes of the link.","summarize: def _get_remote_settle_modes(pn_link): """""" """""" modes = {} snd = pn_link.remote_snd_settle_mode if snd == proton.Link.SND_UNSETTLED: modes['snd-settle-mode'] = 'unsettled' elif snd == proton.Link.SND_SETTLED: modes['snd-settle-mode'] ='settled' if pn_link.remote_rcv_settle_mode == proton.Link.RCV_SECOND: modes['rcv-settle-mode'] ='second' return modes Remove any remote settled by the remote_rcv_settled triggered settled",10.86676978,10.96771084,10.91724031,,,,,,,,,
"summarize: def handle_ignored_message(
        self, state_scope, msgid, line, node, args, confidence
    ):  # pylint: disable=unused-argument
        """"""
        """"""
        if state_scope == MSG_STATE_SCOPE_MODULE:
            try:
                orig_line = self._suppression_mapping[(msgid, line)]
                self._ignored_msgs[(msgid, orig_line)].add(line)
            except KeyError:
                pass",Report an ignored message.,"else: self._ignored_msgs[(msgid, orig_line)].add(line) return orig_line Handle a message to a given message.","except KeyError: pass return self._suppression_to_event(state_scope, node, node, confidence, confidence) Return a MSG message to the more than the scope.",14.16904481,7.645701175,10.90737299,,,,,,,,,
"summarize: def standard(cls, element):
        """"""
        
        """"""

        # We remove all special characters and return the formatted string.
        return (
            Regex(element, cls.regex_replace, replace_with=""@funilrys"")
            .replace()
            .replace(""@funilrys"", """")
        )",Implement the standard and alphabetical sorting.,"summarize: def standard(cls, element): """""" """""" # We remove all special characters and return the formatted string. return ( Regex(element, cls.regex_replace, replace_with=""@funilrys"") .replace() .replace(""@funilrys"", """") ) Standard the given element.","summarize: def standard(cls, element): """""" """""" # We remove all special characters and return the formatted string. return ( Regex(element, cls.regex_replace, replace_with=""@funilrys"") .replace() .replace(""@funilrys"", """") ) Standard the standard standard elements.",10.90666474,10.80827794,10.85747134,,,,,,,,,
"summarize: def get_language(self, text):
        """""" 
        """"""
        files = {'text': text}
        res, status_code = self.post(self.language_service, files=files)

        if status_code != 200:
            logger.debug('Language recognition failed.')

        return self.decode(res), status_code",Recognise the language of the text in input,"summarize: def get_language(self, text): """""" """""" files = {'text': text} res, status_code = self.post(self.language_service, files=files) if status_code!= 200: logger.debug('Language recognition failed.') return self.decode(res), status_code Returns the language representation of the text or code for the text.","summarize: def get_language(self, text): """""" """""" files = {'text': text} res, status_code = self.post(self.language_service, files=files) if status_code!= 200: logger.debug('Language recognition failed.') return self.decode(res), status_code Returns the language of the given text.",10.27955056,10.97969912,10.62962484,,,,,,,,,
"summarize: def _broadcast_maybelist_arg(states, secondary_arg, name):
  """"""""""""
  if _is_list_like(secondary_arg):
    if len(secondary_arg) != len(states):
      raise ValueError('Argument `%s` was a list of different length ({}) than '
                       '`states` ({})'.format(name, len(states)))
  else:
    secondary_arg = [secondary_arg] * len(states)

  return secondary_arg",Broadcast a listable secondary_arg to that of states.,"summarize: def _broadcast_maybelist_arg(states, secondary_arg, name): """""""""""" if _is_list_like(secondary_arg): if len(secondary_arg)!= len(states): raise ValueError('Argument `%s` was a list of different length ({}) than ' '`states` ({})'.format(name, len(states))) else: secondary_arg = [secondary_arg] * len(states) return secondary_arg Convert broadcast arguments to secondary arguments","summarize: def _broadcast_maybelist_arg(states, secondary_arg, name): """""""""""" if _is_list_like(secondary_arg): if len(secondary_arg)!= len(states): raise ValueError('Argument `%s` was a list of different length ({}) than ' '`states` ({})'.format(name, len(states))) else: secondary_arg = [secondary_arg] * len(states) return secondary_arg Returns a dict of relations of a states.",10.62648606,10.63107443,10.62878025,,,,,,,,,
"summarize: def main(argv):
    """"""
    
    """"""
    global g_test_root_dir
    global g_temp_filename

    if len(argv) < 2:
        print(""invoke this script as python extractGLRMRuntimeJavaLog.py javatextlog.\n"")
        sys.exit(1)
    else:   # we may be in business
        javaLogText = argv[1]         # filename while java log is stored

        print(""your java text is {0}"".format(javaLogText))
        extractRunInto(javaLogText)","Main program. Take user input, parse it and call other functions to execute the commands  and extract run summary and store run result in json file","g_metrics = get_global_metrics(argv) g_metrics = get_global_metrics(arg_metrics) g_metrics.update(g_metrics) g_metrics.update(g_metrics) # we don't want to add the extractGLRMRuntimeJavaLog # which is the final lines, but we are done, the global lines we just create the metrics # when the global lines were the global lines were were just add the javaLog.py. # which would be done in the extractGLRMRuntimeJaVaLog.py. extractRunInto(javaLog.metrics) # we are","sys.exit(1) # store while we need to add any java packages, # just add the java ExecutionJob # if there is a javaLog # as there is no packages, it's just replace this packages. packages = [] for arg in argv: packages.append(arg) # add the arguments in any arguments to the global java file argv = [] for arg in argv: packages.append(arg) # Get the packages, which can be used to script java file # and there. for package in packages: packages.append(package) # Get",8.653915225,12.57212604,10.61302063,,,,,,,,,
"summarize: def lowercase_ext(filename):
    """"""
    
    """"""
    if '.' in filename:
        main, ext = os.path.splitext(filename)
        return main + ext.lower()
    # For consistency with os.path.splitext,
    # do not treat a filename without an extension as an extension.
    # That is, do not return filename.lower().
    return filename","This is a helper used by UploadSet.save to provide lowercase extensions for  all processed files, to compare with configured extensions in the same  case.",Returns the filename without a filename and returns an extension.,".replace(""."", ""."") Returns the lowercase of the filename.",12.64533179,8.461649529,10.55349066,,,,,,,,,
"summarize: def pool_full(self, session):
        """"""
        
        """"""
        if not self.task.pool:
            return False

        pool = (
            session
            .query(Pool)
            .filter(Pool.pool == self.task.pool)
            .first()
        )
        if not pool:
            return False
        open_slots = pool.open_slots(session=session)

        return open_slots <= 0",Returns a boolean as to whether the slot pool has room for this    task to run,"summarize: def pool_full(self, session): """""" """""" if not self.task.pool: return False pool = ( session .query(Pool) .filter(Pool.pool == self.task.pool) .first() ) if not pool: return False open_slots = pool.open_slots(session=session) return open_slots <= 0 Returns True if the slots found.","summarize: def pool_full(self, session): """""" """""" if not self.task.pool: return False pool = ( session .query(Pool) .filter(Pool.pool == self.task.pool) .first() ) if not pool: return False open_slots = pool.open_slots(session=session) return open_slots <= 0 Return a list of pools that are found to the input following about the given sessions.",11.17194795,9.826581582,10.49926477,,,,,,,,,
"summarize: def preprocess_JPEG(self, image, **kwargs):
        """"""
        
        """"""
        save_kwargs = {
            'progressive': VERSATILEIMAGEFIELD_PROGRESSIVE_JPEG,
            'quality': QUAL
        }
        if image.mode != 'RGB':
            image = image.convert('RGB')
        return (image, save_kwargs)",Receive a PIL Image instance of a JPEG and returns 2-tuple.,"summarize: def preprocess_JPEG(self, image, **kwargs): """""" """""" save_kwargs = { 'progressive': VERSATILEIMAGEFIELD_PROGRESSIVE_JPEG, 'quality': QUAL } if image.mode!= 'RGB': image = image.convert('RGB') return (image, save_kwargs) Reads JPEG and returns JPEG","summarize: def preprocess_JPEG(self, image, **kwargs): """""" """""" save_kwargs = { 'progressive': VERSATILEIMAGEFIELD_PROGRESSIVE_JPEG, 'quality': QUAL } if image.mode!= 'RGB': image = image.convert('RGB') return (image, save_kwargs) Returns a JPEG object from an image.",10.89662789,9.738215182,10.31742154,,,,,,,,,
"summarize: def _random_adjspecies_pair():
    """"""""""""
    describer, desc_position = random_describer()
    if desc_position == 'prefix':
        return (describer, random_species())
    elif desc_position == 'suffix':
        return (random_species(), describer)",Return an ordered 2-tuple containing a species and a describer.,"summarize: def _random_adjspecies_pair(): """""""""""" describer, desc_position = random_describer() if desc_position == 'prefix': return (describer, random_species()) elif desc_position =='suffix': return (random_species(), describer) else: return desc_position Get a species pair of a species pair of a describer.","summarize: def _random_adjspecies_pair(): """""""""""" describer, desc_position = random_describer() if desc_position == 'prefix': return (describer, random_species()) elif desc_position =='suffix': return (random_species(), describer) else: return (desc_position + desc_position) Returns a list of description of the species and adjacencying the description of the description.",10.78143902,9.816231595,10.29883531,,,,,,,,,
"summarize: def main():
    """"""""""""

    args = parser.parse_args()
    run_ms_bot_framework_server(agent_generator=make_agent,
                                app_id=args.ms_id,
                                app_secret=args.ms_secret,
                                stateful=True)",Parse parameters and run ms bot framework,"if not args.is_init(): sys.exit(not args.ms_id) try: # If the agent is do not already in add the agent. agent_generator = run_ms_bot_framework_server(agent_generator, app_secretator=app_secretator, stateful=stateful) agent_generator = run_ms_bot_framework_server(agent_generator=agent_generator, app_id=app_id, stateful=stateful) except Exception as e: raise errors.InvalidAgent( ""Command: %s: %s: %s"" % ( agent_generator, agent_generator, e)) return agent_generator Parse a list of agents for a given agent.","return run_ms_bot_framework_server(run_ms_bot_framework, run_ms_bot_framework_server) Return a multiple server.",4.590494753,15.70995853,10.15022664,,,,,,,,,
"summarize: def run(self, dag):
        """"""
        
        """"""
        num_dag_qubits = sum([qreg.size for qreg in dag.qregs.values()])
        if num_dag_qubits > self.coupling_map.size():
            raise TranspilerError('Number of qubits greater than device.')
        self.property_set['layout'] = Layout.generate_trivial_layout(*dag.qregs.values())","Pick a layout by assigning n circuit qubits to device qubits 0, .., n-1.",self.property_set['dag_qubits'] = self.property_set['layout'] self.property_set['layout'] = self.property_set['layout'] self.property_set['layout'] = layout = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.property_set['layout'] = layout self.proper,"return self.property_set_diag_qubits(dag.qubits, num_dag_qubits, num_dag_qubits) Returns the running dag.",1.916388429,18.33990039,10.12814441,,,,,,,,,
"summarize: def stretch_demo(input_file, output_file, speed):
    '''
    '''

    # 1. Load the wav file, resample
    print('Loading ', input_file)

    y, sr = librosa.load(input_file)

    # 2. Time-stretch through effects module
    print('Playing back at {:3.0f}% speed'.format(speed * 100))

    y_stretch = librosa.effects.time_stretch(y, speed)

    print('Saving stretched audio to: ', output_file)
    librosa.output.write_wav(output_file, y_stretch, sr)",Phase-vocoder time stretch demo function.,Save the output file to library.,"# 1. 3. Maybe create the stream print('Loading stretch...', speed) stretch.stream.write(""Effects."") # 2. If we don't load any effects, it's any... stretch.stream.write(""{:3f}"".format(speed)) # 2. If we'll have a function then avoid augmenting the # over the speed to stream which create a bug # then save the folder streaming stream_size = 100 for i in range(speed): if i == 0: stream_size += 1 else: stream_size = librosa.SpeedStream( y, speed) speed =",15.1680645,5.072819057,10.12044178,,,,,,,,,
"summarize: def cylindrical_vert(script, radius=1.0, inside=True):
    """"""
    """"""
    if inside:
        function = 'sqrt(x^2+y^2)<={}'.format(radius)
    else:
        function = 'sqrt(x^2+y^2)>={}'.format(radius)
    vert_function(script, function=function)
    return None",Select all vertices within a cylindrical radius,"summarize: def cylindrical_vert(script, radius=1.0, inside=True): """""" """""" if inside: function ='sqrt(x^2+y^2)<={}'.format(radius) else: function ='sqrt(x^2+y^2)>={}'.format(radius) vert_function(script, function=function) return None Finds an vert between vertical vert","summarize: def cylindrical_vert(script, radius=1.0, inside=True): """""" """""" if inside: function ='sqrt(x^2+y^2)<={}'.format(radius) else: function ='sqrt(x^2+y^2)>={}'.format(radius) vert_function(script, function=function) return None Calculates a MacroPlot object from sqrt.",10.3543953,9.812156553,10.08327593,,,,,,,,,
"summarize: def deregister_job(self, id, purge=None):
        """""" 
        """"""
        params = None
        if purge is not None:
            if not isinstance(purge, bool):
                raise nomad.api.exceptions.InvalidParameters(""purge is invalid ""
                        ""(expected type %s but got %s)""%(type(bool()), type(purge)))
            params = {""purge"": purge}
        return self.request(id, params=params, method=""delete"").json()","Deregisters a job, and stops all allocations part of it.",Deletes a job with the job.,Gets the default job object from its job,10.51444651,9.292359048,9.903402779,,,,,,,,,
"summarize: def require_boss(self, callback):
        """"""
        """"""
        def inner(nick, message, channel, *args, **kwargs):
            if nick != self.boss:
                return
            
            return callback(nick, message, channel, *args, **kwargs)
        return inner",\    Decorator to ensure that commands only can come from the boss,"summarize: def require_boss(self, callback): """""" """""" def inner(nick, message, channel, *args, **kwargs): if nick!= self.boss: return return callback(nick, message, channel, *args, **kwargs) return inner(nick, message, channel, *args, **kwargs) Allows the bounds to the specified box.","summarize: def require_boss(self, callback): """""" """""" def inner(nick, message, channel, *args, **kwargs): if nick!= self.boss: return return callback(nick, message, channel, *args, **kwargs) return inner Decorator to require the requirements on the given message.",7.463917733,12.29755661,9.880737172,,,,,,,,,
"summarize: def open(self):
        """"""""""""
        self.stats = self.linter.add_stats()
        self._returns = []
        self._branches = defaultdict(int)
        self._stmts = []",initialize visit variables,"for k,v in self._branches.items(): self._v.priority = k self._priority.append(v) self._handle_back() Plot the stats of the files in the files",for key in self.stats: if key not in self.stats: self.stats.append(key) return self.stats Return a list of keys in the given branches in the page.,3.81498576,15.42257398,9.61877987,,,,,,,,,
"summarize: def get_data(self, cache=True, as_text=False, parse_form_data=False):
        """"""
        """"""
        rv = getattr(self, '_cached_data', None)
        if rv is None:
            if parse_form_data:
                self._load_form_data()
            rv = self.stream.read()
            if cache:
                self._cached_data = rv
        if as_text:
            rv = rv.decode(self.charset, self.encoding_errors)
        return rv",This reads the buffered incoming data from the client into one    bytestring. By default this is cached but that behavior can be    changed by setting `cache` to `False`.,Returns the data for the given text and its characters.,.get_response_form_data() Return the data from the data in the given cache.,5.970587621,13.19046957,9.580528596,,,,,,,,,
"summarize: def _backup(self):
        """"""
        
        """"""

        if PyFunceble.CONFIGURATION[""mining""]:
            # The mining is activated.

            # We backup our mined informations.
            Dict(PyFunceble.INTERN[""mined""]).to_json(self.file)",Backup the mined informations.,"# We have a backup our function. # We can just check that the job jobs are integers. if Dict(self.file): # The file exists for the jobs are fully return self._create_jobs(jobs_key, jobs_key, self.file) return jobs_key Load the jobs into the file and return it.","return Dict(self.files, ""wb"", Dict(self.files, ""wb"")) else: return Dict(self.files, ""wb"", Dict(self.files, ""wb"")) Write a Minimal.",5.315301922,13.40419553,9.359748726,,,,,,,,,
"summarize: def surface_to_element_sets(self, tag):
    """"""
    
    """"""
    surface = self.elements.surfaces[tag]
    for findex in surface.keys():
      if surface[findex].sum() != 0:
        self.elements[(""sets"", ""_SURF_{0}_FACE{1}""
                     .format(tag, findex[1:]), """")] = surface[findex]",Creates elements sets corresponding to a surface.,"summarize: def surface_to_element_sets(self, tag): """""" """""" surface = self.elements.surfaces[tag] for findex in surface.keys(): if surface[findex].sum()!= 0: self.elements[(""sets"", ""_SURF_{0}_FACE{1}"" .format(tag, findex[1:]), """")] = surface[findex] return surface Converts an element set to a surface element.","summarize: def surface_to_element_sets(self, tag): """""" """""" surface = self.elements.surfaces[tag] for findex in surface.keys(): if surface[findex].sum()!= 0: self.elements[(""sets"", ""_SURF_{0}_FACE{1}"" .format(tag, findex[1:]), """")] = surface[findex] return surface Returns a surface to an iterable sets of elements.",9.3803038,9.299362036,9.339832918,,,,,,,,,
"summarize: def join_html_attrs(attrs):
    """"""
    """"""
    attrs = collections.OrderedDict(freeze_dict(attrs or {}))
    template = ' '.join('%s=""{%d}""' % (k, i) for i, k in enumerate(attrs))
    return template, list(attrs.values())",Joins the map structure into HTML attributes.,"summarize: def join_html_attrs(attrs): """""" """""" attrs = collections.OrderedDict(freeze_dict(attrs or {})) template =''.join('%s=""{%d}""' % (k, i) for i, k in enumerate(attrs)) return template, list(attrs.values()) List HTML attributes to ""host"".","summarize: def join_html_attrs(attrs): """""" """""" attrs = collections.OrderedDict(freeze_dict(attrs or {})) template =''.join('%s=""{%d}""' % (k, i) for i, k in enumerate(attrs)) return template, list(attrs.values()) Fills the HTML object.",10.13335859,8.503352101,9.318355346,,,,,,,,,
"summarize: def update_transfer_job(self, job_name, body):
        """"""
        
        """"""
        body = self._inject_project_id(body, BODY, PROJECT_ID)
        return (
            self.get_conn()
            .transferJobs()
            .patch(jobName=job_name, body=body)
            .execute(num_retries=self.num_retries)
        )",Updates a transfer job that runs periodically.,"summarize: def update_transfer_job(self, job_name, body): """""" """""" body = self._inject_project_id(body, BODY, PROJECT_ID) return ( self.get_conn() .transferJobs() .patch(jobName=job_name, body=body) .execute(num_retries=self.num_retries) ) Updates a transaction.","summarize: def update_transfer_job(self, job_name, body): """""" """""" body = self._inject_project_id(body, BODY, PROJECT_ID) return ( self.get_conn() .transferJobs() .patch(jobName=job_name, body=body) .execute(num_retries=self.num_retries) ) Updates a specific job to jobs.",9.424215091,9.124086072,9.274150582,,,,,,,,,
"summarize: def _register_engine(self, uid):
        """"""""""""
        # head of the line:
        self.targets.insert(0,uid)
        self.loads.insert(0,0)

        # initialize sets
        self.completed[uid] = set()
        self.failed[uid] = set()
        self.pending[uid] = {}

        # rescan the graph:
        self.update_graph(None)",New engine with ident `uid` became available.,"# update the results self.procan_session.update({uid: uid}) return self.procan_session.add_source(uid,uid) Register a new engine.",self.targets.remove(uid) self.targets.remove(uid) self.remove(uid) self.remove(uid) Removes the ``UID`` sets.,10.33902259,8.19517447,9.26709853,,,,,,,,,
"summarize: def is_christmas_period():
    """"""""""""
    now = datetime.date.today()
    if now.month != 12:
        return False
    if now.day < 15:
        return False
    if now.day > 27:
        return False
    return True",Is this the christmas period?,"summarize: def is_christmas_period(): """""""""""" now = datetime.date.today() if now.month!= 12: return False if now.day < 15: return False if now.day > 27: return False return True Check if the christmas are alpha.","summarize: def is_christmas_period(): """""""""""" now = datetime.date.today() if now.month!= 12: return False if now.day < 15: return False if now.day > 27: return False return True Find any of the ``day`` if this is a valid character.",9.352570584,8.917295429,9.134933007,,,,,,,,,
"summarize: def isin(self, item):
        """"""
        
        """"""
        if is_type(item, list, tuple, set):
            if self.ncols == 1 and (self.type(0) == 'str' or self.type(0) == 'enum'):
                return self.match(item)
            else:
                return functools.reduce(H2OFrame.__or__, (self == i for i in item))
        else:
            return self == item",Test whether elements of an H2OFrame are contained in the ``item``.,"summarize: def isin(self, item): """""" """""" if is_type(item, list, tuple, set): if self.ncols == 1 and (self.type(0) =='str' or self.type(0) == 'enum'): return self.match(item) else: return functools.reduce(H2OFrame.__or__, (self == i for i in item)) else: return self == item.isin(item) Returns the H2OFrame instance that are in the same item.","summarize: def isin(self, item): """""" """""" if is_type(item, list, tuple, set): if self.ncols == 1 and (self.type(0) =='str' or self.type(0) == 'enum'): return self.match(item) else: return functools.reduce(H2OFrame.__or__, (self == i for i in item)) else: return self == item Return the type of the specified item.",9.137196779,9.129271595,9.133234187,,,,,,,,,
"summarize: def  add_block_lines( self ):
        """"""""""""
        if self.lines != []:
            block = SourceBlock( self, self.filename, self.lineno, self.lines )

            self.blocks.append( block )
            self.format = None
            self.lines  = []",add the current accumulated lines and create a new block,"summarize: def add_block_lines( self ): """""""""""" if self.lines!= []: block = SourceBlock( self, self.filename, self.lineno, self.lines ) self.blocks.append( block ) self.format = None self.lines = [] self.blocks.append( block) Add lines to the blocks","summarize: def add_block_lines( self ): """""""""""" if self.lines!= []: block = SourceBlock( self, self.filename, self.lineno, self.lines ) self.blocks.append( block ) self.format = None self.lines = [] self.blocks.append(block) # create a block list of the blocks. self.blocks.append(block) Add a blocks to the ``bucket``.",8.732131491,8.983049191,8.857590341,,,,,,,,,
"summarize: def parse_change_info(e_change_info):
    """"""
    
    """"""

    if e_change_info is None:
        return e_change_info

    status = e_change_info.find('./{*}Status').text
    submitted_at = e_change_info.find('./{*}SubmittedAt').text
    submitted_at = parse_iso_8601_time_str(submitted_at)

    return {
        'request_id': id,
        'request_status': status,
        'request_submitted_at': submitted_at
    }","Parses a ChangeInfo tag. Seen in CreateHostedZone, DeleteHostedZone,  and ChangeResourceRecordSetsRequest.","summarize: def parse_change_info(e_change_info): """""" """""" if e_change_info is None: return e_change_info status = e_change_info.find('./{*}Status').text submitted_at = e_change_info.find('./{*}SubmittedAt').text submitted_at = parse_iso_8601_time_str(submitted_at) return { 'request_id': id, 'request_status': status, 'request_submitted_at': submitted_at } Parses a needed Event Info Method","summarize: def parse_change_info(e_change_info): """""" """""" if e_change_info is None: return e_change_info status = e_change_info.find('./{*}Status').text submitted_at = e_change_info.find('./{*}SubmittedAt').text submitted_at = parse_iso_8601_time_str(submitted_at) return { 'request_id': id, 'request_status': status, 'request_submitted_at': submitted_at } Returns a change instance.",9.405811787,8.179828787,8.792820287,,,,,,,,,
"summarize: def IsAcceptedKey(self, evt):
        """"
        ## Oops, there's a bug here, we'll have to do it ourself..
        ##return self.base_IsAcceptedKey(evt)
        return (not (evt.ControlDown() or evt.AltDown()) and
                evt.GetKeyCode() != wx.WXK_SHIFT)",Return True to allow the given key to start editing,"summarize: def IsAcceptedKey(self, evt): """" ## Oops, there's a bug here, we'll have to do it ourself.. ##return self.base_IsAcceptedKey(evt) return (not (evt.ControlDown() or evt.AltDown()) and evt.GetKeyCode()!= wx.WXK_SHIFT) Determine the process key on a given evt.","summarize: def IsAcceptedKey(self, evt): """" ## Oops, there's a bug here, we'll have to do it ourself.. ##return self.base_IsAcceptedKey(evt) return (not (evt.ControlDown() or evt.AltDown()) and evt.GetKeyCode()!= wx.WXK_SHIFT) Returns an issue ID of the current keyey.",9.492270047,7.951137072,8.72170356,,,,,,,,,
"summarize: def find_gui_and_backend(gui=None):
    """"""
    """"""

    import matplotlib

    if gui and gui != 'auto':
        # select backend based on requested gui
        backend = backends[gui]
    else:
        backend = matplotlib.rcParams['backend']
        # In this case, we need to find what the appropriate gui selection call
        # should be for IPython, so we can activate inputhook accordingly
        gui = backend2gui.get(backend, None)
    return gui, backend",Given a gui string return the gui and mpl backend.,"summarize: def find_gui_and_backend(gui=None): """""" """""" import matplotlib if gui and gui!= 'auto': # select backend based on requested gui backend = backends[gui] else: backend = matplotlib.rcParams['backend'] # In this case, we need to find what the appropriate gui selection call # should be for IPython, so we can activate inputhook accordingly gui = backend2gui.get(backend, None) return gui, backend Find a backend with a given gui backends","summarize: def find_gui_and_backend(gui=None): """""" """""" import matplotlib if gui and gui!= 'auto': # select backend based on requested gui backend = backends[gui] else: backend = matplotlib.rcParams['backend'] # In this case, we need to find what the appropriate gui selection call # should be for IPython, so we can activate inputhook accordingly gui = backend2gui.get(backend, None) return gui, backend Find a given gui for the given gui gui.",8.505514861,8.60559266,8.555553761,,,,,,,,,
"summarize: def is_contained_in(pe_pe, root):
    '''
    
    '''
    if not pe_pe:
        return False
    
    if type(pe_pe).__name__ != 'PE_PE':
        pe_pe = one(pe_pe).PE_PE[8001]()
    
    ep_pkg = one(pe_pe).EP_PKG[8000]()
    c_c = one(pe_pe).C_C[8003]()
    
    if root in [ep_pkg, c_c]:
        return True
    
    elif is_contained_in(ep_pkg, root):
        return True
    
    elif is_contained_in(c_c, root):
        return True
    
    else:
        return False",Determine if a PE_PE is contained within a EP_PKG or a C_C.,"summarize: def is_contained_in(pe_pe, root): ''' ''' if not pe_pe: return False if type(pe_pe).__name__!= 'PE_PE': pe_pe = one(pe_pe).PE_PE[8001]() ep_pkg = one(pe_pe).EP_PKG[8000]() c_c = one(pe_pe).C_C[8003]() if root in [ep_pkg, c_c]: return True elif is_contained_in(ep_pkg, root): return True elif is_contained_in(c_c, root): return True else: return False Determine if a pe is a contained in the root.","summarize: def is_contained_in(pe_pe, root): ''' ''' if not pe_pe: return False if type(pe_pe).__name__!= 'PE_PE': pe_pe = one(pe_pe).PE_PE[8001]() ep_pkg = one(pe_pe).EP_PKG[8000]() c_c = one(pe_pe).C_C[8003]() if root in [ep_pkg, c_c]: return True elif is_contained_in(ep_pkg, root): return True elif is_contained_in(c_c, root): return True else: return False Return a list of contained in the root.",9.557493822,7.534323335,8.545908579,,,,,,,,,
"summarize: def is_detached(self):
        """"""
        """"""
        cmd_sym = ['git', 'symbolic-ref', 'HEAD']

        try:
            self._exec(cmd_sym, cwd=self.dirpath, env=self.gitenv)
        except RepositoryError as e:
            if e.msg.find(""ref HEAD is not a symbolic ref"") == -1:
                raise e
            return True
        else:
            return False",Check if the repo is in a detached state.,"summarize: def is_detached(self): """""" """""" cmd_sym = ['git','symbolic-ref', 'HEAD'] try: self._exec(cmd_sym, cwd=self.dirpath, env=self.gitenv) except RepositoryError as e: if e.msg.find(""ref HEAD is not a symbolic ref"") == -1: raise e return True else: return False Check if the given authenticated details are deleted or not.","summarize: def is_detached(self): """""" """""" cmd_sym = ['git','symbolic-ref', 'HEAD'] try: self._exec(cmd_sym, cwd=self.dirpath, env=self.gitenv) except RepositoryError as e: if e.msg.find(""ref HEAD is not a symbolic ref"") == -1: raise e return True else: return False Check if the given sym.find('.') is not None and not a ref. If there is a ref. If we are not in the detached symbolic ref and otherwise.",9.090521687,7.724766607,8.407644147,,,,,,,,,
"summarize: def parse_line(self, line):
        """"""
        """"""
        if line[0].isspace():
            # continuation of a multi-line header
            new_part = ' ' + line.lstrip()
            self._as_list[self._last_key][-1] += new_part
            dict.__setitem__(self, self._last_key,
                             self[self._last_key] + new_part)
        else:
            name, value = line.split("":"", 1)
            self.add(name, value.strip())",Updates the dictionary with a single header line.,"summarize: def parse_line(self, line): """""" """""" if line[0].isspace(): # continuation of a multi-line header new_part ='' + line.lstrip() self._as_list[self._last_key][-1] += new_part dict.__setitem__(self, self._last_key, self[self._last_key] + new_part) else: name, value = line.split("":"", 1) self.add(name, value.strip()) return new_part Parse a line with a single line.","summarize: def parse_line(self, line): """""" """""" if line[0].isspace(): # continuation of a multi-line header new_part ='' + line.lstrip() self._as_list[self._last_key][-1] += new_part dict.__setitem__(self, self._last_key, self[self._last_key] + new_part) else: name, value = line.split("":"", 1) self.add(name, value.strip()) self._part(name, value.strip()) return self._part(name, new_part) Updates another line line.",9.036707368,7.290786345,8.163746857,,,,,,,,,
"summarize: def select_name_pattern(source, pat):
    '''
    
    '''
    return filter(lambda x: pat.match(x.xml_name) is not None, select_elements(source))","Yields elements from the source whose name matches the given regular expression pattern  source - if an element, starts with all child elements in order; can also be any other iterator  pat - re.pattern object",Perform a source name pattern to the source name pattern,"Makes a single pattern. If this is a valid name pattern, returns a dictionary of ``Source``.",4.945784962,11.3465223,8.146153631,,,,,,,,,
"summarize: def main():
    """"""""""""
    # magic_files = {}
    for filename in locate_files(ROOT_DIR):
        print(""Processing %s"" % filename)
        with open(filename, ""rt"") as f:
            tokens = list(tokenize.generate_tokens(f.readline))
            text1 = tokenize.untokenize(tokens)
            ntokens = normalize_tokens(tokens)
            text2 = tokenize.untokenize(ntokens)
            assert text1 == text2",Executed when script is run as-is.,"return ntokens, text2, ntokens, ntokens, ntokens, ntokens Adds the magic files to the given files",if text2 == text2: text2 = text2 if text2 == text2: text2 = text2 else: text2 = text2 text2 = text2 else: text2 = text2 else: text2 = text2 text2 = text2 if text2 == text2: text2 = text2 else: text2 = text2 normalized_text2 = text2 text2 = text2 text2 = text2 text2 = text2 text2 = text2 text2 = text2 else: text2 = text2 text2 = text2 text2 = text2 text2 = text2 text2 = text2 if text2 == text2: text2 = text2 return text2 Method to make a floating component of a positive distribution.,5.313915703,10.92099181,8.117453757,,,,,,,,,
"summarize: def upload_link(self, folder_id=None, sha1=None, httponly=False):
        """"""

        """"""

        kwargs = {'folder': folder_id, 'sha1': sha1, 'httponly': httponly}
        params = {key: value for key, value in kwargs.items() if value}
        return self._get('file/ul', params=params)",Makes a request to prepare for file upload.,"summarize: def upload_link(self, folder_id=None, sha1=None, httponly=False): """""" """""" kwargs = {'folder': folder_id,'sha1': sha1, 'httponly': httponly} params = {key: value for key, value in kwargs.items() if value} return self._get('file/ul', params=params) Makes the link to a Folder id.","summarize: def upload_link(self, folder_id=None, sha1=None, httponly=False): """""" """""" kwargs = {'folder': folder_id,'sha1': sha1, 'httponly': httponly} params = {key: value for key, value in kwargs.items() if value} return self._get('file/ul', params=params) Request an URL path from a JSON-List dict.",8.382475612,7.819791412,8.101133512,,,,,,,,,
"summarize: def adobe_glyph_values():
  """"""""""""

  lines  = string.split( adobe_glyph_list, '\n' )
  glyphs = []
  values = []

  for line in lines:
    if line:
      fields = string.split( line, ';' )
#     print fields[1] + ' - ' + fields[0]
      subfields = string.split( fields[1], ' ' )
      if len( subfields ) == 1:
        glyphs.append( fields[0] )
        values.append( fields[1] )

  return glyphs, values",return the list of glyph names and their unicode values,"summarize: def adobe_glyph_values(): """""""""""" lines = string.split( adobe_glyph_list, '\n' ) glyphs = [] values = [] for line in lines: if line: fields = string.split( line, ';' ) # print fields[1] +'-'+ fields[0] subfields = string.split( fields[1],'' ) if len( subfields ) == 1: glyphs.append( fields[0] ) values.append( fields[1] ) return glyphs, values Add a list of glyphs to the glyphs.","summarize: def adobe_glyph_values(): """""""""""" lines = string.split( adobe_glyph_list, '\n' ) glyphs = [] values = [] for line in lines: if line: fields = string.split( line, ';' ) # print fields[1] +'-'+ fields[0] subfields = string.split( fields[1],'' ) if len( subfields ) == 1: glyphs.append( fields[0] ) values.append( fields[1] ) return glyphs, values Add a glyph value to the glyphs Glyphs, returning a list of Glyphs.",8.374391787,7.741940133,8.05816596,,,,,,,,,
"summarize: def verify_md5(md5_expected, data, other_errors=None):
    """"  # O_o ?
    md5_recv = hashlib.md5(data).hexdigest()
    if md5_expected != md5_recv:
        if other_errors is not None:
            logger.critical('\n'.join(other_errors))
        raise FailedVerification('original md5 = %r != %r = received md5' \
                                 % (md5_expected, md5_recv))
    return True","return True if okay, raise Exception if not","summarize: def verify_md5(md5_expected, data, other_errors=None): """" # O_o? md5_recv = hashlib.md5(data).hexdigest() if md5_expected!= md5_recv: if other_errors is not None: logger.critical('\n'.join(other_errors)) raise FailedVerification('original md5 = %r!= %r = received md5' \ % (md5_expected, md5_recv)) return True Verifies the verified data","summarize: def verify_md5(md5_expected, data, other_errors=None): """" # O_o? md5_recv = hashlib.md5(data).hexdigest() if md5_expected!= md5_recv: if other_errors is not None: logger.critical('\n'.join(other_errors)) raise FailedVerification('original md5 = %r!= %r = received md5' \ % (md5_expected, md5_recv)) return True Get another project.",7.918691381,8.058229284,7.988460333,,,,,,,,,
"summarize: def delete_lower(script, layer_num=None):
    """""" 
    """"""
    if layer_num is None:
        layer_num = script.current_layer()
    if layer_num != 0:
        change(script, 0)
    for i in range(layer_num):
        delete(script, 0)
    return None",Delete all layers below the specified one.,"summarize: def delete_lower(script, layer_num=None): """""" """""" if layer_num is None: layer_num = script.current_layer() if layer_num!= 0: change(script, 0) for i in range(layer_num): delete(script, 0) return None Deletes the layer number of layers.","summarize: def delete_lower(script, layer_num=None): """""" """""" if layer_num is None: layer_num = script.current_layer() if layer_num!= 0: change(script, 0) for i in range(layer_num): delete(script, 0) return None Return the delete lower that are installed on `layer_num`.",7.877238104,7.809023738,7.843130921,,,,,,,,,
"summarize: def _make_summary_statistic(attr):
  """"""""""""
  def _fn(self):
    if any(self._dist_fn_args):  # pylint: disable=protected-access
      raise ValueError(
          'Can only compute ' + attr + ' when all distributions are '
          'independent; {}'.format(self.model))
    return self._unflatten(getattr(d(), attr)() for d in self._dist_fn_wrapped)  # pylint: disable=protected-access
  return _fn","Factory for making summary statistics, eg, mean, mode, stddev.","summarize: def _make_summary_statistic(attr): """""""""""" def _fn(self): if any(self._dist_fn_args): # pylint: disable=protected-access raise ValueError( 'Can only compute'+ attr +'when all distributions are ' 'independent; {}'.format(self.model)) return self._unflatten(getattr(d(), attr)() for d in self._dist_fn_wrapped) # pylint: disable=protected-access return _fn Makes a set of Summary statistics to a summary file.","summarize: def _make_summary_statistic(attr): """""""""""" def _fn(self): if any(self._dist_fn_args): # pylint: disable=protected-access raise ValueError( 'Can only compute'+ attr +'when all distributions are ' 'independent; {}'.format(self.model)) return self._unflatten(getattr(d(), attr)() for d in self._dist_fn_wrapped) # pylint: disable=protected-access return _fn Make a summary state of any folders.",7.814620835,7.755761067,7.785190951,,,,,,,,,
"summarize: def argmax(df, column: str, groups: Union[str, List[str]] = None):
    """"""
    
    """"""
    if groups is None:
        df = df[df[column] == df[column].max()].reset_index(drop=True)
    else:
        group_max = df.groupby(groups)[column].transform('max')
        df = (df
              .loc[df[column] == group_max, :]
              .drop_duplicates()
              .reset_index(drop=True)
              )
    return df",Keep the row of the data corresponding to the maximal value in a column,"summarize: def argmax(df, column: str, groups: Union[str, List[str]] = None): """""" """""" if groups is None: df = df[df[column] == df[column].max()].reset_index(drop=True) else: group_max = df.groupby(groups)[column].transform('max') df = (df .loc[df[column] == group_max, :] .drop_duplicates() .reset_index(drop=True) ) return df Make the argmax and the groups of the given groups","summarize: def argmax(df, column: str, groups: Union[str, List[str]] = None): """""" """""" if groups is None: df = df[df[column] == df[column].max()].reset_index(drop=True) else: group_max = df.groupby(groups)[column].transform('max') df = (df .loc[df[column] == group_max, :] .drop_duplicates() .reset_index(drop=True) ) return df Actually fillarize the groups on the group of the Groups.",7.74623766,7.665404042,7.705820851,,,,,,,,,
"summarize: def get_loop_stack(self, subs_consts=False):
        """"""""""""
        for l in self._loop_stack:
            if subs_consts:
                yield {'index': l[0],
                       'start': self.subs_consts(l[1]),
                       'stop': self.subs_consts(l[2]),
                       'increment': self.subs_consts(l[3])}
            else:
                yield {'index': l[0], 'start': l[1], 'stop': l[2], 'increment': l[3]}",Yield loop stack dictionaries in order from outer to inner.,"summarize: def get_loop_stack(self, subs_consts=False): """""""""""" for l in self._loop_stack: if subs_consts: yield {'index': l[0], 'start': self.subs_consts(l[1]), 'stop': self.subs_consts(l[2]), 'increment': self.subs_consts(l[3])} else: yield {'index': l[0],'start': l[1],'stop': l[2], 'increment': l[3]} return yield yield loop stack for the loop stack","summarize: def get_loop_stack(self, subs_consts=False): """""""""""" for l in self._loop_stack: if subs_consts: yield {'index': l[0], 'start': self.subs_consts(l[1]), 'stop': self.subs_consts(l[2]), 'increment': self.subs_consts(l[3])} else: yield {'index': l[0],'start': l[1],'stop': l[2], 'increment': l[3]} Returns the loop stack of the loop stack.",7.461202299,7.167807769,7.314505034,,,,,,,,,
"summarize: def hex_to_rgb(color):
    """"""""""""
    if color.startswith('#'):
        color = color[1:]
    if len(color) == 3:
        color = ''.join([c*2 for c in color])
    if len(color) != 6:
        return False
    try:
        r = int(color[:2],16)
        g = int(color[2:4],16)
        b = int(color[4:],16)
    except ValueError:
        return False
    else:
        return r,g,b",Convert a hex color to rgb integer tuple.,"summarize: def hex_to_rgb(color): """""""""""" if color.startswith('#'): color = color[1:] if len(color) == 3: color = ''.join([c*2 for c in color]) if len(color)!= 6: return False try: r = int(color[:2],16) g = int(color[2:4],16) b = int(color[4:],16) except ValueError: return False else: return r,g,b = b Convert a dictionary to a dataset to a single color","summarize: def hex_to_rgb(color): """""""""""" if color.startswith('#'): color = color[1:] if len(color) == 3: color = ''.join([c*2 for c in color]) if len(color)!= 6: return False try: r = int(color[:2],16) g = int(color[2:4],16) b = int(color[4:],16) except ValueError: return False else: return r,g,b,r Convert a rgb string to an RGB matrices to a CSS file.",7.004059619,7.535801791,7.269930705,,,,,,,,,
"summarize: def show_guestbook():
    """"""""""""
    cursor = flask.g.db.execute(
        'SELECT name, message FROM entry ORDER BY id DESC;')
    entries = [{'name': row[0], 'message': row[1]} for row in cursor.fetchall()]
    return jinja2.Template(LAYOUT).render(entries=entries)",Returns all existing guestbook records.,"summarize: def show_guestbook(): """""""""""" cursor = flask.g.db.execute( 'SELECT name, message FROM entry ORDER BY id DESC;') entries = [{'name': row[0],'message': row[1]} for row in cursor.fetchall()] return jinja2.Template(LAYOUT).render(entries=entries) Checks a guestbook guestbook.","summarize: def show_guestbook(): """""""""""" cursor = flask.g.db.execute( 'SELECT name, message FROM entry ORDER BY id DESC;') entries = [{'name': row[0],'message': row[1]} for row in cursor.fetchall()] return jinja2.Template(LAYOUT).render(entries=entries) Returns a list of GETRAM persons on the guestbook.",7.04049003,7.457191459,7.248840745,,,,,,,,,
"summarize: def elements(all_isotopes=True):
    """"""
    
    """"""
    el = pd.read_pickle(pkgrs.resource_filename('latools', 'resources/elements.pkl'))
    if all_isotopes:
        return el.set_index('element')
    else:
        def wmean(g):
            return (g.atomic_weight * g.percent).sum() / 100
        iel = el.groupby('element').apply(wmean)
        iel.name = 'atomic_weight'
        return iel",Loads a DataFrame of all elements and isotopes.,"summarize: def elements(all_isotopes=True): """""" """""" el = pd.read_pickle(pkgrs.resource_filename('latools','resources/elements.pkl')) if all_isotopes: return el.set_index('element') else: def wmean(g): return (g.atomic_weight * g.percent).sum() / 100 iel = el.groupby('element').apply(wmean) iel.name = 'atomic_weight' return iel Weight elements into a list of GeoJSON and return a list of GeoJSON weight in ``latools``","summarize: def elements(all_isotopes=True): """""" """""" el = pd.read_pickle(pkgrs.resource_filename('latools','resources/elements.pkl')) if all_isotopes: return el.set_index('element') else: def wmean(g): return (g.atomic_weight * g.percent).sum() / 100 iel = el.groupby('element').apply(wmean) iel.name = 'atomic_weight' return iel.sum() Elements the relations of a point",6.976353549,7.516681051,7.2465173,,,,,,,,,
"summarize: def diff(f, s):
    """"""
    
    """"""
    if isinstance(f, base.Root) or f._yang_type in (""container"", None):
        result = _diff_root(f, s)
    elif f._yang_type in (""list"",):
        result = _diff_list(f, s)
    else:
        result = {}
        first = ""{}"".format(f)
        second = ""{}"".format(s)
        if first != second:
            result = {""first"": first, ""second"": second}

    return result","Given two models, return the difference between them.","summarize: def diff(f, s): """""" """""" if isinstance(f, base.Root) or f._yang_type in (""container"", None): result = _diff_root(f, s) elif f._yang_type in (""list"",): result = _diff_list(f, s) else: result = {} first = ""{}"".format(f) second = ""{}"".format(s) if first!= second: result = {""first"": first, ""second"": second} return result Difference a proot of a list of difference on the given frames.","summarize: def diff(f, s): """""" """""" if isinstance(f, base.Root) or f._yang_type in (""container"", None): result = _diff_root(f, s) elif f._yang_type in (""list"",): result = _diff_list(f, s) else: result = {} first = ""{}"".format(f) second = ""{}"".format(s) if first!= second: result = {""first"": first, ""second"": second} return result Convert a different different function to a FDF and return a different different different of the model",7.504114594,6.683211153,7.093662874,,,,,,,,,
"summarize: def load(png_filename):
    """"""
    
    """"""
    # Expand filename to be absolute
    png_filename = os.path.expanduser(png_filename)

    try:
        img = Image.open(png_filename)
    except Exception as e:
        raise ValueError(""Could not load file {0} for conversion.""
                         .format(png_filename))
        raise

    return numpy.array(img)",Import a png file into a numpy array.,"summarize: def load(png_filename): """""" """""" # Expand filename to be absolute png_filename = os.path.expanduser(png_filename) try: img = Image.open(png_filename) except Exception as e: raise ValueError(""Could not load file {0} for conversion."" .format(png_filename)) raise return numpy.array(img) Load files into a specified file.","summarize: def load(png_filename): """""" """""" # Expand filename to be absolute png_filename = os.path.expanduser(png_filename) try: img = Image.open(png_filename) except Exception as e: raise ValueError(""Could not load file {0} for conversion."" .format(png_filename)) raise return numpy.array(img) Returns the path of the pandas into a pandas directory.",7.198311299,6.949773018,7.074042159,,,,,,,,,
"summarize: def set_fields(self, fields = None, **kwargs):
    """"""
    
    """"""
    self.fields = []
    if fields != None:
      for field in fields: 
        self.fields.append(field)",Sets the fields.,"summarize: def set_fields(self, fields = None, **kwargs): """""" """""" self.fields = [] if fields!= None: for field in fields: self.fields.append(field) Set the fields to the given fields.","summarize: def set_fields(self, fields = None, **kwargs): """""" """""" self.fields = [] if fields!= None: for field in fields: self.fields.append(field) self.fields.append(field) Sets the fields and fields.",6.871468406,7.246604803,7.059036605,,,,,,,,,
"summarize: def _warn_if_not_at_expected_pos(self, expected_pos, end_of, start_of):
        """""" """"""
        diff = expected_pos - self.stream.tell()
        if diff != 0:
            logger.warning(
                ""There are {} bytes between {} and {}"".format(diff, end_of, start_of)
            )",Helper function to warn about unknown bytes found in the file,"summarize: def _warn_if_not_at_expected_pos(self, expected_pos, end_of, start_of): """""" """""" diff = expected_pos - self.stream.tell() if diff!= 0: logger.warning( ""There are {} bytes between {} and {}"".format(diff, end_of, start_of) ) return diff Write the warning pos to the current at_expected_pos.","summarize: def _warn_if_not_at_expected_pos(self, expected_pos, end_of, start_of): """""" """""" diff = expected_pos - self.stream.tell() if diff!= 0: logger.warning( ""There are {} bytes between {} and {}"".format(diff, end_of, start_of) ) return None return diff.to_array(expected_pos, start_of, start_of) Will returns the position of another expected end_of.",7.486162567,6.595537938,7.040850253,,,,,,,,,
"summarize: def load_bytecode(self, f):
        """"""""""""
        # make sure the magic header is correct
        magic = f.read(len(bc_magic))
        if magic != bc_magic:
            self.reset()
            return
        # the source code of the file changed, we need to reload
        checksum = pickle.load(f)
        if self.checksum != checksum:
            self.reset()
            return
        self.code = marshal_load(f)",Loads bytecode from a file or file like object.,"summarize: def load_bytecode(self, f): """""""""""" # make sure the magic header is correct magic = f.read(len(bc_magic)) if magic!= bc_magic: self.reset() return # the source code of the file changed, we need to reload checksum = pickle.load(f) if self.checksum!= checksum: self.reset() return self.code = marshal_load(f) return self.code Process the validity of the given file","summarize: def load_bytecode(self, f): """""""""""" # make sure the magic header is correct magic = f.read(len(bc_magic)) if magic!= bc_magic: self.reset() return # the source code of the file changed, we need to reload checksum = pickle.load(f) if self.checksum!= checksum: self.reset() return self.code = marshal_load(f) return checksum Function to load a single file from the given file.",6.465028982,7.468596092,6.966812537,,,,,,,,,
"summarize: def _update_proxy(self, change):
        """""" 
        """"""
        #: Try default handler
        if change['type'] == 'update' and self.proxy_is_active:
            handler = getattr(self.proxy, 'set_' + change['name'], None)
            if handler is not None:
                handler(change['value'])
            else:
                self.proxy.set_attribute(change['name'], change['value'])
            self._notify_modified(change)",Update the proxy widget when the Widget data    changes.,"summarize: def _update_proxy(self, change): """""" """""" #: Try default handler if change['type'] == 'update' and self.proxy_is_active: handler = getattr(self.proxy,'set_' + change['name'], None) if handler is not None: handler(change['value']) else: self.proxy.set_attribute(change['name'], change['value']) self._notify_modified(change) Update proxy for the proxy.","summarize: def _update_proxy(self, change): """""" """""" #: Try default handler if change['type'] == 'update' and self.proxy_is_active: handler = getattr(self.proxy,'set_' + change['name'], None) if handler is not None: handler(change['value']) else: self.proxy.set_attribute(change['name'], change['value']) self._notify_modified(change) Update a service.",7.532133702,6.125053208,6.828593455,,,,,,,,,
"summarize: def get_tail(self, n=10, raw=True, output=False, include_latest=False):
        """"""
        """"""
        self.writeout_cache()
        if not include_latest:
            n += 1
        cur = self._run_sql(""ORDER BY session DESC, line DESC LIMIT ?"",
                                (n,), raw=raw, output=output)
        if not include_latest:
            return reversed(list(cur)[1:])
        return reversed(list(cur))",Get the last n lines from the history database.,"summarize: def get_tail(self, n=10, raw=True, output=False, include_latest=False): """""" """""" self.writeout_cache() if not include_latest: n += 1 cur = self._run_sql(""ORDER BY session DESC, line DESC LIMIT?"", (n,), raw=raw, output=output) if not include_latest: return reversed(list(cur)[1:]) return reversed(list(cur)) Get a list of tails from the given neighbor.","summarize: def get_tail(self, n=10, raw=True, output=False, include_latest=False): """""" """""" self.writeout_cache() if not include_latest: n += 1 cur = self._run_sql(""ORDER BY session DESC, line DESC LIMIT?"", (n,), raw=raw, output=output) if not include_latest: return reversed(list(cur)[1:]) return reversed(list(cur)) Returns the raw data from the specified page.",6.468786153,6.839178775,6.653982464,,,,,,,,,
"summarize: def annotated(func, name=None):
    """"""
    """"""

    if hasattr(func, 'metadata'):
        if name is not None:
            func.metadata = AnnotatedMetadata(func, name)
        return func

    func.metadata = AnnotatedMetadata(func, name)

    func.finalizer = False
    func.takes_cmdline = False
    func.decorated = False
    func.context = False

    return func",Mark a function as callable from the command line.,"summarize: def annotated(func, name=None): """""" """""" if hasattr(func,'metadata'): if name is not None: func.metadata = AnnotatedMetadata(func, name) return func func.metadata = AnnotatedMetadata(func, name) func.finalizer = False func.takes_cmdline = False func.decorated = False func.context = False return func Add a GAL function to the function.","summarize: def annotated(func, name=None): """""" """""" if hasattr(func,'metadata'): if name is not None: func.metadata = AnnotatedMetadata(func, name) return func func.metadata = AnnotatedMetadata(func, name) func.finalizer = False func.takes_cmdline = False func.decorated = False func.context = False return func Create annotatedMetadata from function.",6.392524339,6.371165573,6.381844956,,,,,,,,,
"summarize: def attrs(self):
        """"""""""""
        data = {
            'client_id': self.client_id,
            'redirect_uri': quote(self.redirect_uri),
        }

        if self.scope is not None:
            data['scope'] = quote(self.scope)

        if self.state is not None:
            data['state'] = self.state

        return data",Attributes used when constructing url parameters.,"summarize: def attrs(self): """""""""""" data = { 'client_id': self.client_id, 'redirect_uri': quote(self.redirect_uri), } if self.scope is not None: data['scope'] = quote(self.scope) if self.state is not None: data['state'] = self.state return data Attributes a list of attributes attributes in the model.","summarize: def attrs(self): """""""""""" data = { 'client_id': self.client_id, 'redirect_uri': quote(self.redirect_uri), } if self.scope is not None: data['scope'] = quote(self.scope) if self.state is not None: data['state'] = self.state return data This method gets a dict of the Jote",5.769785082,6.934906077,6.35234558,,,,,,,,,
"summarize: def unicode_urlencode(obj, charset='utf-8'):
    """"""
    """"""
    if not isinstance(obj, string_types):
        obj = text_type(obj)
    if isinstance(obj, text_type):
        obj = obj.encode(charset)
    return text_type(url_quote(obj))",URL escapes a single bytestring or unicode string with the  given charset if applicable to URL safe quoting under all rules  that need to be considered under all supported Python versions.,The unicode URLs can be a string or an unicode_urlencode urlencode,Automatically used to be used in the object of the object.,8.418038338,4.117418814,6.267728576,,,,,,,,,
"summarize: def _to_chi(rep, data, input_dim, output_dim):
    """"""""""""
    if rep == 'Chi':
        return data
    # Check valid n-qubit input
    _check_nqubit_dim(input_dim, output_dim)
    if rep == 'Operator':
        return _from_operator('Chi', data, input_dim, output_dim)
    # Convert via Choi representation
    if rep != 'Choi':
        data = _to_choi(rep, data, input_dim, output_dim)
    return _choi_to_chi(data, input_dim, output_dim)",Transform a QuantumChannel to the Chi representation.,"summarize: def _to_chi(rep, data, input_dim, output_dim): """""""""""" if rep == 'Chi': return data # Check valid n-qubit input _check_nqubit_dim(input_dim, output_dim) if rep == 'Operator': return _from_operator('Chi', data, input_dim, output_dim) # Convert via Choi representation if rep!= 'Choi': data = _to_choi(rep, data, input_dim, output_dim) return _choi_to_chi(data, input_dim, output_dim) The chi and validation of the virtual elements to add `data`.","summarize: def _to_chi(rep, data, input_dim, output_dim): """""""""""" if rep == 'Chi': return data # Check valid n-qubit input _check_nqubit_dim(input_dim, output_dim) if rep == 'Operator': return _from_operator('Chi', data, input_dim, output_dim) # Convert via Choi representation if rep!= 'Choi': data = _to_choi(rep, data, input_dim, output_dim) return _choi_to_chi(data, input_dim, output_dim) Return a copy of the choices of the via.",6.339714127,6.081825272,6.2107697,,,,,,,,,
"summarize: def admin(request):
    """"""""""""
    context = {
        'api_url': settings.API_URL,
        'app_js_bundle': 'manager-%s.js' % dispatch.__version__,
        'app_css_bundle': 'manager-%s.css' % dispatch.__version__
    }
    
    return render_to_response('manager/index.html', context)",Render HTML entry point for manager app.,"summarize: def admin(request): """""""""""" context = { 'api_url': settings.API_URL, 'app_js_bundle':'manager-%s.js' % dispatch.__version__, 'app_css_bundle':'manager-%s.css' % dispatch.__version__ } return render_to_response('manager/index.html', context) Retrieve a detail from the HTML schema.","summarize: def admin(request): """""""""""" context = { 'api_url': settings.API_URL, 'app_js_bundle':'manager-%s.js' % dispatch.__version__, 'app_css_bundle':'manager-%s.css' % dispatch.__version__ } return render_to_response('manager/index.html', context) Application admin to an endpoint.",6.432997726,5.927529619,6.180263673,,,,,,,,,
"summarize: def fix_version(context):
    """"""

    """"""
    if not prerequisites_ok():
        return
    lines = codecs.open('metadata.txt', 'rU', 'utf-8').readlines()
    for index, line in enumerate(lines):
        if line.startswith('version'):
            new_line = 'version=%s\n' % context['new_version']
            lines[index] = new_line
    time.sleep(1)
    codecs.open('metadata.txt', 'w', 'utf-8').writelines(lines)",Fix the version in metadata.txt,"summarize: def fix_version(context): """""" """""" if not prerequisites_ok(): return lines = codecs.open('metadata.txt', 'rU', 'utf-8').readlines() for index, line in enumerate(lines): if line.startswith('version'): new_line ='version=%s\n' % context['new_version'] lines[index] = new_line time.sleep(1) codecs.open('metadata.txt', 'w', 'utf-8').writelines(lines) Fix the version of a new version of a context.","summarize: def fix_version(context): """""" """""" if not prerequisites_ok(): return lines = codecs.open('metadata.txt', 'rU', 'utf-8').readlines() for index, line in enumerate(lines): if line.startswith('version'): new_line ='version=%s\n' % context['new_version'] lines[index] = new_line time.sleep(1) codecs.open('metadata.txt', 'w', 'utf-8').writelines(lines) return codecs.File(context) Fetches the File information.",6.727458226,5.501675012,6.114566619,,,,,,,,,
"summarize: def get_run_object_type(run_object):
        """"""""""""
        if isinstance(run_object, tuple):
            return 'function'
        run_object, _, _ = run_object.partition(' ')
        if os.path.isdir(run_object):
            return 'package'
        return 'module'",Determines run object type.,"summarize: def get_run_object_type(run_object): """""""""""" if isinstance(run_object, tuple): return 'function' run_object, _, _ = run_object.partition(' ') if os.path.isdir(run_object): return 'package' return'module' Returns the full path for the given Run object.","summarize: def get_run_object_type(run_object): """""""""""" if isinstance(run_object, tuple): return 'function' run_object, _, _ = run_object.partition(' ') if os.path.isdir(run_object): return 'package' return'module' Get the object type of a server",5.411814526,6.322114938,5.866964732,,,,,,,,,
"summarize: def allocate_ids(self, partial_keys):
        """"""
        
        """"""
        conn = self.get_conn()

        resp = (conn
                .projects()
                .allocateIds(projectId=self.project_id, body={'keys': partial_keys})
                .execute(num_retries=self.num_retries))

        return resp['keys']",Allocate IDs for incomplete keys.,"summarize: def allocate_ids(self, partial_keys): """""" """""" conn = self.get_conn() resp = (conn .projects() .allocateIds(projectId=self.project_id, body={'keys': partial_keys}) .execute(num_retries=self.num_retries)) return resp['keys'] Get allocate id for the GOILD ID.","summarize: def allocate_ids(self, partial_keys): """""" """""" conn = self.get_conn() resp = (conn .projects() .allocateIds(projectId=self.project_id, body={'keys': partial_keys}) .execute(num_retries=self.num_retries)) return resp['keys'] Retrieve all all the IDs of the given IDs.",6.002738879,5.540612997,5.771675938,,,,,,,,,
"summarize: def mesh2fc(script, all_visible_layers=False):
    """"""
    """"""
    filter_xml = ''.join([
        '  <filter name=""Transfer Color: Mesh to Face"">\n',
        '    <Param name=""allVisibleMesh"" ',
        'value=""%s"" ' % str(all_visible_layers).lower(),
        'description=""Apply to all Meshes"" ',
        'type=""RichBool"" ',
        '/>\n',
        '  </filter>\n'])
    util.write_filter(script, filter_xml)
    return None",Transfer mesh colors to face colors,"summarize: def mesh2fc(script, all_visible_layers=False): """""" """""" filter_xml = ''.join([ ' <filter name=""Transfer Color: Mesh to Face"">\n', ' <Param name=""allVisibleMesh"" ', 'value=""%s""'% str(all_visible_layers).lower(), 'description=""Apply to all Meshes"" ', 'type=""RichBool"" ', '/>\n', ' </filter>\n']) util.write_filter(script, filter_xml) return None Returns the Face Color Address","summarize: def mesh2fc(script, all_visible_layers=False): """""" """""" filter_xml = ''.join([ ' <filter name=""Transfer Color: Mesh to Face"">\n', ' <Param name=""allVisibleMesh"" ', 'value=""%s""'% str(all_visible_layers).lower(), 'description=""Apply to all Meshes"" ', 'type=""RichBool"" ', '/>\n', ' </filter>\n']) util.write_filter(script, filter_xml) return None Format an `Script` instance.",5.92557178,5.355893092,5.640732436,,,,,,,,,
"summarize: def emojis(self, item_type, item_id):
        """"""""""""

        payload = {
            'order_by': 'updated_at',
            'sort': 'asc',
            'per_page': PER_PAGE
        }

        path = urijoin(item_type, str(item_id), GitLabClient.EMOJI)

        return self.fetch_items(path, payload)",Get emojis from pagination,"summarize: def emojis(self, item_type, item_id): """""""""""" payload = { 'order_by': 'updated_at', 'sort': 'asc', 'per_page': PER_PAGE } path = urijoin(item_type, str(item_id), GitLabClient.EMOJI) return self.fetch_items(path, payload) Get an Item object from item_id","summarize: def emojis(self, item_type, item_id): """""""""""" payload = { 'order_by': 'updated_at', 'sort': 'asc', 'per_page': PER_PAGE } path = urijoin(item_type, str(item_id), GitLabClient.EMOJI) return self.fetch_items(path, payload) Emove an item from item_type.",5.779447785,5.254383451,5.516915618,,,,,,,,,
"summarize: def equals_order_sensitive(self, other):
        """"""
        """"""
        # Same short-circuit as BidictBase.__eq__. Factoring out not worth function call overhead.
        if not isinstance(other, Mapping) or len(self) != len(other):
            return False
        return all(i == j for (i, j) in izip(iteritems(self), iteritems(other)))",Order-sensitive equality check.,"summarize: def equals_order_sensitive(self, other): """""" """""" # Same short-circuit as BidictBase.__eq__. Factoring out not worth function call overhead. if not isinstance(other, Mapping) or len(self)!= len(other): return False return all(i == j for (i, j) in izip(iteritems(self), iteritems(other))) Checks the other sensitive sensors.","summarize: def equals_order_sensitive(self, other): """""" """""" # Same short-circuit as BidictBase.__eq__. Factoring out not worth function call overhead. if not isinstance(other, Mapping) or len(self)!= len(other): return False return all(i == j for (i, j) in izip(iteritems(self), iteritems(other))) Returns a valid sensitive equals of anotation circuit.",5.643511497,5.335490518,5.489501008,,,,,,,,,
"summarize: def run_show_bool(obj, what=None):
    """"""""""""
    val = show_onoff(obj.debugger.settings[obj.name])
    if not what: what = obj.name
    return obj.msg(""%s is %s."" % (what, val))",Generic subcommand showing a boolean-valued debugger setting.  'obj' is generally a subcommand that has 'name' and  'debugger.setting' attributes.,Unknown works showing interpretation of the interpretation.,Returns a string for a blocking of a IPython object.,6.344108465,4.290749508,5.317428987,,,,,,,,,
"summarize: def find_packages(top=HERE):
    """"""
    
    """"""
    packages = []
    for d, dirs, _ in os.walk(top, followlinks=True):
        if os.path.exists(pjoin(d, '__init__.py')):
            packages.append(os.path.relpath(d, top).replace(os.path.sep, '.'))
        elif d != top:
            # Do not look for packages in subfolders if current is not a package
            dirs[:] = []
    return packages",Find all of the packages.,"summarize: def find_packages(top=HERE): """""" """""" packages = [] for d, dirs, _ in os.walk(top, followlinks=True): if os.path.exists(pjoin(d, '__init__.py')): packages.append(os.path.relpath(d, top).replace(os.path.sep, '.')) elif d!= top: # Do not look for packages in subfolders if current is not a package dirs[:] = [] return packages Find the packages and return a list of packages files in `top`.","summarize: def find_packages(top=HERE): """""" """""" packages = [] for d, dirs, _ in os.walk(top, followlinks=True): if os.path.exists(pjoin(d, '__init__.py')): packages.append(os.path.relpath(d, top).replace(os.path.sep, '.')) elif d!= top: # Do not look for packages in subfolders if current is not a package dirs[:] = [] return packages Find the packages of the given file.",4.85087111,5.45949696,5.155184035,,,,,,,,,
"summarize: def prepare_classpath():
    """"""
    
    """"""

    if DAGS_FOLDER not in sys.path:
        sys.path.append(DAGS_FOLDER)

    # Add ./config/ for loading custom log parsers etc, or
    # airflow_local_settings etc.
    config_path = os.path.join(AIRFLOW_HOME, 'config')
    if config_path not in sys.path:
        sys.path.append(config_path)

    if PLUGINS_FOLDER not in sys.path:
        sys.path.append(PLUGINS_FOLDER)",Ensures that certain subfolders of AIRFLOW_HOME are on the classpath,"summarize: def prepare_classpath(): """""" """""" if DAGS_FOLDER not in sys.path: sys.path.append(DAGS_FOLDER) # Add./config/ for loading custom log parsers etc, or # airflow_local_settings etc. config_path = os.path.join(AIRFLOW_HOME, 'config') if config_path not in sys.path: sys.path.append(config_path) if PLUGINS_FOLDER not in sys.path: sys.path.append(PLUGINS_FOLDER) # Make sure that they are prepared, when we have anything. # TODO: We have to add the last additional cases. additional_settings = {} for LIME_SIZE in sys.path: # Add the LIME SIZE # Add the LIME settings to the LIME additional_settings[LIME_SIZE] = LIME_SIZE # Add the LIME # Add the LIME additional_settings[LIME_SIZE] = LIME # Get the LIME specified classpath to the additional classpath # For the LIME LIME_SIZE = LIME_SIZE LIME_SI","summarize: def prepare_classpath(): """""" """""" if DAGS_FOLDER not in sys.path: sys.path.append(DAGS_FOLDER) # Add./config/ for loading custom log parsers etc, or # airflow_local_settings etc. config_path = os.path.join(AIRFLOW_HOME, 'config') if config_path not in sys.path: sys.path.append(config_path) if PLUGINS_FOLDER not in sys.path: sys.path.append(PLUGINS_FOLDER) # First, but there are passed to the events, there is any local root, # and skip there is necessary to add the root, but it # we will have any exception, just continue if os.path.isfile(os.path.exists(sys.path)) and os.path.exists(sys.path): sys.path.append(os.path.exists(sys.path)) # FIXME: Skip checks on the local config file # for defaulting any necessary to the passed specified and the # events. try: with open(os.path.dirname(os.path.dirname(__file__), 'w'), 'w') as f: for line in f: # if not f.is_prepared: break f.close() # Fix there and convert the",5.526490699,4.531601033,5.029045866,,,,,,,,,
"summarize: def _insert_continuation_prompt(self, cursor):
        """""" 
        """"""
        super(FrontendWidget, self)._insert_continuation_prompt(cursor)
        cursor.insertText(' ' * self._input_splitter.indent_spaces)",Reimplemented for auto-indentation.,"summarize: def _insert_continuation_prompt(self, cursor): """""" """""" super(FrontendWidget, self)._insert_continuation_prompt(cursor) cursor.insertText(''* self._input_splitter.indent_spaces) return cursor Create a new Continuation prompt.","summarize: def _insert_continuation_prompt(self, cursor): """""" """""" super(FrontendWidget, self)._insert_continuation_prompt(cursor) cursor.insertText(''* self._input_splitter.indent_spaces) cursor.set_cursor(cursor) return cursor.frontend_prompt(cursor) Insert a valid ``SuperText``.",5.476055402,4.442048249,4.959051826,,,,,,,,,
"summarize: def value(self):
    """"""""""""
    if self._value is None:
      try:
        self._value = self.distribution.sample(self.sample_shape_tensor())
      except NotImplementedError:
        raise NotImplementedError(
            ""sample is not implemented for {0}. You must either pass in the ""
            ""value argument or implement sample for {0}.""
            .format(self.distribution.__class__.__name__))
    return self._value",Get tensor that the random variable corresponds to.,"summarize: def value(self): """""""""""" if self._value is None: try: self._value = self.distribution.sample(self.sample_shape_tensor()) except NotImplementedError: raise NotImplementedError( ""sample is not implemented for {0}. You must either pass in the "" ""value argument or implement sample for {0}."" .format(self.distribution.__class__.__name__)) return self._value Add values to the labels for the specified values.","summarize: def value(self): """""""""""" if self._value is None: try: self._value = self.distribution.sample(self.sample_shape_tensor()) except NotImplementedError: raise NotImplementedError( ""sample is not implemented for {0}. You must either pass in the "" ""value argument or implement sample for {0}."" .format(self.distribution.__class__.__name__)) return self._value Calculates value of the dataset.",5.311268551,4.552113389,4.93169097,,,,,,,,,
"summarize: def quit(self):
        """"""
        """"""
        code, message = self.command(""QUIT"")
        if code != 205:
            raise NNTPReplyError(code, message)

        self.socket.close()",QUIT command.,"summarize: def quit(self): """""" """""" code, message = self.command(""QUIT"") if code!= 205: raise NNTPReplyError(code, message) self.socket.close() return code, message Queue quit_channel to the command.","summarize: def quit(self): """""" """""" code, message = self.command(""QUIT"") if code!= 205: raise NNTPReplyError(code, message) self.socket.close() return code Check that the message is done.",4.95808105,4.60269757,4.78038931,,,,,,,,,
"summarize: def lookup(*args, **kwargs):
    """"""
    
    """"""
    if 'mode' in kwargs:
        mode = kwargs['mode']
        if mode not in constructors:
            raise ValueError('Mode %s not supported' % mode)
        del kwargs['mode']
        return constructors[mode]
    else:
        for mode, constructor in constructors:
            if constructor._argcheck(*args, **kwargs):
                return constructor
    return ConstructLocal",Use arguments to route constructor.,"summarize: def lookup(*args, **kwargs): """""" """""" if'mode' in kwargs: mode = kwargs['mode'] if mode not in constructors: raise ValueError('Mode %s not supported' % mode) del kwargs['mode'] return constructors[mode] else: for mode, constructor in constructors: if constructor._argcheck(*args, **kwargs): return constructor return ConstructLocal(**kwargs) Loads the lookup lookup lookup lookup lookups","summarize: def lookup(*args, **kwargs): """""" """""" if'mode' in kwargs: mode = kwargs['mode'] if mode not in constructors: raise ValueError('Mode %s not supported' % mode) del kwargs['mode'] return constructors[mode] else: for mode, constructor in constructors: if constructor._argcheck(*args, **kwargs): return constructor return ConstructLocal(kwargs, **kwargs) Lookup lookup.",4.64846747,4.793615605,4.721041538,,,,,,,,,
"summarize: def check(self):
        """"""
        
        """"""
        if self._only_public:
            raise TypeError(""public key only"")

        if _lib.EVP_PKEY_type(self.type()) != _lib.EVP_PKEY_RSA:
            raise TypeError(""key type unsupported"")

        rsa = _lib.EVP_PKEY_get1_RSA(self._pkey)
        rsa = _ffi.gc(rsa, _lib.RSA_free)
        result = _lib.RSA_check_key(rsa)
        if result:
            return True
        _raise_current_error()",Check the consistency of an RSA private key.,"summarize: def check(self): """""" """""" if self._only_public: raise TypeError(""public key only"") if _lib.EVP_PKEY_type(self.type())!= _lib.EVP_PKEY_RSA: raise TypeError(""key type unsupported"") rsa = _lib.EVP_PKEY_get1_RSA(self._pkey) rsa = _ffi.gc(rsa, _lib.RSA_free) result = _lib.RSA_check_key(rsa) if result: return True _raise_current_error() return False Check if the lib is available.","summarize: def check(self): """""" """""" if self._only_public: raise TypeError(""public key only"") if _lib.EVP_PKEY_type(self.type())!= _lib.EVP_PKEY_RSA: raise TypeError(""key type unsupported"") rsa = _lib.EVP_PKEY_get1_RSA(self._pkey) rsa = _ffi.gc(rsa, _lib.RSA_free) result = _lib.RSA_check_key(rsa) if result: return True _raise_current_error() Check for the field.",4.391816163,4.559216442,4.475516303,,,,,,,,,
"summarize: def hash(self):
        """"
        if self.sender is None:
            raise MissingSignatureError()

        class HashSerializable(rlp.Serializable):
            fields = [(field, sedes) for field, sedes in self.fields
                      if field not in ('v', 'r', 's')] + [('_sender', binary)]
            _sedes = None
        return sha3(rlp.encode(self, HashSerializable))",signatures are non deterministic,"summarize: def hash(self): """" if self.sender is None: raise MissingSignatureError() class HashSerializable(rlp.Serializable): fields = [(field, sedes) for field, sedes in self.fields if field not in ('v', 'r','s')] + [('_sender', binary)] _sedes = None return sha3(rlp.encode(self, HashSerializable)) Hashes the signature of the root function.","summarize: def hash(self): """" if self.sender is None: raise MissingSignatureError() class HashSerializable(rlp.Serializable): fields = [(field, sedes) for field, sedes in self.fields if field not in ('v', 'r','s')] + [('_sender', binary)] _sedes = None return sha3(rlp.encode(self, HashSerializable)) Function for create a FieldSignature.",4.39377596,4.24414938,4.31896267,,,,,,,,,
"summarize: def impad(img, shape, pad_val=0):
    """"""
    """"""
    if not isinstance(pad_val, (int, float)):
        assert len(pad_val) == img.shape[-1]
    if len(shape) < len(img.shape):
        shape = shape + (img.shape[-1], )
    assert len(shape) == len(img.shape)
    for i in range(len(shape) - 1):
        assert shape[i] >= img.shape[i]
    pad = np.empty(shape, dtype=img.dtype)
    pad[...] = pad_val
    pad[:img.shape[0], :img.shape[1], ...] = img
    return pad",Pad an image to a certain shape.,"summarize: def impad(img, shape, pad_val=0): """""" """""" if not isinstance(pad_val, (int, float)): assert len(pad_val) == img.shape[-1] if len(shape) < len(img.shape): shape = shape + (img.shape[-1], ) assert len(shape) == len(img.shape) for i in range(len(shape) - 1): assert shape[i] >= img.shape[i] pad = np.empty(shape, dtype=img.dtype) pad[...] = pad_val pad[:img.shape[0], :img.shape[1],...] = img return pad Apply an image to the fixed pad.","summarize: def impad(img, shape, pad_val=0): """""" """""" if not isinstance(pad_val, (int, float)): assert len(pad_val) == img.shape[-1] if len(shape) < len(img.shape): shape = shape + (img.shape[-1], ) assert len(shape) == len(img.shape) for i in range(len(shape) - 1): assert shape[i] >= img.shape[i] pad = np.empty(shape, dtype=img.dtype) pad[...] = pad_val pad[:img.shape[0], :img.shape[1],...] = img return pad Impad the Image and impad images of a single image.",4.720178359,3.640507456,4.180342908,,,,,,,,,
"summarize: def generateKey(self, template, mecha=MechanismAESGENERATEKEY):
        """"""
        
        """"""
        t = self._template2ckattrlist(template)
        ck_handle = PyKCS11.LowLevel.CK_OBJECT_HANDLE()
        m = mecha.to_native()
        rv = self.lib.C_GenerateKey(self.session, m, t, ck_handle)
        if rv != CKR_OK:
            raise PyKCS11Error(rv)
        return ck_handle",generate a secret key,"summarize: def generateKey(self, template, mecha=MechanismAESGENERATEKEY): """""" """""" t = self._template2ckattrlist(template) ck_handle = PyKCS11.LowLevel.CK_OBJECT_HANDLE() m = mecha.to_native() rv = self.lib.C_GenerateKey(self.session, m, t, ck_handle) if rv!= CKR_OK: raise PyKCS11Error(rv) return ck_handle, rv Generates the key for a given template and template.","summarize: def generateKey(self, template, mecha=MechanismAESGENERATEKEY): """""" """""" t = self._template2ckattrlist(template) ck_handle = PyKCS11.LowLevel.CK_OBJECT_HANDLE() m = mecha.to_native() rv = self.lib.C_GenerateKey(self.session, m, t, ck_handle) if rv!= CKR_OK: raise PyKCS11Error(rv) return ck_handle Convenience to generate a generate key template.",3.937273769,4.146442142,4.041857956,,,,,,,,,
"summarize: def remove(self, recursive=True, ignore_error=True):
        """"""
        
        """"""
        try:
            if recursive or self._cleanup == 'recursive':
                shutil.rmtree(self.path)
            else:
                os.rmdir(self.path)
        except Exception as e:
            if not ignore_error:
                raise e",Remove the directory.,"summarize: def remove(self, recursive=True, ignore_error=True): """""" """""" try: if recursive or self._cleanup =='recursive': shutil.rmtree(self.path) else: os.rmdir(self.path) except Exception as e: if not ignore_error: raise e raise e if ignore_error: if self._cleanup =='recursive': raise e return ignore_error Remove the analysis recursive and return the actions to ignore ignore it","summarize: def remove(self, recursive=True, ignore_error=True): """""" """""" try: if recursive or self._cleanup =='recursive': shutil.rmtree(self.path) else: os.rmdir(self.path) except Exception as e: if not ignore_error: raise e else: raise IgnoreError(e) Remove a recursive cleanup from the interface.",3.597585347,4.080216958,3.838901153,,,,,,,,,
"summarize: def list_hosted_zones(self, page_chunks=100):
        """"""
        
        """"""

        return  self._do_autopaginating_api_call(
            path='hostedzone',
            params={'maxitems': page_chunks},
            method='GET',
            parser_func=xml_parsers.list_hosted_zones_parser,
            next_marker_xpath=""./{*}NextMarker"",
            next_marker_param_name=""marker"",
        )","List all hosted zones associated with this connection's account. Since    this method returns a generator, you can pull as many or as few    entries as you'd like, without having to query and receive every    hosted zone you may have.",List all zones that were generated for a single hosted zone.,Gets the autopaginating hosted zones and hosted zones.,4.582864251,2.849454618,3.716159435,,,,,,,,,
"summarize: def str_strip(x, to_strip=None):
    """"""
    """"""
    # in c++ we give empty string the same meaning as None
    sl = _to_string_sequence(x).strip('' if to_strip is None else to_strip) if to_strip != '' else x
    return column.ColumnStringArrow(sl.bytes, sl.indices, sl.length, sl.offset, string_sequence=sl)",Removes leading and trailing characters.,"summarize: def str_strip(x, to_strip=None): """""" """""" # in c++ we give empty string the same meaning as None sl = _to_string_sequence(x).strip('' if to_strip is None else to_strip) if to_strip!= '' else x return column.ColumnStringArrow(sl.bytes, sl.indices, sl.length, sl.offset, string_sequence=sl) Gets the string to the given x and y.","summarize: def str_strip(x, to_strip=None): """""" """""" # in c++ we give empty string the same meaning as None sl = _to_string_sequence(x).strip('' if to_strip is None else to_strip) if to_strip!= '' else x return column.ColumnStringArrow(sl.bytes, sl.indices, sl.length, sl.offset, string_sequence=sl) List of string strips.",4.06905091,3.312120896,3.690585903,,,,,,,,,
"summarize: def cli_run():
    """"""""""""
    parser = argparse.ArgumentParser(description='Stupidly simple code answers from StackOverflow')
    parser.add_argument('query', help=""What's the problem ?"", type=str, nargs='+')
    parser.add_argument('-t','--tags', help='semicolon separated tags -> python;lambda')
    args = parser.parse_args()
    main(args)",docstring for argparse,"summarize: def cli_run(): """""""""""" parser = argparse.ArgumentParser(description='Stupidly simple code answers from StackOverflow') parser.add_argument('query', help=""What's the problem?"", type=str, nargs='+') parser.add_argument('-t','--tags', help='semicolon separated tags -> python;lambda') args = parser.parse_args() main(args) return parser Configure a query parser for a query parser.","summarize: def cli_run(): """""""""""" parser = argparse.ArgumentParser(description='Stupidly simple code answers from StackOverflow') parser.add_argument('query', help=""What's the problem?"", type=str, nargs='+') parser.add_argument('-t','--tags', help='semicolon separated tags -> python;lambda') args = parser.parse_args() main(args) click.secho(parser) return click.secho(args) Returns the click.secho code code for a parser.",3.612800027,3.320680866,3.466740447,,,,,,,,,
"summarize: def buildjschart(self):
        """"""""""""
        self.jschart = ''

        # add custom tooltip string in jschart
        # default condition (if build_custom_tooltip is not called explicitly with date_flag=True)
        if self.tooltip_condition_string == '':
            self.tooltip_condition_string = 'var y = String(graph.point.y);\n'

        # Include data
        self.series_js = json.dumps(self.series)",generate javascript code for the chart,"# Make sure that were the same jschart condition, # this is a new jschart condition self.series_js = jschart.series_js # We need to add custom to a dictionary, if we'll being provided if self.tooltip_condition_string == 'custom.point.y': self.series_js = jschart.series else: self.series_js = jschart.series # If we don't want to similarly, we need to update if self.tooltip_condition_string == 'custom.point.y': self.series_js = jschart.series_js # Include custom tooltip string self.series_js = jschart.series # Get custom tooltip string self.series_js = js","# If there is an edge, then get an edge, we have a # first one for the given custom_tooltip if self.tooltip is not None: self.tooltip_condition_string = '%s' % self.tooltip self.tooltip_condition = '%s' % self.tooltip self.add_flag = self.tooltip self.add_flag = True # Get the builder self.set_tooltiplication(self.settings.ALL, self.settings.ALL, self.settings.SETTING_PATH) self.settings(self.settings.SETTING_PATH) # Get the flag of the jschart self.settings.SETTING_PATH = self.settings.SETTING_PATH # Get the jschart flag self.settings.SETTING_PATH =",2.89839459,3.320402087,3.109398339,,,,,,,,,
"summarize: def create(self, name, regexes, tag_ids, logs=None):
        """"""
        
        """"""
        data = {
            'name': name,
            'triggers': regexes,
            'sources': logs or [],
            'groups': [],
            'actions': tag_ids
        }
        return self._post(
            request=ApiActions.CREATE.value,
            uri=ApiUri.HOOKS.value,
            params=data
        )",Create a hook,"summarize: def create(self, name, regexes, tag_ids, logs=None): """""" """""" data = { 'name': name, 'triggers': regexes, 'sources': logs or [], 'groups': [], 'actions': tag_ids } return self._post( request=ApiActions.CREATE.value, uri=ApiUri.HOOKS.value, params=data ) Create a new actions.","summarize: def create(self, name, regexes, tag_ids, logs=None): """""" """""" data = { 'name': name, 'triggers': regexes, 'sources': logs or [], 'groups': [], 'actions': tag_ids } return self._post( request=ApiActions.CREATE.value, uri=ApiUri.HOOKS.value, params=data ) Create a JSON response.",2.750320492,2.731053502,2.740686997,,,,,,,,,
"summarize: def apply(self, f, pure, state):
        '''
        '''
        return self.func(Functorisor(pure, f), state)",Runs the lens over the `state` applying `f` to all the foci    collecting the results together using the applicative functor    functions defined in `lenses.typeclass`. `f` must return an    applicative functor. For the case when no focus exists you must    also provide a `pure` which should take a focus and return the    pure form of the functor returned by `f`.,Apply an application function to an application function,Generate an `Func` applying applying the state of the state of the given state.,0.400327585,1.89766955,1.148998568,,,,,,,,,
