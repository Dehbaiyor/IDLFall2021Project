{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from https://github.com/minimaxir/gpt-2-simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T07:01:12.724352Z",
     "iopub.status.busy": "2021-11-04T07:01:12.723852Z",
     "iopub.status.idle": "2021-11-04T07:01:34.155237Z",
     "shell.execute_reply": "2021-11-04T07:01:34.154409Z",
     "shell.execute_reply.started": "2021-11-04T07:01:12.72427Z"
    },
    "id": "KBkpRgBCBS2_",
    "outputId": "629b3068-c9a6-407a-ea09-98773a0c50bf"
   },
   "outputs": [],
   "source": [
    "!pip install -q aitextgen\n",
    "from aitextgen import aitextgen\n",
    "from aitextgen.TokenDataset import TokenDataset, merge_datasets\n",
    "from aitextgen.utils import build_gpt2_config\n",
    "from aitextgen.tokenizers import train_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J98wNTISLXqT"
   },
   "source": [
    "## Training the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T07:01:34.157614Z",
     "iopub.status.busy": "2021-11-04T07:01:34.156832Z",
     "iopub.status.idle": "2021-11-04T07:01:34.161566Z",
     "shell.execute_reply": "2021-11-04T07:01:34.160711Z",
     "shell.execute_reply.started": "2021-11-04T07:01:34.157569Z"
    },
    "id": "5brMzdmzLom3"
   },
   "outputs": [],
   "source": [
    "#train_tokenizer('../input/chess-data/cleaned_merged_chess_data/cleaned_merged_chess_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KP4keZ36LxYl"
   },
   "source": [
    "## Specify a Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T07:01:34.163439Z",
     "iopub.status.busy": "2021-11-04T07:01:34.162723Z",
     "iopub.status.idle": "2021-11-04T07:01:34.171863Z",
     "shell.execute_reply": "2021-11-04T07:01:34.171171Z",
     "shell.execute_reply.started": "2021-11-04T07:01:34.163399Z"
    },
    "id": "GfbexWtKMaQB",
    "outputId": "b9633a2b-c67e-40ff-b8e1-dd4d29fc3150"
   },
   "outputs": [],
   "source": [
    "#config = build_gpt2_config(vocab_size=2000, max_length=500, dropout=0.1, n_embd=256, n_layer=12, n_head=32)\n",
    "#config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZABdZ-FcMmtA"
   },
   "source": [
    "## Instantiating Your Custom GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T07:01:35.73601Z",
     "iopub.status.busy": "2021-11-04T07:01:35.735731Z",
     "iopub.status.idle": "2021-11-04T07:01:35.73969Z",
     "shell.execute_reply": "2021-11-04T07:01:35.738598Z",
     "shell.execute_reply.started": "2021-11-04T07:01:35.735979Z"
    },
    "id": "AOfP_Rc9MvsZ",
    "outputId": "6a29a6af-365b-44e9-9482-ba8589467607"
   },
   "outputs": [],
   "source": [
    "#ai = aitextgen(config=config,\n",
    "#               tokenizer_file=\"./aitextgen.tokenizer.json\",\n",
    "#               to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T07:01:47.084751Z",
     "iopub.status.busy": "2021-11-04T07:01:47.084468Z",
     "iopub.status.idle": "2021-11-04T07:01:53.424154Z",
     "shell.execute_reply": "2021-11-04T07:01:53.423356Z",
     "shell.execute_reply.started": "2021-11-04T07:01:47.084722Z"
    }
   },
   "outputs": [],
   "source": [
    "ai = aitextgen(model_folder=\"../input/gpt-chess-v1\",\n",
    "               tokenizer_file=\"../input/gpt-chess-v1/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T07:01:55.457654Z",
     "iopub.status.busy": "2021-11-04T07:01:55.456807Z",
     "iopub.status.idle": "2021-11-04T07:01:57.08981Z",
     "shell.execute_reply": "2021-11-04T07:01:57.089095Z",
     "shell.execute_reply.started": "2021-11-04T07:01:55.457614Z"
    },
    "id": "Zo4PiSa1NA6j",
    "outputId": "13c41797-abf9-495d-a43f-259e94151c86"
   },
   "outputs": [],
   "source": [
    "ai.generate(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdpZQXknFNY3"
   },
   "source": [
    "## Train GPT-2\n",
    "\n",
    "Important parameters for `train()`:\n",
    "\n",
    "- **`line_by_line`**: Set this to `True` if the input text file is a single-column CSV, with one record per row. aitextgen will automatically process it optimally.\n",
    "- **`from_cache`**: If you compressed your dataset locally (as noted in the previous section) and are using that cache file, set this to `True`.\n",
    "- **`num_steps`**: Number of steps to train the model for.\n",
    "- **`generate_every`**: Interval of steps to generate example text from the model; good for qualitatively validating training.\n",
    "- **`save_every`**: Interval of steps to save the model: the model will be saved in the VM to `/trained_model`.\n",
    "- **`save_gdrive`**: Set this to `True` to copy the model to a unique folder in your Google Drive, if you have mounted it in the earlier cells\n",
    "- **`batch_size`**: Batch size of the model training; setting it too high will cause the GPU to go OOM. _Unlike finetuning, since you are using a small model, you can massively increase the batch size to normalize the training_.\n",
    "- **`fp16`**: Enables half-precision training for faster/more memory-efficient training. Only works on a T4 or V100 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-04T07:02:19.144938Z",
     "iopub.status.busy": "2021-11-04T07:02:19.144657Z",
     "iopub.status.idle": "2021-11-04T07:03:39.304175Z",
     "shell.execute_reply": "2021-11-04T07:03:39.303354Z",
     "shell.execute_reply.started": "2021-11-04T07:02:19.144905Z"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "18a0eb53-7de1-4a2f-c66e-fa4ac911530b"
   },
   "outputs": [],
   "source": [
    "ai.train('../input/chess-data/cleaned_lichess08_test.csv',\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=50_000,\n",
    "         generate_every=1_000,\n",
    "         save_every=1_000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         batch_size=4,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClJwpF_ACONp"
   },
   "source": [
    "## Generate Text From The Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-01T18:33:17.56896Z",
     "iopub.status.busy": "2021-11-01T18:33:17.568679Z",
     "iopub.status.idle": "2021-11-01T18:33:24.029724Z",
     "shell.execute_reply": "2021-11-01T18:33:24.028945Z",
     "shell.execute_reply.started": "2021-11-01T18:33:17.568929Z"
    },
    "id": "QHss16Yy0OHa"
   },
   "outputs": [],
   "source": [
    "ai = aitextgen(model_folder=\"../input/gpt-chess-v1\",\n",
    "               tokenizer_file=\"../input/gpt-chess-v1/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZktHqhV0PYZ"
   },
   "source": [
    "`generate()` without any parameters generates a single text from the loaded model to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-01T18:36:27.9388Z",
     "iopub.status.busy": "2021-11-01T18:36:27.93854Z",
     "iopub.status.idle": "2021-11-01T18:36:28.022788Z",
     "shell.execute_reply": "2021-11-01T18:36:28.02194Z",
     "shell.execute_reply.started": "2021-11-01T18:36:27.938772Z"
    },
    "id": "4RNY6RBI9LmL",
    "outputId": "8579ed7e-14c8-4a76-ecad-ce7acd13b612"
   },
   "outputs": [],
   "source": [
    "ai.generate(max_length = 10, prompt = 'e4', top_k = 40, top_p  = 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF4-PqF0Fl7R"
   },
   "source": [
    "Other optional-but-helpful parameters for `ai.generate()`:\n",
    "\n",
    "*  **`max_length`**: Number of tokens to generate (default 256, you can generate up to 1024 tokens with GPT-2, but it will be _much_ slower)\n",
    "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
    "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
    "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T14:49:31.102787Z",
     "iopub.status.busy": "2021-10-28T14:49:31.102091Z",
     "iopub.status.idle": "2021-10-28T14:49:33.427442Z",
     "shell.execute_reply": "2021-10-28T14:49:33.425945Z",
     "shell.execute_reply.started": "2021-10-28T14:49:31.102751Z"
    },
    "id": "8DKMc0fiej4N",
    "outputId": "8135966f-907d-48a0-c837-36c0be909fee"
   },
   "outputs": [],
   "source": [
    " ai.generate(n=1,\n",
    "            batch_size=5,\n",
    "            prompt =\"d4 g6\",\n",
    "            temperature = 0.7,\n",
    "            top_p=0.9,\n",
    "           top_k = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T14:50:49.3821Z",
     "iopub.status.busy": "2021-10-28T14:50:49.381395Z",
     "iopub.status.idle": "2021-10-28T15:03:19.288777Z",
     "shell.execute_reply": "2021-10-28T15:03:19.288037Z",
     "shell.execute_reply.started": "2021-10-28T14:50:49.382062Z"
    },
    "id": "Fa6p6arifSL0",
    "outputId": "c356cb76-bcf6-45dc-ad41-a00b03a8a847"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_files = 1\n",
    "\n",
    "prompts = [\"a4\",\"b4\",\"c4\",\"d4\",\"e4\",\"f4\",\"g4\",\"h4\", \n",
    "           'e4 c5', 'e4 e5', 'e4 e6','e4 c6','e4 d6',\n",
    "          'e4 d5','e4 g6','e4 Nf6','d4 Nf6','d4 d5','d4 e6',\n",
    "          'd4 d6','d4 f5','d4 g6', 'c4 c5', 'c4 e5',\n",
    "          'c4 e6', 'c4 Nf6', 'c4 f5', 'c4 g6', 'c4 c6']\n",
    "\n",
    "print(len(prompts))\n",
    "\n",
    "for prompt in tqdm(prompts):\n",
    "    for _ in range(num_files):\n",
    "        ai.generate_to_file(n=1000,\n",
    "                         batch_size=100,\n",
    "                        prompt = prompt,\n",
    "                         temperature=0.7,\n",
    "                         top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T15:07:44.254929Z",
     "iopub.status.busy": "2021-10-28T15:07:44.254654Z",
     "iopub.status.idle": "2021-10-28T15:07:44.280996Z",
     "shell.execute_reply": "2021-10-28T15:07:44.280351Z",
     "shell.execute_reply.started": "2021-10-28T15:07:44.254895Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#returns the names of the files in the directory data as a list\n",
    "list_of_files = os.listdir(\"./\")\n",
    "lines=[]\n",
    "for file in list_of_files:\n",
    "    if file != 'result.txt' and file != 'general_generation.csv':\n",
    "        f = open(file, \"r\")\n",
    "        #append each line in the file to a list\n",
    "        inner = f.readlines()\n",
    "        lines.append(inner[0:len(inner):2])\n",
    "        f.close()\n",
    "    #else:\n",
    "     #   print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-28T15:07:52.222263Z",
     "iopub.status.busy": "2021-10-28T15:07:52.221978Z",
     "iopub.status.idle": "2021-10-28T15:07:52.564025Z",
     "shell.execute_reply": "2021-10-28T15:07:52.563328Z",
     "shell.execute_reply.started": "2021-10-28T15:07:52.222229Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(lines).T.to_csv('prompted_chess.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
