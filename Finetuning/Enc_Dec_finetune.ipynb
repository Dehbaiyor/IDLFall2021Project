{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ul52VwW2D-IX"
   },
   "source": [
    "## Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14177,
     "status": "ok",
     "timestamp": 1632734285417,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "IWWLMcr0Yosy",
    "outputId": "467d3f2b-ec16-4801-93fb-fd13f31b263c"
   },
   "outputs": [],
   "source": [
    "#Installation\n",
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "#Tokenizer\n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "#Encoder-Decoder Model\n",
    "from transformers import EncoderDecoderModel\n",
    "\n",
    "#Training\n",
    "# When using previous version of the library you need the following two lines\n",
    "#from seq2seq_trainer import Seq2SeqTrainer\n",
    "#from transformers import TrainingArguments\n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRZ9PVHF7IiX"
   },
   "source": [
    "Define parameters for data location and model folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-BWLTkI7X49"
   },
   "source": [
    "Load the datafile with the product descriptions and names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1632734285420,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "GQ48JL6J7bXl",
    "outputId": "57b1bfe0-3e89-4f20-c238-b67d98a85721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Examples:  1000000\n",
      "Null Values\n",
      " input     0\n",
      "target    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from a CSV file\n",
    "df=pd.read_csv('chess_data/1.csv', usecols=['input','target'])\n",
    "print('Num Examples: ',len(df))\n",
    "print('Null Values\\n', df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1632734285421,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "TT86FAZX7gmP",
    "outputId": "651eeaba-2d60-43bf-f3b4-b22e42cfef87"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e4 : Nf3 c5 e4 Nc6 d4 cxd4 Nxd4 Nf6 Nc3 d6 Bg5...</td>\n",
       "      <td>Nxd3+ cxd3 Bd7 Qh4 Qg8 Nh2 Nd4 Ng4 Nf5 Qh3 Rc8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e4 : g3 e5 d4 exd4 Nf3 c5 c3 d5 cxd4 c4 Bg2 Nf...</td>\n",
       "      <td>Bd6 Qxa4 O-O Nxd7 Qxd7 Qxd7 Nxd7 c5 Be7 Nc3 Nf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e4 : e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Nxe4 d4 ...</td>\n",
       "      <td>Bf5 Rab1 Rd7 Bc2 Rad8 Rfd1 Bg6 Bxd3 Rxd3 Rxd3 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e4 : e4 c5 Nc3 d6 Nf3 g6 d4 cxd4 Nxd4 Nf6 Bc4 ...</td>\n",
       "      <td>f5 Nf3# 0-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e4 : c4 f5 Nc3 Nf6 g3 g6 Bg2 Bg7 Rb1 a5 d3 O-O...</td>\n",
       "      <td>c6 Qc2 Nd8 Nd2 Nf7 Ra1 e5 Rfb1 Qe7 Qb3 Kh8 Qc2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  e4 : Nf3 c5 e4 Nc6 d4 cxd4 Nxd4 Nf6 Nc3 d6 Bg5...   \n",
       "1  e4 : g3 e5 d4 exd4 Nf3 c5 c3 d5 cxd4 c4 Bg2 Nf...   \n",
       "2  e4 : e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Nxe4 d4 ...   \n",
       "3  e4 : e4 c5 Nc3 d6 Nf3 g6 d4 cxd4 Nxd4 Nf6 Bc4 ...   \n",
       "4  e4 : c4 f5 Nc3 Nf6 g3 g6 Bg2 Bg7 Rb1 a5 d3 O-O...   \n",
       "\n",
       "                                              target  \n",
       "0  Nxd3+ cxd3 Bd7 Qh4 Qg8 Nh2 Nd4 Ng4 Nf5 Qh3 Rc8...  \n",
       "1  Bd6 Qxa4 O-O Nxd7 Qxd7 Qxd7 Nxd7 c5 Be7 Nc3 Nf...  \n",
       "2  Bf5 Rab1 Rd7 Bc2 Rad8 Rfd1 Bg6 Bxd3 Rxd3 Rxd3 ...  \n",
       "3                                        f5 Nf3# 0-1  \n",
       "4  c6 Qc2 Nd8 Nd2 Nf7 Ra1 e5 Rfb1 Qe7 Qb3 Kh8 Qc2...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NK0vJg07tnR"
   },
   "source": [
    "## Split the data into train and validation dataset\n",
    "\n",
    "We split the dataset into a training dataset (90%) and a validation dataset (10%). To choose the examples, there is a sampling method to randomly extract the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1632734285422,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "2XiyTneX8B5j",
    "outputId": "59980423-6725-4e51-cb22-83bc623fadf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Train dataset:  990000\n",
      "Length Val dataset:  10000\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and validation\n",
    "# Defining the train size. So 90% of the data will be used for training and the rest will be used for validation. \n",
    "train_size = 0.99\n",
    "\n",
    "# Sampling 90% fo the rows from the dataset\n",
    "train_dataset=df.sample(frac=train_size,random_state = 42)\n",
    "\n",
    "# Reset the indexes\n",
    "val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "print('Length Train dataset: ', len(train_dataset))\n",
    "print('Length Val dataset: ', len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfSfu7QHE-C0"
   },
   "source": [
    "In the next section, we try to limit the number of examples to train on in order to reduce the cost and time for training during the experiments. When the model is ready to be trained, we must train on the whole training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NRy5w_McbLOD"
   },
   "outputs": [],
   "source": [
    "# To limit the training and validation dataset, for testing\n",
    "start = 0\n",
    "stop = 1\n",
    "\n",
    "# Create a Dataset from a pandas dataframe for training and validation\n",
    "train_data=Dataset.from_pandas(train_dataset) #[start*200_000:stop*200_000])\n",
    "val_data=Dataset.from_pandas(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v97UsVpOFs_S"
   },
   "source": [
    "# Create the encoder-decoder model from a pretrained RoBERTa model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyfvVUhC9GGO"
   },
   "source": [
    "## Setting the model and training parameters\n",
    "\n",
    "Now it is time to set the model and training parameters, they will be passed to the dataset generator and to the Trainer object in a latter section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eQ3oqvQN9LN_"
   },
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 64  # input batch size for training (default: 64)\n",
    "VALID_BATCH_SIZE = 2   # input batch size for testing (default: 1000)\n",
    "TRAIN_EPOCHS = 1    # number of epochs to train (default: 10)\n",
    "VAL_EPOCHS = 1 \n",
    "LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
    "SEED = 42               # random seed (default: 42)\n",
    "MAX_LEN = 512      # Max length for product description\n",
    "SUMMARY_LEN = 512      # Max length for product names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At8Jlrr1ldQy"
   },
   "source": [
    "## Load the trained tokenizer on our specific language\n",
    "As we mentioned previously, we have trained a tokenizer and a RoBERTa model from scratch using the Masked Language Modelling technique trying to focus our model on our specific task. Now we can configure our encoder-decoder using this pretrained model.\n",
    "\n",
    "The first step is loading the tokenizer we need to apply to generate our input and target tokens and transform them into a vector representation of the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1632734285947,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "juEoejqqa2e3",
    "outputId": "a0d985a7-4480-4659-f27c-c32c08c0ca69"
   },
   "outputs": [],
   "source": [
    "# Loading the RoBERTa Tokenizer\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('MixedTokens',  max_len=MAX_LEN)\n",
    "# Setting the BOS and EOS token\n",
    "tokenizer.bos_token = tokenizer.cls_token\n",
    "tokenizer.eos_token = tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "9f538f9d8f334ef589bb03ed39c524a2",
      "b9199a2f38b743758229ff96587aade7",
      "17c8957d90b24023bd4f34b7e69dfaff",
      "ca3b225fe04042c1b11361926faf9c72",
      "9f95feb156ad47b4b196b497057603cf",
      "1aa4404546d048be9095ce36f9a7cab7",
      "c60e580c0ae7412a82f598ceaf162462",
      "a0c76b6082e5418bb1624dab8fd6f68a",
      "25764dd28af84378be5588b2c2d771d4",
      "0807f4e7748e4bf2b0ad2a8587ed4e5a",
      "bb44322fee4549318415abec9c8a8325",
      "9d3e9aff149d464f9cf51aad6a3463f4",
      "fdb49bb47e0b4156b1ba9a3cd2aa9caf",
      "8623ad7c0c594f0298c6ede3097fabc9",
      "e70c980936be422fb12f352b6fc0e4e0",
      "10b1cd1eb5054ea4a2dff02443080e0c",
      "bcab682a4dce4516b002f0272be5e5aa",
      "5580f604ab664d4ab28b567376804c91",
      "0fcbbcf6fc964f7f8d7fbf75a453cc68",
      "d047ad4add1e435886d586aebecaa2ee",
      "d07f9a9e090947b1aaaca87429108fb0",
      "cead868d99864f5e9162e2b4bcc922e0"
     ]
    },
    "executionInfo": {
     "elapsed": 5604,
     "status": "ok",
     "timestamp": 1632734291544,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "iElONCScGD9e",
    "outputId": "4ea7823d-9608-4d6f-e6bb-4c3fb3d23ff5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db274f82d62b46f48a5308f47a1b0f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15469 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342486d06c894ed4b02df3dbfb99cbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size=TRAIN_BATCH_SIZE  # change to 16 for full training\n",
    "encoder_max_length=MAX_LEN\n",
    "decoder_max_length=SUMMARY_LEN\n",
    "\n",
    "def process_data_to_model_inputs(batch):\n",
    "  # Tokenize the input and target data\n",
    "  inputs = tokenizer(batch[\"input\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
    "  outputs = tokenizer(batch[\"target\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
    "\n",
    "  batch[\"input_ids\"] = inputs.input_ids\n",
    "  batch[\"attention_mask\"] = inputs.attention_mask\n",
    "  batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "  batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "  batch[\"labels\"] = outputs.input_ids.copy()\n",
    "\n",
    "  batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
    "\n",
    "  return batch\n",
    "\n",
    "# Preprocessing the training data\n",
    "train_data = train_data.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"input\", \"target\"]\n",
    ")\n",
    "train_data.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n",
    "# Preprocessing the validation data\n",
    "val_data = val_data.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"input\", \"target\"]\n",
    ")\n",
    "val_data.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n",
    "# Shuffle the dataset when it is needed\n",
    "#dataset = dataset.shuffle(seed=42, buffer_size=10, reshuffle_each_iteration=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8J6lVbwq-BGV"
   },
   "source": [
    "## Define the RoBERTa Encoder-Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2017,
     "status": "ok",
     "timestamp": 1632734294116,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "r0NyMtoRbAun",
    "outputId": "7acdd998-44e0-494a-d9ca-817e7a6e1467"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at MixedTokens were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at MixedTokens and are newly initialized: ['roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.9.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.9.crossattention.self.key.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  50000\n"
     ]
    }
   ],
   "source": [
    "# set encoder decoder tying to True\n",
    "pretrainedmodel_folder = 'MixedTokens'\n",
    "roberta_shared = EncoderDecoderModel.from_encoder_decoder_pretrained(pretrainedmodel_folder, pretrainedmodel_folder, tie_encoder_decoder=True)\n",
    "\n",
    "# Show the vocab size to check it has been loaded\n",
    "print('Vocab Size: ',roberta_shared.config.encoder.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uqWYGXiBcEKL"
   },
   "outputs": [],
   "source": [
    "# set special tokens\n",
    "roberta_shared.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
    "roberta_shared.config.eos_token_id = tokenizer.eos_token_id\n",
    "roberta_shared.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "# set decoding params                               \n",
    "roberta_shared.config.max_length = SUMMARY_LEN\n",
    "roberta_shared.config.early_stopping = True\n",
    "roberta_shared.config.no_repeat_ngram_size = 1\n",
    "roberta_shared.config.length_penalty = 2.0\n",
    "roberta_shared.config.repetition_penalty = 3.0\n",
    "roberta_shared.config.num_beams = 10\n",
    "roberta_shared.config.vocab_size = roberta_shared.config.encoder.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wZQuCK__KI0"
   },
   "source": [
    "# Training the encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KFWMEZ3McNzM"
   },
   "outputs": [],
   "source": [
    "# load rouge for validation\n",
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i04hngq6IBGu"
   },
   "source": [
    "## Create the Trainer\n",
    "\n",
    "Now it is time to set the training arguments: batch_size, training epochs, save the model, etc. And then we can instantiate a `Seq2SeqTrainer`, a subclass of the `Trainer`object we mentioned, selecting the model to train, the training arguments, the metrics computation, the train, and the evaluation datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2573,
     "status": "ok",
     "timestamp": 1632734334492,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "93qw0sFTPol2",
    "outputId": "369e4817-a235-4cb1-9906-bcfa7eab169f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "#batch_size = 4\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='MixedTokens',\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    predict_with_generate=True,\n",
    "    #evaluate_during_training=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=1_000,  \n",
    "    save_steps=1_000, \n",
    "    warmup_steps=10,  \n",
    "    #max_steps=1500, # delete for full training\n",
    "    num_train_epochs = TRAIN_EPOCHS, #TRAIN_EPOCHS\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=1,\n",
    "    fp16=True, \n",
    ")\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    tokenizer=tokenizer,\n",
    "    model=roberta_shared,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-R2qJClIFvz"
   },
   "source": [
    "Now, we start training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "executionInfo": {
     "elapsed": 6326124,
     "status": "ok",
     "timestamp": 1632740664013,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "W3bT7HuWVBbW",
    "outputId": "4617d138-9cdc-498b-ac9e-22de767f6f52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 990000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 247500\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54710' max='247500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 54710/247500 10:23:39 < 36:37:46, 1.46 it/s, Epoch 0.22/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to MixedTokens/checkpoint-1000\n",
      "Configuration saved in MixedTokens/checkpoint-1000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-16000] due to args.save_total_limit\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-17000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-2000\n",
      "Configuration saved in MixedTokens/checkpoint-2000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-1000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-3000\n",
      "Configuration saved in MixedTokens/checkpoint-3000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-2000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-4000\n",
      "Configuration saved in MixedTokens/checkpoint-4000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-3000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-5000\n",
      "Configuration saved in MixedTokens/checkpoint-5000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-4000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-6000\n",
      "Configuration saved in MixedTokens/checkpoint-6000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-5000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-7000\n",
      "Configuration saved in MixedTokens/checkpoint-7000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-6000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-8000\n",
      "Configuration saved in MixedTokens/checkpoint-8000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-7000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-9000\n",
      "Configuration saved in MixedTokens/checkpoint-9000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-8000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-10000\n",
      "Configuration saved in MixedTokens/checkpoint-10000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-9000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-11000\n",
      "Configuration saved in MixedTokens/checkpoint-11000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-10000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-12000\n",
      "Configuration saved in MixedTokens/checkpoint-12000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-11000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-13000\n",
      "Configuration saved in MixedTokens/checkpoint-13000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-12000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-14000\n",
      "Configuration saved in MixedTokens/checkpoint-14000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-13000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-15000\n",
      "Configuration saved in MixedTokens/checkpoint-15000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-14000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-16000\n",
      "Configuration saved in MixedTokens/checkpoint-16000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-15000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-17000\n",
      "Configuration saved in MixedTokens/checkpoint-17000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-16000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-18000\n",
      "Configuration saved in MixedTokens/checkpoint-18000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-17000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-19000\n",
      "Configuration saved in MixedTokens/checkpoint-19000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-18000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-20000\n",
      "Configuration saved in MixedTokens/checkpoint-20000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-19000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-21000\n",
      "Configuration saved in MixedTokens/checkpoint-21000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-20000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-22000\n",
      "Configuration saved in MixedTokens/checkpoint-22000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-21000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-23000\n",
      "Configuration saved in MixedTokens/checkpoint-23000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-22000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-24000\n",
      "Configuration saved in MixedTokens/checkpoint-24000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-23000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-25000\n",
      "Configuration saved in MixedTokens/checkpoint-25000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-24000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-26000\n",
      "Configuration saved in MixedTokens/checkpoint-26000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-25000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-27000\n",
      "Configuration saved in MixedTokens/checkpoint-27000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-27000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-26000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-28000\n",
      "Configuration saved in MixedTokens/checkpoint-28000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-28000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-27000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-29000\n",
      "Configuration saved in MixedTokens/checkpoint-29000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-29000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-28000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-30000\n",
      "Configuration saved in MixedTokens/checkpoint-30000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-29000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-31000\n",
      "Configuration saved in MixedTokens/checkpoint-31000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-31000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-30000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-32000\n",
      "Configuration saved in MixedTokens/checkpoint-32000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-31000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-33000\n",
      "Configuration saved in MixedTokens/checkpoint-33000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-33000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-32000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-34000\n",
      "Configuration saved in MixedTokens/checkpoint-34000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-34000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-33000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-35000\n",
      "Configuration saved in MixedTokens/checkpoint-35000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-34000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-36000\n",
      "Configuration saved in MixedTokens/checkpoint-36000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-35000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-37000\n",
      "Configuration saved in MixedTokens/checkpoint-37000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-37000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-36000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-38000\n",
      "Configuration saved in MixedTokens/checkpoint-38000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-38000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-37000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-39000\n",
      "Configuration saved in MixedTokens/checkpoint-39000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-39000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-38000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-40000\n",
      "Configuration saved in MixedTokens/checkpoint-40000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-39000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-41000\n",
      "Configuration saved in MixedTokens/checkpoint-41000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-41000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-40000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-42000\n",
      "Configuration saved in MixedTokens/checkpoint-42000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-42000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-41000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-43000\n",
      "Configuration saved in MixedTokens/checkpoint-43000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-43000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-42000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-44000\n",
      "Configuration saved in MixedTokens/checkpoint-44000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-44000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-43000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-45000\n",
      "Configuration saved in MixedTokens/checkpoint-45000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-44000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-46000\n",
      "Configuration saved in MixedTokens/checkpoint-46000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-46000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-46000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-46000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-45000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-47000\n",
      "Configuration saved in MixedTokens/checkpoint-47000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-47000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-47000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-47000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-46000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-48000\n",
      "Configuration saved in MixedTokens/checkpoint-48000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-48000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-47000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-49000\n",
      "Configuration saved in MixedTokens/checkpoint-49000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-49000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-49000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-49000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-48000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-50000\n",
      "Configuration saved in MixedTokens/checkpoint-50000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-49000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-51000\n",
      "Configuration saved in MixedTokens/checkpoint-51000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-51000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-51000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-51000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-50000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-52000\n",
      "Configuration saved in MixedTokens/checkpoint-52000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-52000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-52000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-52000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-51000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-53000\n",
      "Configuration saved in MixedTokens/checkpoint-53000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-53000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-53000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-53000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-52000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to MixedTokens/checkpoint-54000\n",
      "Configuration saved in MixedTokens/checkpoint-54000/config.json\n",
      "Model weights saved in MixedTokens/checkpoint-54000/pytorch_model.bin\n",
      "tokenizer config file saved in MixedTokens/checkpoint-54000/tokenizer_config.json\n",
      "Special tokens file saved in MixedTokens/checkpoint-54000/special_tokens_map.json\n",
      "Deleting older checkpoint [MixedTokens/checkpoint-53000] due to args.save_total_limit\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:490: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model, training and evaluating on the train dataset\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3lRmRvlbFzN"
   },
   "source": [
    "Save the encoder-decoder model just trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1541,
     "status": "ok",
     "timestamp": 1632741920852,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "7xVP7Vtwaz-w",
    "outputId": "2e6db8a7-b4e2-4fbf-daa9-f2961d2b64cc"
   },
   "outputs": [],
   "source": [
    "# Save the encoder-decoder model just trained\n",
    "trainer.save_model('FinetunedModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkGO0gtQGjbI"
   },
   "source": [
    "# Evaluate the model on the test dataset\n",
    "\n",
    "Once we have our model trained, we can use it to generate names for our products and check the result of our fine-tuning process on our objective task. \n",
    "\n",
    "We load a test dataset, a subset of our original dataset and delete rows containing null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1632741925510,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "D727N4XHDhDn",
    "outputId": "c924cc3e-7566-4894-ccb5-0ca7b6f6f806"
   },
   "outputs": [],
   "source": [
    "# Load the dataset: sentence in english, sentence in spanish \n",
    "df=pd.read_csv('chess_data/23.csv')\n",
    "print('Num Examples: ',len(df))\n",
    "print('Null Values\\n', df.isna().sum())\n",
    "print(df.head(5))\n",
    "\n",
    "test_data=Dataset.from_pandas(df[:30])\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8B3MLGJw5uT"
   },
   "source": [
    "If you need to **restore the trained model from a checkpoint** run the next cell, selecting the folder where the checkpoint was saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6HLy-pqrVh7"
   },
   "source": [
    "checkpoint_path = os.path.abspath(os.path.join(model_folder,'checkpoint-3072'))\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx8HQRJqrCqN"
   },
   "source": [
    "Then we load the Tokenizer and the fine-tuned model from a saved version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3659,
     "status": "ok",
     "timestamp": 1612897968696,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "80cdTzPRrJPg",
    "outputId": "df5d278b-e627-45fb-ee8b-90ccbac1a3ae"
   },
   "outputs": [],
   "source": [
    "#Load the Tokenizer and the fine-tuned model\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('FinetunedModel')\n",
    "model = EncoderDecoderModel.from_pretrained('FinetunedModel')\n",
    "\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oukYOQoSIm7q"
   },
   "source": [
    "In order to improve the results, we will define two methods to generate the text, using the Beam search decoding strategy and random sampling, and we will apply them and compare the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W79b87IBcSG-"
   },
   "outputs": [],
   "source": [
    "# Generate the text without setting a decoding strategy\n",
    "def generate_summary(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = tokenizer(batch[\"input\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
    "\n",
    "    #outputs = roberta_shared.generate(input_ids, attention_mask=attention_mask)\n",
    "    outputs = roberta_shared.generate(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"pred\"] = output_str\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RypfesHQnUsE"
   },
   "outputs": [],
   "source": [
    "# Generate a text using beams search\n",
    "def generate_summary_beam_search(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = tokenizer(batch[\"input\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
    "\n",
    "    outputs = roberta_shared.generate(input_ids, attention_mask=attention_mask,\n",
    "                                  num_beams=15,\n",
    "                                  repetition_penalty=3.0, \n",
    "                                  length_penalty=2.0, \n",
    "                                  num_return_sequences = 1\n",
    "    )\n",
    "\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"pred\"] = output_str\n",
    "\n",
    "    return batch\n",
    "\n",
    "# Generate a text using beams search\n",
    "def generate_summary_topk(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = tokenizer(batch[\"input\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
    "\n",
    "    outputs = roberta_shared.generate(input_ids, attention_mask=attention_mask,\n",
    "                                  repetition_penalty=3.0, \n",
    "                                  length_penalty=2.0, \n",
    "                                  num_return_sequences = 1,\n",
    "                                  do_sample=True,\n",
    "                                  top_k=50, \n",
    "                                  top_p=0.95,\n",
    "\n",
    "    )\n",
    "\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"pred\"] = output_str\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfG402bqI3t2"
   },
   "source": [
    "Now, we can make predictions for the test dataset using Beam search strategy and top-k sampling technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152,
     "referenced_widgets": [
      "027dce30a62a40ad9a7c9d0941c020c7",
      "e0e87c7d1bb94a1fa42467a101db1f61",
      "3b441a90c1b948348a5e718b2f20a382",
      "bb6f3e8b55c4472fbe4de30e13674f6e",
      "012b238bb08745b7a6d4ac419f2480c7",
      "d0dd958562304ef89c02216518d2273a",
      "aac6248693ab425db9e5879c9a1705d4",
      "8896aace47ba49efad33b80b68bf0c86",
      "0c3127e067f1411ca3efdd36b233cb10",
      "de898c4bfdf24aa5966b9c31e913b2f5",
      "243d56b7c05248af8cd275b4c03d5453",
      "18dc49750fad41d79c32696610feb651",
      "e0d70b350ce24b618d427907fdd72f9d",
      "426f35e25c5541f2822f3bc7744bb7b5",
      "1004f2e3fcdb429fafb138d869939a89",
      "b97b7461cf33481581ce7fe7d746ef3f",
      "f7476c58ef3b48f4948443679a1bdf47",
      "cd3465e5cd6240debfd29b2ecfb3bfe1",
      "88420b2c8e2341118d1222fc1c19466d",
      "5b7c69538d2d48fca6bb0e454b43a896",
      "ff5a6eb413484323948a15e358a54f78",
      "3e028a9817c746ca824b1a21e3fe6b22"
     ]
    },
    "executionInfo": {
     "elapsed": 202677,
     "status": "ok",
     "timestamp": 1632742143944,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "1XeMAIyxHnqq",
    "outputId": "57eb2600-29a9-4501-b598-b00e46b55cfc"
   },
   "outputs": [],
   "source": [
    "batch_size = TRAIN_BATCH_SIZE\n",
    "\n",
    "#results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"description\"])\n",
    "# Generate predictions using beam search\n",
    "results = test_data.map(generate_summary_beam_search, batched=True, batch_size=batch_size, remove_columns=[\"input\"])\n",
    "pred_str_bs = results[\"pred\"]\n",
    "# Generate predictions using top-k sampling\n",
    "results = test_data.map(generate_summary_topk, batched=True, batch_size=batch_size, remove_columns=[\"input\"])\n",
    "pred_str_topk = results[\"pred\"]\n",
    "\n",
    "#label_str = results[\"Summary\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4stzYN6ZzP-X"
   },
   "source": [
    "Now, we can see some results from our trained model to check its performance on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1632742156758,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "2uHlB8U6f4je",
    "outputId": "9f926162-6d84-40d6-b174-9ad9e4b02c3e"
   },
   "outputs": [],
   "source": [
    "#Show an example\n",
    "print(\"Moves: \",df['input'][1])\n",
    "print(\"Predicted using BS: \", pred_str_bs[1])\n",
    "print(\"Predicted using Top-K Sampling: \", pred_str_topk[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1632742168005,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -120
    },
    "id": "B60rzZ7UhQfp",
    "outputId": "c8095fa2-e911-425b-cadf-5aece2f65a0d"
   },
   "outputs": [],
   "source": [
    "#Show an example\n",
    "print(\"Moves: \",df['input'][10])\n",
    "print(\"Predicted using BS: \", pred_str_bs[10])\n",
    "print(\"Predicted using Top-K Sampling: \", pred_str_topk[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2kc3xwTTFXP"
   },
   "source": [
    "When more than one output are generated we need to join them on a single list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1612981617914,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "wIFmWu1Lu9xb",
    "outputId": "ae4e571b-9e5d-4ea5-f59c-adda1d2f98b4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds=np.reshape(pred_str, (-1, 3))\n",
    "print('Predictions Shape: ',preds.shape)\n",
    "predictions = [','.join(p) for p in preds]\n",
    "print('Num predictions: ', len(predictions),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1612981655396,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "VxYXAvjDvYjV",
    "outputId": "5e5da222-2662-41a7-cb2c-41d829acf210"
   },
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdpdHJ28ThJW"
   },
   "source": [
    "Save the predictions to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1614429421680,
     "user": {
      "displayName": "Eduardo Muñoz Sala",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi9gTFB7xfdxQyNiKRUzqE5vwb9WQjQuMtQz5F16w=s64",
      "userId": "13317831924226771761"
     },
     "user_tz": -60
    },
    "id": "RYBRQ7o8mh0V",
    "outputId": "696e3926-07aa-4dac-d035-261c2d5aae2c"
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame({'name':pred_str})\n",
    "final_df.to_csv(outputfile_path, index=False)\n",
    "print('Output Files generated for review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMRYwOlmiDqw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "W7Sk2Mv-3WYJ"
   ],
   "name": "RoBERTa Encoder Decoder MLM FineTuned for Text generation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "012b238bb08745b7a6d4ac419f2480c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_243d56b7c05248af8cd275b4c03d5453",
      "placeholder": "​",
      "style": "IPY_MODEL_de898c4bfdf24aa5966b9c31e913b2f5",
      "value": " 91/91 [01:54&lt;00:00,  1.11ba/s]"
     }
    },
    "027dce30a62a40ad9a7c9d0941c020c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b441a90c1b948348a5e718b2f20a382",
       "IPY_MODEL_bb6f3e8b55c4472fbe4de30e13674f6e",
       "IPY_MODEL_012b238bb08745b7a6d4ac419f2480c7"
      ],
      "layout": "IPY_MODEL_e0e87c7d1bb94a1fa42467a101db1f61"
     }
    },
    "0807f4e7748e4bf2b0ad2a8587ed4e5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c3127e067f1411ca3efdd36b233cb10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fcbbcf6fc964f7f8d7fbf75a453cc68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1004f2e3fcdb429fafb138d869939a89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b7c69538d2d48fca6bb0e454b43a896",
      "max": 91,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88420b2c8e2341118d1222fc1c19466d",
      "value": 91
     }
    },
    "10b1cd1eb5054ea4a2dff02443080e0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cead868d99864f5e9162e2b4bcc922e0",
      "placeholder": "​",
      "style": "IPY_MODEL_d07f9a9e090947b1aaaca87429108fb0",
      "value": " 198/198 [00:00&lt;00:00, 293.26ba/s]"
     }
    },
    "17c8957d90b24023bd4f34b7e69dfaff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c60e580c0ae7412a82f598ceaf162462",
      "placeholder": "​",
      "style": "IPY_MODEL_1aa4404546d048be9095ce36f9a7cab7",
      "value": "100%"
     }
    },
    "18dc49750fad41d79c32696610feb651": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_426f35e25c5541f2822f3bc7744bb7b5",
       "IPY_MODEL_1004f2e3fcdb429fafb138d869939a89",
       "IPY_MODEL_b97b7461cf33481581ce7fe7d746ef3f"
      ],
      "layout": "IPY_MODEL_e0d70b350ce24b618d427907fdd72f9d"
     }
    },
    "1aa4404546d048be9095ce36f9a7cab7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "243d56b7c05248af8cd275b4c03d5453": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25764dd28af84378be5588b2c2d771d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b441a90c1b948348a5e718b2f20a382": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aac6248693ab425db9e5879c9a1705d4",
      "placeholder": "​",
      "style": "IPY_MODEL_d0dd958562304ef89c02216518d2273a",
      "value": "100%"
     }
    },
    "3e028a9817c746ca824b1a21e3fe6b22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "426f35e25c5541f2822f3bc7744bb7b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd3465e5cd6240debfd29b2ecfb3bfe1",
      "placeholder": "​",
      "style": "IPY_MODEL_f7476c58ef3b48f4948443679a1bdf47",
      "value": "100%"
     }
    },
    "5580f604ab664d4ab28b567376804c91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b7c69538d2d48fca6bb0e454b43a896": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8623ad7c0c594f0298c6ede3097fabc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5580f604ab664d4ab28b567376804c91",
      "placeholder": "​",
      "style": "IPY_MODEL_bcab682a4dce4516b002f0272be5e5aa",
      "value": "100%"
     }
    },
    "88420b2c8e2341118d1222fc1c19466d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8896aace47ba49efad33b80b68bf0c86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d3e9aff149d464f9cf51aad6a3463f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8623ad7c0c594f0298c6ede3097fabc9",
       "IPY_MODEL_e70c980936be422fb12f352b6fc0e4e0",
       "IPY_MODEL_10b1cd1eb5054ea4a2dff02443080e0c"
      ],
      "layout": "IPY_MODEL_fdb49bb47e0b4156b1ba9a3cd2aa9caf"
     }
    },
    "9f538f9d8f334ef589bb03ed39c524a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17c8957d90b24023bd4f34b7e69dfaff",
       "IPY_MODEL_ca3b225fe04042c1b11361926faf9c72",
       "IPY_MODEL_9f95feb156ad47b4b196b497057603cf"
      ],
      "layout": "IPY_MODEL_b9199a2f38b743758229ff96587aade7"
     }
    },
    "9f95feb156ad47b4b196b497057603cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb44322fee4549318415abec9c8a8325",
      "placeholder": "​",
      "style": "IPY_MODEL_0807f4e7748e4bf2b0ad2a8587ed4e5a",
      "value": " 1775/1775 [00:05&lt;00:00, 325.75ba/s]"
     }
    },
    "a0c76b6082e5418bb1624dab8fd6f68a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aac6248693ab425db9e5879c9a1705d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9199a2f38b743758229ff96587aade7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b97b7461cf33481581ce7fe7d746ef3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e028a9817c746ca824b1a21e3fe6b22",
      "placeholder": "​",
      "style": "IPY_MODEL_ff5a6eb413484323948a15e358a54f78",
      "value": " 91/91 [01:26&lt;00:00,  1.41ba/s]"
     }
    },
    "bb44322fee4549318415abec9c8a8325": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb6f3e8b55c4472fbe4de30e13674f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c3127e067f1411ca3efdd36b233cb10",
      "max": 91,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8896aace47ba49efad33b80b68bf0c86",
      "value": 91
     }
    },
    "bcab682a4dce4516b002f0272be5e5aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c60e580c0ae7412a82f598ceaf162462": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca3b225fe04042c1b11361926faf9c72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25764dd28af84378be5588b2c2d771d4",
      "max": 1775,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a0c76b6082e5418bb1624dab8fd6f68a",
      "value": 1775
     }
    },
    "cd3465e5cd6240debfd29b2ecfb3bfe1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cead868d99864f5e9162e2b4bcc922e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d047ad4add1e435886d586aebecaa2ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d07f9a9e090947b1aaaca87429108fb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0dd958562304ef89c02216518d2273a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de898c4bfdf24aa5966b9c31e913b2f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0d70b350ce24b618d427907fdd72f9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0e87c7d1bb94a1fa42467a101db1f61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e70c980936be422fb12f352b6fc0e4e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d047ad4add1e435886d586aebecaa2ee",
      "max": 198,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0fcbbcf6fc964f7f8d7fbf75a453cc68",
      "value": 198
     }
    },
    "f7476c58ef3b48f4948443679a1bdf47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdb49bb47e0b4156b1ba9a3cd2aa9caf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff5a6eb413484323948a15e358a54f78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
