{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ec3968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:27:39.687989Z",
     "iopub.status.busy": "2021-11-29T06:27:39.686468Z",
     "iopub.status.idle": "2021-11-29T06:27:53.387668Z",
     "shell.execute_reply": "2021-11-29T06:27:53.387004Z",
     "shell.execute_reply.started": "2021-11-29T06:22:45.859773Z"
    },
    "papermill": {
     "duration": 13.716624,
     "end_time": "2021-11-29T06:27:53.387832",
     "exception": false,
     "start_time": "2021-11-29T06:27:39.671208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aitextgen\r\n",
      "  Downloading aitextgen-0.5.2.tar.gz (572 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 572 kB 600 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (4.5.1)\r\n",
      "Collecting fire>=0.3.0\r\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 87 kB 5.2 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: pytorch-lightning>=1.3.1 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (1.4.4)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (1.9.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fire>=0.3.0->aitextgen) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire>=0.3.0->aitextgen) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (1.19.5)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (21.0)\r\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (2021.10.1)\r\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.62.3)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (3.10.0.2)\r\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (2.6.0)\r\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.3.1)\r\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.18.2)\r\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (5.4.1)\r\n",
      "Requirement already satisfied: torchmetrics>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.5.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.25.1)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.7.4.post0)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->pytorch-lightning>=1.3.1->aitextgen) (2.4.7)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.14.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.3.4)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (2.0.1)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.38.1)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.19.0)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (58.0.4)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.8.0)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.37.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.6.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.35.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.7.2)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.2.2)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.8.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.8)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2021.10.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.26.6)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (4.0.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.1.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (2021.8.28)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (3.0.12)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (0.10.3)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (0.0.46)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.6.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (21.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (5.1.0)\r\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.5.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=4.5.1->aitextgen) (8.0.1)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=4.5.1->aitextgen) (1.0.1)\r\n",
      "Building wheels for collected packages: aitextgen, fire\r\n",
      "  Building wheel for aitextgen (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for aitextgen: filename=aitextgen-0.5.2-py3-none-any.whl size=575905 sha256=88a58b2dfafaceaa9dda4c62388866cd6b4c1a2651eb1367669731c6b208b0e0\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/83/e2/74/46c887b0989a51a7acee0c09551a3ae9d34b939fb4bea404a0\r\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=15b51bf835fcde6ac488093d931ff5ee38ac1bb12176a9b401cf10dca3209210\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\r\n",
      "Successfully built aitextgen fire\r\n",
      "Installing collected packages: fire, aitextgen\r\n",
      "Successfully installed aitextgen-0.5.2 fire-0.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1157c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:27:53.433490Z",
     "iopub.status.busy": "2021-11-29T06:27:53.432608Z",
     "iopub.status.idle": "2021-11-29T06:28:00.232599Z",
     "shell.execute_reply": "2021-11-29T06:28:00.231862Z",
     "shell.execute_reply.started": "2021-11-29T06:23:50.661820Z"
    },
    "id": "KBkpRgBCBS2_",
    "outputId": "629b3068-c9a6-407a-ea09-98773a0c50bf",
    "papermill": {
     "duration": 6.824803,
     "end_time": "2021-11-29T06:28:00.232731",
     "exception": false,
     "start_time": "2021-11-29T06:27:53.407928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "246aa044",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:28:00.274217Z",
     "iopub.status.busy": "2021-11-29T06:28:00.272509Z",
     "iopub.status.idle": "2021-11-29T06:28:00.274830Z",
     "shell.execute_reply": "2021-11-29T06:28:00.275306Z",
     "shell.execute_reply.started": "2021-11-29T06:23:57.543707Z"
    },
    "papermill": {
     "duration": 0.02539,
     "end_time": "2021-11-29T06:28:00.275454",
     "exception": false,
     "start_time": "2021-11-29T06:28:00.250064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1854f4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:28:00.314142Z",
     "iopub.status.busy": "2021-11-29T06:28:00.313588Z",
     "iopub.status.idle": "2021-11-29T06:28:07.434738Z",
     "shell.execute_reply": "2021-11-29T06:28:07.434252Z",
     "shell.execute_reply.started": "2021-11-29T06:23:57.553070Z"
    },
    "papermill": {
     "duration": 7.141887,
     "end_time": "2021-11-29T06:28:07.434868",
     "exception": false,
     "start_time": "2021-11-29T06:28:00.292981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai = aitextgen(model_folder=\"../input/gpt-code-t1-model-v1/gpt_code_task1_model_v1\",\n",
    "               tokenizer_file=\"../input/gpt-code-t1-model-v1/gpt_code_task1_model_v1/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ef2c8",
   "metadata": {
    "id": "LdpZQXknFNY3",
    "papermill": {
     "duration": 0.016333,
     "end_time": "2021-11-29T06:28:07.468450",
     "exception": false,
     "start_time": "2021-11-29T06:28:07.452117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train GPT-2\n",
    "\n",
    "Important parameters for `train()`:\n",
    "\n",
    "- **`line_by_line`**: Set this to `True` if the input text file is a single-column CSV, with one record per row. aitextgen will automatically process it optimally.\n",
    "- **`from_cache`**: If you compressed your dataset locally (as noted in the previous section) and are using that cache file, set this to `True`.\n",
    "- **`num_steps`**: Number of steps to train the model for.\n",
    "- **`generate_every`**: Interval of steps to generate example text from the model; good for qualitatively validating training.\n",
    "- **`save_every`**: Interval of steps to save the model: the model will be saved in the VM to `/trained_model`.\n",
    "- **`save_gdrive`**: Set this to `True` to copy the model to a unique folder in your Google Drive, if you have mounted it in the earlier cells\n",
    "- **`batch_size`**: Batch size of the model training; setting it too high will cause the GPU to go OOM. _Unlike finetuning, since you are using a small model, you can massively increase the batch size to normalize the training_.\n",
    "- **`fp16`**: Enables half-precision training for faster/more memory-efficient training. Only works on a T4 or V100 GPU.\n",
    "\n",
    "Here are other important parameters for `train()` that are useful but you likely do not need to change.\n",
    "\n",
    "- **`learning_rate`**: Learning rate of the model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd9dac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:28:07.506238Z",
     "iopub.status.busy": "2021-11-29T06:28:07.505537Z",
     "iopub.status.idle": "2021-11-29T11:25:38.467823Z",
     "shell.execute_reply": "2021-11-29T11:25:38.469255Z",
     "shell.execute_reply.started": "2021-11-28T14:33:26.541583Z"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "18a0eb53-7de1-4a2f-c66e-fa4ac911530b",
    "papermill": {
     "duration": 17850.984661,
     "end_time": "2021-11-29T11:25:38.469509",
     "exception": false,
     "start_time": "2021-11-29T06:28:07.484848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4f5ddd13bf401ca6c1bbd2f32494d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265734 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5477f76c5c6b4965bcd11c62450821b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Forward containing a topic of a topic. def topic(self, topic_id, topic_id, region):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        # Map a topic in topic in topic.\n",
      "        topic_id = self.topic_id\n",
      "        self.topic_id = topic_id\n",
      "        self.topic_id = topic_id\n",
      "        self.topic_id = topic_id\n",
      "        self.topic_id = topic_id\n",
      "        self.topic_id = self.topic_id\n",
      "        self.topic_id = topic_id\n",
      "==========\n",
      "\u001b[1m2,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Return the status of the targets, as a string,  so the last location, or an invoked string, if the field is not found. def _get_targets(self, target_name, specification, specification_name, specification_name):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if not isinstance(specification_name, string_types.string_types):\n",
      "            raise TypeError(\"Unknown type '{}'\".format(specification_name))\n",
      "\n",
      "        if isinstance(target_name, string_types.Iterable):\n",
      "            return target_name\n",
      "\n",
      "        if isinstance(target_name, string_types.Iterable):\n",
      "            for specification_name in specification_name.split(','):\n",
      "                if specification_name not in target_name.split('\n",
      "==========\n",
      "\u001b[1m3,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Deletes the does not have one of the same as a dict with an API. def _delete_one_does(self):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if not self.delete:\n",
      "            self.delete = None\n",
      "        self.delete = {}\n",
      "        self.delete_one_does = {}\n",
      "==========\n",
      "\u001b[1m4,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "_table_name = get_table_name())\n",
      "        if not self.is_conf:\n",
      "            return None\n",
      "\n",
      "        # First it's not on a json file\n",
      "        # If the file is specified, this is just just something without\n",
      "        # If the file is not in the Json file\n",
      "        # then the file is specified, then the file is the json file\n",
      "        if not self.is_conf:\n",
      "            return None\n",
      "\n",
      "        # Get the Json file\n",
      "        file_name = os.path.join(os.path.dirname(os.path.isfile(file)))\n",
      "        if not os.path.isdir(file_name):\n",
      "            return None\n",
      "\n",
      "        # Use the file to Json file\n",
      "        if file_name:\n",
      "            file_name = os.path.abspath(file_name)\n",
      "\n",
      "        # Attempt to get the file to the Json\n",
      "==========\n",
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Convenius of days. def check_tays(cls, seconvention):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if not seconvention:\n",
      "            return False\n",
      "        else:\n",
      "            if seconvention.is_primary:\n",
      "                return False\n",
      "            return seconvention.is_primary(seconvention)\n",
      "\n",
      "        return False\n",
      "==========\n",
      "\u001b[1m6,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m6,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Returns all the form of the form reference. def _list_form(self):\n",
      "        \"\"\"\n",
      "\n",
      "        \"\"\"\n",
      "        form = self.form\n",
      "\n",
      "        if reference and reference and reference!= self._form:\n",
      "            return form\n",
      "\n",
      "        return self._list_form\n",
      "==========\n",
      "\u001b[1m7,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m7,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Signal helps. def signal_signal_hps(self, idxs, yaml):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        self.model = self.hpm1.signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_sig\n",
      "==========\n",
      "\u001b[1m8,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m8,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Return value from a GCSMAPIC. def get_value(self, value):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        return self._get_value_from_value(value)\n",
      "==========\n",
      "\u001b[1m9,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m9,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Start the scope, if the key is defined, or the database, overwrite, and convert it to the client and condition def client_session(self, client):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if client is not None:\n",
      "            try:\n",
      "                # Session is the scope\n",
      "                client.session = self.signed_client\n",
      "            except FileNotFound:\n",
      "                self.session_dir = None\n",
      "            try:\n",
      "                self.scope = self.session_dir\n",
      "                self.scope = self.signed_scope\n",
      "            except KeyboardInterrupt:\n",
      "                self.session_dir = self.signed_scope\n",
      "            self.session_dir = None\n",
      "        else:\n",
      "            self.session_dir = None\n",
      "==========\n",
      "\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate:\n",
      "            metadata.get_metadata.update(self.metadata.get(metadata, {}))\n",
      "==========\n",
      "\u001b[1m11,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m11,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: This is a removed rather than the \"\n",
      "        \"success\" in this torch to use this, also \" \"\n",
      "        \"can call connection\":\n",
      "        \"success\": self._get_success(), \"deleted\": self._config.deleted(\n",
      "            self.config.options.delete_connection_args(\"auth\"))\n",
      "        self._config.valid_connection()\n",
      "        self._remove_connection_args(\n",
      "            self._config.on_connection_args(\"auth\"))\n",
      "        return State.Handler(\n",
      "            self._session, self._request_url, \n",
      "            self.config.options,\n",
      "        )\n",
      "==========\n",
      "\u001b[1m12,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m12,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Go chunked chunks of two chunks def _chunked_chunks(self, chunks, chunks, chunks, chunks, alignoring):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    tw_chunks = chunks\n",
      "    tw_predicate = None\n",
      "    stredicate = \"\\x0\"\n",
      "    for chunk in chunks:\n",
      "      chunk_chunk_list = []\n",
      "      for chunk in chunks:\n",
      "        if chunk.chunk_list[chunk.chunk_list[chunk]]:\n",
      "          continue\n",
      "      tw_chunk_list.append(chunk)\n",
      "      else:\n",
      "        stredicate = None\n",
      "        for chunk in chunk_list:\n",
      "          tw_chunks.append(chunk)\n",
      "    return tw_chunks\n",
      "==========\n",
      "\u001b[1m13,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m13,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Add an item to the tag. def get_tags(self, tag):\n",
      "        \"\"\n",
      "        tag.tags = tag.tags\n",
      "\n",
      "        # if there is an item in the tag. Tag, try to run the tag\n",
      "        # and perform the tag.\n",
      "        if tag.tags is None:\n",
      "            return tag\n",
      "\n",
      "        # rollbacks the tag\n",
      "        if tag.tags == user_agent:\n",
      "            tag.tags = tag.tags\n",
      "\n",
      "        # rollback\n",
      "        tag.tags = tag.tags\n",
      "==========\n",
      "\u001b[1m14,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m14,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Determine whether for the module is registered. def _set_module(self, version):\n",
      "        \"\"\"\"\"\"\n",
      "        if version.startswith(\"$REGEX\"):\n",
      "            if vars(\"$REGEX\"):\n",
      "                vars(self, version)\n",
      "            else:\n",
      "                return False\n",
      "\n",
      "        if \"$REGEX\" in  # pragma: no cover\n",
      "            if vars(self, version):\n",
      "                return False\n",
      "\n",
      "        return 0\n",
      "==========\n",
      "\u001b[1m15,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m15,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Reads a new performance reference of the area in the performance reference. def read(self):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        self.read_reference(self.reference, self.reference, self.reference)\n",
      "==========\n",
      "\u001b[1m16,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m16,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Looks for the record. def _get_record_record(self, record, record):\n",
      "        \"\"\"\"\"\"\n",
      "        record_id = record_id.record_id\n",
      "        if record_id:\n",
      "            self._record_record_record = record_id\n",
      "            self._record_record = record\n",
      "            self._add_record(record, self._record_record, record)\n",
      "            return record\n",
      "        raise self.RecordRecordRecordRecordRecationData(record)\n",
      "==========\n",
      "\u001b[1m17,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m17,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Boolean cache cache for a queryset def boolean(obj, offset):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    if not isinstance(obj, (np.float, np.float)):\n",
      "        raise TypeError(\"object must be a tuple\", obj)\n",
      "    gene = obj.gene\n",
      "    gene = obj.gene\n",
      "    inter = gene.interterpolate(reverse=interpolations.Gene)\n",
      "    spec = obj.spec\n",
      "    interpolations = gene.interpolations\n",
      "    interpolations = gene.interpolations\n",
      "    gene = obj.gene\n",
      "    gene.gene\n",
      "    idx = gene.gene\n",
      "    if idx:\n",
      "        gene.gene = gene.gene\n",
      "    gene.gene = gene.gene\n",
      "    g\n",
      "==========\n",
      "\u001b[1m18,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m18,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Gets an instance of software def get_instance_instance(self):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if self.instance is None:\n",
      "            return None\n",
      "        if self.instance is None:\n",
      "            return None\n",
      "        if self.instance is None:\n",
      "            return self._instance\n",
      "        if self.instance is None:\n",
      "            return None\n",
      "        if self.instance is None:\n",
      "            return self._instance\n",
      "        if self.instance is not None:\n",
      "            return self._instance\n",
      "        if self.instance is None:\n",
      "            return self._instance\n",
      "        if self.instance is not None:\n",
      "            return self._instance\n",
      "        if self.instance is not None:\n",
      "            return self._instance\n",
      "        return self._instance\n",
      "==========\n",
      "\u001b[1m19,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m19,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Logs the model from the server. async def log_spec(self, server):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        sph_msg_spec = self._server.log_spec\n",
      "        if not self.log_spec:\n",
      "            return\n",
      "        # Verify that model requires this state\n",
      "        async definition = self.log_spec(server)\n",
      "\n",
      "        # Log threads\n",
      "        LOG.info('Loging for log-specs for log-specs..  Log.')\n",
      "        self.log_spec = Log.rough_loop.get_log_spec_log_spec(server)\n",
      "        # Setup log specs\n",
      "        self._log_spec.log_spec.setup_log_spec(self.log_spec)\n",
      "        self._log_spec.log\n",
      "==========\n",
      "\u001b[1m20,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m20,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Checks that ``value` is a ``node``. def check_node(value):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    if isinstance(value, list):\n",
      "        for node in node.node_nodes:\n",
      "            if node.name not in (str, type(value)):\n",
      "                raise TypeError(\n",
      "                    \"Node %s is not a valid node, got \"\n",
      "                    \"value\" % type(node.name))\n",
      "    if isinstance(value, Attribute):\n",
      "        return value\n",
      "    return True\n",
      "==========\n",
      "\u001b[1m21,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m21,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Get the link and add the style by its topic. def get_link(self):\n",
      "        '''\n",
      "        \n",
      "        '''\n",
      "        link = self.links['link'] + [line -1]\n",
      "        return self._Get([self._Get(self._Get(self._Get(line)) for line in link])\n",
      "==========\n",
      "\u001b[1m22,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m22,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Strip an leading background with the given leading def strip_leading(leading: Float):\n",
      "    \"\"\"\"\"\"\n",
      "    if leading!= 0:\n",
      "        leading = 0\n",
      "    last = last.rstrip(\"\\t\")\n",
      "    leading = 0\n",
      "    last.rstrip(\"   (\" + last) + \")\"\n",
      "    leading = 0\n",
      "    last = last.rstrip(\" \")\n",
      "    last.rstrip(\"  \" + last) + \" (\" + last) + \" \" + last + \" (\" + last) + \" (\" + last) + \" (\" + last) + \" (\" + last) + \" (\" + last) + \" (\" + last) + \" (\" + last) + \n",
      "==========\n",
      "\u001b[1m23,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m23,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Return a list of query sets def get_querysets(self):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if self.querysets:\n",
      "            return self.querysets[self.querysets[self.querysets[self.queryset]]]\n",
      "        return self\n",
      "==========\n",
      "\u001b[1m24,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m24,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Return the most required for a given list of query required.  If there is a no required for a given list of query required. def query(self, required_query=None, **kwargs):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if self.session.match(self.query) is None:\n",
      "            return\n",
      "\n",
      "        # If there is no longer something to work again\n",
      "        if not self.is_required(self.query) and self.session.is_required:\n",
      "            return\n",
      "\n",
      "        # Return the next non-required for a specified previron\n",
      "        # point\n",
      "        if self.session.is_required(self.query) and self.session.is_required(self.query) and self.session.is_required(self\n",
      "==========\n",
      "\u001b[1m25,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m25,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Decorates the encodes def encode(self):\n",
      "        \"\"\"  \"\"\"\n",
      "        net = ''.join(self.encode)\n",
      "        net = None\n",
      "        if len(net) - net is None:\n",
      "            net = self.mask.decode(\"wb\")\n",
      "        return net\n",
      "==========\n",
      "\u001b[1m26,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m26,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "        log.warning(\"Search for another check for another search for a specified address: %s\", address)\n",
      "        return None\n",
      "==========\n",
      "\u001b[1m27,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m27,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: This is a dict. def is_dict(self, limits):\n",
      "        \"\"\"\"\"\"\n",
      "        if isinstance(limits, dict):\n",
      "            return []\n",
      "        if isinstance(limits, dict):\n",
      "            return list(map(lambda x: x, limits))\n",
      "        if isinstance(limits, dict):\n",
      "            return [mapping_mappings[x] for x in limits]\n",
      "        else:\n",
      "            raise TypeError(\"Link is not an integer\", \"remaining\")\n",
      "==========\n",
      "\u001b[1m28,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m28,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Returns the first query. def expire_query(self):\n",
      "        \"\"\"\"\"\"\n",
      "        query = {\n",
      "            '$TemporaryDate': self.beare_date,\n",
      "            'BeareResponse': self.beare_date,\n",
      "        }\n",
      "\n",
      "        url = URL_REQUEST.format(url)\n",
      "        data = {\n",
      "            'query': url,\n",
      "            'query': data}\n",
      "\n",
      "        return self.get_url(url)\n",
      "==========\n",
      "\u001b[1m29,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m29,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Display IPv4-server helperflow. def import_ipv4_id(ipv4_id, schema=None):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    ipv4_id = Ipv4IPv4IPv4Ipv4(ipv4_id)\n",
      "    if ipv4_id == ipv4_id:\n",
      "        ipv4_id = Ipv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IPv4IP\n",
      "==========\n",
      "\u001b[1m30,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m30,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Parse filters of an robuted view. def target_auth_view(self, auth_view, query, query, query):\n",
      "        \"\"\"\"\"\"\n",
      "        if query.is_robuted():\n",
      "            self.target_auth_view = query\n",
      "        else:\n",
      "            self.target_auth_view = query\n",
      "        # We've always have available, the view is not available\n",
      "        self.view_view = query\n",
      "        # Only to filter the query or query\n",
      "        for target_auth_view in self.target_auth_view:\n",
      "            if target_auth_view and query is not None:\n",
      "                self.target_auth_view = query\n",
      "                self.target_auth_view = query\n",
      "        # If the view was filtered, the\n",
      "==========\n",
      "\u001b[1m31,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m31,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Reads the doc ``file_size``, always transfering to the `file_size``. def do_read_file(filename, transfera, transfera=None):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    size = file_size\n",
      "\n",
      "    if size:\n",
      "        size = file_size\n",
      "    if transfera:\n",
      "        transfera = transfera\n",
      "\n",
      "    if transfera:\n",
      "        transfera = file_size\n",
      "\n",
      "    for size in transfera:\n",
      "        func = file_size\n",
      "\n",
      "    if transfera is not None:\n",
      "        if size is 0:\n",
      "            if size is not None:\n",
      "                transfera = transfera\n",
      "                transfera = check_simple(\n",
      "                    transfera, transfera)\n",
      "\n",
      "\n",
      "==========\n",
      "\u001b[1m32,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m32,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: The function to add an view. def add_view(self, view, view):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        self.view = view\n",
      "\n",
      "        self.view_meta.add_view(view)\n",
      "\n",
      "        # Need to generate an view\n",
      "        model = self\n",
      "        if model:\n",
      "            self.view_meta.add_view(view)\n",
      "            self.view_meta.add_view(view)\n",
      "            model.add_view(view)\n",
      "\n",
      "        return model\n",
      "==========\n",
      "\u001b[1m33,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m33,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ", match):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    no_google_mode = None\n",
      "    # Return the mode\n",
      "    if match:\n",
      "        if match:\n",
      "            if match:\n",
      "                return __import__(mode.text)\n",
      "        elif match:\n",
      "            return __import__(mode.text, match)\n",
      "    return __import__(mode.text, mode.text)\n",
      "==========\n",
      "\u001b[1m34,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m34,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "ining state def state(self, state, state, state, state_name):\n",
      "        \"\"\"\"\"\"\n",
      "        msg = 'There was no state names specified by the given state.'\n",
      "        if state.state.type == \"great\":\n",
      "            msg = 'The state names specified by the given app'\n",
      "            msg +='was no state names specified by the given app'\n",
      "            msg +='was no state names specified by the given app'\n",
      "            msg +='was no state names specified by the given app'\n",
      "            msg += 'was no state names specified by the given app'\n",
      "            state_name = 'great Multiple state names s\n",
      "==========\n",
      "\u001b[1m35,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m35,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Add this layer to the layer. Handler. def add_layer(layer_layer, layer, allow_command, layer, n, layer_name):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    image = layer_layer.layer_layer\n",
      "    command = commands[0]\n",
      "    create_changes_from_command(layer, layer, n, layer, n, layer, layer, n)\n",
      "    layer.add(layer, layer, n, layer, n, layer), n, layer_layer, n, layer, n)\n",
      "    layer.add(layer)\n",
      "    commands[-layer] = commands[-layer]\n",
      "    layer.add(layer, layer, n, layer, n, layer, n, layer, n, layer, n, layer,\n",
      "==========\n",
      "\u001b[1m36,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m36,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Return the content of the given cache with a given time in ``to```. def _cache_content(self, to):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        if to is None and len(to) == 2:\n",
      "            return self._cache\n",
      "        elif len(to) == 2:\n",
      "            return self._cache\n",
      "        else:\n",
      "            return self._cache\n",
      "==========\n",
      "\u001b[1m37,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m37,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Loads the ``file`` to a string. def load_file(filename):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    if os.path.isfile(filename):\n",
      "        raise PathError('Loading file from file and is not generated.')\n",
      "    return filename\n",
      "==========\n",
      "\u001b[1m38,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m38,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Gets the given query parameters. def get_query_params(self, query_params):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        params = params.get('params', {})\n",
      "        if hasattr(q, \"query_params\"):\n",
      "            params['query_params'] = query_params\n",
      "        return params\n",
      "==========\n",
      "\u001b[1m39,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m39,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Return the tile of the GETI instance to the    the GETI class. def get_tile(self, tile, tile_name, layout=None):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        tile = self.tiles[tile_name]\n",
      "        tile_name = tile_name\n",
      "        if tile_name in self._tiles:\n",
      "            raise ValueError(\n",
      "                'This is no tile for GETI named: %s' % tile_name\n",
      "                )\n",
      "\n",
      "        self._tiles[tile_name] = tile_name\n",
      "\n",
      "        tile_name, tile_name = self._tiles[tile_name]\n",
      "        self._tiles[tile_name] = tile_name\n",
      "\n",
      "        return tile\n",
      "==========\n",
      "\u001b[1m40,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m40,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Compute whose spaices. def calculate_and_whose_spice(self, spa_id, spa_id, initial_id,\n",
      "                                     initial_id,\n",
      "                                     spa_id, service,\n",
      "                                     initial_id,\n",
      "                                     initial_id,\n",
      "                                     initial_id,\n",
      "                                     initial_id,\n",
      "                                     determinator):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        # We cannot support for other service ids.\n",
      "        calculate_id_or_errors(initial_id, initial_id, spa_id,\n",
      "                                     initial_id, initial_id,\n",
      "                                     initial_id,\n",
      "                                     initial_id,\n",
      "                                     initial_id,\n",
      "                                     initial_id,\n",
      "                                     ini\n",
      "==========\n",
      "\u001b[1m41,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m41,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Returns the Maps only points for a one-direct Map. def _get_maps_from_maps(self, maps, points):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "\n",
      "        return maps[self.get_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_maps_from_m\n",
      "==========\n",
      "\u001b[1m42,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m42,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Sets the targets for the base. def target_base(self):\n",
      "        \"\"\"\"\"\"\n",
      "        self.targets = []\n",
      "        self.targets = []\n",
      "        joke_bs = []\n",
      "        for targets, names in self.targets:\n",
      "            for select, target in self.targets:\n",
      "                select.dp_targets(select, target)\n",
      "==========\n",
      "\u001b[1m43,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m43,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "s=self.even_value\n",
      "        data_step=data_step,\n",
      "        step=self.step)\n",
      "        self._data_step = self._data_step.pop(data_step)\n",
      "        self._data_step = data_step\n",
      "        self._data_step = data_step\n",
      "\n",
      "        self._data_step.pop(self._data_step)\n",
      "        self._data_step = data_step\n",
      "==========\n",
      "\u001b[1m44,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m44,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Loads a JSON version string for specific file. def load_from_file(file_name, filename, content_path, content_path, content_path, content_path=content_path, content_path=content_path):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    # Get JSON file name from JSON file name, content_path=content_path, content_path=content_path\n",
      "    content_path = os.path.join(os.path.dirname(file_name) / content_path)\n",
      "    jsON_path = os.path.join(jsON_path, content_path)\n",
      "    jsON_path = os.path.join(jsON_path, content_path)\n",
      "    jsON_path = os.path.join(jsON_path, content_path)\n",
      "    jsON_path = os.path.join(jsON_path\n",
      "==========\n",
      "\u001b[1m45,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m45,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Changes the given edge from the cache def _update_cache(self, dample):\n",
      "        \"\"\"\"\"\"\n",
      "        self._set_edge(self._cache_id, dample)\n",
      "==========\n",
      "\u001b[1m46,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m46,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Convert an image to images. def create(img_to_axis=None, axis=None):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    if axis is None:\n",
      "        axis = get_to_bin_normalize(img_to_bin_normalize)\n",
      "    axis = get_to_axis(img_to_bin_normalize)\n",
      "    if axis is None:\n",
      "        axis = get_to_axis(img_to_bin_normalize)\n",
      "    if axis is None:\n",
      "        axis = get_to_bin_normalize(img_to_bin_normalize)\n",
      "    if axis is None:\n",
      "        axis = get_to_bin_normalize(img_to_bin_normalize)\n",
      "    if axis is None:\n",
      "        axis = get_\n",
      "==========\n",
      "\u001b[1m47,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m47,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ".op.add_head(\n",
      "            'op', root, base_url + base_url + base_url + '/')\n",
      "        )\n",
      "    )\n",
      "\n",
      "    url = '/v1/file/{}/open/v1/{}/file/{}/file'.format(file_url + '/v1/file/file/file/{}'.format(file_url + '/v2/file/file/file/{}/file/file/file'.format(file_url + '/v1/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file/file\n",
      "==========\n",
      "\u001b[1m48,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m48,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Create an output file. def CreateAttributeFile(filepath):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    # Create an output file.\n",
      "    filename = os.path.join(filepath, os.path.abspath(filepath))\n",
      "    if os.path.exists(path):\n",
      "        # Create an input file.\n",
      "        output_file = open(path, 'rb')\n",
      "        output_file.close()\n",
      "    else:\n",
      "        # Write the output file.\n",
      "        output_file.close()\n",
      "        output_file.close()\n",
      "==========\n",
      "\u001b[1m49,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m49,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "ge_default_stdout. def get_stdout_fcp_definition(self, tex_dep_default):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        stdout_fcp_definition = None\n",
      "        pypp_definition_func = None\n",
      "        pypp_definition_func = None\n",
      "        if 'posites' in tex_dep_definition_func:\n",
      "            pypp_definition_func = None\n",
      "        elif 'posites' in tex_dep_definition_func:\n",
      "            pyp_definition_func = None\n",
      "            for pypp_definition_func in self.posites:\n",
      "                pypp_definition_func(tex_dep_definition_func)\n",
      "        else:\n",
      "            pypp_definition_func = None\n",
      "            pypp_defini\n",
      "==========\n",
      "\u001b[1m50,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m50,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Make a single Modification format for the given tabular version. def get_modification_format(tabular_version):\n",
      "    \"\"\"\"\"\"\n",
      "    if tabular_version == \"GivenTab \":\n",
      "        return \"Unexpected version\"\n",
      "\n",
      "    supported_format_format = posix.format_format(tabular_version=tabular_version)\n",
      "    return \"Input\".join(supported_format)\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "ai.train('../input/idl-project-code-encoder-set/encoder_docstring_to_code_train.csv',\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=50_000,\n",
    "         generate_every=1_000,\n",
    "         save_every=1_000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         batch_size=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93068c32",
   "metadata": {
    "papermill": {
     "duration": 0.096725,
     "end_time": "2021-11-29T11:25:38.661819",
     "exception": false,
     "start_time": "2021-11-29T11:25:38.565094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48d10cdf",
   "metadata": {
    "id": "pel-uBULXO2L",
    "papermill": {
     "duration": 0.092382,
     "end_time": "2021-11-29T11:25:38.845239",
     "exception": false,
     "start_time": "2021-11-29T11:25:38.752857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Load a Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654d54a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T21:35:56.672341Z",
     "iopub.status.busy": "2021-11-27T21:35:56.671546Z",
     "iopub.status.idle": "2021-11-27T21:35:59.547952Z",
     "shell.execute_reply": "2021-11-27T21:35:59.546868Z",
     "shell.execute_reply.started": "2021-11-27T21:35:56.672307Z"
    },
    "papermill": {
     "duration": 0.09037,
     "end_time": "2021-11-29T11:25:39.025902",
     "exception": false,
     "start_time": "2021-11-29T11:25:38.935532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ai = aitextgen(model_folder=\"../input/finetuned-gpt/trained_model\",\n",
    "               tokenizer_file=\"../input/model-tuned/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc6a05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:24:41.195071Z",
     "iopub.status.busy": "2021-11-29T06:24:41.194781Z",
     "iopub.status.idle": "2021-11-29T06:24:41.465190Z",
     "shell.execute_reply": "2021-11-29T06:24:41.464185Z",
     "shell.execute_reply.started": "2021-11-29T06:24:41.195037Z"
    },
    "papermill": {
     "duration": 0.055137,
     "end_time": "2021-11-29T11:25:39.147974",
     "exception": false,
     "start_time": "2021-11-29T11:25:39.092837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../input/idl-project-code-encoder-set/encoder_docstring_to_code_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45862403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:24:45.354781Z",
     "iopub.status.busy": "2021-11-29T06:24:45.354219Z",
     "iopub.status.idle": "2021-11-29T06:24:45.367218Z",
     "shell.execute_reply": "2021-11-29T06:24:45.366205Z",
     "shell.execute_reply.started": "2021-11-29T06:24:45.354740Z"
    },
    "papermill": {
     "duration": 0.055174,
     "end_time": "2021-11-29T11:25:39.258906",
     "exception": false,
     "start_time": "2021-11-29T11:25:39.203732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "i = 100\n",
    "string = df.iloc[i]['input'][:df.iloc[i]['input'].index('def')]\n",
    "code = df.iloc[i]['input'][df.iloc[i]['input'].index('def'):]\n",
    "\n",
    "print(f'String: {string}')\n",
    "print()\n",
    "print(f'Code: {code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46b8fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:25:58.108060Z",
     "iopub.status.busy": "2021-11-29T06:25:58.107773Z",
     "iopub.status.idle": "2021-11-29T06:26:03.938527Z",
     "shell.execute_reply": "2021-11-29T06:26:03.937692Z",
     "shell.execute_reply.started": "2021-11-29T06:25:58.108024Z"
    },
    "id": "4RNY6RBI9LmL",
    "outputId": "8579ed7e-14c8-4a76-ecad-ce7acd13b612",
    "papermill": {
     "duration": 0.055618,
     "end_time": "2021-11-29T11:25:39.370161",
     "exception": false,
     "start_time": "2021-11-29T11:25:39.314543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ai.generate(max_length = 512, \n",
    "            prompt = string, \n",
    "            top_k = 100, \n",
    "            top_p  = 0.9, \n",
    "            temperature = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6344f29",
   "metadata": {
    "papermill": {
     "duration": 0.055429,
     "end_time": "2021-11-29T11:25:39.480807",
     "exception": false,
     "start_time": "2021-11-29T11:25:39.425378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaddbf0e",
   "metadata": {
    "papermill": {
     "duration": 0.055405,
     "end_time": "2021-11-29T11:25:39.591906",
     "exception": false,
     "start_time": "2021-11-29T11:25:39.536501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17890.091964,
   "end_time": "2021-11-29T11:25:42.387298",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-29T06:27:32.295334",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00dce96061414482a880bb9671c21d02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "06736a466f554853be09c506d246fdde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1af7a49433e44abe9cf62c46a6f0f5f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "21316954f27f4ca9bb2e495935d7ad1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48446c50b8c94721adce424f0551f3f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_21316954f27f4ca9bb2e495935d7ad1d",
       "max": 265734.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fe6356f2c91b490fa49844d256a486c5",
       "value": 265734.0
      }
     },
     "4e4b21ea4f6f42eea0be19239a2e869f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53e8c10ba8eb456799890a7eaf4af4ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5477f76c5c6b4965bcd11c62450821b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_593e5b934e474370b878176ee5353b7a",
        "IPY_MODEL_83d0262f30f348e084702bc8dff9ec61",
        "IPY_MODEL_d780418b079f46adb5829ba126128cd9"
       ],
       "layout": "IPY_MODEL_fc95c817e604414aaff2560091a36e82"
      }
     },
     "566f791220b74cd1acda8aab1d513a50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "593e5b934e474370b878176ee5353b7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4e4b21ea4f6f42eea0be19239a2e869f",
       "placeholder": "​",
       "style": "IPY_MODEL_06736a466f554853be09c506d246fdde",
       "value": "Loss: 1.480 — Avg: 1.412 — GPU Mem: 13597 MB: 100%"
      }
     },
     "83d0262f30f348e084702bc8dff9ec61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e98dec44724f47be8b61e4558f1fa1e6",
       "max": 50000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ada96a23ea3c47a48ea12b66ff6fbc88",
       "value": 50000.0
      }
     },
     "88ae1922e8c94ff593fa42f53874e228": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "9693db1d85e14d7380df2e20f0fa3cd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_566f791220b74cd1acda8aab1d513a50",
       "placeholder": "​",
       "style": "IPY_MODEL_1af7a49433e44abe9cf62c46a6f0f5f0",
       "value": " 265734/265734 [02:44&lt;00:00, 1612.98it/s]"
      }
     },
     "9b4f5ddd13bf401ca6c1bbd2f32494d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9c1f432d7dc14260ad516b1b91b76636",
        "IPY_MODEL_48446c50b8c94721adce424f0551f3f6",
        "IPY_MODEL_9693db1d85e14d7380df2e20f0fa3cd7"
       ],
       "layout": "IPY_MODEL_88ae1922e8c94ff593fa42f53874e228"
      }
     },
     "9c1f432d7dc14260ad516b1b91b76636": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cbc9e932849640cd854bc50ed5ca1bae",
       "placeholder": "​",
       "style": "IPY_MODEL_fea09d8269e04d958a84c927b232f8ed",
       "value": "100%"
      }
     },
     "ada96a23ea3c47a48ea12b66ff6fbc88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cbc9e932849640cd854bc50ed5ca1bae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d780418b079f46adb5829ba126128cd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_00dce96061414482a880bb9671c21d02",
       "placeholder": "​",
       "style": "IPY_MODEL_53e8c10ba8eb456799890a7eaf4af4ce",
       "value": " 50000/50000 [4:54:36&lt;00:00,  2.83it/s]"
      }
     },
     "e98dec44724f47be8b61e4558f1fa1e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc95c817e604414aaff2560091a36e82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "fe6356f2c91b490fa49844d256a486c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fea09d8269e04d958a84c927b232f8ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
