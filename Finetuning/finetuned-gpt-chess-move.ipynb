{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T08:54:41.223536Z",
     "iopub.status.busy": "2021-11-27T08:54:41.223182Z",
     "iopub.status.idle": "2021-11-27T08:54:53.423622Z",
     "shell.execute_reply": "2021-11-27T08:54:53.422866Z",
     "shell.execute_reply.started": "2021-11-27T08:54:41.223425Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T08:54:55.386459Z",
     "iopub.status.busy": "2021-11-27T08:54:55.385680Z",
     "iopub.status.idle": "2021-11-27T08:55:02.352754Z",
     "shell.execute_reply": "2021-11-27T08:55:02.352019Z",
     "shell.execute_reply.started": "2021-11-27T08:54:55.386415Z"
    },
    "id": "KBkpRgBCBS2_",
    "outputId": "629b3068-c9a6-407a-ea09-98773a0c50bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T08:55:05.560899Z",
     "iopub.status.busy": "2021-11-27T08:55:05.560617Z",
     "iopub.status.idle": "2021-11-27T08:55:05.564825Z",
     "shell.execute_reply": "2021-11-27T08:55:05.563870Z",
     "shell.execute_reply.started": "2021-11-27T08:55:05.560867Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T14:26:14.279824Z",
     "iopub.status.busy": "2021-11-27T14:26:14.279349Z",
     "iopub.status.idle": "2021-11-27T14:26:14.375056Z",
     "shell.execute_reply": "2021-11-27T14:26:14.373707Z",
     "shell.execute_reply.started": "2021-11-27T14:26:14.279736Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai = aitextgen(model_folder=\"../input/model-tuned\",\n",
    "               tokenizer_file=\"../input/model-tuned/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T08:56:20.395870Z",
     "iopub.status.busy": "2021-11-27T08:56:20.395544Z",
     "iopub.status.idle": "2021-11-27T08:56:21.437111Z",
     "shell.execute_reply": "2021-11-27T08:56:21.436238Z",
     "shell.execute_reply.started": "2021-11-27T08:56:20.395829Z"
    }
   },
   "outputs": [],
   "source": [
    "ai.generate(max_length = 20, prompt = 'e4 c5', top_k = 40, top_p  = 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdpZQXknFNY3"
   },
   "source": [
    "## Train GPT-2\n",
    "\n",
    "Important parameters for `train()`:\n",
    "\n",
    "- **`line_by_line`**: Set this to `True` if the input text file is a single-column CSV, with one record per row. aitextgen will automatically process it optimally.\n",
    "- **`from_cache`**: If you compressed your dataset locally (as noted in the previous section) and are using that cache file, set this to `True`.\n",
    "- **`num_steps`**: Number of steps to train the model for.\n",
    "- **`generate_every`**: Interval of steps to generate example text from the model; good for qualitatively validating training.\n",
    "- **`save_every`**: Interval of steps to save the model: the model will be saved in the VM to `/trained_model`.\n",
    "- **`save_gdrive`**: Set this to `True` to copy the model to a unique folder in your Google Drive, if you have mounted it in the earlier cells\n",
    "- **`batch_size`**: Batch size of the model training; setting it too high will cause the GPU to go OOM. _Unlike finetuning, since you are using a small model, you can massively increase the batch size to normalize the training_.\n",
    "- **`fp16`**: Enables half-precision training for faster/more memory-efficient training. Only works on a T4 or V100 GPU.\n",
    "\n",
    "Here are other important parameters for `train()` that are useful but you likely do not need to change.\n",
    "\n",
    "- **`learning_rate`**: Learning rate of the model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T08:56:59.710524Z",
     "iopub.status.busy": "2021-11-27T08:56:59.709958Z",
     "iopub.status.idle": "2021-11-27T13:56:22.918982Z",
     "shell.execute_reply": "2021-11-27T13:56:22.917906Z",
     "shell.execute_reply.started": "2021-11-27T08:56:59.710485Z"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "18a0eb53-7de1-4a2f-c66e-fa4ac911530b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai.train('../input/finetuned-gpt-data/chess_finetuned/10.csv',\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=50_000,\n",
    "         generate_every=1_000,\n",
    "         save_every=1_000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         batch_size=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pel-uBULXO2L"
   },
   "source": [
    "\n",
    "## Load a Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = aitextgen(model_folder=\"trained_model\",\n",
    "               tokenizer_file=\"trained_model/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RNY6RBI9LmL",
    "outputId": "8579ed7e-14c8-4a76-ecad-ce7acd13b612"
   },
   "outputs": [],
   "source": [
    "ai.generate(max_length = 512, prompt = 'e4 : ', top_k = 100, top_p  = 0.9, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('chess_data/39.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
