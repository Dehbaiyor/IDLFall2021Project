{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KBkpRgBCBS2_",
    "outputId": "629b3068-c9a6-407a-ea09-98773a0c50bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarize: def sina_xml_to_url_list(xml_data):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl \n",
      "str->list  Convert XML to URL List.  From Biligrab.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('encoder_code_to_docstring_test.csv')\n",
    "#print(df['input'][0])\n",
    "print(df['input'][0][:275])\n",
    "print(df['input'][0][275:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai = aitextgen(model_folder=\"chess_pretrained_model\",\n",
    "               tokenizer_file=\"chess_pretrained_model/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1msummarize: def sina_xml_to_url_list(xml_data):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl \u001b[0m& (recurseString(dom, dom.docs()))\n"
     ]
    }
   ],
   "source": [
    "ai.generate(max_length = 512, prompt = df['input'][0][:275], top_k = 100, top_p  = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdpZQXknFNY3"
   },
   "source": [
    "## Train GPT-2\n",
    "\n",
    "Important parameters for `train()`:\n",
    "\n",
    "- **`line_by_line`**: Set this to `True` if the input text file is a single-column CSV, with one record per row. aitextgen will automatically process it optimally.\n",
    "- **`from_cache`**: If you compressed your dataset locally (as noted in the previous section) and are using that cache file, set this to `True`.\n",
    "- **`num_steps`**: Number of steps to train the model for.\n",
    "- **`generate_every`**: Interval of steps to generate example text from the model; good for qualitatively validating training.\n",
    "- **`save_every`**: Interval of steps to save the model: the model will be saved in the VM to `/trained_model`.\n",
    "- **`save_gdrive`**: Set this to `True` to copy the model to a unique folder in your Google Drive, if you have mounted it in the earlier cells\n",
    "- **`batch_size`**: Batch size of the model training; setting it too high will cause the GPU to go OOM. _Unlike finetuning, since you are using a small model, you can massively increase the batch size to normalize the training_.\n",
    "- **`fp16`**: Enables half-precision training for faster/more memory-efficient training. Only works on a T4 or V100 GPU.\n",
    "\n",
    "Here are other important parameters for `train()` that are useful but you likely do not need to change.\n",
    "\n",
    "- **`learning_rate`**: Learning rate of the model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-28T13:07:01.344218Z",
     "iopub.status.busy": "2021-11-28T13:07:01.343734Z",
     "iopub.status.idle": "2021-11-28T13:19:41.246535Z",
     "shell.execute_reply": "2021-11-28T13:19:41.245163Z",
     "shell.execute_reply.started": "2021-11-28T13:07:01.344189Z"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "18a0eb53-7de1-4a2f-c66e-fa4ac911530b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai.train('encoder_code_to_docstring_train.csv',\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=50_000,\n",
    "         generate_every=1_000,\n",
    "         save_every=1_000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         batch_size=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pel-uBULXO2L"
   },
   "source": [
    "\n",
    "## Load a Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T21:35:56.672341Z",
     "iopub.status.busy": "2021-11-27T21:35:56.671546Z",
     "iopub.status.idle": "2021-11-27T21:35:59.547952Z",
     "shell.execute_reply": "2021-11-27T21:35:59.546868Z",
     "shell.execute_reply.started": "2021-11-27T21:35:56.672307Z"
    }
   },
   "source": [
    "ai = aitextgen(model_folder=\"../input/finetuned-gpt/trained_model\",\n",
    "               tokenizer_file=\"../input/model-tuned/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T21:41:40.799568Z",
     "iopub.status.busy": "2021-11-27T21:41:40.798832Z",
     "iopub.status.idle": "2021-11-27T21:41:41.441898Z",
     "shell.execute_reply": "2021-11-27T21:41:41.440779Z",
     "shell.execute_reply.started": "2021-11-27T21:41:40.799522Z"
    },
    "id": "4RNY6RBI9LmL",
    "outputId": "8579ed7e-14c8-4a76-ecad-ce7acd13b612"
   },
   "source": [
    "ai.generate(max_length = 512, prompt = 'e4 : a4', top_k = 100, top_p  = 0.9, temperature = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
