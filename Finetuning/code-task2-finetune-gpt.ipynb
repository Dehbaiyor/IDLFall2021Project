{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe55d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:30:51.085552Z",
     "iopub.status.busy": "2021-11-29T06:30:51.084053Z",
     "iopub.status.idle": "2021-11-29T06:31:05.862366Z",
     "shell.execute_reply": "2021-11-29T06:31:05.861447Z",
     "shell.execute_reply.started": "2021-11-29T06:13:32.709730Z"
    },
    "papermill": {
     "duration": 14.793709,
     "end_time": "2021-11-29T06:31:05.862516",
     "exception": false,
     "start_time": "2021-11-29T06:30:51.068807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aitextgen\r\n",
      "  Downloading aitextgen-0.5.2.tar.gz (572 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 572 kB 288 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (4.5.1)\r\n",
      "Collecting fire>=0.3.0\r\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 87 kB 3.6 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: pytorch-lightning>=1.3.1 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (1.4.4)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (1.9.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fire>=0.3.0->aitextgen) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire>=0.3.0->aitextgen) (1.1.0)\r\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (2.6.0)\r\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (2021.10.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (3.10.0.2)\r\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.3.1)\r\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (5.4.1)\r\n",
      "Requirement already satisfied: torchmetrics>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.5.0)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (21.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (1.19.5)\r\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.18.2)\r\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.62.3)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.7.4.post0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.25.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->pytorch-lightning>=1.3.1->aitextgen) (2.4.7)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.19.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (2.0.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.8.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.3.4)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.14.0)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (58.0.4)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.6.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.35.0)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.38.1)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.37.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.6)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.7.2)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.2.2)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.8.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.8)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (4.0.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.10)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.26.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2021.10.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.1.1)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (0.0.46)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (2021.8.28)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (0.10.3)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (3.0.12)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.6.3)\r\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (5.1.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (21.2.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.5.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=4.5.1->aitextgen) (8.0.1)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=4.5.1->aitextgen) (1.0.1)\r\n",
      "Building wheels for collected packages: aitextgen, fire\r\n",
      "  Building wheel for aitextgen (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for aitextgen: filename=aitextgen-0.5.2-py3-none-any.whl size=575905 sha256=311b26563360676692f4efc825e14fa7a839c557dc623a9ccb0b5e571bc1f4e8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/83/e2/74/46c887b0989a51a7acee0c09551a3ae9d34b939fb4bea404a0\r\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=d3ed76a0ae8260de7e8a98ffec7dbd4157a83735903a417f95fddc34bb6fa954\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\r\n",
      "Successfully built aitextgen fire\r\n",
      "Installing collected packages: fire, aitextgen\r\n",
      "Successfully installed aitextgen-0.5.2 fire-0.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b887c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:31:05.904865Z",
     "iopub.status.busy": "2021-11-29T06:31:05.904088Z",
     "iopub.status.idle": "2021-11-29T06:31:12.817735Z",
     "shell.execute_reply": "2021-11-29T06:31:12.816752Z",
     "shell.execute_reply.started": "2021-11-29T06:13:49.963704Z"
    },
    "id": "KBkpRgBCBS2_",
    "outputId": "629b3068-c9a6-407a-ea09-98773a0c50bf",
    "papermill": {
     "duration": 6.935629,
     "end_time": "2021-11-29T06:31:12.817889",
     "exception": false,
     "start_time": "2021-11-29T06:31:05.882260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ea0bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:31:12.857967Z",
     "iopub.status.busy": "2021-11-29T06:31:12.857213Z",
     "iopub.status.idle": "2021-11-29T06:31:12.859685Z",
     "shell.execute_reply": "2021-11-29T06:31:12.860060Z",
     "shell.execute_reply.started": "2021-11-29T06:13:58.167612Z"
    },
    "papermill": {
     "duration": 0.024227,
     "end_time": "2021-11-29T06:31:12.860192",
     "exception": false,
     "start_time": "2021-11-29T06:31:12.835965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cdeedd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:31:12.902012Z",
     "iopub.status.busy": "2021-11-29T06:31:12.901170Z",
     "iopub.status.idle": "2021-11-29T06:31:13.154923Z",
     "shell.execute_reply": "2021-11-29T06:31:13.154441Z",
     "shell.execute_reply.started": "2021-11-29T06:13:58.178610Z"
    },
    "papermill": {
     "duration": 0.277387,
     "end_time": "2021-11-29T06:31:13.155055",
     "exception": false,
     "start_time": "2021-11-29T06:31:12.877668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarize: def sina_xml_to_url_list(xml_data):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl \n",
      "str->list  Convert XML to URL List.  From Biligrab.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../input/idl-project-code-encoder-set/encoder_code_to_docstring_test.csv')\n",
    "#print(df['input'][0])\n",
    "print(df['input'][0][:275])\n",
    "print(df['input'][0][275:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029d4dd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:31:13.195875Z",
     "iopub.status.busy": "2021-11-29T06:31:13.195198Z",
     "iopub.status.idle": "2021-11-29T06:31:20.415859Z",
     "shell.execute_reply": "2021-11-29T06:31:20.416288Z",
     "shell.execute_reply.started": "2021-11-29T06:14:35.642601Z"
    },
    "papermill": {
     "duration": 7.243304,
     "end_time": "2021-11-29T06:31:20.416484",
     "exception": false,
     "start_time": "2021-11-29T06:31:13.173180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai = aitextgen(model_folder=\"../input/pretrained-model-gpt/trained_model\",\n",
    "               tokenizer_file=\"../input/pretrained-model-gpt/trained_model/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52ad6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:31:20.457817Z",
     "iopub.status.busy": "2021-11-29T06:31:20.457283Z",
     "iopub.status.idle": "2021-11-29T06:31:21.367562Z",
     "shell.execute_reply": "2021-11-29T06:31:21.367069Z",
     "shell.execute_reply.started": "2021-11-29T06:14:48.588004Z"
    },
    "papermill": {
     "duration": 0.932902,
     "end_time": "2021-11-29T06:31:21.367700",
     "exception": false,
     "start_time": "2021-11-29T06:31:20.434798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1msummarize: def sina_xml_to_url_list(xml_data):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl \u001b[0murl\n"
     ]
    }
   ],
   "source": [
    "ai.generate(max_length = 512, prompt = df['input'][0][:275], top_k = 100, top_p  = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97f2e0",
   "metadata": {
    "id": "LdpZQXknFNY3",
    "papermill": {
     "duration": 0.01831,
     "end_time": "2021-11-29T06:31:21.404077",
     "exception": false,
     "start_time": "2021-11-29T06:31:21.385767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train GPT-2\n",
    "\n",
    "Important parameters for `train()`:\n",
    "\n",
    "- **`line_by_line`**: Set this to `True` if the input text file is a single-column CSV, with one record per row. aitextgen will automatically process it optimally.\n",
    "- **`from_cache`**: If you compressed your dataset locally (as noted in the previous section) and are using that cache file, set this to `True`.\n",
    "- **`num_steps`**: Number of steps to train the model for.\n",
    "- **`generate_every`**: Interval of steps to generate example text from the model; good for qualitatively validating training.\n",
    "- **`save_every`**: Interval of steps to save the model: the model will be saved in the VM to `/trained_model`.\n",
    "- **`save_gdrive`**: Set this to `True` to copy the model to a unique folder in your Google Drive, if you have mounted it in the earlier cells\n",
    "- **`batch_size`**: Batch size of the model training; setting it too high will cause the GPU to go OOM. _Unlike finetuning, since you are using a small model, you can massively increase the batch size to normalize the training_.\n",
    "- **`fp16`**: Enables half-precision training for faster/more memory-efficient training. Only works on a T4 or V100 GPU.\n",
    "\n",
    "Here are other important parameters for `train()` that are useful but you likely do not need to change.\n",
    "\n",
    "- **`learning_rate`**: Learning rate of the model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfd60c59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:31:21.445005Z",
     "iopub.status.busy": "2021-11-29T06:31:21.444479Z",
     "iopub.status.idle": "2021-11-29T11:29:48.799533Z",
     "shell.execute_reply": "2021-11-29T11:29:48.800185Z",
     "shell.execute_reply.started": "2021-11-29T06:16:44.475620Z"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "18a0eb53-7de1-4a2f-c66e-fa4ac911530b",
    "papermill": {
     "duration": 17907.380118,
     "end_time": "2021-11-29T11:29:48.802006",
     "exception": false,
     "start_time": "2021-11-29T06:31:21.421888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e102b4fc10174a2886b0f3b4ac2678f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/265734 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ac415b826b45e78dfbd25a530a0f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "armarize: def _get_call(self, callback, callback, **kwargs):\n",
      "        \"\"\"\"\"\"\n",
      "\n",
      "        return self._get_call(callback, callback, **kwargs) Create an processing connection models.\n",
      "==========\n",
      "\u001b[1m2,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def _comong(self, source, schema, schema):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if source == self.schema:\n",
      "            return\n",
      "        if source == self.schema:\n",
      "            return\n",
      "        if source!= source:\n",
      "            self._schema = source\n",
      "            if source == self.schema:\n",
      "                return\n",
      "            source_cont = source\n",
      "        if not source:\n",
      "            # Installation\n",
      "            source_cont = None\n",
      "            if source == self.schema:\n",
      "                self._schema = source\n",
      "            if source == self.schema:\n",
      "                return\n",
      "            if source == self.schema:\n",
      "                return\n",
      "            if source == self.schema:\n",
      "                return\n",
      "            if source!= self.schema:\n",
      "                return\n",
      "            # For execute source\n",
      "            if source == self.schema:\n",
      "                # He don't h\n",
      "==========\n",
      "\u001b[1m3,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "\n",
      "    return truncate(self) + template.truncate_template(self.template_dir, os.getcwd())) Make sure the truncate metadata to any array in a template.\n",
      "==========\n",
      "\u001b[1m4,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "s: def generated_session(self, session_name):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        if not session_name:\n",
      "            return self.session.delete(auth_name)\n",
      "        else:\n",
      "            return self.session.delete(session_name) Get a session.\n",
      "==========\n",
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def load_content(self, content):\n",
      "        \"\"\"\"\"\"\n",
      "\n",
      "        self.content = self._content.get_content()\n",
      "\n",
      "        if not self._content_types:\n",
      "            self._content = None\n",
      "\n",
      "        self._response = content.get_content()\n",
      "\n",
      "        self._content_types.update({\n",
      "            'content': content.get_content_type(),\n",
      "            'content-type': content.get_content_type(),\n",
      "            'content-type': content.get_content_type(),\n",
      "            'pkg_id': content.get_content_type(),\n",
      "            'pkg_id': content.get_content_type(),\n",
      "            'ipv6_id': content.get_ipv6_id(),\n",
      "            'ipv6_id': content.get('ipv6_id'),\n",
      "        })\n",
      "\n",
      "        # Process to send if we shouldn't\n",
      "==========\n",
      "\u001b[1m6,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m6,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "    \"\"\"\"\"\"\n",
      "    # Get the tag of the tag of this model in this access\n",
      "    tag.attr_list = tag.attr_list\n",
      "    # Tag list of the test and the new tag list at this possible\n",
      "    test_list = []\n",
      "    for tag in test_list:\n",
      "        test_list.append(tag)\n",
      "    return test_list Return the tag list of taglist of tag list of tag list of taglist\n",
      "==========\n",
      "\u001b[1m7,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m7,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "    db.depend(db['UUIDS_STATED', 'ID_SUCCE'))\n",
      "    db['UUID_TIME'] = db['UUID_TIME']\n",
      "    db['UUID_TIME'] = db['UUID_TIME']\n",
      "    db['UUID_TIME'] = db['UUID_TIME']\n",
      "    db['UUID_TIME'] = db['UUID_TIME']\n",
      "    group = db['UUID_TIME']\n",
      "    # Autohttps://github.com/html/callbackschemas.html/callbackschemas/{0}/_html/callbackschemas.html/callbackschemas/{10}/{2}\n",
      "    group['group_id_\n",
      "==========\n",
      "\u001b[1m8,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m8,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def update_call(self, callback, option):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        callback = callback(self.callback(callback))\n",
      "        callback(callback) Call a context\n",
      "==========\n",
      "\u001b[1m9,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m9,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        cur_cmd = (\"cmd=\"cmd -ccmd\")\n",
      "        if not isinstance(cur_cmd, nbio.LineText):\n",
      "            raise RuntimeError(\"Invalid cmd -cmd: -cmd -cmd -cmd -cmd -cmd -cmd -cmd -cmd -cmd -cmd -cmd -cmd -cmd -h %s\" % cur_cmd)\n",
      "\n",
      "    return cur_cmd Creates a cmd to a cmd -h cur_cmd -h -cmd -h 'cmd -h' in the    cur_cmd -cmd -h -cmd -cmd -h -cmd -cmd -h -h -h -h -h -h -h -h -h -h -cmd -h -h -h -h -h -h -h -h -h -h -h -h -h -h -h -h -h -h -h -h -h -h -h -h -\n",
      "==========\n",
      "\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def calculate_calculated(self, period, page_cand=0):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if isinstance(period, (int, float)):\n",
      "            period = period\n",
      "        else:\n",
      "            raise ValueError(\"period has not been calculated\")\n",
      "\n",
      "        if not isinstance(period, str):\n",
      "            raise ValueError(\"period must be an int\")\n",
      "        if not isinstance(period, int):\n",
      "            raise ValueError(\"period is not int or int, not int.\")\n",
      "        # Set a dictionary\n",
      "        if not isinstance(period, str):\n",
      "            period = \".period\"\n",
      "        # Calculatement can be required for a specific calculated operator\n",
      "        if period is None or period is None:\n",
      "            period = p\n",
      "==========\n",
      "\u001b[1m11,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m11,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "_type, value_type: int, value_type: int, value_type: int, value_type: int, value_type: int,\n",
      "                      value_type: int, value_type: int, value_type: int,\n",
      "                      value_type: int, value_type: int, value_type: int, value_type: int,\n",
      "                      value_type: int, value_type: int, value_type: int, value_type: int, value_type: int,\n",
      "                      value_type: str, value_type: dtype, value_type: int, value_type: str,\n",
      "                      value_type: int, value_type: int, value_type: int, value_type: int,\n",
      "                      value_type: int, value_type: int, value_type: int, value_type: int,\n",
      "                      value_type: int, value_type: int, value_type: int, value_type: int,\n",
      "                      value_type: int=int, value_type: int, value_type: int, value_type: int, value_type\n",
      "==========\n",
      "\u001b[1m12,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m12,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def find(*args, **kwargs):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    try:\n",
      "        size = int(args)\n",
      "    except IndexError:\n",
      "        # This is not a bool, we can use the functions\n",
      "        return size.where(args)\n",
      "\n",
      "    try:\n",
      "        value = func(**args)\n",
      "        return size.get(size)\n",
      "        return func(*args, **kwargs)\n",
      "\n",
      "    except TypeError:\n",
      "        return return \"Date is missing that happens the function is missing one\"\n",
      "\n",
      "    if size.endswith(\"Unique\"):\n",
      "        raise ValueError(\"Unique Unique that happens to be a Unique that happens \"\n",
      "                        \"super through adding size\")\n",
      "\n",
      "    if isinstance(args, int):\n",
      "        return\n",
      "==========\n",
      "\u001b[1m13,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m13,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def read_regex_pubsubner(self, pubsubner_path, pubsubnet_obj):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        pubsubnet_obj = pubsubnet_obj\n",
      "        pubsubnet_obj = pubsubnet_obj\n",
      "        if pubsubnet_obj is None:\n",
      "            pubsubnet_obj = pubsubnet_obj\n",
      "        else:\n",
      "            pubsubnet_obj = pubsubnet_obj\n",
      "        else:\n",
      "            pubsubnet_obj = pubsubnet_obj\n",
      "        pubsubnet_obj = pubsubnet_obj\n",
      "\n",
      "        return pubsubnet_obj Calculates are regex pubsubnet object.\n",
      "==========\n",
      "\u001b[1m14,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m14,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def _get_related_file(self, seq_path):\n",
      "        \"\"\"\"\"\"\n",
      "        if self._path:\n",
      "            for seq_path in self._paths:\n",
      "                with open(seq_path) as f:\n",
      "                    f.write(seq_path)\n",
      "        else:\n",
      "            raise RuntimeError(\"Could not contain an attempt to be related it\")\n",
      "        return seq_path Convert a Runtime to a directory of sequence into the directory.\n",
      "==========\n",
      "\u001b[1m15,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m15,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def check(self, highlights, import_import=None):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if import_import is not None:\n",
      "            highlights = self.import_import_hights\n",
      "\n",
      "        if isinstance(import_import, ImportError):\n",
      "            import_import = import_import\n",
      "\n",
      "        if isinstance(import_import, Import):\n",
      "            import_import = ImportPath(import_import)\n",
      "\n",
      "        if isinstance(import_import, ImportError):\n",
      "            import_import = import_import\n",
      "\n",
      "        if isinstance(import_import, ImportError):\n",
      "            if isinstance(import_import, Import):\n",
      "                import_import = self.import_import_import\n",
      "                import_import = import_import\n",
      "\n",
      "        if isinstance(import_import, Import):\n",
      "            import_i\n",
      "==========\n",
      "\u001b[1m16,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m16,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "dd.get_output_dir(outdir,\n",
      "                                       zip=False,\n",
      "                                       release_name=True,\n",
      "                                       preprocessing=False,\n",
      "                                       expiration=True,\n",
      "                                       expiration=True):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    if not _is_stream():\n",
      "        return None\n",
      "\n",
      "    if dd.get_output_dir(outdir, os.path.join(outdir, \"name\")):\n",
      "        if release_name is None:\n",
      "            release_name = \"%s\" % (dd.get_output_dir(outdir, \"stream\")\n",
      "        # TODO: could be used but were connection\n",
      "        if os.path.exists(outdir):\n",
      "            os.makedirs(outdir)\n",
      "        else:\n",
      "            return None\n",
      "\n",
      "    name = dd.get_outdir(outdir, \"name\")\n",
      "    if os.path.isfile(name\n",
      "==========\n",
      "\u001b[1m17,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m17,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ", data=None):\n",
      "        '''  '''\n",
      "        if data is None or data is None:\n",
      "            data = data\n",
      "\n",
      "        data = self.proxy.get_data(data)\n",
      "        return data Convert a number of data string to meshaded data.\n",
      "==========\n",
      "\u001b[1m18,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m18,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def _set_border_border(self, border, mincount):\n",
      "        \"\"\"\"\"\"\n",
      "        self.allow_border_border = maxcount\n",
      "        self.allow_border = maxcount\n",
      "        self.allow_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_border_\n",
      "==========\n",
      "\u001b[1m19,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m19,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def _remove_removed(self, port):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        if port is not None:\n",
      "            return '\\n'.join([\n",
      "                '{0}{1}:'.format(\n",
      "                    port.strip(),\n",
      "                    '\\n'.join(struct.pack(port)))\n",
      "                for (\n",
      "                    '{0}'.format(port)))\n",
      "            ]\n",
      "        try:\n",
      "            for port in port:\n",
      "                if port == port:\n",
      "                    return True\n",
      "        except IOError:\n",
      "            pass Ut wants to delete all removed removed port\n",
      "==========\n",
      "\u001b[1m20,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m20,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def get_aws_aws_aggregate(self, aws_agent):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        return self.get_aws_agent(agent) Return aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws aws the aws aws aws aws aws aws aws aws aws aw\n",
      "==========\n",
      "\u001b[1m21,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m21,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def generate_node_node_node_path(self, node_node):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        start, end = self.generate_node_node_node_node_node_node_node_node(node_node)\n",
      "        self.generator_node_node_node(end, start, end)\n",
      "        self.set_generate_node_node(end)\n",
      "        logger.info(\"Generated node with generated nodes\")\n",
      "        self.generate_node_node(node_node)\n",
      "        logger.info(\"Generated node filenode\")\n",
      "        self.generate_node_node_node(node_node)\n",
      "        self.generate_node_node_node(node_node)\n",
      "        logger.info(\"Generated node node with generated nodes\")\n",
      "        logger.info(\"Generated node node from generated nodes\"\n",
      "==========\n",
      "\u001b[1m22,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m22,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def _get_by_response(self, exc):\n",
      "        \"\"\"\"\"\"\n",
      "        if '__get_by_response':\n",
      "            return None\n",
      "        if self.cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_cb_c\n",
      "==========\n",
      "\u001b[1m23,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m23,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def _get_token(self, key, port=None):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        key = self.token\n",
      "        if port is None:\n",
      "            port = self.token\n",
      "        else:\n",
      "            port = self.token\n",
      "        filter = self.token\n",
      "        if port is None:\n",
      "            port = port\n",
      "\n",
      "        if filter is None:\n",
      "            filter = self.token.get(name=port)\n",
      "        if not filter:\n",
      "            filter = self.token.get_token()\n",
      "        return filter Retrieves a by any key into a `key`\n",
      "==========\n",
      "\u001b[1m24,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m24,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def _summ_to_serializer(self, func):\n",
      "        \"\"\"\"\"\"\n",
      "        if self.coordinate:\n",
      "            self.sub_func(func)\n",
      "\n",
      "        self.coordinate = self.coordinate\n",
      "        self.summ_func(func)\n",
      "        self.summ_unc(func)\n",
      "\n",
      "        self.summ_func(func)\n",
      "        return self Sets the summ coordinated by the given function.\n",
      "==========\n",
      "\u001b[1m25,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m25,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def create_unix_for_unix_for_unix_for_unix(unix_for_unix_for_unix):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    # Get all\n",
      "    snapshot = snapshot[unix_for_unix_for_unix(unix_for_uniX_for_unix)]\n",
      "    snapshots = snapshot.create_unix_for_unix(unix_for_unix)\n",
      "    snapshots.create_unix_for_unix_for_unix(unix_for_unix_for_unix_for_unix_for_unix)\n",
      "    snapshots.create_unix_for_unix_for_unix(unix_for_unix_for_unix_for_uni\n",
      "==========\n",
      "\u001b[1m26,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m26,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "store',\n",
      "                   *path,\n",
      "                   **kwargs)\n",
      "    # For path files.\n",
      "    return path\n",
      "    # Get http_path on zip file-like object. If zipfile cannot be generated.\n",
      "    # For file-like object is zipped.\n",
      "    # For found we are generated.\n",
      "    if zipfile_like object is None:\n",
      "        zipfile_like object = path.getsize(Zipfile_like object)\n",
      "    for file_like obj in zipfile_like object.path:\n",
      "        yield file_like object.file_like object with zip file-like object.\n",
      "==========\n",
      "\u001b[1m27,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m27,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def __get_device(self, *items):\n",
      "        \"\"\"\"\"\"\n",
      "        if not self.device:\n",
      "            return False\n",
      "\n",
      "        if not self.device:\n",
      "            del self.device.get('device')\n",
      "\n",
      "        if not self.device:\n",
      "            del self.device.get('device')\n",
      "\n",
      "        if not self.device:\n",
      "            return True\n",
      "\n",
      "        del self.device.set('device')\n",
      "        if not self.device:\n",
      "            # If we have a caching the port, must be installed at least\n",
      "            # If we have a string in this converting to the\n",
      "            # caching to the DVICE HEAD\n",
      "            if self.can_cached:\n",
      "                self.can_cached = False\n",
      "            # If we have no caching to the caching\n",
      "            # a\n",
      "==========\n",
      "\u001b[1m28,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m28,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def corpus_corpushed(self, callable_corpushed):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        return self.get_corpushed(callable_corpushed, callable_corpushed) Corpus a single corpushed corpushed\n",
      "==========\n",
      "\u001b[1m29,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m29,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def separate(self, stream_number):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        self.separate(stream_number)\n",
      "        self.separate(stream_number)\n",
      "        self.separate(stream_number)\n",
      "        self.separate(stream_number)\n",
      "        self.separate(stream_number) Stores the separate based on the separate\n",
      "==========\n",
      "\u001b[1m30,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m30,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def realmerate_submit(self, ubid, client):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        resp = self.session.request(url, url, data=data)\n",
      "        return self.session.post(resp) Lookup a notice to a Submit an account\n",
      "==========\n",
      "\u001b[1m31,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m31,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def get_available_cov(self, cov):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        # make the cov\n",
      "        assert self.ivailable_cov is None:\n",
      "            self.ivailable_cov(cov, self.ivailable_cov)\n",
      "            self.ivailable_cov(cov, self.ivailable_cov)\n",
      "            self.ivailable_cov is None\n",
      "            self.ivailable_cov is None:\n",
      "                self.ivailable_cov.cov = None\n",
      "                self.ivailable_cov.cov = None\n",
      "\n",
      "        # add total tabular line:\n",
      "        self.ivailable_cov = None\n",
      "\n",
      "        # I'm the core on this tag, call it already expects.\n",
      "        # I\n",
      "==========\n",
      "\u001b[1m32,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m32,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def sort_by_name(self, name, section, db.Key=None):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if not isinstance(db, types.Series):\n",
      "            return basename(self.section_name)\n",
      "        if not db.Key is None:\n",
      "            return basename(name)\n",
      "        if not db.Key is not None:\n",
      "            return basename(name)\n",
      "        if not isinstance(name, basename):\n",
      "            return str(name)\n",
      "        if not isinstance(name, basename):\n",
      "            raise basename(name)\n",
      "        if not isinstance(name, basename):\n",
      "            return name\n",
      "        if not isinstance(name, basename):\n",
      "            raise type(name)\n",
      "        if name.startswith(\"BY\") and name.startswith(\"B\"):\n",
      "            name = self.name.name + name\n",
      "        if name.startswith(\"F\"):\n",
      "            return basename(name)\n",
      "        if name.\n",
      "==========\n",
      "\u001b[1m33,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m33,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def initalize(self, **kwargs):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        try:\n",
      "            initalize_rules = ','.join(self.body_url_list)\n",
      "        except AttributeError:\n",
      "            raise ValueError(\"unexpected initial body\")\n",
      "        initalize_rules = []\n",
      "        for name, value in zip(self.body_url_list):\n",
      "            initalize_rules += (\n",
      "                [\n",
      "                    '/{0}'.format(name)\n",
      "                )\n",
      "                for name, value in kttp_conf.items()\n",
      "                ]\n",
      "        initalize_run_name = ('{0}'.format(value)\n",
      "            )\n",
      "        uri = 'a'\n",
      "        return self.uri + 1 Initiates a Converter 'BundleSerialCalls'\n",
      "==========\n",
      "\u001b[1m34,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m34,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def _get_monitor(self, monitor):\n",
      "        \"\"\" \n",
      "        \"\"\"\n",
      "        if monitor is None:\n",
      "            raise Monitor()\n",
      "        if monitor is None:\n",
      "            monitor = monitor.get_monitor()\n",
      "            monitor.get_monitor()\n",
      "        else:\n",
      "            monitor.get_monitor()\n",
      "        monitor.get_monitor()\n",
      "        monitor.get_monitor() Returns a monitors on the given monitor.\n",
      "==========\n",
      "\u001b[1m35,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m35,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def persist_persist_style_construct(self, data):\n",
      "        '''''\n",
      "        if data.get(key):\n",
      "            raise TypeError('Bad data value  %s' % (data, data))\n",
      "\n",
      "        # construct method and persist method.\n",
      "        if data.get(key, 'rb'):\n",
      "            # End and end\n",
      "            params = data.get(key, {})\n",
      "            if params['status'] > 40:\n",
      "                params['status'] = 'persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persist_persi\n",
      "==========\n",
      "\u001b[1m36,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m36,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def create_frag_file(self, frag_file):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        if not isinstance(self.get_file_objects(), FragSourceFragSourceFragSource):\n",
      "            raise TypeError(\"FragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragInfo\")\n",
      "\n",
      "        create_file = self.get_file_objects()\n",
      "        if not create_file:\n",
      "            raise TypeError(\"FragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSourceFragSource\n",
      "==========\n",
      "\u001b[1m37,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m37,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def find_args(args, args, **kwargs):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    refname = args.get('refname')\n",
      "    args = args.get('refname', args.get('refname'))\n",
      "    args = args.get('args', args.get('args'))\n",
      "    args = args.get('args', args.get('custom_args', args.get('args'))\n",
      "    args = args.get('args', args.get('args'))\n",
      "    args = args.get('args', args.get('args'))\n",
      "    args = args.get('args', args.get('args'))\n",
      "    args = args.get('args', args.get('args'))\n",
      "    args = args.get('args', args.get('args'))\n",
      "    args = args.get('args', args.get('args'), args.get('args'))\n",
      "    args = args.get('args', args.get('args'))\n",
      "    args = args.get('args', args.get('args'))\n",
      "    args = args\n",
      "==========\n",
      "\u001b[1m38,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m38,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def __install_thread_handler(self, self, url):\n",
      "        \"\"\"\"\"\"\n",
      "        if not self._dest_thread_handler:\n",
      "            raise self.threading_handler(\n",
      "                'Could not find anythread.'\n",
      "            )\n",
      "        self._emon_thread = True\n",
      "        threading.basic_handler(url)\n",
      "        self._threading_handler.remove(url)\n",
      "        self._threading_handler.start()\n",
      "        self._wait_for_handler(url)\n",
      "        self._thread_handler(url)\n",
      "        self._thread_handler.start()\n",
      "        self._threading_handler.start()\n",
      "\n",
      "        if not self._threading_handler:\n",
      "            self._threading_handler()\n",
      "\n",
      "        self._threading_handler.start()\n",
      "       \n",
      "==========\n",
      "\u001b[1m39,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m39,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " params=None, params=None, timeout=None):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    if params:\n",
      "        params = params\n",
      "\n",
      "    if params:\n",
      "        click.echo(\"Invalid param from \" + params + \":\" + params + \":\\n\")\n",
      "        params += \"\\n\"\n",
      "        params += params + \":\" + params + \":\" + params + \":\" + params + \":\" + params:\" + params + \":\" + params + \":\" + params + \":\" + params + \":\" + params + \":\" + params + \":\" + params + \":\" + params + \":\" +\n",
      "        params + \":\" + params + \":\" + params + \":\" + params + \":\" + str(params + \":\" + params + \":\" + \" + params + \n",
      "==========\n",
      "\u001b[1m40,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m40,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "        format, message, err=None):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        if message and format:\n",
      "            return StringEncoder(message, message, exception.message)\n",
      "        else:\n",
      "            return StringEncoder(message, exception.message) Retrieves an err and every hide to be an errors.\n",
      "==========\n",
      "\u001b[1m41,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m41,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ": def doc(cls, **kwargs):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    cls = cls.doc\n",
      "    cls.doc = 1\n",
      "    cls.day = float(cls.day)\n",
      "    cls.doc = datetime.now(timedelta(seconds=1.0))\n",
      "    cls.day = float(cls.day)\n",
      "    cls.day = float(cls.day)\n",
      "    cls.day = float(cls.day)\n",
      "    cls.day = float(cls.day)\n",
      "    cls.day = float(cls.day)\n",
      "    cls.day = float(cls.day)\n",
      "    cls.day = float(cls.day)\n",
      "    cls.day = float(cls.day)\n",
      "    cls.day = float(cls.day)\n",
      "    cls.day = float(cls.day)\n",
      "==========\n",
      "\u001b[1m42,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m42,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "    position_string = '',\n",
      "\n",
      "        global_id,\n",
      "        position_string_str = '',\n",
      "        position_string\n",
      "    else:\n",
      "        position_string = '',\n",
      "        global_id,\n",
      "        global_id,\n",
      "        position_string\n",
      "    for i, position_string in enumerate(self._cutoff):\n",
      "        position_string = '',\n",
      "        position_string = i\n",
      "        last_id = ''\n",
      "        last_indent = '',\n",
      "        last_indent.atoms[i].get('last_indent', False)\n",
      "        last_indent = '',\n",
      "        position_string = '',\n",
      "\n",
      "        if last_indent is not None:\n",
      "            last_indent += ', '\n",
      "        if last_indent is not None:\n",
      "            last_indent += ', '\n",
      "\n",
      "==========\n",
      "\u001b[1m43,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m43,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " if simply_to_decorated_to_decorated_stated:\n",
      "        if simply_to_decorated:\n",
      "            if simply_to_decorated_stated:\n",
      "                self.simply_decorated_stated_decorated_decorated_stated = False\n",
      "                signal_decorated_stated = True\n",
      "                # save an association is empty\n",
      "                if signal_decorated_stated is not None:\n",
      "                    signal_decorated = True\n",
      "                    signal_decorated_stated = True\n",
      "\n",
      "                # set the decorated decorated state descriptor\n",
      "                if signal_decorated_stated is not None:\n",
      "                    signal_decorated_stated = True\n",
      "                    sign\n",
      "==========\n",
      "\u001b[1m44,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m44,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "    return None, \\\n",
      "        sr_global_sr_global.Upload(cdf_file, target=target, sr_global_sr_global_sr_global,\n",
      "                        target=target, target=target, sr_global_sr_global_sr_global_sr_global_sr_global_sr_global_sr_global_sr_global_sr_global_sr_global_sr_global_sr_global_sr_global_global_sr_global_sr_global_sr_global_sr_global_sr_global_sr_global_sr_global_sr_global_sr_\n",
      "==========\n",
      "\u001b[1m45,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m45,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def salt_bottom_config(self):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if not self._find_config(self._config):\n",
      "            self._config = self._config\n",
      "        self._config.update_config(self._config)\n",
      "        self._config.update_config(self._config)\n",
      "        self._config.update_config(self._config)\n",
      "        self._config.update_config(self._config) Salt a serial config to Cycle Following Following HTTP config\n",
      "==========\n",
      "\u001b[1m46,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m46,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def create_submodule_home_home_input(self):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        self._submodule_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_home_h\n",
      "==========\n",
      "\u001b[1m47,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m47,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "wize: def main(self, name, access_key):\n",
      "        \"\"\"\"\"\"\n",
      "        name = ''\n",
      "        if self.access_key is None:\n",
      "            self.children.add(None)\n",
      "        elif self.access_key is None:\n",
      "            for access_key in self.access_key.get('access_key'):\n",
      "                if access_key.get('name', None):\n",
      "                    self.children.add(access_key)\n",
      "        elif self.access_access_key is None:\n",
      "            self.children.add(access_key) Add the pipeline to a pipeline.\n",
      "==========\n",
      "\u001b[1m48,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m48,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def __command(self, command, text):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        return self.command_to_context(self.host, text) Cache and returns a command to the context from the context\n",
      "==========\n",
      "\u001b[1m49,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m49,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def padd_module(self):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        if self.name in self.modules:\n",
      "            self.modules[self.name].append(self.modules[self.modules[self.modules[self.name]])\n",
      "        return self.modules[self.modules[self.name] Pass the modules are in possible on the modules and    possibers and padding in zero connections.\n",
      "==========\n",
      "\u001b[1m50,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m50,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def _distribute_request(self, request_path, request_path):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        valid_request = get_validation(request_path)\n",
      "        valid_request.set_request_request_request(request_path)\n",
      "        valid_request.set_request_request(request_path)\n",
      "        valid_request.set_request_request(request_path)\n",
      "        valid_request.set_request_request(request_path)\n",
      "        valid_request.set_request(request_path)\n",
      "        valid_request.set_request(request_path) Update new validation\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "ai.train('../input/idl-project-code-encoder-set/encoder_code_to_docstring_train.csv',\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=50_000,\n",
    "         generate_every=1_000,\n",
    "         save_every=1_000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         batch_size=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbcfead",
   "metadata": {
    "id": "pel-uBULXO2L",
    "papermill": {
     "duration": 0.060306,
     "end_time": "2021-11-29T11:29:48.922653",
     "exception": false,
     "start_time": "2021-11-29T11:29:48.862347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Load a Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aade9538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T21:35:56.672341Z",
     "iopub.status.busy": "2021-11-27T21:35:56.671546Z",
     "iopub.status.idle": "2021-11-27T21:35:59.547952Z",
     "shell.execute_reply": "2021-11-27T21:35:59.546868Z",
     "shell.execute_reply.started": "2021-11-27T21:35:56.672307Z"
    },
    "papermill": {
     "duration": 0.058686,
     "end_time": "2021-11-29T11:29:49.040189",
     "exception": false,
     "start_time": "2021-11-29T11:29:48.981503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ai = aitextgen(model_folder=\"../input/finetuned-gpt/trained_model\",\n",
    "               tokenizer_file=\"../input/model-tuned/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e89487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T21:41:40.799568Z",
     "iopub.status.busy": "2021-11-27T21:41:40.798832Z",
     "iopub.status.idle": "2021-11-27T21:41:41.441898Z",
     "shell.execute_reply": "2021-11-27T21:41:41.440779Z",
     "shell.execute_reply.started": "2021-11-27T21:41:40.799522Z"
    },
    "id": "4RNY6RBI9LmL",
    "outputId": "8579ed7e-14c8-4a76-ecad-ce7acd13b612",
    "papermill": {
     "duration": 0.061144,
     "end_time": "2021-11-29T11:29:49.161052",
     "exception": false,
     "start_time": "2021-11-29T11:29:49.099908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ai.generate(max_length = 512, prompt = 'e4 : a4', top_k = 100, top_p  = 0.9, temperature = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f924b14",
   "metadata": {
    "papermill": {
     "duration": 0.056364,
     "end_time": "2021-11-29T11:29:49.275035",
     "exception": false,
     "start_time": "2021-11-29T11:29:49.218671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3718622",
   "metadata": {
    "papermill": {
     "duration": 0.056666,
     "end_time": "2021-11-29T11:29:49.388632",
     "exception": false,
     "start_time": "2021-11-29T11:29:49.331966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17948.823327,
   "end_time": "2021-11-29T11:29:52.183730",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-29T06:30:43.360403",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0ab2db38bb654da8ae0d425ae3dadc8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d56b4370ef94dffb54b4d3e63820cee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1c592242cf19487080248567fdfc0e99",
       "max": 265734.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_26d84fd4646d45c8b46aa795e4c2fc53",
       "value": 265734.0
      }
     },
     "16e6dca9a1ca4b449258d8a9fef05d3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8ca7a10138f945c085762e5534a308c4",
       "placeholder": "​",
       "style": "IPY_MODEL_183f66ae3efb425d9a04ff1b32411d76",
       "value": "100%"
      }
     },
     "183f66ae3efb425d9a04ff1b32411d76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1c592242cf19487080248567fdfc0e99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2295141d9b9c4c948d3a1c71bbd1682b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22f180d06224407b9873756b56832109": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dfc87ede88d94ecabd8467750f1fb3aa",
       "placeholder": "​",
       "style": "IPY_MODEL_92cc0088a75f48559902e41fb2193094",
       "value": " 50000/50000 [4:55:33&lt;00:00,  2.82it/s]"
      }
     },
     "24ac415b826b45e78dfbd25a530a0f9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_746993eeae124845966475c4b8cf312b",
        "IPY_MODEL_f331dd1e6b8b490fabbcd38cc9baeb2a",
        "IPY_MODEL_22f180d06224407b9873756b56832109"
       ],
       "layout": "IPY_MODEL_2d5c743985ca4cb5ad2285131cd4b343"
      }
     },
     "26d84fd4646d45c8b46aa795e4c2fc53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "28c8cae37cb34ea8b13e611a31603951": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2d5c743985ca4cb5ad2285131cd4b343": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "6c1cb1f26e4e493196f41d3a7f7497b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "746993eeae124845966475c4b8cf312b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ab2db38bb654da8ae0d425ae3dadc8c",
       "placeholder": "​",
       "style": "IPY_MODEL_6c1cb1f26e4e493196f41d3a7f7497b5",
       "value": "Loss: 1.470 — Avg: 1.473 — GPU Mem: 13597 MB: 100%"
      }
     },
     "765a16e51692400abfe77c8d3c04ff81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "7fb06a09297f415cb3f0f28136628305": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bc52c61d5f4447bd81b9abf3cc484ec2",
       "placeholder": "​",
       "style": "IPY_MODEL_28c8cae37cb34ea8b13e611a31603951",
       "value": " 265734/265734 [02:43&lt;00:00, 1620.83it/s]"
      }
     },
     "860c9ba4b70a4e9484a99ad0b553005f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8ca7a10138f945c085762e5534a308c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "92cc0088a75f48559902e41fb2193094": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bc52c61d5f4447bd81b9abf3cc484ec2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfc87ede88d94ecabd8467750f1fb3aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e102b4fc10174a2886b0f3b4ac2678f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_16e6dca9a1ca4b449258d8a9fef05d3d",
        "IPY_MODEL_0d56b4370ef94dffb54b4d3e63820cee",
        "IPY_MODEL_7fb06a09297f415cb3f0f28136628305"
       ],
       "layout": "IPY_MODEL_765a16e51692400abfe77c8d3c04ff81"
      }
     },
     "f331dd1e6b8b490fabbcd38cc9baeb2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2295141d9b9c4c948d3a1c71bbd1682b",
       "max": 50000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_860c9ba4b70a4e9484a99ad0b553005f",
       "value": 50000.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
