{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T08:54:55.386459Z",
     "iopub.status.busy": "2021-11-27T08:54:55.385680Z",
     "iopub.status.idle": "2021-11-27T08:55:02.352754Z",
     "shell.execute_reply": "2021-11-27T08:55:02.352019Z",
     "shell.execute_reply.started": "2021-11-27T08:54:55.386415Z"
    },
    "id": "KBkpRgBCBS2_",
    "outputId": "629b3068-c9a6-407a-ea09-98773a0c50bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T08:55:05.560899Z",
     "iopub.status.busy": "2021-11-27T08:55:05.560617Z",
     "iopub.status.idle": "2021-11-27T08:55:05.564825Z",
     "shell.execute_reply": "2021-11-27T08:55:05.563870Z",
     "shell.execute_reply.started": "2021-11-27T08:55:05.560867Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T14:26:14.279824Z",
     "iopub.status.busy": "2021-11-27T14:26:14.279349Z",
     "iopub.status.idle": "2021-11-27T14:26:14.375056Z",
     "shell.execute_reply": "2021-11-27T14:26:14.373707Z",
     "shell.execute_reply.started": "2021-11-27T14:26:14.279736Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai = aitextgen(model_folder=\"pretrained_model_gpt\",\n",
    "               tokenizer_file=\"pretrained_model_gpt/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'def sharpe_ratio(return_series, N = 255, rf = 0.01, annualized = True):'\n",
    "#   mean = return_series.mean() * N -rf'\n",
    "#    sigma = return_series.std()\\\n",
    "#    if annualized:\\\n",
    "#        sigma *= np.sqrt(N)'\n",
    "#return mean / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T08:56:20.395870Z",
     "iopub.status.busy": "2021-11-27T08:56:20.395544Z",
     "iopub.status.idle": "2021-11-27T08:56:21.437111Z",
     "shell.execute_reply": "2021-11-27T08:56:21.436238Z",
     "shell.execute_reply.started": "2021-11-27T08:56:20.395829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mdef sharpe_ratio(return_series, N = 255, rf = 0.01, annualized = True):\u001b[0m\n",
      "    if not (isinstance(return_series, int)):\n",
      "        return return_series\n",
      "    if not return_series:\n",
      "        return_series = []\n",
      "    if rf == 0:\n",
      "        return_series = [rf]\n",
      "    if rf == 0:\n",
      "        return_series = []\n",
      "    if rf == 0:\n",
      "        if rf == 0:\n",
      "            return_series = []\n",
      "        else:\n",
      "            return_series = []\n",
      "        if rf == 0:\n",
      "            return_series = []\n",
      "    return return_series\n"
     ]
    }
   ],
   "source": [
    "ai.generate(prompt = p, max_length = 512, top_k = 100, top_p  = 0.9, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'def _get_abs_corr_mat(self, X_filled, tolerance=1e-6): n_features = X_filled.shape[1]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mdef _get_abs_corr_mat(self, X_filled, tolerance=1e-6): n_features = X_filled.shape[1]\u001b[0m\n",
      "  tolerance = np.floor(tolerance)\n",
      "  tolerance = tolerance\n",
      "  tolerance = tolerance.shape[0]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[0]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[0]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[0]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n",
      "  tolerance = tolerance.shape[1]\n"
     ]
    }
   ],
   "source": [
    "ai.generate(prompt = p, max_length = 512, top_k = 100, top_p  = 0.9, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'def show_current_number(parser, token): try: tag_name, args = '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mdef show_current_number(parser, token): try: tag_name, args = \u001b[0mzipfile.ZipFile(parser, token)\n",
      "    except Exception as e:\n",
      "        raise Exception(\"Tag show tag show tag show tag show tag: {0}\".format(e))\n",
      "    if not os.path.isfile(parser):\n",
      "        print(\"Tag show tag show tag: {1}\".format(parser, token))\n",
      "    if not os.path.isfile(parser):\n",
      "        os.makedirs(parser)\n",
      "    else:\n",
      "        os.makedirs(parser, token)\n",
      "    if not os.path.isfile(parser):\n",
      "        raise Exception(\"Tag show tag show tag show tag show tag show tag show tag show tag show tag show tag show tag show tag show tag show tag show tag showtag showtagshow tag showtag showtag showtag showtag showtagshow tag show tag show tag showtag showtag showtagshowtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtagshowtag showtag showtag showtag showtagshowtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag showtag\n"
     ]
    }
   ],
   "source": [
    "ai.generate(prompt = p, max_length = 512, top_k = 100, top_p  = 0.9, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1me4\u001b[0m e6 d4 d5 e5 Ne7 Bd3 c5 c3 Nbc6 Nf3 cxd4 cxd4 Nf5 O-O Be7 Nc3 O-O Be3 a6 Rc1 b5 b3 Bb7 Bb1 Rc8 Ne2 Na5 a3 Nbc4 Bxc4 bxc4 Nd2 Ba8 f4 Qb6 b4 g6 Nf3 Ba4 Bd2 Bb5 Qc2 Rc7 h3 Qc6 Ne1 Ne8 f5 exf5 Nxf5 gxf5 exf6 Nxf6 Nxf6+ Bxf6 g3 Re8 Qf2 Re4 Qf3 Nd7 Rf2 Qe6 Qf4 Nf8 Rf4 Qe2 Qg4+ Rg6 Qh5 Re8 Qf3 Qxf3 Rxf3 Re1 Rf6 Bc3 Nd7 Rf6 Ne5 Be2 Re8 Bf3 Ng4 Rf8+ Kxf8 gxf4 Re2 Rf7+ Ke8 Re7+ Kd8 Bf4 Nf6 Re6 Nd7 Bg5+ Kc8 Bd2 Bxd2 Rxd2 Re4 Rf7 Kd8 Rxa7 c3 Rc7 c2 Rxc2 Kd7 b5 c1=Q Rxc1 Rxc1+ Kg2 Kc7 b6+ Kxb6 b7 Kc5 b8=Q Kd4 Qe8 Kc3 Qc8+ Kb2 Qb7+ Kc3 Qc6+ Kd3 Qc3+ Ke2 Qe4+ Kd2 Qf5 Kc2 Qf7+ Kb3 Qd5+ Ka4 Qe4+ Ka5 Qc4 Kb6 Qe6+ Ka7 Qc4+ Ka7 Qe7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe8+ Ka7 Qc8+ Ka7 Qe7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe6+ Ka7 Qc8+ Ka8 Qe7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe7+ Ka7 Qe7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe7+ Ka7 Qc7+ Ka8 Qe8+ Ka7 Qe7+ Ka8 Qe7+ Ka8 Qe8\n"
     ]
    }
   ],
   "source": [
    "p = 'e4'\n",
    "ai.generate(prompt = p, max_length = 512, top_k = 100, top_p  = 0.9, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1me4 c5\u001b[0m Nf3 d6 Bb5+ Bd7 Bxd7+ Nxd7 O-O Ngf6 Nc3 g6 d3 Bg7 Qe2 O-O Re1 e5 h3 Re8 Bg5 Qb6 Nd2 a6 Rad1 Qc7 Nc4 b5 Ne3 b4 Ned5 Nxd5 Nxd5 a5 c3 a4 a3 Rb8 Kh2 Nd7 b3 cxb3 Qxb3 Nc5 Nxc5 dxc5 Qxd8 Rxd8 d4 cxd4 cxd4 exd4 Nxd4 Rbc8 d5 b3 Rd3 Rc2 Red1 Rxd2 Rxd2 Rc1 f3 Rxc2 Rxc2 Rxc2+ Kg3 Kg7 h4 h5 f4 Rc3+ f3 Re3+ Kf2 Re2+ Kg3 Rxf2 Kxf2 g5 hxg5 Kg6 g3 h4 g4 h3 g5 h2 g6 fxg6 fxg6 Kxg6 Ke3 Kf6 Kd3 Ke5 Kc4 Kd6 Kd4 Kc6 Kc4 Kd6 Kb5 Ke6 Kc6 Kd6 Kb5 Kc7 Ka6 Kd6 Kb7 Ke5 Ka7 Kd6 Kxa4 Ke5 Ka5 Kd5 Kb6 Kc4 Ka5 Kb3 Kb5 Ka3 Ka5 Kb3 Ka6 Kc4 Ka7 Kb5 Kb7 Kc5 Ka6 Kd6 Ka5 Kc5 Ka4 Kd4 Ka3 Ke3 Ka4 Kf4 Ka3 Ke3 Ka2 Kf3 Ka1 Ke2 Ka2 Kd2 Ka1 Kc2 Ka2 Kd2 Ka1 Ke2 Ka1 Kd2 Ka2 Ke2 Ka1 Ke1 Ka2 Kd2 Ka1 Kd3 Ka2 Kc2 Ka1 Kd2 Ka2 Kc2 Ka1 Kd3 Ka2 Kc3 Ka1 Kd2 Ka2 Kc2 Ka1 Kd2 Ka1 Ke2 Ka2 Kd2 Ka1 Ke2 Ka2 Kd2 Ka1 Kc2 Ka2 Kd2 Ka1 Kc2 Ka2 Kd2 Ka1 Kc3 Ka2 Kc4 Ka3 Kc3 Ka4 Kd4 Ka5 Kd3 Ka6 Kc4 Ka7 Kc3 Ka8 Kd4 Ka7 Kc4 Ka8 Kd4 Ka8 Ke4 Ka7 Kd5 Ka8 Kc6 Ka7 Kc7 Ka8 Kd6 Ka8 Kc7 Ka7 Kd6 Ka6 Kc7 Ka7 Kd6 Ka6 Ke5 Ka7 Ke6 Ka8 Kd6 Ka8 Ke7 Ka7 Ke6 Ka6 Kd5 Ka5 Ke\n"
     ]
    }
   ],
   "source": [
    "p = 'e4 c5'\n",
    "ai.generate(prompt = p, max_length = 512, top_k = 100, top_p  = 0.9, temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
