{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T17:40:20.606100Z",
     "iopub.status.busy": "2021-12-03T17:40:20.605405Z",
     "iopub.status.idle": "2021-12-03T17:40:44.990455Z",
     "shell.execute_reply": "2021-12-03T17:40:44.989577Z",
     "shell.execute_reply.started": "2021-12-03T17:40:20.605992Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aitextgen\n",
      "  Downloading aitextgen-0.5.2.tar.gz (572 kB)\n",
      "\u001b[K     |████████████████████████████████| 572 kB 291 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (4.5.1)\n",
      "Collecting fire>=0.3.0\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 3.4 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pytorch-lightning>=1.3.1 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (1.4.4)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (1.9.1+cpu)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fire>=0.3.0->aitextgen) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire>=0.3.0->aitextgen) (1.1.0)\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.3.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (3.10.0.2)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (2021.10.1)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (2.5.0)\n",
      "Requirement already satisfied: torchmetrics>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.5.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (21.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.62.3)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.25.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.7.4.post0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->pytorch-lightning>=1.3.1->aitextgen) (2.4.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.37.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (58.0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.14.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.35.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.19.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.38.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (2021.8.28)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (0.0.46)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.6.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (21.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.5.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=4.5.1->aitextgen) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=4.5.1->aitextgen) (8.0.1)\n",
      "Building wheels for collected packages: aitextgen, fire\n",
      "  Building wheel for aitextgen (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for aitextgen: filename=aitextgen-0.5.2-py3-none-any.whl size=575905 sha256=1fe3ddee3555049e02bca8c305ed67fba14764227ebf2d29030ebdb4691130f3\n",
      "  Stored in directory: /root/.cache/pip/wheels/83/e2/74/46c887b0989a51a7acee0c09551a3ae9d34b939fb4bea404a0\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=068e812a99cdc2f0f5ee31e805f7320ce5ddefefbdd12f03d650873ce3733b1f\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "Successfully built aitextgen fire\n",
      "Installing collected packages: fire, aitextgen\n",
      "Successfully installed aitextgen-0.5.2 fire-0.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting chess\n",
      "  Downloading chess-1.7.0-py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 288 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: chess\n",
      "Successfully installed chess-1.7.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install aitextgen\n",
    "!pip install chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T17:40:44.993125Z",
     "iopub.status.busy": "2021-12-03T17:40:44.992829Z",
     "iopub.status.idle": "2021-12-03T17:40:53.941487Z",
     "shell.execute_reply": "2021-12-03T17:40:53.940597Z",
     "shell.execute_reply.started": "2021-12-03T17:40:44.993088Z"
    },
    "id": "KBkpRgBCBS2_",
    "outputId": "629b3068-c9a6-407a-ea09-98773a0c50bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# GPT\n",
    "from aitextgen import aitextgen\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "#Tokenizer\n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "#Encoder-Decoder Model\n",
    "from transformers import EncoderDecoderModel\n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForCausalLM, RobertaConfig\n",
    "import torch\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T17:40:53.943515Z",
     "iopub.status.busy": "2021-12-03T17:40:53.943172Z",
     "iopub.status.idle": "2021-12-03T17:40:53.949018Z",
     "shell.execute_reply": "2021-12-03T17:40:53.948047Z",
     "shell.execute_reply.started": "2021-12-03T17:40:53.943471Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pel-uBULXO2L"
   },
   "source": [
    "## Load Trained Models for Chess Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T17:53:39.635197Z",
     "iopub.status.busy": "2021-12-03T17:53:39.634866Z",
     "iopub.status.idle": "2021-12-03T17:53:39.655137Z",
     "shell.execute_reply": "2021-12-03T17:53:39.654322Z",
     "shell.execute_reply.started": "2021-12-03T17:53:39.635137Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_float(element) -> bool:\n",
    "    try:\n",
    "        float(element)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def get_metrics(labels, predictions):\n",
    "    float_pred, not_float_pred = [], []\n",
    "    type_match = {\"float\":0, \"string\":0, \"diff\": 0}\n",
    "    for i in range(len(predictions)):\n",
    "        if is_float(predictions[i]) == is_float(labels[i]):\n",
    "            if is_float(predictions[i]) and is_float(labels[i]):\n",
    "                type_match[\"float\"] += 1\n",
    "                float_pred.append((float(labels[i]), float(predictions[i])))\n",
    "            else:\n",
    "                type_match[\"string\"] += 1\n",
    "                not_float_pred.append((labels[i], predictions[i]))\n",
    "        else:\n",
    "            #mismatch.append((labels[i], predictions[i]))\n",
    "            type_match[\"diff\"] += 1\n",
    "    mse = mean_squared_error(list(zip(*float_pred))[0], list(zip(*float_pred))[1]) if len(float_pred)!=0 else -1 \n",
    "    accuracy = accuracy_score(list(zip(*not_float_pred))[0], list(zip(*not_float_pred))[1]) if len(not_float_pred)!=0 else -1\n",
    "    type_match[\"float\"] /= len(labels)\n",
    "    type_match[\"string\"] /= len(labels)\n",
    "    type_match[\"diff\"] /= len(labels)\n",
    "    return mse, accuracy, type_match\n",
    "    \n",
    "def get_pred_token_encdec(labels):\n",
    "    new_label = np.zeros(len(labels), dtype=object)\n",
    "    for i in range(len(labels)):\n",
    "        new_label[i] = labels[i].split()[0][2:]\n",
    "    return new_label\n",
    "\n",
    "def get_pred_token_gpt(labels):\n",
    "    new_label = np.zeros(len(labels), dtype=object)\n",
    "    for i in range(len(labels)):\n",
    "        new_label[i] = labels[i].split()[-1]\n",
    "    return new_label\n",
    "\n",
    "def pred_enc_dec(model, tokenizer, data):\n",
    "    preds = np.zeros(len(data), dtype=object)\n",
    "    for i,d in enumerate(data):\n",
    "        input_ids = tokenizer.encode(d, return_tensors='pt')\n",
    "        sample_outputs = model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True, \n",
    "            max_length=5, \n",
    "            top_k=100, \n",
    "            top_p=0.7, \n",
    "            num_return_sequences=3\n",
    "        )\n",
    "        output = sample_outputs[0]\n",
    "        output = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        preds[i] = output\n",
    "    return preds\n",
    "        \n",
    "def pred_gpt(model, data):\n",
    "    preds = np.zeros(len(data), dtype=object)\n",
    "    for i, d in enumerate(data):\n",
    "        preds[i] = model.generate_one(max_length = 512, prompt = d, top_k = 100, top_p = 0.9, temperature = 0.9)\n",
    "    return preds\n",
    "\n",
    "def save_preds(prompts, preds, filename=\"out.csv\"):\n",
    "    out = np.zeros((len(preds), 2), dtype=object)\n",
    "    out[:, 0] = prompts\n",
    "    out[:, 1] = preds\n",
    "    pd.DataFrame(data=out, columns=[\"prompt\", \"prediction\"]).to_csv(filename, index=False)\n",
    "\n",
    "def save_metrics(filename, mse, accuracy, type_match):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"We have three cases. The first case the generated evaluation has the same type as the true evaluation\\n\")\n",
    "        f.write(\"In the case they are both real values (e.g. 1.0 and -2.0) we compute the MSE\\n\")\n",
    "        f.write(\"In the case they are both strings (#1 or 0-1) we compute the accuracy (exact match)\\n\")\n",
    "        f.write(\"The type mismatch is the fraction of times the types are the different for the generated evaluation and the true one\\n\")\n",
    "        f.write(\"Note: -1 for MSE or accuracy means that it was not computed\\n\")\n",
    "        f.write(\"-\"*100)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"-\"*100)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(f\"Matched floats: {type_match['float']}\\n\")\n",
    "        f.write(f\"Mean Squared Error: {mse}\\n\\n\")\n",
    "        f.write(f\"Matched string: {type_match['string']}\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy}\\n\\n\")\n",
    "        f.write(f\"Type mismatch: {type_match['diff']}\")\n",
    "        f.write(f\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T17:51:08.385144Z",
     "iopub.status.busy": "2021-12-03T17:51:08.384866Z",
     "iopub.status.idle": "2021-12-03T17:52:01.828917Z",
     "shell.execute_reply": "2021-12-03T17:52:01.828064Z",
     "shell.execute_reply.started": "2021-12-03T17:51:08.385116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Examples:  12746073\n",
      "Null Values\n",
      " input     0\n",
      "target    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['chess eval: Nf3 d5 e4 dxe4 Ng5 Nf6 d3 exd3 Bxd3 h6 Nxf7 Kxf7 Bg6+ Kxg6 Qxd8 Bf5 Qxc7 Nbd7 O-O e6 Nc3 Bc5 Qg3+ Kf7 Be3 Bxe3',\n",
       "       '7.0'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#array = np.loadtxt(\"../input/chess-evaluation-dataset/enc_dec_chess_evaluation.csv\", dtype=object, delimiter=\",\", max_rows=1_000)\n",
    "df=pd.read_csv('../input/chess-evaluation-dataset/enc_dec_chess_evaluation.csv', usecols=['input','target'], low_memory=True)\n",
    "print('Num Examples: ',len(df))\n",
    "print('Null Values\\n', df.isna().sum())\n",
    "\n",
    "test_size = 1_000\n",
    "test_dataset=df.sample(n=test_size,random_state = 5).reset_index(drop=True) # use a different random_state to hopefully get different sample\n",
    "test_dataset = test_dataset.to_numpy()\n",
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T17:55:10.010566Z",
     "iopub.status.busy": "2021-12-03T17:55:10.009813Z",
     "iopub.status.idle": "2021-12-03T17:55:10.014892Z",
     "shell.execute_reply": "2021-12-03T17:55:10.014024Z",
     "shell.execute_reply.started": "2021-12-03T17:55:10.010529Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = 100\n",
    "test_prompt, test_label = test_dataset[: , 0][:tmp], test_dataset[:, 1][:tmp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T17:52:51.975668Z",
     "iopub.status.busy": "2021-12-03T17:52:51.975407Z",
     "iopub.status.idle": "2021-12-03T17:52:54.185861Z",
     "shell.execute_reply": "2021-12-03T17:52:54.184946Z",
     "shell.execute_reply.started": "2021-12-03T17:52:51.975642Z"
    }
   },
   "outputs": [],
   "source": [
    "ai = aitextgen(model_folder=\"../input/gpt-finetuned-model/chess_task2_gpt_finetune_model_v1/chess_task2_gpt_finetune_model_v1\",\n",
    "               tokenizer_file=\"../input/gpt-finetuned-model/chess_task2_gpt_finetune_model_v1/chess_task2_gpt_finetune_model_v1/aitextgen.tokenizer.json\",\n",
    "              )#to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T17:55:18.832238Z",
     "iopub.status.busy": "2021-12-03T17:55:18.831818Z",
     "iopub.status.idle": "2021-12-03T17:58:54.589675Z",
     "shell.execute_reply": "2021-12-03T17:58:54.588761Z",
     "shell.execute_reply.started": "2021-12-03T17:55:18.832206Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpt_preds = pred_gpt(ai, test_prompt)\n",
    "save_preds(test_prompt, gpt_preds, \"gpt_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T17:58:54.591506Z",
     "iopub.status.busy": "2021-12-03T17:58:54.591271Z",
     "iopub.status.idle": "2021-12-03T17:58:54.596156Z",
     "shell.execute_reply": "2021-12-03T17:58:54.595492Z",
     "shell.execute_reply.started": "2021-12-03T17:58:54.591478Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt_preds_tokens = get_pred_token_gpt(gpt_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T17:58:54.597461Z",
     "iopub.status.busy": "2021-12-03T17:58:54.597144Z",
     "iopub.status.idle": "2021-12-03T17:58:54.609922Z",
     "shell.execute_reply": "2021-12-03T17:58:54.609380Z",
     "shell.execute_reply.started": "2021-12-03T17:58:54.597436Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt_mse, gpt_accuracy, gpt_type_match = get_metrics(test_label, gpt_preds_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T17:58:54.611525Z",
     "iopub.status.busy": "2021-12-03T17:58:54.611226Z",
     "iopub.status.idle": "2021-12-03T17:58:54.621639Z",
     "shell.execute_reply": "2021-12-03T17:58:54.620742Z",
     "shell.execute_reply.started": "2021-12-03T17:58:54.611499Z"
    }
   },
   "outputs": [],
   "source": [
    "save_metrics(\"gpt_metrics.txt\", gpt_mse, gpt_accuracy, gpt_type_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Encoder Decoder model, generate, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:40:16.047521Z",
     "iopub.status.busy": "2021-12-02T20:40:16.047241Z",
     "iopub.status.idle": "2021-12-02T20:40:28.088182Z",
     "shell.execute_reply": "2021-12-02T20:40:28.087407Z",
     "shell.execute_reply.started": "2021-12-02T20:40:16.047489Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ../input/chessevaluationmodel/FinetunedModel/added_tokens.json. We won't load it.\n",
      "loading file ../input/chessevaluationmodel/FinetunedModel/vocab.json\n",
      "loading file ../input/chessevaluationmodel/FinetunedModel/merges.txt\n",
      "loading file None\n",
      "loading file ../input/chessevaluationmodel/FinetunedModel/special_tokens_map.json\n",
      "loading file ../input/chessevaluationmodel/FinetunedModel/tokenizer_config.json\n",
      "loading file ../input/chessevaluationmodel/FinetunedModel/tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('../input/chessevaluationmodel/FinetunedModel')\n",
    "enc_dec_model = EncoderDecoderModel.from_pretrained('../input/chessevaluationmodel/FinetunedModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T22:14:58.089953Z",
     "iopub.status.busy": "2021-12-02T22:14:58.089667Z",
     "iopub.status.idle": "2021-12-02T22:55:47.321852Z",
     "shell.execute_reply": "2021-12-02T22:55:47.321001Z",
     "shell.execute_reply.started": "2021-12-02T22:14:58.089917Z"
    }
   },
   "outputs": [],
   "source": [
    "enc_dec_preds = pred_enc_dec(enc_dec_model, tokenizer, test_prompt)\n",
    "save_preds(test_prompt, enc_dec_preds, \"enc_dec_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T22:55:47.323813Z",
     "iopub.status.busy": "2021-12-02T22:55:47.323552Z",
     "iopub.status.idle": "2021-12-02T22:55:47.328431Z",
     "shell.execute_reply": "2021-12-02T22:55:47.327733Z",
     "shell.execute_reply.started": "2021-12-02T22:55:47.323778Z"
    }
   },
   "outputs": [],
   "source": [
    "encdec_preds_tokens = get_pred_token_encdec(enc_dec_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T22:55:47.330188Z",
     "iopub.status.busy": "2021-12-02T22:55:47.329734Z",
     "iopub.status.idle": "2021-12-02T22:55:47.345120Z",
     "shell.execute_reply": "2021-12-02T22:55:47.344361Z",
     "shell.execute_reply.started": "2021-12-02T22:55:47.330153Z"
    }
   },
   "outputs": [],
   "source": [
    "encdec_mse, encdec_accuracy, encdec_type_match = get_metrics(test_label, encdec_preds_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T22:55:47.347891Z",
     "iopub.status.busy": "2021-12-02T22:55:47.347308Z",
     "iopub.status.idle": "2021-12-02T22:55:47.355173Z",
     "shell.execute_reply": "2021-12-02T22:55:47.354444Z",
     "shell.execute_reply.started": "2021-12-02T22:55:47.347842Z"
    }
   },
   "outputs": [],
   "source": [
    "save_metrics(\"encdec_metrics.txt\", encdec_mse, encdec_accuracy, encdec_type_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
