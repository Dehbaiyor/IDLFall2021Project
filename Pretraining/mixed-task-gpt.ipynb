{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da9fe72b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:37:58.484800Z",
     "iopub.status.busy": "2021-12-02T15:37:58.483231Z",
     "iopub.status.idle": "2021-12-02T15:38:11.419506Z",
     "shell.execute_reply": "2021-12-02T15:38:11.418814Z",
     "shell.execute_reply.started": "2021-12-02T15:30:49.583626Z"
    },
    "papermill": {
     "duration": 12.951744,
     "end_time": "2021-12-02T15:38:11.419653",
     "exception": false,
     "start_time": "2021-12-02T15:37:58.467909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aitextgen\r\n",
      "  Downloading aitextgen-0.5.2.tar.gz (572 kB)\r\n",
      "     |████████████████████████████████| 572 kB 922 kB/s            \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (4.12.5)\r\n",
      "Collecting fire>=0.3.0\r\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\r\n",
      "     |████████████████████████████████| 87 kB 5.5 MB/s             \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: pytorch-lightning>=1.3.1 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (1.4.4)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from aitextgen) (1.9.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fire>=0.3.0->aitextgen) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire>=0.3.0->aitextgen) (1.1.0)\r\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.62.3)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (3.10.0.2)\r\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.18.2)\r\n",
      "Requirement already satisfied: torchmetrics>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.5.0)\r\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (21.0)\r\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (2.6.0)\r\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (2021.11.1)\r\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (1.19.5)\r\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (6.0)\r\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.3.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (3.3.2)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (0.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (2021.11.10)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (0.0.46)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (4.8.2)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (0.10.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=4.5.1->aitextgen) (2.25.1)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.8.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.6)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (2.0.2)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.42.0)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.8.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.35.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.15.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.6.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.6)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.3.6)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.19.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (59.1.1)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.37.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.5.1->aitextgen) (1.26.7)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.5.1->aitextgen) (4.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.5.1->aitextgen) (2021.10.8)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.5.1->aitextgen) (2.10)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.5.1->aitextgen) (3.6.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=4.5.1->aitextgen) (8.0.3)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers>=4.5.1->aitextgen) (1.1.0)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.2.4)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.7.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.2.7)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.0)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (0.13.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.7.2)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (5.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.0.7)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (4.0.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (21.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.2.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.1.1)\r\n",
      "Building wheels for collected packages: aitextgen, fire\r\n",
      "  Building wheel for aitextgen (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for aitextgen: filename=aitextgen-0.5.2-py3-none-any.whl size=575905 sha256=5d18c247bd2b2bcd6bb545be2a7031fe3e34edbfa9c79b020cfc3aa5033e139a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/83/e2/74/46c887b0989a51a7acee0c09551a3ae9d34b939fb4bea404a0\r\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=cf5e2faf129f020daef6bd80c1e6f993fc106d3913fb076e153c0e410d786d94\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\r\n",
      "Successfully built aitextgen fire\r\n",
      "Installing collected packages: fire, aitextgen\r\n",
      "Successfully installed aitextgen-0.5.2 fire-0.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddbb2006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:11.464031Z",
     "iopub.status.busy": "2021-12-02T15:38:11.463260Z",
     "iopub.status.idle": "2021-12-02T15:38:19.126871Z",
     "shell.execute_reply": "2021-12-02T15:38:19.127288Z",
     "shell.execute_reply.started": "2021-12-02T15:31:03.344990Z"
    },
    "id": "KBkpRgBCBS2_",
    "outputId": "629b3068-c9a6-407a-ea09-98773a0c50bf",
    "papermill": {
     "duration": 7.686915,
     "end_time": "2021-12-02T15:38:19.127468",
     "exception": false,
     "start_time": "2021-12-02T15:38:11.440553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45fbea58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:19.167659Z",
     "iopub.status.busy": "2021-12-02T15:38:19.167080Z",
     "iopub.status.idle": "2021-12-02T15:38:19.170638Z",
     "shell.execute_reply": "2021-12-02T15:38:19.171029Z",
     "shell.execute_reply.started": "2021-12-02T15:31:12.286398Z"
    },
    "papermill": {
     "duration": 0.025468,
     "end_time": "2021-12-02T15:38:19.171154",
     "exception": false,
     "start_time": "2021-12-02T15:38:19.145686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436f31e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:19.210874Z",
     "iopub.status.busy": "2021-12-02T15:38:19.210129Z",
     "iopub.status.idle": "2021-12-02T15:38:27.003864Z",
     "shell.execute_reply": "2021-12-02T15:38:27.003317Z",
     "shell.execute_reply.started": "2021-12-02T15:31:12.301048Z"
    },
    "papermill": {
     "duration": 7.815088,
     "end_time": "2021-12-02T15:38:27.004009",
     "exception": false,
     "start_time": "2021-12-02T15:38:19.188921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai = aitextgen(model_folder=\"../input/gpt-mixed-model/gpt_mixed_model\",\n",
    "               tokenizer_file=\"../input/gpt-mixed-model/gpt_mixed_model/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da18b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:31:35.953242Z",
     "iopub.status.busy": "2021-12-02T15:31:35.952908Z",
     "iopub.status.idle": "2021-12-02T15:32:00.379484Z",
     "shell.execute_reply": "2021-12-02T15:32:00.378115Z",
     "shell.execute_reply.started": "2021-12-02T15:31:35.953196Z"
    },
    "papermill": {
     "duration": 0.018029,
     "end_time": "2021-12-02T15:38:27.040589",
     "exception": false,
     "start_time": "2021-12-02T15:38:27.022560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ai.generate(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a68d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:34:39.871044Z",
     "iopub.status.busy": "2021-12-02T15:34:39.870399Z",
     "iopub.status.idle": "2021-12-02T15:34:41.724635Z",
     "shell.execute_reply": "2021-12-02T15:34:41.723771Z",
     "shell.execute_reply.started": "2021-12-02T15:34:39.871002Z"
    },
    "papermill": {
     "duration": 0.017849,
     "end_time": "2021-12-02T15:38:27.076345",
     "exception": false,
     "start_time": "2021-12-02T15:38:27.058496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ai.generate(prompt = 'summarize: def explain(item):\\n return item.explanation()')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d76c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:35:11.624569Z",
     "iopub.status.busy": "2021-12-02T15:35:11.624028Z",
     "iopub.status.idle": "2021-12-02T15:35:19.207451Z",
     "shell.execute_reply": "2021-12-02T15:35:19.206667Z",
     "shell.execute_reply.started": "2021-12-02T15:35:11.624532Z"
    },
    "papermill": {
     "duration": 0.017809,
     "end_time": "2021-12-02T15:38:27.112604",
     "exception": false,
     "start_time": "2021-12-02T15:38:27.094795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ai.generate(prompt= 'chess eval: e4 c5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169afa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:35:33.990479Z",
     "iopub.status.busy": "2021-12-02T15:35:33.989765Z",
     "iopub.status.idle": "2021-12-02T15:35:43.571271Z",
     "shell.execute_reply": "2021-12-02T15:35:43.570524Z",
     "shell.execute_reply.started": "2021-12-02T15:35:33.990424Z"
    },
    "papermill": {
     "duration": 0.018411,
     "end_time": "2021-12-02T15:38:27.149022",
     "exception": false,
     "start_time": "2021-12-02T15:38:27.130611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ai.generate(prompt= 'e4: e4 c5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43833c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:36:40.692874Z",
     "iopub.status.busy": "2021-12-02T15:36:40.692621Z",
     "iopub.status.idle": "2021-12-02T15:36:51.961092Z",
     "shell.execute_reply": "2021-12-02T15:36:51.960273Z",
     "shell.execute_reply.started": "2021-12-02T15:36:40.692845Z"
    },
    "papermill": {
     "duration": 0.01805,
     "end_time": "2021-12-02T15:38:27.184926",
     "exception": false,
     "start_time": "2021-12-02T15:38:27.166876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ai.generate(prompt= 'generate: return the explanation of item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f9d581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:27.227159Z",
     "iopub.status.busy": "2021-12-02T15:38:27.226583Z",
     "iopub.status.idle": "2021-12-02T20:35:56.251275Z",
     "shell.execute_reply": "2021-12-02T20:35:56.252604Z"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "18a0eb53-7de1-4a2f-c66e-fa4ac911530b",
    "papermill": {
     "duration": 17849.04994,
     "end_time": "2021-12-02T20:35:56.252852",
     "exception": false,
     "start_time": "2021-12-02T15:38:27.202912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50aca89aeea446ed9dd365523ba04deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66018524fa324c39857ff8f34daa810d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def sent_matching(self, match, entry=-1):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        self.sentences = []\n",
      "        if self.matching:\n",
      "            self.matching.append(' '.join(self.matching),''.join(self.matching))\n",
      "        if matching:\n",
      "            self.matching.append(' '.join(self.matching))\n",
      "        if matching:\n",
      "            self.matching.append(' '.join([self.matching]))\n",
      "        if entry:\n",
      "            self.matching.append(' '.join(self.matching) +''.join(self.matching))\n",
      "        else:\n",
      "            self.matching =''.join(self.matching) +''.join(self.matching) +''.join(self.matching +''.join(self.matching))\n",
      "        if self.matching:\n",
      "            if self.matching.\n",
      "==========\n",
      "\u001b[1m2,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "==========\n",
      "\u001b[1m3,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def get_insert_package_value(self, package_name, package_type):\n",
      "        \"\"\"\"\"\"\n",
      "        assert package_type == package_type\n",
      "\n",
      "        defined_package_parameter(package_type):\n",
      "            package_type = get_package_type(package_type)\n",
      "            return tuple(package_value for package_type in package_type)\n",
      "==========\n",
      "\u001b[1m4,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "dummarize: def update_contents(self, contents, section_type, page_type):\n",
      "        \"\"\" \n",
      "        \"\"\"\n",
      "        self._check_contents(contents, contents, page_type, page_type) Updates the updated contents of the updated query and appropriated contents.\n",
      "==========\n",
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "==========\n",
      "\u001b[1m6,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m6,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 c5 Nf3 d6 d4 cxd4 Nxd4 Nf6 Nc3 a6 Bc4 e5 Nf3 Nc6 Bg5 Be7 Qe2 Be6 Bxe6 fxe6 Nxc6 bxc6 O-O-O Qc8 Bxf6 Bxf6 Nb1 O-O Nd2 Rb8 b3 Bg4 f3 Bd7 Qe2 Nd4 Qg4 c5 exd5 exd5 Qe2 c4 Nd4 Bc5 g4 Nc6 h3 Qe5+ Kh8 Bc4 Bf4 Nc6 Qf4 Nf5 Kg8 Bxf7 Rxf7 Nxd6 Rbf8 Qg2 Rxg2 Rxg2+ Qxg2 Qe4 Nd4 Bxd4 cxd4 Qb7 Nf5 Qa7 Rxd4 c3 Qf5 Rd7 c2 Rc7 d3 Rd7 c1=Q+ Rxc1 Qxc1+ Kb2 Qd2+ Ka3 Qa5+ Kb2 Qd3 0-1\n",
      "==========\n",
      "\u001b[1m7,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m7,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "        return exec_cmd_info\n",
      "\n",
      "    # Get the MemoryMemoryList or access to the tuple\n",
      "    match = Deployment.Get_MemoryList(\n",
      "        Storage.Storage)\n",
      "    # Get the MemoryList or MemoryList\n",
      "    # Tuple\n",
      "    # Get the MemoryList (be detection)\n",
      "    # Get the next feature elements from Get\n",
      "\n",
      "    # Process\n",
      "    for Get the MemoryList in the CrostRequestoryList.\n",
      "\n",
      "    # Get them instance from the Geteric instance from the\n",
      "    # View, skip them to the Getericinal MemoryList\n",
      "    # MemoryList(1.\n",
      "==========\n",
      "\u001b[1m8,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m8,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def non_message_msg(message_msg):\n",
      "    \"\"\"\"\"\"\n",
      "    # Converting message message to json dictionaries\n",
      "    data = {}\n",
      "\n",
      "    if message_msg_to_json(message_msg):\n",
      "        duplicate_key = message_msg_to_json_to_json(message_msg_to_json)\n",
      "\n",
      "    return data Converts a message and message representation.\n",
      "==========\n",
      "\u001b[1m9,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m9,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Generates a general minus between post. def generate_minus_inspect(self, general_value):\n",
      "        \"\"\"\"\"\"\n",
      "        if general_value is None:\n",
      "            return None\n",
      "        minus_spec_string = general_value.findall(self.name, minus_spec)\n",
      "        minus_spec = self.minus_inspect_points(general_value.center_points(general_value.center_points).values)\n",
      "        if minus_spec > 0:\n",
      "            minus_spec = minus_spec\n",
      "        else:\n",
      "            minus_spec = self.minus_spec\n",
      "\n",
      "        if minus_spec < 1:\n",
      "            minus_spec = general_value.center_points(general_value.center_point\n",
      "==========\n",
      "\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "e4 : d4 d5 Nf3 Nf6 Bf4 Bf5 e3 e6 c3 Bd6 Bxd6 Qxd6 Bd3 Ne4 Bxb7 Rb8 Qa4+ Qd7 Nbd2 Nxd2 Nxd2 Nf6 O-O O-O Rfc1 a5 c4 dxc4 Bxc4 Rfc8 Rc3 Nd5 Rxc7 Nxc7 Bxc7 Qxc7 Qxc7 bxc5 Rc1 Rxc7 Rxc7 Rc1 Rxc5 Rxc3 Bb4 Rc5 Ba3 Rxb5 Bb6 a3 e4 Rb5 e5 Re1 exd4 Rb5 g6 Rb7 Rd5 Rb8+ Kg7 Rb7 Rd3 Rb7 Re3 Rb6 Re2 a4 Rxe4 a5 Re1+ Kg2 Ra3 Ra7 Re3 Rb7 Re4 Rb8 Re5 Rb7 f5 Rb6 Re5 Rc7 Kg7 Rb7 Ra3 Rb6 Rb3 Kf1 Kf6 Ke2 Ke5 Kd3 Kd4 Rc8 Ke3 Re8+ Kd3 Ra8 Ke3 Ra5 Kf2 Ra6 Re6 Ra5 Re6 Ra4 Re4 Rxd4 Kf3 Ra3+ Kg2 Kg2 Kh2 Rb3 Kg1 Kf3 Ra3+ Kf2 Ra2+\n",
      "==========\n",
      "\u001b[1m11,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m11,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def _get_rules_with_memoize(self, memoize):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        if memoize:\n",
      "            return None\n",
      "\n",
      "        for rule in memoize:\n",
      "            if rule in memoize:\n",
      "                return rule\n",
      "\n",
      "        raise ValueError(\"Running for rule %s\" %\n",
      "                       memoize) Return memoize for the an IPLS in the memoize\n",
      "==========\n",
      "\u001b[1m12,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m12,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 e5 Nc3 Nf6 d4 exd4 Nxd4 Nc6 Nxc6 dxc6 Qxd8+ Kxd8 f3 b5 Be3 Be7 a3 b4 axb4 a6 Na4 c5 c3 axb4 c4 Kf2 Ba6 Ke2 Bb5 O-O-O Ke7 c4 g5 h3 Bxd4 Bxd4 h6 Bxf6+ Kxf6 f4 g4 hxg4 fxg4 f5 c3 bxc3 Bxc3 f6+ Kf7 Rhf1+ Ke6 f7 Rg8 fxg8=Q Bxg8 Rxd7 Kxd7 Kd3 Ke7 Ke4 Kf7 f6 Kg6 Kd5 Kf6 Kd4 Ke6 Kc5 Kd7 b5 Kc6 b6 Kb7 b7 Kc6 Kd4 Kd6 Ke5 Kc6 Kd5 Kd7 Ke4 Kc6 Kf5 Kc5 Kf6 Kd6 Kg6 Kc5 Kf6 Kd6 g4 Kd5 Ke7 Ke5 Kf7 Kd6 g5 Kd5 Kf6 g6 Kg8 f7+ Kg8 f8=Q+ Kh8 Qe7 Kg8 Qff8# 1-0\n",
      "==========\n",
      "\u001b[1m13,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m13,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def get_modules(region,\n",
      "                        key=None,\n",
      "                        signature=None,\n",
      "                        remote_orientation=None,\n",
      "                        environment=None):\n",
      "    \"\"\"\n",
      "        \n",
      "    \"\"\"\n",
      "\n",
      "    if region is None:\n",
      "        region = reference_string()\n",
      "        if environment is None:\n",
      "            session = os.environ.get(\"SEBUG_NAME, \"\")\n",
      "        else:\n",
      "            groups = [\"SEBUG_MODED\"]\n",
      "    elif key is None:\n",
      "        environment = ''\n",
      "    else:\n",
      "        environment = \"region\"\n",
      "\n",
      "    if remote is None:\n",
      "        region = ''\n",
      "\n",
      "    if local is None:\n",
      "        region = ''\n",
      "    if region is None:\n",
      "        remote = ''\n",
      "\n",
      "    if operation:\n",
      "        envir\n",
      "==========\n",
      "\u001b[1m14,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m14,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "e4 : e4 e6 d4 Bb4+ c3 Bxc3+ bxc3 d6 Nf3 d5 e5 Ne7 Bd3 Ng6 O-O Nc6 Re1 Nf4 Bxf4 exf4 Qb3 fxe3 Rxe3+ Kf8 Re1 Ne5 Nxe5 Bxe5 Rxe5 Rxe5 dxe5 Rxe5 Bxe5 Qe8+ Kf8 Qb5+ Kg8 Qxh7+ Kf8 Qh6+ Ke7 Bf5 Qd3 Qb1+ Kd6 c4+ Kc5 c6 Bb6 d5+ Kb6 Qxb7+ Kxb7 Bb2 Kxb7 0-1\n",
      "==========\n",
      "\u001b[1m15,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m15,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "callback(self),\n",
      "                        root_error=True,\n",
      "                        callback=self._callback,\n",
      "                        details=self._details,\n",
      "                        retries=self._rules,\n",
      "                        body=self._body,\n",
      "                        details=self._getbounds,\n",
      "                        retries=self._details,\n",
      "                        retries=self._retries,\n",
      "                        equal_callback=self._equal_callback)\n",
      "    return\n",
      "    return True Calls the inputs.\n",
      "==========\n",
      "\u001b[1m16,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m16,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "e4 : d4 Nf6 c4 e6 Nc3 Bb4 Qc2 O-O a3 Bxc3+ Qxc3 c6 Nf3 d5 e3 Nbd7 cxd5 exd5 Bd3 Nb8 O-O Re8 Bd2 Ne4 Rc1 Nd6 Ne5 Nf5 Nc3 Nbd7 f3 Nd3 Rc2 Ne4 Nxe4 fxe4 fxe4 dxe4 Nf5 Bxf5 Rxf5 Qd7 Rc3 Nf6 Rc5 Qf7 Rcc1 e3 Bxe3 Nxe3 Rxe3 exd2 Qxd2 g6 b3 Qe7 a4 Re3 Qc2 Re8 Qc4 Qg5 Qc5 Re2 Qc4 Rxc2 Rxc2 Qf5 Rd2 Kf8 Kf2 Qe6 Rd3 Qf5+ Ke2 Qxg2+ Kf1 Qe2+ Kg1 Qxe3+ Kh1 Qe1+ Kg1 Qe1+ Kh2 Qf2+ Kg1 Qe1+ Kg2 Qe7 Rf2 Qd1+ Kf2 Qf1+ Ke3 Qg1+ Kf3 Qe3+ 0-1\n",
      "==========\n",
      "\u001b[1m17,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m17,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 e5 Nf3 Nc6 Bc4 Nf6 Ng5 d6 Nxf7 Kxf7 Qf3+ g6 d4 e4 Qe2 d5 Bb3 Be6 Nc3 Qd7 f3 exf3 Qxf3+ Ke8 Rxf8+ Kd8 O-O Bg7 d5 Nb8 Bg5 Re8 Qf2+ Kc8 Nd1 Na6 -10.0\n",
      "==========\n",
      "\u001b[1m18,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m18,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 e5 Nf3 Nc6 Bc4 Nf6 Nc3 Bb4 O-O Bxc3 bxc3 d5 exd5 Nxd5 d4 exd4 cxd4 O-O Re1 Re8 Qd2 a6 Bd2 Ne7 Bg5 c6 Ne4 Nf5 Nxf6+ Qxf6 g4 Ne7 h4 h6 h5 Nf5 Rh2 b5 Qd1 a5 Rh4 Qc7 Qh1 Ba6 Bh3 g6 Ng3 Qc4 Ne4 Re7 Ng5 hxg5 Bxg4 g5 Bxg5 10.0\n",
      "==========\n",
      "\u001b[1m19,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m19,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "e4 : d4 Nf6 Nf3 g6 Bf4 Bg7 e3 O-O Be2 d5 O-O c6 c3 Nbd7 Nbd2 b6 a3 Bb7 Qc1 Qc7 Re1 Rfd8 Rad1 e5 dxe5 Nxe5 Nxe5 Bxe5 Rxd8 Rxd8 Nxe5 Bxe4 Bxh6 Bd5 Bf4 Bxf4 exf4 Qd7 Re2 Re8 g3 Qd6 Qxf4 Qe7 Bf6 Qxf6 Qxf6 Rxe1+ Bxe1 Rd2 Qe7 h5 h3 Kg7 a4 a5 Kg2 a4 Bd2 a3 bxa3 Rxa3 Qf7+ Kh6 Qe6 b5 Kh2 Ra2 Qf8+ Kh7 Qe7+ Kh6 Qxh7+ Kg5 Qf5+ Kf6 Qf3+ Ke7 Qxg3+ Kd7 Qf4 Kc7 Qg5 Kd7 h4 Ke7 h5 Kd7 h6 Ke6 h7 Kf6 g4 Ke7 g5 Kf8 Kg1 Ke7 h7 Kf7 g6+ Ke6 g7 Kf6 h8=Q+ Kxg7 #4\n",
      "==========\n",
      "\u001b[1m20,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m20,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 c5 Nf3 Nc6 Bb5 a6 Bxc6 dxc6 e5 Bg4 h3 Bxf3 Qxf3 e6 d3 h6 Qd1 Ne7 Nd2 Ng6 O-O Be7 b3 Nf6 Bb2 O-O f4 Nh7 Nf3 Nf5 Ng5 g6 Rae1 O-O Nh7 Nxh7 Kxh7 Nf3 Nxf4 Qxf4 Bd6 Bg5 Be7 Bd5 Qd7 e4 Rad8 exf5 exf5 Qh4+ Kg8 Bxe7 Qxe7 dxe7 Qxe7 Bxb6 Rxd1 Kh2 Bxc5 axb5 axb5 Rd6 Rxa6 Rf8 b6 Qe6 Ra8+ Kh7 Rxa7 Qg4+ Kh1 Qh5 b7 Qh4 b8=Q Qxh3 Qg8+ Kh7 Qf7+ Kh6 Qf8+ Kh5 Qf4+ Qg4+ Qxg4+ Kxg4 b4 Kf3 b5 f6 b4 f5 b6 f4 c3 Kf3 b2 Ke4 b1=Q f3+ Kh4 f2 Kh3 f1=Q+ Kh2 Qd4+ Kh1 Qh4# 0-1\n",
      "==========\n",
      "\u001b[1m21,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m21,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: d4 d5 c4 e6 Nc3 Nf6 e3 a6 cxd5 exd5 Nf3 Be7 Bd3 b5 O-O c6 O-O b4 Nb5 O-O Na3 Bd7 Ne5 Be8 b3 a5 Ba6 Re8 Bb2 a4 bxa3 Bxa3 Rb1 Bxb2+ -5.0\n",
      "==========\n",
      "\u001b[1m22,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m22,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "e4 : d4 e5 dxe5 Nc6 Nf3 Bc5 e3 Nge7 c3 O-O Bd3 d6 Nd4 Bb6 O-O Re8 Qe2 Bg4 f3 Bxe2 Qxe2 Nxf3+ Kh1 Bxd4 cxd4 Nxd4 Qc2 Qe7 Nc3 Nc6 Bf4 Nxd4 Bxd4 Rxe3 Be2 Nd5 Bd2 Nxf4 Rxf4 Bxf4 Ne4 Re8 Ng3 Re8 Raf1 h6 Nf5 Kh8 Ng3 Rxe3 Nxe3 Be5 Qxe6 Rxe6 Nf5 Re8 h4 Kh7 Kg1 Kg6 g3 h5 h5+ Kf6 Bc3 Re4 b3 a5 a3 a4 bxa4 bxa4 Ra8 Ra6+ Kf5 0-1\n",
      "==========\n",
      "\u001b[1m23,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m23,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Create a `b` model and set the value in a given base of the given value. def build_value(self, plane_value, copy=None):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        if copy:\n",
      "            copy = self.copy()\n",
      "\n",
      "        if copy:\n",
      "            copy = self.copy(self.copy)\n",
      "\n",
      "        if copy:\n",
      "            copy = self.copy()\n",
      "\n",
      "        for value in copy:\n",
      "            if copy.pop(value) or copy.pop(value) or copy.pop(self.copy):\n",
      "                copy = self.copy()\n",
      "                copy = self.copy([self.copy[value]]])\n",
      "\n",
      "            if copy.pop(self.type) in self.copy(self.copy[value]) or copy.pop(self.type) in copy.pop\n",
      "==========\n",
      "\u001b[1m24,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m24,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "e4 : e4 c5 Nf3 Nc6 Nc3 e6 Bb5 a6 Bxc6 dxc6 O-O Bd6 d3 b5 Qe2 Ba6 Rd1 Qc7 e5 Ne7 Ne8 d4 cxd4 Nxd4 O-O f4 Nc5 b4 Ne4 Nxe4 Qxe4 Bb2 Ne7 Qe2 a5 Rad1 Rfd8 h3 Ba6 Kh2 c5 Rd5 Qc6 f5 Qd7 Ng5 Be2 Nc6 Rd7 Rd7 Rad1 cxd4 Rxd4 Qc6 Nf3 Ba4 Qe4 Bxc2 Qf4 Qd7 Qe5 Qd2 Re1 Qc7 Qe4 Bxe2 Qxe2 a4 Re2 b4 Red2 Rxd7 Rxd7 Rc8 Re7 Qd8 Rxd7 Rxd7 Qxd7 Rxd7 Nd4 Kf2 Nc6 a3 a3 b3 Nb8 a4 Bb5 Nc2 Bxc2 bxc4 Nd7 c5 Nd5 Kb3 f6 Kc4 Ne3 Nb3 Ng2 Nd2 Ne4 Kb5 Kd4 Kxa4 Kc6 Kd3 Kb5 Kc2 Nc4 Kb1 Na5 Kc2 Nc4 Kb2 Na5 Kc2 Nc4 Kb2 Nd2 Kb3 Nc4+\n",
      "==========\n",
      "\u001b[1m25,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m25,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "O eval: d4 Nf6 c4 e6 Nc3 Bb4 e3 d5 a3 Bxc3+ bxc3 Nbd7 c4 c6 Ne2 O-O Ng3 Re8 Be2 e5 O-O e4 Bxa6 bxa6 Nb5 Ba6 a4 c5 f3 cxd4 cxd5 Ne5 Rb1 Nd7 Qc2 Nc5 Rb7 Na4 Ba3 Rc8 Rb1 Rb8 Rxf7 Kxf7 Nf4 Rc8 Qb2 g6 e4 Rb8 Be1 h5 h3 Rc8 g4 Kg7 Rg1 Rb8 Bf2 Qd6 Rg2 Qc7 Bf1 f6 Ra1 Rc8 gxh5 gxh5 Be2 Qe7 e5 Nb3 Rb2 Nd4 Bh7 Rb8 Ra1 Qc7 Ra8 Rc3 Be3 Nc2 0.6\n",
      "==========\n",
      "\u001b[1m26,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m26,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "e4 : e4 e5 Nf3 Nc6 Nc3 Nf6 Bb5 Nxe4 d4 Nxd4 Qxd4 d5 Qe3 Bd6 O-O-O O-O Bxc6 bxc6 f3 d4 Qe2 Bf4+ Kb1 a5 Bg5 h6 Be3 Bf4+ Ka1 Qe7 g3 Rab8 b3 Ba6 c3 Bb4 Rxd4 Bxc3+ Qxc3 e4 Qxc6 Qxc6 Rxd4 e3 c4 Rb2+ Kb1 Rd8 Rhd1 h5 Rb4 Rxb4 cxb4 Rb8 Rc4 Rxb3+ axb3 Rxb3+ Kc2 Rf3 Rd5 Kf8 Rxa5 Rxe3+ Kd2 Rc3 Rb5 Ra3 a4 Rb3 Ra6 Ke7 Ra7+ Kf6 Ra8 Ke5 Ra6 f5 Ra7 g6 Ra8 g5 Ra6 g4 Ra5+ Rd5 Rxd5+ Kxd5 Rxh5 gxh3 a5 f4 Ke2 Kf5 Kf3 Kg5 Ke3 e3 Kf3 e5 g3 e2 g4 e2 g5 f3 gxf6 Kxf6 Kf4 Kf7 Kg5 Kg7 Kf5 Kf7 Ke5 Kf7 Kf5 Kf6\n",
      "==========\n",
      "\u001b[1m27,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m27,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 e5 Nf3 Nc6 Bb5 a6 Ba4 Nf6 O-O Be7 d4 exd4 Nxd4 Nxd4 Qxd4 d5 exd5 Nxd5 Qxd5 Qxd5 Bxd5 Nc6 Nc3 Be6 Bd3 O-O Be2 Rfd8 Be3 Bf6 Bxf6 gxf6 Ne4 Be7 Rad1 Rad8 Rxd8+ Rxd8 Rd1 Rxd1+ Kxd1 Rd8+ Ke2 c5 Nf5 f5 Na4 b6 Ne5 Rd3+ Kf1 Bd4 Bb5 Bc4+ Kf1 Kg7 Kg1 Kg6 Kf1 Bc3 c3 Bd4+ Ke1 Ba7 Bc4 Bc6 Bb5 b5 Kd2 a5 Nd2 b4 Kd2 b3 axb3 axb4 Nxb3 h5 Kf1 h4 Kg1 h3 g4 fxg4 fxg4 hxg4 hxg4 Kf6 Ke1 Ke5 Kf1 Kd4 Kg2 Kc3 Kg3 Kc2 Kg3 Kd3 Kf3 Kc2 Ke4 Kd2 Kf3 Ke3 Kd1 Kf2 Ke4 Bc6+ Kf5 Bb7+ Ke6 c4 Kd7 d5 Kf6 c5 Ke6 c6 Kd6 c7\n",
      "==========\n",
      "\u001b[1m28,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m28,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "e4 : e4 c6 d4 d5 exd5 cxd5 Bf4 Nc6 Nc3 Nf6 e3 Bg4 Be2 e6 h3 Bxf3 Bxf3 Bb4 a3 Bxc3+ bxc3 O-O Qd2 Ne4 Qf4 Nb6 O-O a5 Rfe1 b5 Rac1 a4 Qc3 h6 c4 bxc4 c3 Nd7 cxd5 exd5 c4 Nf6 cxd5 Nxd5 Qd4 Nxc3 Rxc3 c5 Qf4 Nf6 Bxh6 gxh6 Qh5 0-1\n",
      "==========\n",
      "\u001b[1m29,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m29,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Function if an exception is Fnonable. def _execute(self, trace):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        return copy.deepcopy(self.execute(trace) + self.execute(b'\\n' + self.absolute_name)\n",
      "==========\n",
      "\u001b[1m30,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m30,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def get_gateway(self, gateway, sample_type):\n",
      "        \"\"\"\n",
      "\n",
      "        \"\"\"\n",
      "        db = Gateway()\n",
      "        return db.fetchone_key('gateway_fetch').get(ref=gateway) Gateway a Gateway object.\n",
      "==========\n",
      "\u001b[1m31,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m31,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarized=True,\n",
      "                           random_basical_size=False,\n",
      "                           stage_size=4,\n",
      "                           stage_size=stage_size,\n",
      "                           stage_size=stage_size,\n",
      "                           version_in=True,\n",
      "                           verbose=False,\n",
      "                           stage_size=False):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    # Return the digits\n",
      "    return digits.DIGI_DIGITS(mode=mode, stage_size=stage_size, version_in=version_in,\n",
      "                           stage_size=version_in,\n",
      "                           stage_size=stage_size, version_in=version_in, version_in=version_in,\n",
      "                           version_in=version_in, version_in=version_in, version_in=version_in,\n",
      "                           version_in=version_in, version_in=version_in,\n",
      "                          \n",
      "==========\n",
      "\u001b[1m32,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m32,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "e4 : d4 c5 d5 d6 Nf3 Nf6 Nc3 g6 g3 Bg7 Bg2 O-O O-O a6 e4 b5 a4 b4 Nd5 Nxd5 exd5 h6 a5 e6 axb4 axb4 c3 bxc3 bxc3 Bg4 Ne1 Na6 Be3 Nxc3 bxc3 Bxa1 Qxa1 Rxa1 Rxa1 Rb8 Qa4 Rxb2 Nc2 Rb3 Qa4 Rb1+ Rxb1 Bxb1 Qa6 Qb8 Qc2 Bf8 Nb4 Qa8+ Kg7 Qc6 Qxc6 dxc6 Bg7 Ne1 Qb5 Ne3 Qb2 Nd5 Qc1+ Kg2 Qe1 Qb5 Qc1 Qd2 Qc4 Qe1 f5 Qe3 Bh3+ Kf1 Bd7 Nb4 Bc8 Nc6 Qb7 Ke2 Qc8 Ke3 Qc6+ Kd3 Qc7 c4 Qb6+ Kd2 Qc6 Kd3 Bf3+ Kc2 Qc5+ Kb2 Qd6+ Kb3 Qd7 Nc2 Kc3 Qc3+ Kd1 Ke3 Ke1 f4 gxf4 Qxf4 Qc2+ Ke4 Qc4+ Ke5 Ne1 Kd6 Qd3+ Kc5 Qd5+ Kd\n",
      "==========\n",
      "\u001b[1m33,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m33,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 e6 d4 d5 Nc3 dxe4 Nxe4 Bb4+ c3 Ba5 Bd3 Bb6 Nf3 Nf6 Ng5 h6 Nxe6 Qe7 O-O Qxe4 Re1 Qd5 Nf5 Qxf5 Qxd5 exd5 Bg5 Nc6 Bxf6 gxf6 cxd5 Ne5 d6 Nc6 Nd5 Nxd4 Bxd4 Bc5 Rad1 Bf2+ Kxf2 hxg5 Nxg5 Rh5 h4 Rh7 Bxg5 fxg5 Qxg5 Rh6 Qxh5 O-O-O Bg6 Rf8+ Kg1 Rf3 Kf1 Rf8 -2.2\n",
      "==========\n",
      "\u001b[1m34,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m34,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Get a new authenticated by each timeout. def get_new_authenticated(cls, new_id, patch_id):\n",
      "        \"\"\"\"\"\"\n",
      "        # The package can be found.\n",
      "        return cls._connect_connection(cls._conn, new_id, patch_id)\n",
      "==========\n",
      "\u001b[1m35,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m35,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "        d3 d4 Nf3 Rb8 a4 h5 h3 g5 Nh2 Nh6 e4 Bg7 Nb3 dxe4 dxe4 Nf5 Be3 b6 Be2 O-O O-O Bb7 f3 Nc6 Nc3 Nd4 Bxd4 exd4 Qxd4 Qe7 Rab1 Rad8 b4 a5 Rfd1 axb4 Nd5 Bxd5 exd5 Nd4 c4 Nf4 Qd2 Nxe2+ Qxe2 Nd4 Kh2 Qg5 g3 h4 Rf1 h3 Rf2 hxg2 Rxg2 Qf4+ Qxf4 Rxf2+ Bg2 Re2 Rc1 Ne2 Rc2 Rxd3 Rcb2 Rd1 f5 cxb5 axb5 Bxb5 Rb3 Bc6 c5 Rc3 Rdd3 Rb8 a5 Kf7 a6 Rd5 a7 Ra5 Rb7+ Ke8 a8=Q+ Kf7 Qb7+ Kg6 Rg2+ Kf6 Rxg3 Kg5 Rc3 Ra5+ Kf4 Ke6 Rc5+ Kf6 Re5 Rxb6 Bxb6 g4 hxg4 Kxg4 Kg2 Kg4 Kxf4 Kg5 Kf3 Kg6 Ke4 Kg5 Kd5 Kg4 Ke4 Kg3 Ke3 Kg2 Ke2\n",
      "==========\n",
      "\u001b[1m36,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m36,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 e5 Bc4 Nc6 Nf3 d5 exd5 Nxd4 Nxd4 exd4 d3 Nf6 O-O Bc5 Qh5+ g6 Qh4 Nxd5 Bxd5 Bxd5 Qxd5 Re1+ Be7 Bg5 Rd8 Bc4 Be6 Bxd5 Bxd5 Qxd5 Re4 Bxe4 Qxe4 O-O Re1 Rad8 Re1 Rd2 b3 Qg2+ Kh1 Rd1 Qe3 Qg3 h3 h6 g4 g5 Kg2 Qxe3 Rxe3 Rd3 Re1 -10.0\n",
      "==========\n",
      "\u001b[1m37,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m37,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " = get_root_type_table(name, root_name, name, root_name)\n",
      "        return root_name\n",
      "==========\n",
      "\u001b[1m38,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m38,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "==========\n",
      "\u001b[1m39,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m39,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 e5 Nf3 Nc6 Nc3 d6 Bc4 Be7 O-O Nf6 d3 O-O Bg5 Be6 Bxe6 fxe6 Ng5 Qd7 Bxf6 Qxf6 Nxe7+ Qxe7 f4 Ne7 Qf3 Nf5 Qxf5 Qxf5 Rxf5 Kh8 Raf1 b6 Kf2 Rf7 g4 g6 h3 h5 g5 Rac8 Kg3 h4+ Kh2 Rf8 g6 Nxg6 Ra8 Rh5+ Kg8 Kg3 hxg3 fxg3 Rxg6+ Nf3 Rf6 Rh8+ Kg7 d4 Rf7 Rd8 Rff1 d5 Rxe3 dxe4 Rf8 Ne1 Rxf8 Rxf8 Kxf8 Kg4 Ke7 Kg3 Kd6 Nd4 Kc5 h4 Kd4 h5 Kc3 h6 Kxc2 h7 Kc3 h8=Q Kxc2 Qf6 Kd3 Qxc6 Ke2 Qc8 Kd2 Qxc7 Ke2 Qc3 Ke1 Qd5 Kf1 Qc4 Ke1 Qc2 Kf1 0.0\n",
      "==========\n",
      "\u001b[1m40,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m40,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "\n",
      "    \"\"\"\"\"\"\n",
      "    for i, value in enumerate(image_params_to_pdf.params):\n",
      "        if argument_param is None:\n",
      "            return\n",
      "\n",
      "    # create the image or address\n",
      "    # assume image\n",
      "    for i in argument_params:\n",
      "        image = image.assign_image().assign_image(image, **arks)\n",
      "        if image:\n",
      "            return\n",
      "\n",
      "    return image Create assignment image from the image, return an image or assignment image.\n",
      "==========\n",
      "\u001b[1m41,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m41,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "e4 : d4 Nf6 c4 e6 Nf3 d5 Bg5 dxc4 e4 b6 Bxc4 Be7 O-O Bb7 Nbd2 Nbd7 a4 a6 a5 b5 Bb7 Qc2 O-O Rac1 Be4 Nxe4 Nxe4 Qe2 Nd6 Nd3 Bxd3 Qxd3 c6 Rfd1 Rc8 h3 f6 d5 Bd5 Bb3 Nf5 Qe3 Qd5 Qe2 Qc4 Qxc4 Bxc4 Rxc4 Ne3 Rc1 Ra7 Rd2 h5 Rb1 b4 Bg1 g6 Rbd1 Rc2 h4 g4 hxg4 hxg4 Rd2 Rxd2 Rxd2 Kg7 Kf1 Kf7 Ke2 Ke7 Ke3 Kd6 g5 Nd5+ Ke2 Kc5 Rxb4 Nf4+ Ke3 Ng2+ Kf4 Nf4 Ra4 Nh3+ Kg3 Nd4 Ra3 Nxe2+ Kf4 Nd4 Rd3 e5+ Ke3 e4 Rd1 c5 Rd2 Rxd2 Kxd2 Kc4 g6 Kxd2 Kxe4 Kd1 Kd3 Ke1 1/2-1/2\n",
      "==========\n",
      "\u001b[1m42,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m42,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Update the given captions. def generate(cls, switch='/', capt=1.0, capt=[], capt=[], 'draw', capt=[], capt=[], min=[], val=[], capt=[],\n",
      "            start=[],\n",
      "            epu=[],\n",
      "            key= '',\n",
      "            quare_ref=[],\n",
      "            ann=[],\n",
      "            vertic_ref=[],\n",
      "            quare_date=[],\n",
      "            date=[],\n",
      "            method='home',\n",
      "            home=[],\n",
      "            default_dim=[',',\n",
      "            cls=[],\n",
      "        ):\n",
      "        \"\"\"\"\"\"\n",
      "        if cls is None:\n",
      "            raise ValueError(\"Coverhing generated class '%s'\" % (s)\n",
      "        if quare_date:\n",
      "            quare_date\n",
      "==========\n",
      "\u001b[1m43,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m43,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "e4 : d4 b6 Nc3 Bb7 e4 e6 f3 Bb4 Bd3 d5 e5 Ne7 Ne2 a6 O-O O-O f4 c5 Nf4 d4 Ne4 Nd5 Bd2 Nxd5 exd5 Bxd2+ Qxd2 exd5 Nxd5 Qxd5 c4 Qe6 b3 Qh6 h3 f6 f4 g5 fxg5 fxg5 Rae1 Ng6 h4 Qd8 Qf3 Nf8 g3 Qd6 g4 h5 gxh5 Nxh5 Qxh5 g4 Qh7 Re5 Kf7 Re1 Rae8 R1e2 Rxe5 dxe5 Qe7 h5 Qc7 h6 Qf7 Qg5 Ke8 h7 1/2-1/2\n",
      "==========\n",
      "\u001b[1m44,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m44,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "generate: Format the `f` that could be used in ``f``. def f(self, args):\n",
      "        \"\"\"\n",
      "        \n",
      "        \"\"\"\n",
      "        return self.explain.f(*args, **kwargs)\n",
      "==========\n",
      "\u001b[1m45,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m45,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "''\n",
      "    \n",
      "    '''\n",
      "    p = OrderedDict()\n",
      "    for name in __details():\n",
      "        p['p'] = __global_page__(name)\n",
      "        if name in salt.utils.chain.ResultsForm.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Screen.Sc\n",
      "==========\n",
      "\u001b[1m46,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m46,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 e6 d4 d5 exd5 exd5 Bd3 Nf6 Nf3 Bg4 O-O Nc6 Re1 Be7 Be3 O-O c3 a6 Nbd2 Qc7 Qb3 b5 a4 a5 b4 axb4 axb5 Na5 Qxb7 Rab8 Qa4 Qb6 h3 Bxf3 Bxf3 Rb7 Qa3 Rxb5 Qxb3 Rxb3 cxb3 c5 dxc5 Nxc5 Nb3 Ne4 Be3 Nd6 Nxd5 Qxd5 Bd2 Re8 Ra1 Qe6 Ba5 h5 f4 Ne4 Bxe4 Rxe4 Rxa6 Bc5 Ra5 Be7 Ra7 Qf5 Bf3 Qd5 Bb2 Qg5 Kf2 h4 Ra8 Bd6 Ra7 Bc5+ Bxc5 Qxc5+ Kf3 g5 fxg5 Qxg5 Ra8+ Kg7 Ra7 h3 gxh3 Qh5+ Kg3 Rf8 Rxa5 10.0\n",
      "==========\n",
      "\u001b[1m47,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m47,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "summarize: def _check_required(self, prefix):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "        required = re.sub('[^,+)', prefix)\n",
      "        required = required or []\n",
      "        required = required.group(1)\n",
      "        if required:\n",
      "            # Index and optimization itself will be requires\n",
      "            if len(required) == 1:\n",
      "                required.insert(1, required)\n",
      "            elif len(required) == 1:\n",
      "                required = required.group(1).lower()\n",
      "            elif required:\n",
      "                required.insert(0, required)\n",
      "            else:\n",
      "                required = required or required[1]\n",
      "        if required:\n",
      "            required.add(0)\n",
      "            # Return the string\n",
      "            requ\n",
      "==========\n",
      "\u001b[1m48,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m48,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 d5 exd5 Qxd5 Nc3 Qd8 d4 Nf6 Bf4 Nc6 Nf3 Bg4 Be2 e6 Qd2 Nd5 Bg3 Ne7 a3 a6 O-O Ng6 Bh4 Nf4 Ne5 Bxe2 Nxe2 Nxe2+ Qxe2 Qe7 g3 g6 Rfd1 O-O-O Ne4 Bxe2 Qxe2 Bg7 Ne5 Qd6 c3 b5 g4 g5 c4 b4 cxb5 axb5 a4 bxa3 bxa3 Rxa3 Rxa3 Rxa3 Rxa3 Qc2 Nb4 Qc4 Rd8 h3 Rd7 hxg4 hxg4 f3 c5 dxc5 Bxc5 Nxc5 dxc5 Qxc5 c4 Qxc4+ Qd2 Rd1+ Kh2 Rd5 Qc3+ Kb7 Qc4+ Kc7 Qc5+ Kb7 Qf8+ Ka6 Qg7+ Ka5 f4 Ka4 f5 exf5+ Qxf5+ Ka3 Re1 Qd7+ Kh5 f6 Qd1 f7 Qxg4 fxg7 Qxg7 fxg7 Kb2 Rf1 h5 10.0\n",
      "==========\n",
      "\u001b[1m49,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m49,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "_center(self):\n",
      "        \"\"\"\n",
      "            \n",
      "        \"\"\"\n",
      "        path = self._path\n",
      "        if self._config['success']:\n",
      "            self._config['success'] = os.path.join(self._config['success'], os.path.basename(self._config['success']))\n",
      "        return self._config Get successfully given path\n",
      "==========\n",
      "\u001b[1m50,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m50,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "chess eval: e4 c5 f4 Nc6 e5 d5 d4 Bf5 c3 e6 Nf3 cxd4 cxd4 a6 Nc3 Nf6 a3 Be7 Bd3 O-O Bd2 Rc8 Qd2 a5 h4 b5 a4 Rc4 Be1 Nh5 Be3 Nb4 -9.0\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "ai.train('../input/mixed-finetune-data-bal/mixed_finetune_data_bal_v1/mixed_finetune_data_bal_small.csv',\n",
    "         line_by_line=True,\n",
    "         from_cache=False,\n",
    "         num_steps=50_000,\n",
    "         generate_every=1_000,\n",
    "         save_every=1_000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-3,\n",
    "         batch_size=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672bfe7d",
   "metadata": {
    "papermill": {
     "duration": 0.057489,
     "end_time": "2021-12-02T20:35:56.380092",
     "exception": false,
     "start_time": "2021-12-02T20:35:56.322603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e6d130d",
   "metadata": {
    "id": "pel-uBULXO2L",
    "papermill": {
     "duration": 0.058015,
     "end_time": "2021-12-02T20:35:56.499132",
     "exception": false,
     "start_time": "2021-12-02T20:35:56.441117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Load a Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1715ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-27T21:35:56.672341Z",
     "iopub.status.busy": "2021-11-27T21:35:56.671546Z",
     "iopub.status.idle": "2021-11-27T21:35:59.547952Z",
     "shell.execute_reply": "2021-11-27T21:35:59.546868Z",
     "shell.execute_reply.started": "2021-11-27T21:35:56.672307Z"
    },
    "papermill": {
     "duration": 0.057476,
     "end_time": "2021-12-02T20:35:56.614322",
     "exception": false,
     "start_time": "2021-12-02T20:35:56.556846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ai = aitextgen(model_folder=\"../input/finetuned-gpt/trained_model\",\n",
    "               tokenizer_file=\"../input/model-tuned/aitextgen.tokenizer.json\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79cdeb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T21:12:56.070111Z",
     "iopub.status.busy": "2021-11-30T21:12:56.069556Z",
     "iopub.status.idle": "2021-11-30T21:13:00.582059Z",
     "shell.execute_reply": "2021-11-30T21:13:00.581331Z",
     "shell.execute_reply.started": "2021-11-30T21:12:56.07007Z"
    },
    "papermill": {
     "duration": 0.056973,
     "end_time": "2021-12-02T20:35:56.728284",
     "exception": false,
     "start_time": "2021-12-02T20:35:56.671311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../input/chess-evaluation-dataset/sample_lm_chess_evaluation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037514f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T21:14:53.314684Z",
     "iopub.status.busy": "2021-11-30T21:14:53.314078Z",
     "iopub.status.idle": "2021-11-30T21:14:53.321102Z",
     "shell.execute_reply": "2021-11-30T21:14:53.320217Z",
     "shell.execute_reply.started": "2021-11-30T21:14:53.314642Z"
    },
    "papermill": {
     "duration": 0.060379,
     "end_time": "2021-12-02T20:35:56.845921",
     "exception": false,
     "start_time": "2021-12-02T20:35:56.785542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "string = 'chess eval: e4 c5 c3 Nc6 d4 cxd4 cxd4 d6 Nc3 e6 Nf3 a6 Bd3 Nf6 O-O \\\n",
    "Be7 Qe2 b5 e5 dxe5 dxe5 Nd7 Bf4 Bb7 Ne4 Qb6 Rac1 Rc8 Be3 Qa5 Nc5 Nxc5 Bxc5 Bxc5 \\\n",
    "Rxc5 Qxa2 Rfc1 O-O Qe4 g6 Qh4 Qxb2 Ng5 h5 Ne4 Nxe5 Nf6+'\n",
    "\n",
    "df['input'][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d959c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T06:24:45.354781Z",
     "iopub.status.busy": "2021-11-29T06:24:45.354219Z",
     "iopub.status.idle": "2021-11-29T06:24:45.367218Z",
     "shell.execute_reply": "2021-11-29T06:24:45.366205Z",
     "shell.execute_reply.started": "2021-11-29T06:24:45.35474Z"
    },
    "papermill": {
     "duration": 0.060629,
     "end_time": "2021-12-02T20:35:56.966156",
     "exception": false,
     "start_time": "2021-12-02T20:35:56.905527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "i = 100\n",
    "string = df.iloc[i]['input'][:df.iloc[i]['input'].index('def')]\n",
    "code = df.iloc[i]['input'][df.iloc[i]['input'].index('def'):]\n",
    "\n",
    "print(f'String: {string}')\n",
    "print()\n",
    "print(f'Code: {code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfd283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T21:15:08.242277Z",
     "iopub.status.busy": "2021-11-30T21:15:08.242009Z",
     "iopub.status.idle": "2021-11-30T21:15:08.929694Z",
     "shell.execute_reply": "2021-11-30T21:15:08.928963Z",
     "shell.execute_reply.started": "2021-11-30T21:15:08.242247Z"
    },
    "id": "4RNY6RBI9LmL",
    "outputId": "8579ed7e-14c8-4a76-ecad-ce7acd13b612",
    "papermill": {
     "duration": 0.064586,
     "end_time": "2021-12-02T20:35:57.091371",
     "exception": false,
     "start_time": "2021-12-02T20:35:57.026785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ai.generate(max_length = 512, \n",
    "            prompt = string, \n",
    "            top_k = 100, \n",
    "            top_p  = 0.9, \n",
    "            temperature = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050632be",
   "metadata": {
    "papermill": {
     "duration": 0.05796,
     "end_time": "2021-12-02T20:35:57.212506",
     "exception": false,
     "start_time": "2021-12-02T20:35:57.154546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00386e",
   "metadata": {
    "papermill": {
     "duration": 0.057542,
     "end_time": "2021-12-02T20:35:57.328040",
     "exception": false,
     "start_time": "2021-12-02T20:35:57.270498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17890.172692,
   "end_time": "2021-12-02T20:36:00.868813",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-02T15:37:50.696121",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00321b34b3c44119bbfce6b481c4d156": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "099e6d1521dd4746aa977390cc7fc1a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "48d7fa6432e44e9d8cb82520d6b46129": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5091886ad8f84347804e04742df24f31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_beeb7b04fff2490a92ec0aa9248c63d8",
       "max": 50000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_da46c4dc3f0d4a50a330ed5ad68fee83",
       "value": 50000.0
      }
     },
     "50aca89aeea446ed9dd365523ba04deb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cbf6cc5f114c42c1b301297bbd14954d",
        "IPY_MODEL_82f2b5c891974bd99260d08394d524ed",
        "IPY_MODEL_d954fa1cce724db28f620b0c9182acde"
       ],
       "layout": "IPY_MODEL_099e6d1521dd4746aa977390cc7fc1a1"
      }
     },
     "53dd250132cb480484ff24d9e5f661fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5bbe376c10794f5fbc48e1d6cb56eeb7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "66018524fa324c39857ff8f34daa810d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c18725673a584f2f9770975f5a809e52",
        "IPY_MODEL_5091886ad8f84347804e04742df24f31",
        "IPY_MODEL_c3d6a5a094354863a5ffd4f99e1d0e65"
       ],
       "layout": "IPY_MODEL_00321b34b3c44119bbfce6b481c4d156"
      }
     },
     "765c247041984ad6b7dc00120c3696c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82f2b5c891974bd99260d08394d524ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ec5b0a5f7b054f84afcf78505570578f",
       "max": 250000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_53dd250132cb480484ff24d9e5f661fd",
       "value": 250000.0
      }
     },
     "8d13c4f0e2ce423d9b4529de01d1f089": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aa0838c80fdf4c2585935085bc4a4e52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "beeb7b04fff2490a92ec0aa9248c63d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c18725673a584f2f9770975f5a809e52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_48d7fa6432e44e9d8cb82520d6b46129",
       "placeholder": "​",
       "style": "IPY_MODEL_aa0838c80fdf4c2585935085bc4a4e52",
       "value": "Loss: 1.580 — Avg: 1.596 — GPU Mem: 13597 MB: 100%"
      }
     },
     "c3d6a5a094354863a5ffd4f99e1d0e65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_765c247041984ad6b7dc00120c3696c2",
       "placeholder": "​",
       "style": "IPY_MODEL_f4c9f4d0b3f24cb2a87a9b0d0f726a0b",
       "value": " 50000/50000 [4:55:07&lt;00:00,  2.82it/s]"
      }
     },
     "cbf6cc5f114c42c1b301297bbd14954d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5bbe376c10794f5fbc48e1d6cb56eeb7",
       "placeholder": "​",
       "style": "IPY_MODEL_8d13c4f0e2ce423d9b4529de01d1f089",
       "value": "100%"
      }
     },
     "cc56a288aa104774bfa3279f5eaa8596": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d954fa1cce724db28f620b0c9182acde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fb687cea15f64146bcab583c4a1fab4d",
       "placeholder": "​",
       "style": "IPY_MODEL_cc56a288aa104774bfa3279f5eaa8596",
       "value": " 250000/250000 [02:14&lt;00:00, 1863.44it/s]"
      }
     },
     "da46c4dc3f0d4a50a330ed5ad68fee83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ec5b0a5f7b054f84afcf78505570578f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4c9f4d0b3f24cb2a87a9b0d0f726a0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fb687cea15f64146bcab583c4a1fab4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
